Paper ID,Title,URL,Summary,First Author,Publish Date,Update Date,Code URL,Stars,Categories
2502.05179v1,FlashVideo:Flowing Fidelity to Detail for Efficient High-Resolution Video Generation,http://arxiv.org/abs/2502.05179v1,"DiT diffusion models have achieved great success in text-to-video generation,leveraging their scalability in model capacity and data scale. High content andmotion fidelity aligned with text prompts, however, often require large modelparameters and a substantial number of function evaluations (NFEs). Realisticand visually appealing details are typically reflected in high resolutionoutputs, further amplifying computational demands especially for single stageDiT models. To address these challenges, we propose a novel two stageframework, FlashVideo, which strategically allocates model capacity and NFEsacross stages to balance generation fidelity and quality. In the first stage,prompt fidelity is prioritized through a low resolution generation processutilizing large parameters and sufficient NFEs to enhance computationalefficiency. The second stage establishes flow matching between low and highresolutions, effectively generating fine details with minimal NFEs.Quantitative and visual results demonstrate that FlashVideo achievesstate-of-the-art high resolution video generation with superior computationalefficiency. Additionally, the two-stage design enables users to preview theinitial output before committing to full resolution generation, therebysignificantly reducing computational costs and wait times as well as enhancingcommercial viability .",Shilong Zhang,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05178v1,QLIP: Text-Aligned Visual Tokenization Unifies Auto-Regressive Multimodal Understanding and Generation,http://arxiv.org/abs/2502.05178v1,"We introduce Quantized Language-Image Pretraining (QLIP), a visualtokenization method that combines state-of-the-art reconstruction quality withstate-of-the-art zero-shot image understanding. QLIP trains abinary-spherical-quantization-based autoencoder with reconstruction andlanguage-image alignment objectives. We are the first to show that the twoobjectives do not need to be at odds. We balance the two loss terms dynamicallyduring training and show that a two-stage training pipeline effectively mixesthe large-batch requirements of image-language pre-training with the memorybottleneck imposed by the reconstruction objective. We validate theeffectiveness of QLIP for multimodal understanding and text-conditioned imagegeneration with a single model. Specifically, QLIP serves as a drop-inreplacement for the visual encoder for LLaVA and the image tokenizer forLlamaGen with comparable or even better performance. Finally, we demonstratethat QLIP enables a unified mixed-modality auto-regressive model forunderstanding and generation.",Yue Zhao,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05177v1,Long-VITA: Scaling Large Multi-modal Models to 1 Million Tokens with Leading Short-Context Accuray,http://arxiv.org/abs/2502.05177v1,"Establishing the long-context capability of large vision-language models iscrucial for video understanding, high-resolution image understanding,multi-modal agents and reasoning. We introduce Long-VITA, a simple yeteffective large multi-modal model for long-context visual-languageunderstanding tasks. It is adept at concurrently processing and analyzingmodalities of image, video, and text over 4K frames or 1M tokens whiledelivering advanced performances on short-context multi-modal tasks. We proposean effective multi-modal training schema that starts with large language modelsand proceeds through vision-language alignment, general knowledge learning, andtwo sequential stages of long-sequence fine-tuning. We further implementcontext-parallelism distributed inference and logits-masked language modelinghead to scale Long-VITA to infinitely long inputs of images and texts duringmodel inference. Regarding training data, Long-VITA is built on a mix of $17$Msamples from public datasets only and demonstrates the state-of-the-artperformance on various multi-modal benchmarks, compared against recentcutting-edge models with internal data. Long-VITA is fully reproducible andsupports both NPU and GPU platforms for training and testing. We hope Long-VITAcan serve as a competitive baseline and offer valuable insights for theopen-source community in advancing long-context multi-modal understanding.",Yunhang Shen,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05175v1,Fillerbuster: Multi-View Scene Completion for Casual Captures,http://arxiv.org/abs/2502.05175v1,"We present Fillerbuster, a method that completes unknown regions of a 3Dscene by utilizing a novel large-scale multi-view latent diffusion transformer.Casual captures are often sparse and miss surrounding content behind objects orabove the scene. Existing methods are not suitable for handling this challengeas they focus on making the known pixels look good with sparse-view priors, oron creating the missing sides of objects from just one or two photos. Inreality, we often have hundreds of input frames and want to complete areas thatare missing and unobserved from the input frames. Additionally, the imagesoften do not have known camera parameters. Our solution is to train agenerative model that can consume a large context of input frames whilegenerating unknown target views and recovering image poses when desired. Weshow results where we complete partial captures on two existing datasets. Wealso present an uncalibrated scene completion task where our unified modelpredicts both poses and creates new content. Our model is the first to predictmany images and poses together for scene completion.",Ethan Weber,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.GR']"
2502.05174v1,MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison,http://arxiv.org/abs/2502.05174v1,"Recent research has explored that LLM agents are vulnerable to indirectprompt injection (IPI) attacks, where malicious tasks embedded intool-retrieved information can redirect the agent to take unauthorized actions.Existing defenses against IPI have significant limitations: either requireessential model training resources, lack effectiveness against sophisticatedattacks, or harm the normal utilities. We present MELON (Masked re-Executionand TooL comparisON), a novel IPI defense. Our approach builds on theobservation that under a successful attack, the agent's next action becomesless dependent on user tasks and more on malicious tasks. Following this, wedesign MELON to detect attacks by re-executing the agent's trajectory with amasked user prompt modified through a masking function. We identify an attackif the actions generated in the original and masked executions are similar. Wealso include three key designs to reduce the potential false positives andfalse negatives. Extensive evaluation on the IPI benchmark AgentDojodemonstrates that MELON outperforms SOTA defenses in both attack prevention andutility preservation. Moreover, we show that combining MELON with a SOTA promptaugmentation defense (denoted as MELON-Aug) further improves its performance.We also conduct a detailed ablation study to validate our key designs.",Kaijie Zhu,2025-02-07,2025-02-07,,N/A,"['cs.CR', 'cs.AI']"
2502.05172v1,Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient,http://arxiv.org/abs/2502.05172v1,"Mixture of Experts (MoE) architectures have significantly increasedcomputational efficiency in both research and real-world applications oflarge-scale machine learning models. However, their scalability and efficiencyunder memory constraints remain relatively underexplored. In this work, wepresent joint scaling laws for dense and MoE models, incorporating key factorssuch as the number of active parameters, dataset size, and the number ofexperts. Our findings provide a principled framework for selecting the optimalMoE configuration under fixed memory and compute budgets. Surprisingly, we showthat MoE models can be more memory-efficient than dense models, contradictingconventional wisdom. To derive and validate the theoretical predictions of ourscaling laws, we conduct over 280 experiments with up to 2.7B active parametersand up to 5B total parameters. These results offer actionable insights fordesigning and deploying MoE models in practical large-scale training scenarios.",Jan Ludziejewski,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.05171v1,Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach,http://arxiv.org/abs/2502.05171v1,"We study a novel language model architecture that is capable of scalingtest-time computation by implicitly reasoning in latent space. Our model worksby iterating a recurrent block, thereby unrolling to arbitrary depth attest-time. This stands in contrast to mainstream reasoning models that scale upcompute by producing more tokens. Unlike approaches based on chain-of-thought,our approach does not require any specialized training data, can work withsmall context windows, and can capture types of reasoning that are not easilyrepresented in words. We scale a proof-of-concept model to 3.5 billionparameters and 800 billion tokens. We show that the resulting model can improveits performance on reasoning benchmarks, sometimes dramatically, up to acomputation load equivalent to 50 billion parameters.",Jonas Geiping,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.CL']"
2502.05170v1,Observation of a dynamic magneto-chiral instability in photoexcited tellurium,http://arxiv.org/abs/2502.05170v1,"In a system of charged chiral fermions driven out of equilibrium, an electriccurrent parallel to the magnetic field can generate a dynamic instability bywhich electromagnetic waves become amplified. Whether a similar instability canoccur in chiral solid-state systems remains an open question. Using time-domainterahertz (THz) emission spectroscopy, we detect signatures of what we dub a``dynamic magneto-chiral instability"" in elemental tellurium, a structurallychiral crystal. Upon transient photoexcitation in a moderate external magneticfield, tellurium emits THz radiation consisting of coherent modes that amplifyover time. An explanation for this amplification is proposed using atheoretical model based on a dynamic instability of electromagnetic wavesinteracting with infrared-active oscillators of impurity acceptor states intellurium to form an amplifying polariton. Our work not only uncovers thepresence of a magneto-chiral instability but also highlights its promise forTHz-wave amplification in chiral materials.",Yijing Huang,2025-02-07,2025-02-07,,N/A,"['cond-mat.mes-hall', 'cond-mat.dis-nn', 'cond-mat.stat-mech']"
2502.05167v1,NoLiMa: Long-Context Evaluation Beyond Literal Matching,http://arxiv.org/abs/2502.05167v1,"Recent large language models (LLMs) support long contexts ranging from 128Kto 1M tokens. A popular method for evaluating these capabilities is theneedle-in-a-haystack (NIAH) test, which involves retrieving a ""needle""(relevant information) from a ""haystack"" (long irrelevant context). Extensionsof this approach include increasing distractors, fact chaining, and in-contextreasoning. However, in these benchmarks, models can exploit existing literalmatches between the needle and haystack to simplify the task. To address this,we introduce NoLiMa, a benchmark extending NIAH with a carefully designedneedle set, where questions and needles have minimal lexical overlap, requiringmodels to infer latent associations to locate the needle within the haystack.We evaluate 12 popular LLMs that claim to support contexts of at least 128Ktokens. While they perform well in short contexts (<1K), performance degradessignificantly as context length increases. At 32K, for instance, 10 models dropbelow 50% of their strong short-length baselines. Even GPT-4o, one of thetop-performing exceptions, experiences a reduction from an almost-perfectbaseline of 99.3% to 69.7%. Our analysis suggests these declines stem from theincreased difficulty the attention mechanism faces in longer contexts whenliteral matches are absent, making it harder to retrieve relevant information.",Ali Modarressi,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.05165v1,Multitwine: Multi-Object Compositing with Text and Layout Control,http://arxiv.org/abs/2502.05165v1,"We introduce the first generative model capable of simultaneous multi-objectcompositing, guided by both text and layout. Our model allows for the additionof multiple objects within a scene, capturing a range of interactions fromsimple positional relations (e.g., next to, in front of) to complex actionsrequiring reposing (e.g., hugging, playing guitar). When an interaction impliesadditional props, like `taking a selfie', our model autonomously generatesthese supporting objects. By jointly training for compositing andsubject-driven generation, also known as customization, we achieve a morebalanced integration of textual and visual inputs for text-driven objectcompositing. As a result, we obtain a versatile model with state-of-the-artperformance in both tasks. We further present a data generation pipelineleveraging visual and language models to effortlessly synthesize multimodal,aligned training data.",Gemma Canet Tarrés,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05164v1,In-context denoising with one-layer transformers: connections between attention and associative memory retrieval,http://arxiv.org/abs/2502.05164v1,"We introduce in-context denoising, a task that refines the connection betweenattention-based architectures and dense associative memory (DAM) networks, alsoknown as modern Hopfield networks. Using a Bayesian framework, we showtheoretically and empirically that certain restricted denoising problems can besolved optimally even by a single-layer transformer. We demonstrate that atrained attention layer processes each denoising prompt by performing a singlegradient descent update on a context-aware DAM energy landscape, where contexttokens serve as associative memories and the query token acts as an initialstate. This one-step update yields better solutions than exact retrieval ofeither a context token or a spurious local minimum, providing a concreteexample of DAM networks extending beyond the standard retrieval paradigm.Overall, this work solidifies the link between associative memory and attentionmechanisms first identified by Ramsauer et al., and demonstrates the relevanceof associative memory models in the study of in-context learning.",Matthew Smart,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cond-mat.dis-nn']"
2502.05163v1,DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails,http://arxiv.org/abs/2502.05163v1,"The rapid advancement of large language models (LLMs) has increased the needfor guardrail models to ensure responsible use, particularly in detectingunsafe and illegal content. While substantial safety data exist in English,multilingual guardrail modeling remains underexplored due to the scarcity ofopen-source safety data in other languages. To address this gap, we propose anovel two-player Reinforcement Learning (RL) framework, where a generator and aguardrail model co-evolve adversarially to produce high-quality synthetic datafor multilingual guardrail training. We theoretically formalize thisinteraction as a two-player game, proving convergence to a Nash equilibrium.Empirical evaluations show that our model \ours outperforms state-of-the-artmodels, achieving nearly 10% improvement over LlamaGuard3 (8B) on Englishbenchmarks while being 4.5x faster at inference with a significantly smallermodel (0.5B). We achieve substantial advancements in multilingual safety tasks,particularly in addressing the imbalance for lower-resource languages in acollected real dataset. Ablation studies emphasize the critical role ofsynthetic data generation in bridging the imbalance in open-source data betweenEnglish and other languages. These findings establish a scalable and efficientapproach to synthetic data generation, paving the way for improved multilingualguardrail models to enhance LLM safety. Code, model, and data will beopen-sourced at https://github.com/yihedeng9/DuoGuard.",Yihe Deng,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.LG']"
2502.05159v1,A Lightweight Method to Disrupt Memorized Sequences in LLM,http://arxiv.org/abs/2502.05159v1,"Large language models (LLMs) demonstrate impressive capabilities across manytasks yet risk reproducing copyrighted content verbatim, raising legal andethical concerns. Although methods like differential privacy or neuron editingcan reduce memorization, they typically require costly retraining or directaccess to model weights and may degrade performance. To address thesechallenges, we propose TokenSwap, a lightweight, post-hoc approach thatreplaces the probabilities of grammar-related tokens with those from a smallauxiliary model (e.g., DistilGPT-2). We run extensive experiments on commercialgrade models such as Pythia-6.9b and LLaMA-3-8b and demonstrate that our methodeffectively reduces well-known cases of memorized generation by upto 10x withlittle to no impact on downstream tasks. Our approach offers a uniquelyaccessible and effective solution to users of real-world systems.",Parjanya Prajakta Prashant,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.CL']"
2502.05157v1,Efficient distributional regression trees learning algorithms for calibrated non-parametric probabilistic forecasts,http://arxiv.org/abs/2502.05157v1,"The perspective of developing trustworthy AI for critical applications inscience and engineering requires machine learning techniques that are capableof estimating their own uncertainty. In the context of regression, instead ofestimating a conditional mean, this can be achieved by producing a predictiveinterval for the output, or to even learn a model of the conditionalprobability $p(y|x)$ of an output $y$ given input features $x$. While this canbe done under parametric assumptions with, e.g. generalized linear model, theseare typically too strong, and non-parametric models offer flexiblealternatives. In particular, for scalar outputs, learning directly a model ofthe conditional cumulative distribution function of $y$ given $x$ can lead tomore precise probabilistic estimates, and the use of proper scoring rules suchas the weighted interval score (WIS) and the continuous ranked probabilityscore (CRPS) lead to better coverage and calibration properties.  This paper introduces novel algorithms for learning probabilistic regressiontrees for the WIS or CRPS loss functions. These algorithms are madecomputationally efficient thanks to an appropriate use of known data structures- namely min-max heaps, weight-balanced binary trees and Fenwick trees. Throughnumerical experiments, we demonstrate that the performance of our methods iscompetitive with alternative approaches. Additionally, our methods benefit fromthe inherent interpretability and explainability of trees. As a by-product, weshow how our trees can be used in the context of conformal prediction andexplain why they are particularly well-suited for achieving group-conditionalcoverage guarantees.",Duchemin Quentin,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.DS']"
2502.05156v1,Tractable description of hydrodynamic limits of a class of interacting jump processes on sparse graphs,http://arxiv.org/abs/2502.05156v1,"We consider dynamics of the empirical measure of vertex neighborhood statesof Markov interacting jump processes on sparse random graphs, in a suitableasymptotic limit as the graph size goes to infinity. Under the assumption of acertain acyclic structure on single-particle transitions, we provide atractable autonomous description of the evolution of this hydrodynamic limit interms of a finite coupled system of ordinary differential equations. Keyingredients of the proof include a characterization of the hydrodynamic limitof the neighborhood empirical measure in terms of a certain local-fieldequation, well-posedness of its Markovian projection, and a Markov random fieldproperty of the time-marginals, which may be of independent interest. We alsoshow how our results lead to principled approximations for classes ofinteracting jump processes and illustrate its efficacy via simulations onseveral examples, including an idealized model of seizure spread in the brain.",Juniper Cocomello,2025-02-07,2025-02-07,,N/A,"['math.PR', 'Primary: 60K35 Secondary: 60J74, 60J27']"
2502.05155v1,Deep Dynamic Probabilistic Canonical Correlation Analysis,http://arxiv.org/abs/2502.05155v1,"This paper presents Deep Dynamic Probabilistic Canonical Correlation Analysis(D2PCCA), a model that integrates deep learning with probabilistic modeling toanalyze nonlinear dynamical systems. Building on the probabilistic extensionsof Canonical Correlation Analysis (CCA), D2PCCA captures nonlinear latentdynamics and supports enhancements such as KL annealing for improvedconvergence and normalizing flows for a more flexible posterior approximation.D2PCCA naturally extends to multiple observed variables, making it a versatiletool for encoding prior knowledge about sequential datasets and providing aprobabilistic understanding of the system's dynamics. Experimental validationon real financial datasets demonstrates the effectiveness of D2PCCA and itsextensions in capturing latent dynamics.",Shiqin Tang,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'stat.ML']"
2502.05153v1,Hummingbird: High Fidelity Image Generation via Multimodal Context Alignment,http://arxiv.org/abs/2502.05153v1,"While diffusion models are powerful in generating high-quality, diversesynthetic data for object-centric tasks, existing methods struggle withscene-aware tasks such as Visual Question Answering (VQA) and Human-ObjectInteraction (HOI) Reasoning, where it is critical to preserve scene attributesin generated images consistent with a multimodal context, i.e. a referenceimage with accompanying text guidance query. To address this, we introduceHummingbird, the first diffusion-based image generator which, given amultimodal context, generates highly diverse images w.r.t. the reference imagewhile ensuring high fidelity by accurately preserving scene attributes, such asobject interactions and spatial relationships from the text guidance.Hummingbird employs a novel Multimodal Context Evaluator that simultaneouslyoptimizes our formulated Global Semantic and Fine-grained Consistency Rewardsto ensure generated images preserve the scene attributes of reference images inrelation to the text guidance while maintaining diversity. As the first modelto address the task of maintaining both diversity and fidelity given amultimodal context, we introduce a new benchmark formulation incorporating MMEPerception and Bongard HOI datasets. Benchmark experiments show Hummingbirdoutperforms all existing methods by achieving superior fidelity whilemaintaining diversity, validating Hummingbird's potential as a robustmultimodal context-aligned image generator in complex visual tasks.",Minh-Quan Le,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05152v1,Extreme-Scale EV Charging Infrastructure Planning for Last-Mile Delivery Using High-Performance Parallel Computing,http://arxiv.org/abs/2502.05152v1,"This paper addresses stochastic charger location and allocation (SCLA)problems under queue congestion for last-mile delivery using electric vehicles(EVs). The objective is to decide where to open charging stations and how manychargers of each type to install, subject to budgetary and waiting-timeconstraints. We formulate the problem as a mixed-integer non-linear program,where each station-charger pair is modeled as a multiserver queue withstochastic arrivals and service times to capture the notion of waiting in fleetoperations. The model is extremely large, with billions of variables andconstraints for a typical metropolitan area; and even loading the model insolver memory is difficult, let alone solving it. To address this challenge, wedevelop a Lagrangian-based dual decomposition framework that decomposes theproblem by station and leverages parallelization on high-performance computingsystems, where the subproblems are solved by using a cutting plane method andtheir solutions are collected at the master level. We also develop a three-steprounding heuristic to transform the fractional subproblem solutions intofeasible integral solutions. Computational experiments on data from the Chicagometropolitan area with hundreds of thousands of households and thousands ofcandidate stations show that our approach produces high-quality solutions incases where existing exact methods cannot even load the model in memory. Wealso analyze various policy scenarios, demonstrating that combining existingdepots with newly built stations under multiagency collaboration substantiallyreduces costs and congestion. These findings offer a scalable and efficientframework for developing sustainable large-scale EV charging networks.",Waquar Kaleem,2025-02-07,2025-02-07,,N/A,['math.OC']
2502.05151v1,"Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation",http://arxiv.org/abs/2502.05151v1,"With the advent of large multimodal language models, science is now at athreshold of an AI-based technological transformation. Recently, a plethora ofnew AI models and tools has been proposed, promising to empower researchers andacademics worldwide to conduct their research more effectively and efficiently.This includes all aspects of the research cycle, especially (1) searching forrelevant literature; (2) generating research ideas and conductingexperimentation; generating (3) text-based and (4) multimodal content (e.g.,scientific figures and diagrams); and (5) AI-based automatic peer review. Inthis survey, we provide an in-depth overview over these exciting recentdevelopments, which promise to fundamentally alter the scientific researchprocess for good. Our survey covers the five aspects outlined above, indicatingrelevant datasets, methods and results (including evaluation) as well aslimitations and scope for future research. Ethical concerns regardingshortcomings of these tools and potential for misuse (fake science, plagiarism,harms to research integrity) take a particularly prominent place in ourdiscussion. We hope that our survey will not only become a reference guide fornewcomers to the field but also a catalyst for new AI-based initiatives in thearea of ""AI4Science"".",Steffen Eger,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI', 'cs.CV', 'cs.LG']"
2502.05150v1,CodeSCM: Causal Analysis for Multi-Modal Code Generation,http://arxiv.org/abs/2502.05150v1,"In this paper, we propose CodeSCM, a Structural Causal Model (SCM) foranalyzing multi-modal code generation using large language models (LLMs). Byapplying interventions to CodeSCM, we measure the causal effects of differentprompt modalities, such as natural language, code, and input-output examples,on the model. CodeSCM introduces latent mediator variables to separate the codeand natural language semantics of a multi-modal code generation prompt. Usingthe principles of Causal Mediation Analysis on these mediators we quantifydirect effects representing the model's spurious leanings. We find that, inaddition to natural language instructions, input-output examples significantlyinfluence code generation.",Mukur Gupta,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.05148v1,An Annotated Reading of 'The Singer of Tales' in the LLM Era,http://arxiv.org/abs/2502.05148v1,"The Parry-Lord oral-formulaic theory was a breakthrough in understanding howoral narrative poetry is learned, composed, and transmitted by illiteratebards. In this paper, we provide an annotated reading of the mechanismunderlying this theory from the lens of large language models (LLMs) andgenerative artificial intelligence (AI). We point out the the similarities anddifferences between oral composition and LLM generation, and comment on theimplications to society and AI policy.",Kush R. Varshney,2025-02-07,2025-02-07,,N/A,"['cs.CY', 'cs.CL']"
2502.05147v1,LP-DETR: Layer-wise Progressive Relations for Object Detection,http://arxiv.org/abs/2502.05147v1,"This paper presents LP-DETR (Layer-wise Progressive DETR), a novel approachthat enhances DETR-based object detection through multi-scale relationmodeling. Our method introduces learnable spatial relationships between objectqueries through a relation-aware self-attention mechanism, which adaptivelylearns to balance different scales of relations (local, medium and global)across decoder layers. This progressive design enables the model to effectivelycapture evolving spatial dependencies throughout the detection pipeline.Extensive experiments on COCO 2017 dataset demonstrate that our method improvesboth convergence speed and detection accuracy compared to standardself-attention module. The proposed method achieves competitive results,reaching 52.3\% AP with 12 epochs and 52.5\% AP with 24 epochs using ResNet-50backbone, and further improving to 58.0\% AP with Swin-L backbone. Furthermore,our analysis reveals an interesting pattern: the model naturally learns toprioritize local spatial relations in early decoder layers while graduallyshifting attention to broader contexts in deeper layers, providing valuableinsights for future research in object detection.",Zhengjian Kang,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.AI']"
2502.05146v1,Torsion pairs and 3-fold flops,http://arxiv.org/abs/2502.05146v1,"This paper classifies t-structures on the local derived category of a 3-foldflopping contraction, that are intermediate with respect to the heart ofperverse coherent sheaves. Equivalently, this describes the complete lattice oftorsion classes for the associated modification algebra. The intermediatehearts are (1) categories of coherent sheaves on birational models and tiltsthereof in skyscrapers, (2) algebraic t-structures described in the homologicalminimal model programme, or (3) combinations of the above over appropriate opencovers. An analogous classification is also proved for minimal (and partial)resolutions of Kleinian singularities, thus providing a description of alltorsion pairs in the module categories of (contracted) affine preprojectivealgebras. The results have immediate applications to the classification ofspherical modules and (semi)bricks, and are first steps towards describing allt-structures and spherical objects in derived categories of surfaces and3-folds.",Parth Shimpi,2025-02-07,2025-02-07,,N/A,"['math.AG', 'math.RT', '14F08, 14B05, 16E20, 16E35, 18E40']"
2502.05143v1,pyMethods2Test: A Dataset of Python Tests Mapped to Focal Methods,http://arxiv.org/abs/2502.05143v1,"Python is one of the fastest-growing programming languages and currentlyranks as the top language in many lists, even recently overtaking JavaScript asthe top language on GitHub. Given its importance in data science and machinelearning, it is imperative to be able to effectively train LLMs to generategood unit test cases for Python code. This motivates the need for a largedataset to provide training and testing data. To date, while other largedatasets exist for languages like Java, none publicly exist for Python. Pythonposes difficult challenges in generating such a dataset, due to its less rigidnaming requirements. In this work, we consider two commonly used Python unittesting frameworks: Pytest and unittest. We analyze a large corpus of over 88Kopen-source GitHub projects utilizing these testing frameworks. Using acarefully designed set of heuristics, we are able to locate over 22 milliontest methods. We then analyze the test and non-test code and map individualunit tests to the focal method being tested. This provides an explicittraceability link from the test to the tested method. Our pyMethods2Testdataset contains over 2 million of these focal method mappings, as well as theability to generate useful context for input to LLMs. The pyMethods2Testdataset is publicly available on Zenodo at:https://doi.org/10.5281/zenodo.14264518",Idriss Abdelmadjid,2025-02-07,2025-02-07,,N/A,['cs.SE']
2502.05142v1,Chest X-ray Foundation Model with Global and Local Representations Integration,http://arxiv.org/abs/2502.05142v1,"Chest X-ray (CXR) is the most frequently ordered imaging test, supportingdiverse clinical tasks from thoracic disease detection to postoperativemonitoring. However, task-specific classification models are limited in scope,require costly labeled data, and lack generalizability to out-of-distributiondatasets. To address these challenges, we introduce CheXFound, aself-supervised vision foundation model that learns robust CXR representationsand generalizes effectively across a wide range of downstream tasks. Wepretrain CheXFound on a curated CXR-1M dataset, comprising over one millionunique CXRs from publicly available sources. We propose a Global and LocalRepresentations Integration (GLoRI) module for downstream adaptations, byincorporating disease-specific local features with global image features forenhanced performance in multilabel classification. Our experimental resultsshow that CheXFound outperforms state-of-the-art models in classifying 40disease findings across different prevalence levels on the CXR-LT 24 datasetand exhibits superior label efficiency on downstream tasks with limitedtraining data. Additionally, CheXFound achieved significant improvements on newtasks with out-of-distribution datasets, including opportunistic cardiovasculardisease risk estimation and mortality prediction. These results highlightCheXFound's strong generalization capabilities, enabling diverse adaptationswith improved label efficiency. The project source code is publicly availableat https://github.com/RPIDIAL/CheXFound.",Zefan Yang,2025-02-07,2025-02-07,,N/A,"['eess.IV', 'cs.CV']"
2502.05141v1,Maximin Share Guarantees for Few Agents with Subadditive Valuations,http://arxiv.org/abs/2502.05141v1,"We study the problem of fairly allocating a set of indivisible items among aset of agents. We consider the notion of (approximate) maximin share (MMS) andwe provide an improved lower bound of $1/2$ (which is tight) for the case ofsubadditive valuations when the number of agents is at most four. We alsoprovide a tight lower bound for the case of multiple agents, when they areequipped with one of two possible types of valuations. Moreover, we propose anew model that extends previously studied models in the area of fair division,which will hopefully give rise to further research. We demonstrate theusefulness of this model by employing it as a technical tool to derive our mainresult, and we provide a thorough analysis for this model for the case of threeagents. Finally, we provide an improved impossibility result for the case ofthree submodular agents.",George Christodoulou,2025-02-07,2025-02-07,,N/A,['cs.GT']
2502.05139v1,"Meta Audiobox Aesthetics: Unified Automatic Quality Assessment for Speech, Music, and Sound",http://arxiv.org/abs/2502.05139v1,"The quantification of audio aesthetics remains a complex challenge in audioprocessing, primarily due to its subjective nature, which is influenced byhuman perception and cultural context. Traditional methods often depend onhuman listeners for evaluation, leading to inconsistencies and high resourcedemands. This paper addresses the growing need for automated systems capable ofpredicting audio aesthetics without human intervention. Such systems arecrucial for applications like data filtering, pseudo-labeling large datasets,and evaluating generative audio models, especially as these models become moresophisticated. In this work, we introduce a novel approach to audio aestheticevaluation by proposing new annotation guidelines that decompose humanlistening perspectives into four distinct axes. We develop and trainno-reference, per-item prediction models that offer a more nuanced assessmentof audio quality. Our models are evaluated against human mean opinion scores(MOS) and existing methods, demonstrating comparable or superior performance.This research not only advances the field of audio aesthetics but also providesopen-source models and datasets to facilitate future work and benchmarking. Werelease our code and pre-trained model at:https://github.com/facebookresearch/audiobox-aesthetics",Andros Tjandra,2025-02-07,2025-02-07,,N/A,"['cs.SD', 'cs.LG', 'eess.AS']"
2502.05138v1,Collision energy dependence in heavy ion collisions from nonlinear QCD evolution,http://arxiv.org/abs/2502.05138v1,"We explore the effects of including the energy dependence determined fromevolution equations within the color glass condensate framework on observablesin ultra-relativistic heavy-ion collisions. This amounts to integrating theJIMWLK evolution equations into the IP-Glasma model, which is then coupled toviscous relativistic hydrodynamics. This methodology allows for a systematicrepresentation of nuclei at specific Bjorken-$x$ values, which are probed atdifferent center-of-mass energies of the collision and rapidities of finalstate particles. Comparing to the conventional IP-Glasma model, we findsignificant effects on multiplicity distributions and particle spectra,especially in smaller collision systems at the highest center of mass energies.Our results highlight the importance of incorporating nonlinear QCD evolutionin the description of heavy ion collisions at varying center of mass energies,as the precise extraction of transport coefficients will be affected. This workestablishes a robust framework for understanding the quark gluon plasma andnuclear structure at high energy, integrating small-$x$ physics into theinitial conditions of heavy-ion collisions.",Heikki Mäntysaari,2025-02-07,2025-02-07,,N/A,"['nucl-th', 'hep-ex', 'hep-ph', 'nucl-ex']"
2502.05134v1,Information-Theoretic Guarantees for Recovering Low-Rank Tensors from Symmetric Rank-One Measurements,http://arxiv.org/abs/2502.05134v1,"In this paper, we investigate the sample complexity of recovering tensorswith low symmetric rank from symmetric rank-one measurements. This setting isparticularly motivated by the study of higher-order interactions and theanalysis of two-layer neural networks with polynomial activations (polynomialnetworks). Using a covering numbers argument, we analyze the performance of thesymmetric rank minimization program and establish near-optimal samplecomplexity bounds when the underlying distribution is log-concave. Ourmeasurement model involves random symmetric rank-one tensors, which lead toinvolved probability calculations. To address these challenges, we employ theCarbery-Wright inequality, a powerful tool for studying anti-concentrationproperties of random polynomials, and leverage orthogonal polynomials.Additionally, we provide a sample complexity lower bound based on Fano'sinequality, and discuss broader implications of our results for two-layerpolynomial networks.",Eren C. Kızıldağ,2025-02-07,2025-02-07,,N/A,"['math.ST', 'cs.IT', 'math.IT', 'math.PR', 'stat.ML', 'stat.TH']"
2502.05133v1,Data-Parallel Neural Network Training via Nonlinearly Preconditioned Trust-Region Method,http://arxiv.org/abs/2502.05133v1,"Parallel training methods are increasingly relevant in machine learning (ML)due to the continuing growth in model and dataset sizes. We propose a variantof the Additively Preconditioned Trust-Region Strategy (APTS) for training deepneural networks (DNNs). The proposed APTS method utilizes a data-parallelapproach to construct a nonlinear preconditioner employed in the nonlinearoptimization strategy. In contrast to the common employment of StochasticGradient Descent (SGD) and Adaptive Moment Estimation (Adam), which are bothvariants of gradient descent (GD) algorithms, the APTS method implicitlyadjusts the step sizes in each iteration, thereby removing the need for costlyhyperparameter tuning. We demonstrate the performance of the proposed APTSvariant using the MNIST and CIFAR-10 datasets. The results obtained indicatethat the APTS variant proposed here achieves comparable validation accuracy toSGD and Adam, all while allowing for parallel training and obviating the needfor expensive hyperparameter tuning.",Samuel A. Cruz Alegría,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.NA', 'math.NA']"
2502.05130v1,Latent Swap Joint Diffusion for Long-Form Audio Generation,http://arxiv.org/abs/2502.05130v1,"Previous work on long-form audio generation using global-view diffusion oriterative generation demands significant training or inference costs. Whilerecent advancements in multi-view joint diffusion for panoramic generationprovide an efficient option, they struggle with spectrum generation with severeoverlap distortions and high cross-view consistency costs. We initially explorethis phenomenon through the connectivity inheritance of latent maps and uncoverthat averaging operations excessively smooth the high-frequency components ofthe latent map. To address these issues, we propose Swap Forward (SaFa), aframe-level latent swap framework that synchronizes multiple diffusions toproduce a globally coherent long audio with more spectrum details in aforward-only manner. At its core, the bidirectional Self-Loop Latent Swap isapplied between adjacent views, leveraging stepwise diffusion trajectory toadaptively enhance high-frequency components without disrupting low-frequencycomponents. Furthermore, to ensure cross-view consistency, the unidirectionalReference-Guided Latent Swap is applied between the reference and thenon-overlap regions of each subview during the early stages, providingcentralized trajectory guidance. Quantitative and qualitative experimentsdemonstrate that SaFa significantly outperforms existing joint diffusionmethods and even training-based long audio generation models. Moreover, we findthat it also adapts well to panoramic generation, achieving comparablestate-of-the-art performance with greater efficiency and modelgeneralizability. Project page is available at https://swapforward.github.io/.",Yusheng Dai,2025-02-07,2025-02-07,,N/A,"['cs.SD', 'cs.AI', 'cs.CV', 'cs.MM', 'eess.AS']"
2502.05129v1,Counting Fish with Temporal Representations of Sonar Video,http://arxiv.org/abs/2502.05129v1,"Accurate estimates of salmon escapement - the number of fish migratingupstream to spawn - are key data for conservation and fishery management.Existing methods for salmon counting using high-resolution imaging sonarhardware are non-invasive and compatible with computer vision processing. Priorwork in this area has utilized object detection and tracking based methods forautomated salmon counting. However, these techniques remain inaccessible tomany sonar deployment sites due to limited compute and connectivity in thefield. We propose an alternative lightweight computer vision method for fishcounting based on analyzing echograms - temporal representations that compressseveral hundred frames of imaging sonar video into a single image. We predictupstream and downstream counts within 200-frame time windows directly fromechograms using a ResNet-18 model, and propose a set of domain-specific imageaugmentations and a weakly-supervised training protocol to further improveresults. We achieve a count error of 23% on representative data from the KenaiRiver in Alaska, demonstrating the feasibility of our approach.",Kai Van Brunt,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05127v1,Self-supervised Conformal Prediction for Uncertainty Quantification in Imaging Problems,http://arxiv.org/abs/2502.05127v1,"Most image restoration problems are ill-conditioned or ill-posed and henceinvolve significant uncertainty. Quantifying this uncertainty is crucial forreliably interpreting experimental results, particularly when reconstructedimages inform critical decisions and science. However, most existing imagerestoration methods either fail to quantify uncertainty or provide estimatesthat are highly inaccurate. Conformal prediction has recently emerged as aflexible framework to equip any estimator with uncertainty quantificationcapabilities that, by construction, have nearly exact marginal coverage. Toachieve this, conformal prediction relies on abundant ground truth data forcalibration. However, in image restoration problems, reliable ground truth datais often expensive or not possible to acquire. Also, reliance on ground truthdata can introduce large biases in situations of distribution shift betweencalibration and deployment. This paper seeks to develop a more robust approachto conformal prediction for image restoration problems by proposing aself-supervised conformal prediction method that leverages Stein's UnbiasedRisk Estimator (SURE) to self-calibrate itself directly from the observed noisymeasurements, bypassing the need for ground truth. The method is suitable forany linear imaging inverse problem that is ill-conditioned, and it isespecially powerful when used with modern self-supervised image restorationtechniques that can also be trained directly from measurement data. Theproposed approach is demonstrated through numerical experiments on imagedenoising and deblurring, where it delivers results that are remarkablyaccurate and comparable to those obtained by supervised conformal predictionwith ground truth data.",Jasper M. Everink,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'stat.ME', '62H35']"
2502.05122v1,Distinguishing Cause from Effect with Causal Velocity Models,http://arxiv.org/abs/2502.05122v1,"Bivariate structural causal models (SCM) are often used to infer causaldirection by examining their goodness-of-fit under restricted model classes. Inthis paper, we describe a parametrization of bivariate SCMs in terms of acausal velocity by viewing the cause variable as time in a dynamical system.The velocity implicitly defines counterfactual curves via the solution ofinitial value problems where the observation specifies the initial condition.Using tools from measure transport, we obtain a unique correspondence betweenSCMs and the score function of the generated distribution via its causalvelocity. Based on this, we derive an objective function that directlyregresses the velocity against the score function, the latter of which can beestimated non-parametrically from observational data. We use this to develop amethod for bivariate causal discovery that extends beyond known model classessuch as additive or location scale noise, and that requires no assumptions onthe noise distributions. When the score is estimated well, the objective isalso useful for detecting model non-identifiability and misspecification. Wepresent positive results in simulation and benchmark experiments where manyexisting methods fail, and perform ablation studies to examine the method'ssensitivity to accurate score estimation.",Johnny Xi,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG', 'stat.ME']"
2502.05121v1,Refining Integration-by-Parts Reduction of Feynman Integrals with Machine Learning,http://arxiv.org/abs/2502.05121v1,"Integration-by-parts reductions of Feynman integrals pose a frequentbottle-neck in state-of-the-art calculations in theoretical particle andgravitational-wave physics, and rely on heuristic approaches for selectingintegration-by-parts identities, whose quality heavily influences theperformance. In this paper, we investigate the use of machine-learningtechniques to find improved heuristics. We use funsearch, a genetic programmingvariant based on code generation by a Large Language Model, in order to explorepossible approaches, then use strongly typed genetic programming to zero in onuseful solutions. Both approaches manage to re-discover the state-of-the-artheuristics recently incorporated into integration-by-parts solvers, and in oneexample find a small advance on this state of the art.",Matt von Hippel,2025-02-07,2025-02-07,,N/A,"['hep-th', 'cs.LG', 'hep-ph']"
2502.05117v1,"Adoption of AI-Assisted E-Scooters: The Role of Perceived Trust, Safety, and Demographic Drivers",http://arxiv.org/abs/2502.05117v1,"E-scooters have become a more dominant mode of transport in recent years.However, the rise in their usage has been accompanied by an increase ininjuries, affecting the trust and perceived safety of both users and non-users.Artificial intelligence (AI), as a cutting-edge and widely applied technology,has demonstrated potential to enhance transportation safety, particularly indriver assistance systems. The integration of AI into e-scooters presents apromising approach to addressing these safety concerns. This study aims toexplore the factors influencing individuals willingness to use AI-assistede-scooters. Data were collected using a structured questionnaire, capturingresponses from 405 participants. The questionnaire gathered information ondemographic characteristics, micromobility usage frequency, road users'perception of safety around e-scooters, perceptions of safety in AI-enabledtechnology, trust in AI-enabled e-scooters, and involvement in e-scooter crashincidents. To examine the impact of demographic factors on participants'preferences between AI-assisted and regular e-scooters, decision tree analysisis employed, indicating that ethnicity, income, and age significantly influencepreferences. To analyze the impact of other factors on the willingness to useAI-enabled e-scooters, a full-scale Structural Equation Model (SEM) is applied,revealing that the perception of safety in AI enabled technology and the levelof trust in AI-enabled e-scooters are the strongest predictors.",Amit Kumar,2025-02-07,2025-02-07,,N/A,['cs.HC']
2502.05116v1,Optimizing Wireless Resource Management and Synchronization in Digital Twin Networks,http://arxiv.org/abs/2502.05116v1,"In this paper, we investigate an accurate synchronization between a physicalnetwork and its digital network twin (DNT), which serves as a virtualrepresentation of the physical network. The considered network includes a setof base stations (BSs) that must allocate its limited spectrum resources toserve a set of users while also transmitting its partially observed physicalnetwork information to a cloud server to generate the DNT. Since the DNT canpredict the physical network status based on its historical status, the BSs maynot need to send their physical network information at each time slot, allowingthem to conserve spectrum resources to serve the users. However, if the DNTdoes not receive the physical network information of the BSs over a large timeperiod, the DNT's accuracy in representing the physical network may degrade. Tothis end, each BS must decide when to send the physical network information tothe cloud server to update the DNT, while also determining the spectrumresource allocation policy for both DNT synchronization and serving the users.We formulate this resource allocation task as an optimization problem, aimingto maximize the total data rate of all users while minimizing theasynchronization between the physical network and the DNT. To address thisproblem, we propose a method based on the GRUs and the value decompositionnetwork (VDN). Simulation results show that our GRU and VDN based algorithmimproves the weighted sum of data rates and the similarity between the statusof the DNT and the physical network by up to 28.96%, compared to a baselinemethod combining GRU with the independent Q learning.",Hanzhi Yu,2025-02-07,2025-02-07,,N/A,"['cs.NI', 'cs.LG', 'cs.SY', 'eess.SY']"
2502.05114v1,SpecTUS: Spectral Translator for Unknown Structures annotation from EI-MS spectra,http://arxiv.org/abs/2502.05114v1,"Compound identification and structure annotation from mass spectra is awell-established task widely applied in drug detection, criminal forensics,small molecule biomarker discovery and chemical engineering.  We propose SpecTUS: Spectral Translator for Unknown Structures, a deep neuralmodel that addresses the task of structural annotation of small molecules fromlow-resolution gas chromatography electron ionization mass spectra (GC-EI-MS).Our model analyzes the spectra in \textit{de novo} manner -- a directtranslation from the spectra into 2D-structural representation. Our approach isparticularly useful for analyzing compounds unavailable in spectral libraries.  In a rigorous evaluation of our model on the novel structure annotation taskacross different libraries, we outperformed standard database search techniquesby a wide margin. On a held-out testing set, including \numprint{28267} spectrafrom the NIST database, we show that our model's single suggestion perfectlyreconstructs 43\% of the subset's compounds. This single suggestion is strictlybetter than the candidate of the database hybrid search (common method amongpractitioners)  in 76\% of cases. In a~still affordable scenario of~10 suggestions, perfectreconstruction is achieved in 65\%, and 84\% are better than the hybrid search.",Adam Hájek,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'physics.data-an']"
2502.05113v1,GiesKaNe: Bridging Past and Present in Grammatical Theory and Practical Application,http://arxiv.org/abs/2502.05113v1,"This article explores the requirements for corpus compilation within theGiesKaNe project (University of Giessen and Kassel, Syntactic Basic Structuresof New High German). The project is defined by three central characteristics:it is a reference corpus, a historical corpus, and a syntactically deeplyannotated treebank. As a historical corpus, GiesKaNe aims to establishconnections with both historical and contemporary corpora, ensuring itsrelevance across temporal and linguistic contexts. The compilation processstrikes the balance between innovation and adherence to standards, addressingboth internal project goals and the broader interests of the researchcommunity. The methodological complexity of such a project is managed through acomplementary interplay of human expertise and machine-assisted processes. Thearticle discusses foundational topics such as tokenization, normalization,sentence definition, tagging, parsing, and inter-annotator agreement, alongsideadvanced considerations. These include comparisons between grammatical models,annotation schemas, and established de facto annotation standards as well asthe integration of human and machine collaboration. Notably, a novel method formachine-assisted classification of texts along the continuum of conceptualorality and literacy is proposed, offering new perspectives on text selection.Furthermore, the article introduces an approach to deriving de facto standardannotations from existing ones, mediating between standardization andinnovation. In the course of describing the workflow the article demonstratesthat even ambitious projects like GiesKaNe can be effectively implemented usingexisting research infrastructure, requiring no specialized annotation tools.Instead, it is shown that the workflow can be based on the strategic use of asimple spreadsheet and integrates the capabilities of the existinginfrastructure.",Volker Emmrich,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.05112v1,Disentangling the Effects of Curvature and Misorientation on the Shrinkage Behavior of Loop-Shaped Grain Boundaries,http://arxiv.org/abs/2502.05112v1,"The material properties of polycrystals are strongly affected by theevolution and coarsening of their internal grain structures. Yet, studying thisprocess is challenging due to the complex interactions within grain boundarynetworks. Here, we systematically investigate the shrinkage of isolatedloop-shaped grain boundaries in 2D colloidal crystals. Unexpectedly, we findthat shear coupling decreases with increasing grain misorientation, contrary togeometric predictions. This counterintuitive result is attributed to enhancedconcurrent sliding driven by the annihilation of dislocations. Furthermore, byfocusing on the evolution of the grain size, we reveal a transition inshrinkage kinetics between small and large loop sizes, offering an explanationfor previously observed discrepancies in grain boundary mobility. Thesefindings reveal a more intricate dependence of grain boundary behavior oncurvature and misorientation than previously reported, offering new insightsinto polycrystal coarsening dynamics.",Fabrizio Camerin,2025-02-07,2025-02-07,,N/A,"['cond-mat.soft', 'cond-mat.mtrl-sci', 'cond-mat.stat-mech']"
2502.05111v1,Flexible and Efficient Grammar-Constrained Decoding,http://arxiv.org/abs/2502.05111v1,"Large Language Models (LLMs) are often asked to generate structured outputsthat obey precise syntactic rules, such as code snippets or formatted data.Grammar-constrained decoding (GCD) can guarantee that LLM outputs matches suchrules by masking out tokens that will provably lead to outputs that do notbelong to a specified context-free grammar (CFG). To guarantee soundness, GCDalgorithms have to compute how a given LLM subword tokenizer can align with thetokens used  by a given context-free grammar and compute token masks based on thisinformation. Doing so efficiently is challenging and existing GCD algorithmsrequire tens of minutes to preprocess common grammars. We present a new GCDalgorithm together with an implementation that offers 17.71x faster offlinepreprocessing than existing approaches while preserving state-of-the-artefficiency in online mask computation.",Kanghee Park,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI']"
2502.05110v1,ApplE: An Applied Ethics Ontology with Event Context,http://arxiv.org/abs/2502.05110v1,"Applied ethics is ubiquitous in most domains, requiring much deliberation dueto its philosophical nature. Varying views often lead to conflicting courses ofaction where ethical dilemmas become challenging to resolve. Although manyfactors contribute to such a decision, the major driving forces can bediscretized and thus simplified to provide an indicative answer. Knowledgerepresentation and reasoning offer a way to explicitly translate abstractethical concepts into applicable principles within the context of an event. Toachieve this, we propose ApplE, an Applied Ethics ontology that capturesphilosophical theory and event context to holistically describe the morality ofan action. The development process adheres to a modified version of theSimplified Agile Methodology for Ontology Development (SAMOD) and utilizesstandard design and publication practices. Using ApplE, we model a use casefrom the bioethics domain that demonstrates our ontology's social andscientific value. Apart from the ontological reasoning and quality checks,ApplE is also evaluated using the three-fold testing process of SAMOD. ApplEfollows FAIR principles and aims to be a viable resource for applied ethicistsand ontology engineers.",Aisha Aijaz,2025-02-07,2025-02-07,,N/A,"['cs.CY', 'cs.AI']"
2502.05108v1,Towards Emotionally Intelligent Software Engineers: Understanding Students' Self-Perceptions After a Cooperative Learning Experience,http://arxiv.org/abs/2502.05108v1,"[Background] Emotional Intelligence (EI) can impact Software Engineering (SE)outcomes through improved team communication, conflict resolution, and stressmanagement. SE workers face increasing pressure to develop both technical andinterpersonal skills, as modern software development emphasizes collaborativework and complex team interactions. Despite EI's documented importance inprofessional practice, SE education continues to prioritize technical knowledgeover emotional and social competencies. [Objective] This paper analyzes SEstudents' self-perceptions of their EI after a two-month cooperative learningproject, using Mayer and Salovey's four-ability model to examine how studentshandle emotions in collaborative development. [Method] We conducted a casestudy with 29 SE students organized into four squads within a project-basedlearning course, collecting data through questionnaires and focus groups thatincluded brainwriting and sharing circles, then analyzing the data usingdescriptive statistics and open coding. [Results] Students demonstratedstronger abilities in managing their own emotions compared to interpretingothers' emotional states. Despite limited formal EI training, they developedinformal strategies for emotional management, including structured planning andpeer support networks, which they connected to improved productivity andconflict resolution. [Conclusion] This study shows how SE students perceive EIin a collaborative learning context and provides evidence-based insights intothe important role of emotional competencies in SE education.",Allysson Allex Araújo,2025-02-07,2025-02-07,,N/A,['cs.SE']
2502.05107v1,3DMolFormer: A Dual-channel Framework for Structure-based Drug Discovery,http://arxiv.org/abs/2502.05107v1,"Structure-based drug discovery, encompassing the tasks of protein-liganddocking and pocket-aware 3D drug design, represents a core challenge in drugdiscovery. However, no existing work can deal with both tasks to effectivelyleverage the duality between them, and current methods for each task arehindered by challenges in modeling 3D information and the limitations ofavailable data. To address these issues, we propose 3DMolFormer, a unifieddual-channel transformer-based framework applicable to both docking and 3D drugdesign tasks, which exploits their duality by utilizing docking functionalitieswithin the drug design process. Specifically, we represent 3D pocket-ligandcomplexes using parallel sequences of discrete tokens and continuous numbers,and we design a corresponding dual-channel transformer model to handle thisformat, thereby overcoming the challenges of 3D information modeling.Additionally, we alleviate data limitations through large-scale pre-training ona mixed dataset, followed by supervised and reinforcement learning fine-tuningtechniques respectively tailored for the two tasks. Experimental resultsdemonstrate that 3DMolFormer outperforms previous approaches in bothprotein-ligand docking and pocket-aware 3D drug design, highlighting itspromising application in structure-based drug discovery. The code is availableat: https://github.com/HXYfighter/3DMolFormer .",Xiuyuan Hu,2025-02-07,2025-02-07,,N/A,"['cs.CE', 'cs.LG']"
2502.05104v1,Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types,http://arxiv.org/abs/2502.05104v1,"Consumer energy forecasting is essential for managing energy consumption andplanning, directly influencing operational efficiency, cost reduction,personalized energy management, and sustainability efforts. In recent years,deep learning techniques, especially LSTMs and transformers, have been greatlysuccessful in the field of energy consumption forecasting. Nevertheless, thesetechniques have difficulties in capturing complex and sudden variations, and,moreover, they are commonly examined only on a specific type of consumer (e.g.,only offices, only schools). Consequently, this paper proposes HyperEnergy, aconsumer energy forecasting strategy that leverages hypernetworks for improvedmodeling of complex patterns applicable across a diversity of consumers.Hypernetwork is responsible for predicting the parameters of the primaryprediction network, in our case LSTM. A learnable adaptable kernel, comprisedof polynomial and radial basis function kernels, is incorporated to enhanceperformance. The proposed HyperEnergy was evaluated on diverse consumersincluding, student residences, detached homes, a home with electric vehiclecharging, and a townhouse. Across all consumer types, HyperEnergy consistentlyoutperformed 10 other techniques, including state-of-the-art models such asLSTM, AttentionLSTM, and transformer.",Muhammad Umair Danish,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.05103v1,Design of a Piezoelectric Wind Energy Harvester for Bacterial Disinfection of Drinking Water,http://arxiv.org/abs/2502.05103v1,"In this thesis, a piezoelectric wind energy harvester is proposed forbacterial disinfection of drinking water. A mathematical model of apiezoelectric wind energy harvester is developed to predict the electricalenergy from the wind induced vibration based on the galloping phenomenon.Structure of a piezoelectric wind energy harvester is a cantileverpiezolaminated elastic beam with a bluff body attached to the free end. Lineartime invariant and lumped parameter approach is considered to model thestructure. In order to improve the performance of the harvester, bluff body ismodified by attaching different attachment in the form of circular-shaped,triangular-shaped, square-shaped, Y-shaped, and curve-shaped. Bacterialdisinfection of drinking water is performed using the electrical output of thepiezoelectric wind energy harvester. Energy harvester with a curve-shapedattachment to a bluff body is used for this application because it providesenhanced electrical output as compared to other shaped harvesters. It has beenfound both numerically and experimentally that the harvester with acurve-shaped attachment to the bluff body provides the best electrical output.",Prakash Poudel,2025-02-07,2025-02-07,,N/A,['physics.flu-dyn']
2502.05102v1,Time Series Analysis of Rankings: A GARCH-Type Approach,http://arxiv.org/abs/2502.05102v1,"Ranking data are frequently obtained nowadays but there are still scarcemethods for treating these data when temporally observed. The present papercontributes to this topic by proposing and developing novel models for handlingtime series of ranking data. We introduce a class of time-varying rankingmodels inspired by the Generalized AutoRegressive ConditionalHeteroskedasticity (GARCH) models. More specifically, the temporal dynamics aredefined by the conditional distribution of the current ranking given the pastrankings, which are assumed to follow a Mallows distribution, which implicitlydepends on a distance. Then, autoregressive and feedback components areincorporated into the model through the conditional expectation of theassociated distances. Theoretical properties of our ranking GARCH models suchas stationarity and ergodicity are established. The estimation of parameters isperformed via maximum likelihood estimation when data is fully observed. Wedevelop a Monte Carlo Expectation-Maximisation algorithm to deal with casesinvolving missing data. Monte Carlo simulation studies are presented to studythe performance of the proposed estimators under both non-missing and missingdata scenarios. A real data application about the weekly ranking ofprofessional tennis players from 2015 to 2019 is presented under our proposedranking GARCH models.",Luiza Piancastelli,2025-02-07,2025-02-07,,N/A,"['stat.ME', 'stat.CO', 'stat.ML']"
2502.05098v1,Learning Temporal Invariance in Android Malware Detectors,http://arxiv.org/abs/2502.05098v1,"Learning-based Android malware detectors degrade over time due to naturaldistribution drift caused by malware variants and new families. This papersystematically investigates the challenges classifiers trained with empiricalrisk minimization (ERM) face against such distribution shifts and attributestheir shortcomings to their inability to learn stable discriminative features.Invariant learning theory offers a promising solution by encouraging models togenerate stable representations crossing environments that expose theinstability of the training set. However, the lack of prior environment labels,the diversity of drift factors, and low-quality representations caused bydiverse families make this task challenging. To address these issues, wepropose TIF, the first temporal invariant training framework for malwaredetection, which aims to enhance the ability of detectors to learn stablerepresentations across time. TIF organizes environments based on applicationobservation dates to reveal temporal drift, integrating specialized multi-proxycontrastive learning and invariant gradient alignment to generate and alignenvironments with high-quality, stable representations. TIF can be seamlesslyintegrated into any learning-based detector. Experiments on a decade-longdataset show that TIF excels, particularly in early deployment stages,addressing real-world needs and outperforming state-of-the-art methods.",Xinran Zheng,2025-02-07,2025-02-07,,N/A,"['cs.CR', 'cs.AI']"
2502.05095v1,Segment Geometry Optimization and Prototype Studies of a Multi-Coincidence GAGG Solar Neutrino Detector,http://arxiv.org/abs/2502.05095v1,"A GAGG detector capable of dissecting a multi-coincidence solar neutrinointeraction on ${}^{71}$Ga is under development for potential space-basedapplications. We identify three distinct detection signatures when${}^{71}$Ge$^*$ is produced, two of which are significantly delayed in time andcould be detected within a single large GAGG volume. Further optimizations canbe made by optically isolating smaller segments of GAGG to maximize theprobability of a spatial separation between the prompt/delayed signals. Weconstruct and test prototype GAGG detectors capable of sub 4% energy resolution@ ${}^{137}$Cs and reliable detection of spatially-separated ${}^{57}$Codouble-pulse decays.",Brooks Hartsock,2025-02-07,2025-02-07,,N/A,"['hep-ex', 'physics.ins-det']"
2502.05092v1,Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs,http://arxiv.org/abs/2502.05092v1,"Understanding time from visual representations is a fundamental cognitiveskill, yet it remains a challenge for multimodal large language models (MLLMs).In this work, we investigate the capabilities of MLLMs in interpreting time anddate through analogue clocks and yearly calendars. To facilitate this, wecurated a structured dataset comprising two subsets: 1) $\textit{ClockQA}$,which comprises various types of clock styles$-$standard, black-dial,no-second-hand, Roman numeral, and arrow-hand clocks$-$paired with time relatedquestions; and 2) $\textit{CalendarQA}$, which consists of yearly calendarimages with questions ranging from commonly known dates (e.g., Christmas, NewYear's Day) to computationally derived ones (e.g., the 100th or 153rd day ofthe year). We aim to analyse how MLLMs can perform visual recognition,numerical reasoning, and temporal inference when presented with time-relatedvisual data. Our evaluations show that despite recent advancements, reliablyunderstanding time remains a significant challenge for MLLMs.",Rohit Saxena,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.AI', 'cs.CL']"
2502.05091v1,DCFormer: Efficient 3D Vision-Language Modeling with Decomposed Convolutions,http://arxiv.org/abs/2502.05091v1,"Vision-language models (VLMs) align visual and textual representations,enabling high-performance zero-shot classification and image-text retrieval in2D medical imaging. However, extending VLMs to 3D medical imaging remainscomputationally challenging. Existing 3D VLMs rely on Vision Transformers(ViTs), which are computationally expensive due to self-attention's quadraticcomplexity, or 3D convolutions, which demand excessive parameters and FLOPs askernel size increases. We introduce DCFormer, an efficient 3D medical imageencoder that factorizes 3D convolutions into three parallel 1D convolutionsalong depth, height, and width. This design preserves spatial information whilesignificantly reducing computational cost. Integrated into a CLIP-basedvision-language framework, DCFormer is evaluated on CT-RATE, a dataset of50,188 paired 3D chest CT volumes and radiology reports, for zero-shotmulti-abnormality detection across 18 pathologies. Compared to ViT, ConvNeXt,PoolFormer, and TransUNet, DCFormer achieves superior efficiency and accuracy,with DCFormer-Tiny reaching 62.0% accuracy and a 46.3% F1-score while usingsignificantly fewer parameters. These results highlight DCFormer's potentialfor scalable, clinically deployable 3D medical VLMs. Our codes will be publiclyavailable.",Gorkem Can Ates,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05087v1,Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs,http://arxiv.org/abs/2502.05087v1,"Federated learning (FL) is a popular paradigm for collaborative trainingwhich avoids direct data exposure between clients. However, data privacy issuesstill remain: FL-trained large language models are capable of memorizing andcompleting phrases and sentences contained in training data when given withtheir prefixes. Thus, it is possible for adversarial and honest-but-curiousclients to recover training data of other participants simply through targetedprompting. In this work, we demonstrate that a popular and simple fine-tuningstrategy, low-rank adaptation (LoRA), reduces memorization during FL up to afactor of 10. We study this effect by performing a medical question-answeringfine-tuning task and injecting multiple replicas of out-of-distributionsensitive sequences drawn from an external clinical dataset. We observe areduction in memorization for a wide variety of Llama 2 and 3 models, and findthat LoRA can reduce memorization in centralized learning as well. Furthermore,we show that LoRA can be combined with other privacy-preserving techniques suchas gradient clipping and Gaussian noising, secure aggregation, and Goldfishloss to further improve record-level privacy while maintaining performance.",Thierry Bossy,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.05085v1,Causality can systematically address the monsters under the bench(marks),http://arxiv.org/abs/2502.05085v1,"Effective and reliable evaluation is essential for advancing empiricalmachine learning. However, the increasing accessibility of generalist modelsand the progress towards ever more complex, high-level tasks make systematicevaluation more challenging. Benchmarks are plagued by various biases,artifacts, or leakage, while models may behave unreliably due to poorlyexplored failure modes. Haphazard treatments and inconsistent formulations ofsuch ""monsters"" can contribute to a duplication of efforts, a lack of trust inresults, and unsupported inferences. In this position paper, we argue causalityoffers an ideal framework to systematically address these challenges. By makingcausal assumptions in an approach explicit, we can faithfully model phenomena,formulate testable hypotheses with explanatory power, and leverage principledtools for analysis. To make causal model design more accessible, we identifyseveral useful Common Abstract Topologies (CATs) in causal graphs which helpgain insight into the reasoning abilities in large language models. Through aseries of case studies, we demonstrate how the precise yet pragmatic languageof causality clarifies the strengths and limitations of a method and inspiresnew approaches for systematic progress.",Felix Leeb,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.05084v1,ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework,http://arxiv.org/abs/2502.05084v1,"The astonishing performance of large language models (LLMs) and theirremarkable achievements in production and daily life have led to theirwidespread application in collaborative tasks. However, current large modelsface challenges such as hallucination and lack of specificity in contentgeneration in vertical domain tasks. Inspired by the contrast andclassification mechanisms in human cognitive processes, this paper constructsan adversarial learning-based prompt framework named ChallengeMe, whichincludes three cascaded solutions: generation prompts, evaluation prompts, andfeedback optimization. In this process, we designed seven core optimizationdimensions and set the threshold for adversarial learning. The results of mixedcase studies on the text summarization task show that the proposed frameworkcan generate more accurate and fluent text summaries compared to the currentadvanced mainstream LLMs.",Xiaoyu Deng,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI']"
2502.05081v1,Stochastic internal habit formation and optimality,http://arxiv.org/abs/2502.05081v1,"Growth models with internal habit formation have been studied in varioussettings under the assumption of deterministic dynamics. The purpose of thispaper is to explore a stochastic version of the model in Carroll et al. [1997,2000], one the most influential on the subject. The goal is twofold: on onehand, to determine how far we can advance in the technical study of the model;on the other, to assess whether at least some of the deterministic outcomesremain valid in the stochastic setting. The resulting optimal control problemproves to be challenging, primarily due to the lack of concavity in theobjective function. This feature is present in the model even in thedeterministic case (see, e.g., Bambi and Gozzi [2020]). We develop an approachbased on Dynamic Programming to establish several useful results, including theregularity of the solution to the corresponding HJB equation and a verificationtheorem. There results lay the groundwork for studying the model optimal pathsand comparing them with the deterministic case.",Michele Aleandri,2025-02-07,2025-02-07,,N/A,"['math.OC', 'math.PR', '49L20, 49L12, 49L25, 49J55, 93E20,']"
2502.05078v1,"Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures",http://arxiv.org/abs/2502.05078v1,"Large Language Models (LLMs) have demonstrated impressive reasoningcapabilities, yet their performance is highly dependent on the promptingstrategy and model scale. While reinforcement learning and fine-tuning havebeen deployed to boost reasoning, these approaches incur substantialcomputational and data overhead. In this work, we introduce Adaptive Graph ofThoughts (AGoT), a dynamic, graph-based inference framework that enhances LLMreasoning solely at test time. Rather than relying on fixed-step methods likeChain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposescomplex queries into structured subproblems, forming an dynamic directedacyclic graph (DAG) of interdependent reasoning steps. By selectively expandingonly those subproblems that require further analysis, AGoT unifies thestrengths of chain, tree, and graph paradigms into a cohesive framework thatallocates computation where it is most needed. We validate our approach ondiverse benchmarks spanning multi-hop retrieval, scientific reasoning, andmathematical problem-solving, achieving up to 46.2% improvement on scientificreasoning tasks (GPQA) - comparable to gains achieved through computationallyintensive reinforcement learning approaches and outperforming state-of-the-artiterative approaches. These results suggest that dynamic decomposition andstructured recursion offer a scalable, cost-effective alternative topost-training modifications, paving the way for more robust, general-purposereasoning in LLMs.",Tushar Pandey,2025-02-07,2025-02-07,,N/A,"['cs.AI', 'cs.CL']"
2502.05076v1,Paying Attention to Facts: Quantifying the Knowledge Capacity of Attention Layers,http://arxiv.org/abs/2502.05076v1,"In this paper, we investigate the ability of single-layer attention-onlytransformers (i.e. attention layers) to memorize facts contained in databasesfrom a linear-algebraic perspective. We associate with each database a3-tensor, propose the rank of this tensor as a measure of the size of thedatabase, and provide bounds on the rank in terms of properties of thedatabase. We also define a 3-tensor corresponding to an attention layer, andempirically demonstrate the relationship between its rank and database rank ona dataset of toy models and random databases. By highlighting the roles playedby the value-output and query-key weights, and the effects of argmax andsoftmax on rank, our results shed light on the `additive motif' of factualrecall in transformers, while also suggesting a way of increasing layercapacity without increasing the number of parameters.",Liang Ze Wong,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.CL']"
2502.05075v1,Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension,http://arxiv.org/abs/2502.05075v1,"Weak-to-strong (W2S) generalization is a type of finetuning (FT) where astrong (large) student model is trained on pseudo-labels generated by a weakteacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek tounderstand this phenomenon through the observation that FT often occurs inintrinsically low-dimensional spaces. Leveraging the low intrinsicdimensionality of FT, we analyze W2S in the ridgeless regression setting from avariance reduction perspective. For a strong student - weak teacher pair withsufficiently expressive low-dimensional feature subspaces $\mathcal{V}_s,\mathcal{V}_w$, we provide an exact characterization of the variance thatdominates the generalization error of W2S. This unveils a virtue of discrepancybetween the strong and weak models in W2S: the variance of the weak teacher isinherited by the strong student in $\mathcal{V}_s \cap \mathcal{V}_w$, whilereduced by a factor of $\dim(\mathcal{V}_s)/N$ in the subspace of discrepancy$\mathcal{V}_w \setminus \mathcal{V}_s$ with $N$ pseudo-labels for W2S.Further, our analysis casts light on the sample complexities and the scaling ofperformance gap recovery in W2S. The analysis is supported with experiments onboth synthetic regression problems and real vision tasks.",Yijun Dong,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.NA', 'math.NA', 'stat.ML']"
2502.05074v1,Two-Point Deterministic Equivalence for Stochastic Gradient Dynamics in Linear Models,http://arxiv.org/abs/2502.05074v1,"We derive a novel deterministic equivalence for the two-point function of arandom matrix resolvent. Using this result, we give a unified derivation of theperformance of a wide variety of high-dimensional linear models trained withstochastic gradient descent. This includes high-dimensional linear regression,kernel regression, and random feature models. Our results include previouslyknown asymptotics as well as novel ones.",Alexander Atanasov,2025-02-07,2025-02-07,,N/A,"['cond-mat.dis-nn', 'cs.LG', 'stat.ML']"
2502.05072v1,Joint TITE-CRM for Dual Agent Dose Finding Studies,http://arxiv.org/abs/2502.05072v1,"Dual agent dose-finding trials study the effect of a combination of more thanone agent, where the objective is to find the Maximum Tolerated DoseCombination (MTC), the combination of doses of the two agents that isassociated with a pre-specified risk of being unsafe. In a Phase I/II setting,the objective is to find a dose combination that is both safe and active, theOptimal Biological Dose (OBD), that optimizes a criterion based on both safetyand activity. Since Oncology treatments are typically given over multiplecycles, both the safety and activity outcome can be considered as late-onset,potentially occurring in the later cycles of treatment. This work proposes twomodel-based designs for dual-agent dose finding studies with late-onsetactivity and late-onset toxicity outcomes, the Joint TITE-POCRM and the JointTITE-BLRM. Their performance is compared alongside a model-assisted comparatorin a comprehensive simulation study motivated by a real trial example, with anextension to consider alternative sized dosing grids. It is found that bothmodel-based methods outperform the model-assisted design. Whilst on average thetwo model-based designs are comparable, this comparability is not consistentacross scenarios.",Helen Barnett,2025-02-07,2025-02-07,,N/A,['stat.AP']
2502.05069v1,Exploring the Generalizability of Geomagnetic Navigation: A Deep Reinforcement Learning approach with Policy Distillation,http://arxiv.org/abs/2502.05069v1,"The advancement in autonomous vehicles has empowered navigation andexploration in unknown environments. Geomagnetic navigation for autonomousvehicles has drawn increasing attention with its independence from GPS orinertial navigation devices. While geomagnetic navigation approaches have beenextensively investigated, the generalizability of learned geomagneticnavigation strategies remains unexplored. The performance of a learned strategycan degrade outside of its source domain where the strategy is learned, due toa lack of knowledge about the geomagnetic characteristics in newly enteredareas. This paper explores the generalization of learned geomagnetic navigationstrategies via deep reinforcement learning (DRL). Particularly, we employ DRLagents to learn multiple teacher models from distributed domains that representdispersed navigation strategies, and amalgamate the teacher models forgeneralizability across navigation areas. We design a reward shaping mechanismin training teacher models where we integrate both potential-based andintrinsic-motivated rewards. The designed reward shaping can enhance theexploration efficiency of the DRL agent and improve the representation of theteacher models. Upon the gained teacher models, we employ multi-teacher policydistillation to merge the policies learned by individual teachers, leading to anavigation strategy with generalizability across navigation domains. We conductnumerical simulations, and the results demonstrate an effective transfer of thelearned DRL model from a source domain to new navigation areas. Compared toexisting evolutionary-based geomagnetic navigation methods, our approachprovides superior performance in terms of navigation length, duration, headingdeviation, and success rate in cross-domain navigation.",Wenqi Bai,2025-02-07,2025-02-07,,N/A,['cs.RO']
2502.05067v1,Programming optical-lattice Fermi-Hubbard quantum simulators,http://arxiv.org/abs/2502.05067v1,"Fermionic atoms in optical lattices provide a native implementation ofFermi-Hubbard (FH) models that can be used as analog quantum simulators ofmany-body fermionic systems. Recent experimental advances include thetime-dependent local control of chemical potentials and tunnelings, and thusenable to operate this platform digitally as a programmable quantum simulator.Here, we explore these opportunities and develop ground-state preparationalgorithms for different fermionic models, based on the ability to implementboth single-particle and many-body, high-fidelity fermionic gates, as providedby the native FH Hamiltonian. In particular, we first design variational,pre-compiled quantum circuits to prepare the ground state of the nativelyimplemented FH model, with significant speedups relative to competing adiabaticprotocols. Besides, the versatility of this variational approach enables totarget extended FH models, i.e., including terms that are not natively realizedon the platform. As an illustration, we include next-nearest-neighbortunnelings at finite dopings, relevant in the context of $d$-wavesuperconductivity. Furthermore, we discuss how to approximate theimaginary-time evolution using variational fermionic circuits, both as analternative state-preparation strategy, and as a subroutine for the QuantumLanczos algorithm to further improve the energy estimation. We benchmark ourprotocols for ladder geometries, though they can be readily applied to 2Dexperimental setups to address regimes beyond the capabilities of currentclassical methods. These results pave the way for more efficient andcomprehensive explorations of relevant many-body phases with existingprogrammable fermionic quantum simulators.",Cristian Tabares,2025-02-07,2025-02-07,,N/A,"['quant-ph', 'cond-mat.quant-gas', 'cond-mat.str-el']"
2502.05066v1,"Beautiful Images, Toxic Words: Understanding and Addressing Offensive Text in Generated Images",http://arxiv.org/abs/2502.05066v1,"State-of-the-art visual generation models, such as Diffusion Models (DMs) andVision Auto-Regressive Models (VARs), produce highly realistic images. Whileprior work has successfully mitigated Not Safe For Work (NSFW) content in thevisual domain, we identify a novel threat: the generation of NSFW text embeddedwithin images. This includes offensive language, such as insults, racial slurs,and sexually explicit terms, posing significant risks to users. We show thatall state-of-the-art DMs (e.g., SD3, Flux, DeepFloyd IF) and VARs (e.g.,Infinity) are vulnerable to this issue. Through extensive experiments, wedemonstrate that existing mitigation techniques, effective for visual content,fail to prevent harmful text generation while substantially degrading benigntext generation. As an initial step toward addressing this threat, we exploresafety fine-tuning of the text encoder underlying major DM architectures usinga customized dataset. Thereby, we suppress NSFW generation while preservingoverall image and text generation quality. Finally, to advance research in thisarea, we introduce ToxicBench, an open-source benchmark for evaluating NSFWtext generation in images. ToxicBench provides a curated dataset of harmfulprompts, new metrics, and an evaluation pipeline assessing both NSFW-ness andgeneration quality. Our benchmark aims to guide future efforts in mitigatingNSFW text generation in text-to-image models and is available athttps://github.com/sprintml/ToxicBench",Aditya Kumar,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05062v1,Stochastic neutral fractions and the effective population size,http://arxiv.org/abs/2502.05062v1,"The dynamics of a general structured population is modelled using a generalstochastic differential equation (SDE) with an infinite divisibility property.This property allows the population to be divided into an arbitrary number ofallelic components, also known as stochastic neutral fractions. Whendemographic noise is small, a fast-slow principle provides a general formulafor the effective population size in structured populations. To illustrate thisapproach, we revisit several examples from the literature, includingage-structured models and expansion fronts.",Raphaël Forien,2025-02-07,2025-02-07,,N/A,"['math.PR', 'q-bio.PE']"
2502.05061v1,Emission from multiple molecular isotopologues in a high-inclination protoplanetary disk,http://arxiv.org/abs/2502.05061v1,"We present a MIRI-MRS spectrum of the high-inclination protoplanetary diskaround the solar-mass (K0) star MY Lup, obtained as part of the JWST DiskInfrared Spectral Chemistry Survey (JDISCS). The spectrum shows an unusuallyweak water emission spectrum for a disk around a star of its spectral type, butstrong emission from CO$_2$, HCN, and isotopologues of both molecules. Thisincludes the first ever detection of C$^{18}$O$^{16}$O and H$^{13}$CN in aninner disk, as well as tentative detections of C$^{17}$O$^{16}$O andHC$^{15}$N. Slab modeling provides molecular temperatures, column densities andemitting areas of the detected molecules. The emitting molecular gas is coldcompared to that of other observed protoplanetary disk spectra. We estimate theisotopologue ratios of CO$_2$ and HCN, albeit with significant uncertainty. Wesuggest that the unusual spectrum of MY Lup arises from a combination of innerdisk clearing, which removes emission from warm water, and its nearly edge-oninclination, which enhances line-of-sight column densities, although unusualchemistry may also be required. MY Lup's spectrum highlights the potential todetect and measure trace isotopologues to study isotopic fractionation inprotoplanetary disks; observations at higher spectral resolving power is neededto constrain the isotopologue ratios to greater precision.",Colette Salyk,2025-02-07,2025-02-07,,N/A,"['astro-ph.SR', 'astro-ph.EP', 'astro-ph.GA']"
2502.05060v1,Preference-aware compensation policies for crowdsourced on-demand services,http://arxiv.org/abs/2502.05060v1,"Crowdsourced on-demand services offer benefits such as reduced costs, fasterservice fulfillment times, greater adaptability, and contributions tosustainable urban transportation in on-demand delivery contexts. However, thesuccess of an on-demand platform that utilizes crowdsourcing relies on findinga compensation policy that strikes a balance between creating attractive offersfor gig workers and ensuring profitability. In this work, we examine a dynamicpricing problem for an on-demand platform that sets request-specificcompensation of gig workers in a discrete-time framework, where requests andworkers arrive stochastically. The operator's goal is to determine acompensation policy that maximizes the total expected reward over the timehorizon. Our approach introduces compensation strategies that explicitlyaccount for gig worker request preferences. To achieve this, we employ theMultinomial Logit model to represent the acceptance probabilities of gigworkers, and, as a result, derive an analytical solution that utilizespost-decision states. Subsequently, we integrate this solution into anapproximate dynamic programming algorithm. We compare our algorithm againstbenchmark algorithms, including formula-based policies and an upper boundprovided by the full information linear programming solution. Our algorithmdemonstrates consistent performance across diverse settings, achievingimprovements of at least 2.5-7.5% in homogeneous gig worker populations and 9%in heterogeneous populations over benchmarks, based on fully synthetic data.For real-world data, it surpasses benchmarks by 8% in weak and 20% in stronglocation preference scenarios.",Georgina Nouli,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'math.OC']"
2502.05057v1,On modified Euler methods for McKean-Vlasov stochastic differential equations with super-linear coefficients,http://arxiv.org/abs/2502.05057v1,"We introduce a new class of numerical methods for solving McKean-Vlasovstochastic differential equations, which are relevant in the context ofdistribution-dependent or mean-field models, under super-linear growthconditions for both the drift and diffusion coefficients. Under certainnon-globally Lipschitz conditions, the proposed numerical approaches havehalf-order convergence in the strong sense to the corresponding system ofinteracting particles associated with McKean-Vlasov SDEs. By leveraging aresult on the propagation of chaos, we establish the full convergence rate ofthe modified Euler approximations to the solution of the McKean-Vlasov SDEs.Numerical experiments are included to validate the theoretical results.",Jiamin Jian,2025-02-07,2025-02-07,,N/A,"['math.NA', 'cs.NA', '65C30']"
2502.05051v1,Pion condensation at non-zero isospin chemical potential with Wilson fermions,http://arxiv.org/abs/2502.05051v1,"In contrast to the case of non-zero baryon chemical potential, the isospinchemical potential does not introduce a sign problem and can be simulated onthe lattice. When the isospin chemical potential is large enough, a phasetransition to a Bose-Einstein condensate of pions takes place. Currentlyavailable results in the literature on the phase diagram and the equation ofstate in this setup employ staggered fermions. We present preliminary resultson the onset of the pion condensation phase in simulations with Wilsonfermions.",Rocco Francesco Basta,2025-02-07,2025-02-07,,N/A,['hep-lat']
2502.05049v1,On the Inference of Sociodemographics on Reddit,http://arxiv.org/abs/2502.05049v1,"Inference of sociodemographic attributes of social media users is anessential step for computational social science (CSS) research to link onlineand offline behavior. However, there is a lack of a systematic evaluation andclear guidelines for optimal methodologies for this task on Reddit, one oftoday's largest social media. In this study, we fill this gap by comparingstate-of-the-art (SOTA) and probabilistic models.  To this end, first we collect a novel data set of more than 850kself-declarations on age, gender, and partisan affiliation from Redditcomments. Then, we systematically compare alternatives to the widely usedembedding-based model and labeling techniques for the definition of theground-truth. We do so on two tasks: ($i$) predicting binary labels(classification); and ($ii$)~predicting the prevalence of a demographic classamong a set of users (quantification).  Our findings reveal that Naive Bayes models not only offer transparency andinterpretability by design but also consistently outperform the SOTA.Specifically, they achieve an improvement in ROC AUC of up to $19\%$ andmaintain a mean absolute error (MAE) below $15\%$ in quantification forlarge-scale data settings. Finally, we discuss best practices for researchersin CSS, emphasizing coverage, interpretability, reliability, and scalability.  The code and model weights used for the experiments are publiclyavailable.\footnote{https://anonymous.4open.science/r/SDI-submission-5234}",Federico Cinus,2025-02-07,2025-02-07,,N/A,"['cs.SI', 'cs.CY']"
2502.05045v1,Energy dynamics in a class of local random matrix Hamiltonians,http://arxiv.org/abs/2502.05045v1,"Random matrix theory yields valuable insights into the universal features ofquantum many-body chaotic systems. Although all-to-all interactions aretraditionally studied, many interesting dynamical questions, such as transportof a conserved density, require a notion of spatially local interactions. Westudy the transport of the energy, the most basic conserved density, infew-body and 1D chains of nearest-neighbor random matrix terms that square toone. In the few-body but large local Hilbert space dimension case, we develop amapping for the energy dynamics to a single-particle hopping picture. Thisallows for the computation of the energy density autocorrelators and anout-of-time-ordered correlator of the energy density. In the 1D chain, wenumerically study the energy transport for a small local Hilbert spacedimension. We also discuss the density of states throughout and touch upon therelation to free probability theory.",Klée Pollock,2025-02-07,2025-02-07,,N/A,"['cond-mat.stat-mech', 'cond-mat.str-el', 'hep-th', 'quant-ph']"
2502.05044v1,Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures,http://arxiv.org/abs/2502.05044v1,"This study introduces a hybrid machine learning-based scale-bridgingframework for predicting the permeability of fibrous textile structures. Byaddressing the computational challenges inherent to multiscale modeling, theproposed approach evaluates the efficiency and accuracy of differentscale-bridging methodologies combining traditional surrogate models and evenintegrating physics-informed neural networks (PINNs) with numerical solvers,enabling accurate permeability predictions across micro- and mesoscales. Fourmethodologies were evaluated: Single Scale Method (SSM), Simple UpscalingMethod (SUM), Scale-Bridging Method (SBM), and Fully Resolved Model (FRM). SSM,the simplest method, neglects microscale permeability and exhibitedpermeability values deviating by up to 150\% of the FRM model, which was takenas ground truth at an equivalent lower fiber volume content. SUM improvedpredictions by considering uniform microscale permeability, yielding closervalues under similar conditions, but still lacked structural variability. TheSBM method, incorporating segment-based microscale permeability assignments,showed significant enhancements, achieving almost equivalent values whilemaintaining computational efficiency and modeling runtimes of ~45 minutes persimulation. In contrast, FRM, which provides the highest fidelity by fullyresolving microscale and mesoscale geometries, required up to 270 times morecomputational time than SSM, with model files exceeding 300 GB. Additionally, ahybrid dual-scale solver incorporating PINNs has been developed and shows thepotential to overcome generalization errors and the problem of data scarcity ofthe data-driven surrogate approaches. The hybrid framework advancespermeability modelling by balancing computational cost and predictionreliability, laying the foundation for further applications in fibrouscomposite manufacturing.",Denis Korolev,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.05043v1,EcoServe: Designing Carbon-Aware AI Inference Systems,http://arxiv.org/abs/2502.05043v1,"The rapid increase in LLM ubiquity and scale levies unprecedented demands oncomputing infrastructure. These demands not only incur large compute and memoryresources, but also significant energy, yielding large operational and embodiedcarbon emissions. In this work, we present two main observations. First, whileGPUs dominate operational carbon, host processing systems (e.g., CPUs, memory,storage) dominate embodied carbon. Second, based on traces from productiondeployment of two Generative AI services in the cloud, offline, batch-inferenceaccounts for a significant portion (up to 55\%) of serving capacity. We proposefour pillars of carbon-conscious infrastructure design for LLM serving systems:\textbf{\textit{Reduce, Reuse, Rightsize, and Recycle}}. We demonstrate thatEcoServe can lower carbon emissions by up to 47\%, compared to performance,energy, and cost-optimized design points, while maintaining performance targetsand SLOs.",Yueying,2025-02-07,2025-02-07,,N/A,['cs.DC']
2502.05041v1,Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks,http://arxiv.org/abs/2502.05041v1,"Anomaly detection is crucial in the energy sector to identify irregularpatterns indicating equipment failures, energy theft, or other issues. Machinelearning techniques for anomaly detection have achieved great success, but aretypically centralized, involving sharing local data with a central server whichraises privacy and security concerns. Federated Learning (FL) has been gainingpopularity as it enables distributed learning without sharing local data.However, FL depends on neural networks, which are vulnerable to adversarialattacks that manipulate data, leading models to make erroneous predictions.While adversarial attacks have been explored in the image domain, they remainlargely unexplored in time series problems, especially in the energy domain.Moreover, the effect of adversarial attacks in the FL setting is also mostlyunknown. This paper assesses the vulnerability of FL-based anomaly detection inenergy data to adversarial attacks. Specifically, two state-of-the-art models,Long Short Term Memory (LSTM) and Transformers, are used to detect anomalies inan FL setting, and two white-box attack methods, Fast Gradient Sign Method(FGSM) and Projected Gradient Descent (PGD), are employed to perturb the data.The results show that FL is more sensitive to PGD attacks than to FGSM attacks,attributed to PGD's iterative nature, resulting in an accuracy drop of over 10%even with naive, weaker attacks. Moreover, FL is more affected by these attacksthan centralized learning, highlighting the need for defense mechanisms in FL.",Yohannis Kifle Telila,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'cs.DC', '68', 'I.2; I.5; I.2.11; I.5.4']"
2502.05040v1,GaussRender: Learning 3D Occupancy with Gaussian Rendering,http://arxiv.org/abs/2502.05040v1,"Understanding the 3D geometry and semantics of driving scenes is critical fordeveloping of safe autonomous vehicles. While 3D occupancy models are typicallytrained using voxel-based supervision with standard losses (e.g.,cross-entropy, Lovasz, dice), these approaches treat voxel predictionsindependently, neglecting their spatial relationships. In this paper, wepropose GaussRender, a plug-and-play 3D-to-2D reprojection loss that enhancesvoxel-based supervision. Our method projects 3D voxel representations intoarbitrary 2D perspectives and leverages Gaussian splatting as an efficient,differentiable rendering proxy of voxels, introducing spatial dependenciesacross projected elements. This approach improves semantic and geometricconsistency, handles occlusions more efficiently, and requires no architecturalmodifications. Extensive experiments on multiple benchmarks(SurroundOcc-nuScenes, Occ3D-nuScenes, SSCBench-KITTI360) demonstrateconsistent performance gains across various 3D occupancy models (TPVFormer,SurroundOcc, Symphonies), highlighting the robustness and versatility of ourframework. The code is available at https://github.com/valeoai/GaussRender.",Loick Chambon,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05039v1,A spatially resolved and lipid-structured model for macrophage populations in early human atherosclerotic lesions,http://arxiv.org/abs/2502.05039v1,"Atherosclerosis is a chronic inflammatory disease of the artery wall. Theearly stages of atherosclerosis are driven by interactions between lipids andmonocyte-derived-macrophages (MDMs). The mechanisms that govern the spatialdistribution of lipids and MDMs in the lesion remain poorly understood. In thispaper, we develop a spatially-resolved and lipid-structured model for earlyatherosclerosis. The model development and analysis are guided by images ofhuman coronary lesions by Nakashima et al. 2007. Consistent with theirfindings, the model predicts that lipid initially accumulates deep in theintima due to a spatially non-uniform LDL retention capacity. The model alsoqualitatively reproduces the global internal maxima in the Nakashima imagesonly when the MDM mobility is sufficiently sensitive to lipid content, and MDMlifespan sufficiently insensitive. Introducing lipid content-dependence to MDMmobility and mean lifespan produced minimal impact on model behaviour at earlytimes, but strongly impacted lesion composition at steady state. Increases tothe sensitivity of MDM lifespan to lipid content yield lesions with fewer MDMs,less total lesion lipid content and reduced mean MDM infiltration depth.Increases to the sensitivity of MDM mobility to lipid content also reduces theMDM infiltration depth, but increases the proportion of lipid-laden MDMs. Wefind that MDM lipid content increases with spatial depth, regardless of bloodLDL and HDL content. These results shed light on the mechanisms that drivespatial variation in the composition of early atherosclerotic lesions, and therole of macrophage lipid content in disease progression.",Keith L. Chambers,2025-02-07,2025-02-07,,N/A,['q-bio.CB']
2502.05036v1,nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow,http://arxiv.org/abs/2502.05036v1,"Natural Language to Visualization (NL2Vis) seeks to convert natural-languagedescriptions into visual representations of given tables, empowering users toderive insights from large-scale data. Recent advancements in Large LanguageModels (LLMs) show promise in automating code generation to transform tabulardata into accessible visualizations. However, they often struggle with complexqueries that require reasoning across multiple tables. To address thislimitation, we propose a collaborative agent workflow, termed nvAgent, forNL2Vis. Specifically, nvAgent comprises three agents: a processor agent fordatabase processing and context filtering, a composer agent for planningvisualization generation, and a validator agent for code translation and outputverification. Comprehensive evaluations on the new VisEval benchmarkdemonstrate that nvAgent consistently surpasses state-of-the-art baselines,achieving a 7.88% improvement in single-table and a 9.23% improvement inmulti-table scenarios. Qualitative analyses further highlight that nvAgentmaintains nearly a 20% performance margin over previous models, underscoringits capacity to produce high-quality visual representations from complex,heterogeneous data sources.",Geliang Ouyang,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.05035v1,Quantum anomalous Hall domains in a Quenched Topological Mott Insulator,http://arxiv.org/abs/2502.05035v1,"We study an interacting spinless quadratic band touching model that realizesa topological Mott insulating state. We quench the interaction from a valuecorresponding to the nematic insulator to that of the quantum anomalous Hall(QAH) ordered phase. We perform time-dependent Hartree-Fock simulations andshow that after the quench the system realizes an excited Dirac semimetalstate, which is however unstable and spontaneously evolves to a state withinhomogeneous nematic and QAH order parameters. The modulations form a stripepattern that grows exponentially with time until the local Chern marker reachesunity. The alternating QAH order defines a domain structure with boundariesthat host chiral sublattice currents.",Lara Ulčakar,2025-02-07,2025-02-07,,N/A,"['cond-mat.str-el', 'quant-ph']"
2502.05034v1,MindAligner: Explicit Brain Functional Alignment for Cross-Subject Visual Decoding from Limited fMRI Data,http://arxiv.org/abs/2502.05034v1,"Brain decoding aims to reconstruct visual perception of human subject fromfMRI signals, which is crucial for understanding brain's perception mechanisms.Existing methods are confined to the single-subject paradigm due to substantialbrain variability, which leads to weak generalization across individuals andincurs high training costs, exacerbated by limited availability of fMRI data.To address these challenges, we propose MindAligner, an explicit functionalalignment framework for cross-subject brain decoding from limited fMRI data.The proposed MindAligner enjoys several merits. First, we learn a BrainTransfer Matrix (BTM) that projects the brain signals of an arbitrary newsubject to one of the known subjects, enabling seamless use of pre-traineddecoding models. Second, to facilitate reliable BTM learning, a BrainFunctional Alignment module is proposed to perform soft cross-subject brainalignment under different visual stimuli with a multi-level brain alignmentloss, uncovering fine-grained functional correspondences with highinterpretability. Experiments indicate that MindAligner not only outperformsexisting methods in visual decoding under data-limited conditions, but alsoprovides valuable neuroscience insights in cross-subject functional analysis.The code will be made publicly available.",Yuqin Dai,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05032v1,News about Global North considered Truthful! The Geo-political Veracity Gradient in Global South News,http://arxiv.org/abs/2502.05032v1,"While there has been much research into developing AI techniques for fakenews detection aided by various benchmark datasets, it has often been pointedout that fake news in different geo-political regions traces differentcontours. In this work we uncover, through analytical arguments and empiricalevidence, the existence of an important characteristic in news originating fromthe Global South viz., the geo-political veracity gradient. In particular, weshow that Global South news about topics from Global North -- such as news froman Indian news agency on US elections -- tend to be less likely to be fake.Observing through the prism of the political economy of fake news creation, weposit that this pattern could be due to the relative lack of monetarily alignedincentives in producing fake news about a different region than the regionalremit of the audience. We provide empirical evidence for this from benchmarkdatasets. We also empirically analyze the consequences of this effect inapplying AI-based fake news detection models for fake news AI trained on oneregion within another regional context. We locate our work within emergingcritical scholarship on geo-political biases within AI in general, particularlywith AI usage in fake news identification; we hope our insight into thegeo-political veracity gradient could help steer fake news AI scholarshiptowards positively impacting Global South societies.",Sujit Mandava,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.05030v1,Scaling of highly excited Schrödinger-Poisson eigenstates and universality of their rotation curves,http://arxiv.org/abs/2502.05030v1,"This work provides a comprehensive numerical characterization of the excitedspherically symmetric stationary states of the Schr\""odinger-Poisson problem.The analysis is conducted with reference to dark matter distributions aroundgalaxies; the squared modulus of the eigenfunction represents the dark matterdensity distribution, and an associated eigenvelocity models the experimentalgalactic rotation curves. This paper aims to establish a connection between thefundamental structure of these eigenfunctions and eigenvelocities and thephysical properties of the system.  Through numerical simulations of highly excited eigenstates, novel heuristiclaws are proposed, which describe how their fundamental features scale with theexcitation index $n$. Key characteristics of the eigenfunctions include: theeffective support, which exhibits a parabolic dependence on the excitationindex; the distances between adjacent nodes, whose pattern varies regularlywith $n$; and the oscillation amplitude, which follows a power law with anexponent approaching $-1$ for large $n$, consistent with astrophysicalobservations. The eigenvelocities exhibit a mid-range oscillatory region withan average linear trend, whose slope approaches zero in the large $n$ limit,consistent with the physical expectation of a flat plateau for the rotationcurves. Additionally, we derive heuristic scaling relationships with theexcitation index $n$, revealing a universal behavior in the predicted rotationcurves.",Gaia Marangon,2025-02-07,2025-02-07,,N/A,"['math-ph', 'math.MP']"
2502.05029v1,Assessment of averaged 1D models for column adsorption with 3D computational experiments,http://arxiv.org/abs/2502.05029v1,"In the present manuscript, we formulate a 3D mathematical model describingthe capture of a contaminant in an adsorption column. The novelty of ourapproach involves the description of mass transfer by adsorption via anevolution equation defined on the surface of the porous media, while Stokesflow and an advection-diffusion equation describe the contaminant transportthrough the interstices. Numerical simulations of the 3D model on differentporous geometries, with the same porosity but different microstructure, haverevealed a minimal impact of the microstructure on contaminant distributionwithin the column. Of particular interest is the little variation in the radialdirection. Then, assuming a fine structure made of a periodic array of spheresand employing homogenization theory, we have rigorously derived an averaged 1Dmodel of column adsorption. The model has the same mathematical form than thestandard 1D column adsorption model, but contains a dispersion coefficient thatexplicitly incorporates microstructural details of the porous media.Consequently, our model offers a theoretical foundation for the widely used 1Dmodel in the literature. Lastly, we compare the numerical solution of the 1Dmodel with numerical simulations of the 3D model. The concentration profiles ofthe 1D model closely match the cross-section averaged concentration profiles ofthe 3D model. Likewise, the contaminant breakthrough curves at the outlet ofboth models are nearly indistinguishable. These results confirm the reliabilityof 1D models for investigating, optimizing, and aiding in the design of columnadsorption processes for practical applications.",Maria Aguareles,2025-02-07,2025-02-07,,N/A,['physics.flu-dyn']
2502.05027v1,Trust-Aware Diversion for Data-Effective Distillation,http://arxiv.org/abs/2502.05027v1,"Dataset distillation compresses a large dataset into a small synthetic subsetthat retains essential information. Existing methods assume that all samplesare perfectly labeled, limiting their real-world applications where incorrectlabels are ubiquitous. These mislabeled samples introduce untrustworthyinformation into the dataset, which misleads model optimization in datasetdistillation. To tackle this issue, we propose a Trust-Aware Diversion (TAD)dataset distillation method. Our proposed TAD introduces an iterative dual-loopoptimization framework for data-effective distillation. Specifically, the outerloop divides data into trusted and untrusted spaces, redirecting distillationtoward trusted samples to guarantee trust in the distillation process. Thisstep minimizes the impact of mislabeled samples on dataset distillation. Theinner loop maximizes the distillation objective by recalibrating untrustedsamples, thus transforming them into valuable ones for distillation. Thisdual-loop iteratively refines and compensates for each other, graduallyexpanding the trusted space and shrinking the untrusted space. Experimentsdemonstrate that our method can significantly improve the performance ofexisting dataset distillation methods on three widely used benchmarks (CIFAR10,CIFAR100, and Tiny ImageNet) in three challenging mislabeled settings(symmetric, asymmetric, and real-world).",Zhuojie Wu,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.05025v1,Impact of radiative accelerations on the stellar characterization of FGK-type stars using spectroscopic and seismic constraints,http://arxiv.org/abs/2502.05025v1,"Chemical transport mechanisms are fundamental processes in stellar evolutionmodels. They are responsible for the chemical distribution, and their impactdetermines how accurately we can characterize stars. Radiative accelerationsare one of these processes. They allow the accumulation of elements atdifferent depths in the star. We aim to assess the impact of radiativeaccelerations on the modeling of FGK-type stars and their impact on theprediction of surface abundances. To reduce the cost of the computation ofradiative accelerations, we implemented the single-valued parameters (SVP)method in the stellar evolution code MESA. The SVP method is more efficient incalculating radiative accelerations, which enables computations of large enoughgrids of models for stellar characterization. Compared to models that includeatomic diffusion (with only gravitational settling), the inclusion of radiativeaccelerations has a small effect on the inference of fundamental properties,with an impact of 2\%, 0.7\%, and 5\% for mass, radius, and age. However, thetreatment of radiative accelerations is necessary to predict the chemicalcomposition of and accurately characterize stars.",Nuno Moedas,2025-02-07,2025-02-07,,N/A,['astro-ph.SR']
2502.05024v1,Prospects for detecting generic fast-time features in the neutrino lightcurve of nearby supernovae in neutrino telescopes,http://arxiv.org/abs/2502.05024v1,"Neutrino emission offers a direct probe into the hydrodynamics and energytransport processes within a supernova. Fast-time variations in the neutrinoluminosity and mean energy can provide insights into phenomena like turbulence,convection, and shock revival. In this paper, we explore the detectioncapabilities of large-volume neutrino telescopes such as the IceCube NeutrinoObservatory and the planned IceCube-Gen2 detector in identifying genericfast-time features in the neutrino light curve. We also investigate thepotential enhancement in detection sensitivity using wavelength shifters, whichcan improve light collection efficiency. By employing a Short-Time FourierTransform analysis, we quantify the excess power in the frequency spectrumarising from fast-time modulations and compute the detection horizon for arange of generic models. We find that with IceCube we can already see thestrongest modulation models (>50% amplitude) for progenitors located anywherein the Milky Way. Sensitivity to weaker modulations (>20% amplitude) ispossible in future detectors like IceCube-Gen2, in particular with the use ofwavelength shifters. For all detector configurations, the frequency and centraltime of the fast-time feature at the 5$\sigma$ detection horizon can bemeasured with a resolution of 7.0 Hz and 17 ms respectively.",Jakob Beise,2025-02-07,2025-02-07,,N/A,"['astro-ph.HE', 'astro-ph.IM']"
2502.05023v1,On the Possibility of Breaking Copyleft Licenses When Reusing Code Generated by ChatGPT,http://arxiv.org/abs/2502.05023v1,"AI assistants can help developers by recommending code to be included intheir implementations (e.g., suggesting the implementation of a method from itssignature). Although useful, these recommendations may mirror copyleft codeavailable in public repositories, exposing developers to the risk of reusingcode that they are allowed to reuse only under certain constraints (e.g., aspecific license for the derivative software). This paper presents alarge-scale study about the frequency and magnitude of this phenomenon inChatGPT. In particular, we generate more than 70,000 method implementationsusing a range of configurations and prompts, revealing that a larger contextincreases the likelihood of reproducing copyleft code, but higher temperaturesettings can mitigate this issue.",Gaia Colombo,2025-02-07,2025-02-07,,N/A,['cs.SE']
2502.05021v1,Stability and performance guarantees for misspecified multivariate score-driven filters,http://arxiv.org/abs/2502.05021v1,"We consider the problem of tracking latent time-varying parameter vectorsunder model misspecification. We analyze implicit and explicit score-driven(ISD and ESD) filters, which update a prediction of the parameters using thegradient of the logarithmic observation density (i.e., the score). In the ESDfilter, the score is computed using the predicted parameter values, whereas inthe ISD filter, the score is evaluated using the new, updated parameter values.For both filter types, we derive novel sufficient conditions for theexponential stability (i.e., invertibility) of the filtered parameter path andexistence of a finite mean squared error (MSE) bound with respect to thepseudo-true parameter path. In addition, we present expressions forfinite-sample and asymptotic MSE bounds. Our performance guarantees rely onmild moment conditions on the data-generating process, while our stabilityresult is entirely agnostic about the true process. As a result, our primaryconditions depend only on the characteristics of the filter; hence, they areverifiable in practice. Concavity of the postulated log density combined withsimple parameter restrictions is sufficient (but not necessary) for ISD-filterstability, whereas ESD-filter stability additionally requires the score to beLipschitz continuous. Extensive simulation studies validate our theoreticalfindings and demonstrate the enhanced stability and improved performance of ISDover ESD filters. An empirical application to U.S. Treasury-bill rates confirmsthe practical relevance of our contribution.",Simon Donker van Heel,2025-02-07,2025-02-07,,N/A,"['stat.ME', 'eess.SP', 'stat.ML']"
2502.05020v1,Analog and Multi-modal Manufacturing Datasets Acquired on the Future Factories Platform V2,http://arxiv.org/abs/2502.05020v1,"This paper presents two industry-grade datasets captured during an 8-hourcontinuous operation of the manufacturing assembly line at the Future FactoriesLab, University of South Carolina, on 08/13/2024. The datasets adhere toindustry standards, covering communication protocols, actuators, controlmechanisms, transducers, sensors, and cameras. Data collection utilized bothintegrated and external sensors throughout the laboratory, including sensorsembedded within the actuators and externally installed devices. Additionally,high-performance cameras captured key aspects of the operation. In a priorexperiment [1], a 30-hour continuous run was conducted, during which allanomalies were documented. Maintenance procedures were subsequently implementedto reduce potential errors and operational disruptions. The two datasetsinclude: (1) a time-series analog dataset, and (2) a multi-modal time-seriesdataset containing synchronized system data and images. These datasets aim tosupport future research in advancing manufacturing processes by providing aplatform for testing novel algorithms without the need to recreate physicalmanufacturing environments. Moreover, the datasets are open-source and designedto facilitate the training of artificial intelligence models, streamliningresearch by offering comprehensive, ready-to-use resources for variousapplications and projects.",Ramy Harik,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.05017v1,Bridging Voting and Deliberation with Algorithms: Field Insights from vTaiwan and Kultur Komitee,http://arxiv.org/abs/2502.05017v1,"Democratic processes increasingly aim to integrate large-scale voting withface-to-face deliberation, addressing the challenge of reconciling individualpreferences with collective decision-making. This work introduces new methodsthat use algorithms and computational tools to bridge online voting withface-to-face deliberation, tested in two real-world scenarios: Kultur Komitee2024 (KK24) and vTaiwan. These case studies highlight the practicalapplications and impacts of the proposed methods.  We present three key contributions: (1) Radial Clustering for PreferenceBased Subgroups, which enables both in-depth and broad discussions indeliberative settings by computing homogeneous and heterogeneous groupcompositions with balanced and adjustable group sizes; (2) Human-in-the-loopMES, a practical method that enhances the Method of Equal Shares (MES)algorithm with real-time digital feedback. This builds algorithmic trust bygiving participants full control over how much decision-making is delegated tothe voting aggregation algorithm as compared to deliberation; and (3) theReadTheRoom deliberation method, which uses opinion space mapping to identifyagreement and divergence, along with spectrum-based preference visualisation totrack opinion shifts during deliberation. This approach enhances transparencyby clarifying collective sentiment and fosters collaboration by encouragingparticipants to engage constructively with differing perspectives.  By introducing these actionable frameworks, this research extends in-persondeliberation with scalable digital methods that address the complexities ofmodern decision-making in participatory processes.",Joshua C. Yang,2025-02-07,2025-02-07,,N/A,"['cs.HC', 'cs.AI', 'econ.GN', 'q-fin.EC', '91B14, 91B12, 91A12, 68T01, 68T20, 68U35', 'H.5.3; I.2.0; I.2.11; J.1; G.2.0; G.2.2; K.4.1; K.4.3']"
2502.05016v1,Impact of Model Mismatch on DOA Estimation with MUSIC: Near-Field and Far-Field,http://arxiv.org/abs/2502.05016v1,"There has been substantial work on developing variants of the multiple signalclassification (MUSIC) algorithms that take advantage of the informationpresent in the near-field propagation regime. However, it is not always easy todetermine the correct propagation regime, which opens the possibility ofincorrectly applying simpler algorithms (meant for far-field) in the near-fieldregime. Inspired by this, we use simulation results to investigate theperformance drop when there is a mismatch between the signal model in the MUSICalgorithm and the propagation regime. For direction of arrival (DOA)estimation, we consider the cases when the receiver is in the near-field regionbut uses i) the near-field model, ii) the approximate near-field model (ANM)model, and iii) the far-field model to design the beamforming matrix in theMUSIC algorithm. We also consider the case when the receiver is in thefar-field region, and we use the correct far-field model to design thebeamforming matrix in the MUSIC algorithm. One contribution is that in thenear-field, we have quantified the loss in performance when the ANM and thefar-field model are used to create the beamforming matrix for the MUSICalgorithm, causing a reduction in estimation accuracy compared to the case whenthe correct near-field model is used to design the beamforming matrix. Anotherresult is that in the near-field, when we incorrectly assume that the receiveris in the far-field and subsequently use the far-field beamforming matrix, weunderestimate the DOA estimation error. Finally, we show that the MUSICalgorithm can provide very accurate range estimates for distances less than theFraunhofer distance. This estimate gradually becomes inaccurate as thedistances exceed the Fraunhofer distance.",Don-Roberts Emenonye,2025-02-07,2025-02-07,,N/A,['eess.SP']
2502.05014v1,Seasonal Station-Keeping of Short Duration High Altitude Balloons using Deep Reinforcement Learning,http://arxiv.org/abs/2502.05014v1,"Station-Keeping short-duration high-altitude balloons (HABs) in a region ofinterest is a challenging path-planning problem due to partially observable,complex, and dynamic wind flows. Deep reinforcement learning is a popularstrategy for solving the station-keeping problem. A custom simulationenvironment was developed to train and evaluate Deep Q-Learning (DQN) forshort-duration HAB agents in the simulation. To train the agents on realisticwinds, synthetic wind forecasts were generated from aggregated historicalradiosonde data to apply horizontal kinematics to simulated agents. Thesynthetic forecasts were closely correlated with ECWMF ERA5 Reanalysisforecasts, providing a realistic simulated wind field and seasonal andaltitudinal variances between the wind models. DQN HAB agents were then trainedand evaluated across different seasonal months. To highlight differences andtrends in months with vastly different wind fields, a Forecast Score algorithmwas introduced to independently classify forecasts based on wind diversity, andtrends between station-keeping success and the Forecast Score were evaluatedacross all seasons.",Tristan K. Schuler,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.RO', 'physics.ao-ph']"
2502.05013v1,Output-Feedback Full-State Targeting Model Predictive Control for Station-Keeping on Near-Rectilinear Halo Orbits,http://arxiv.org/abs/2502.05013v1,"We develop a model predictive control (MPC) policy for station-keeping (SK)on a Near-Rectilinear Halo Orbit (NRHO). The proposed policy achievesfull-state tracking of a reference NRHO via a two-maneuver control horizonplaced one revolution apart. Our method abides by the typical missionrequirement that at most one maneuver is used for SK during each NRHOrevolution. Simultaneously, the policy has sufficient controllability forfull-state tracking, making it immune to phase deviation issues in thealong-track direction of the reference NRHO, a common drawback of existing SKmethods with a single maneuver per revolution. We report numerical simulationswith a navigation filter to demonstrate the MPC's performance with outputfeedback. Our approach successfully maintains the spacecraft's motion in thevicinity of the reference in both space and phase, with tighter tracking thanstate-of-the-art SK methods and comparable delta-V performance.",Yuri Shimane,2025-02-07,2025-02-07,,N/A,"['eess.SY', 'cs.SY', 'math.OC']"
2502.05012v1,EnseSmells: Deep ensemble and programming language models for automated code smells detection,http://arxiv.org/abs/2502.05012v1,"A smell in software source code denotes an indication of suboptimal designand implementation decisions, potentially hindering the code understanding and,in turn, raising the likelihood of being prone to changes and faults.Identifying these code issues at an early stage in the software developmentprocess can mitigate these problems and enhance the overall quality of thesoftware. Current research primarily focuses on the utilization of deeplearning-based models to investigate the contextual information concealedwithin source code instructions to detect code smells, with limited attentiongiven to the importance of structural and design-related features. This paperproposes a novel approach to code smell detection, constructing a deep learningarchitecture that places importance on the fusion of structural features andstatistical semantics derived from pre-trained models for programminglanguages. We further provide a thorough analysis of how different source codeembedding models affect the detection performance with respect to differentcode smell types. Using four widely-used code smells from well-designeddatasets, our empirical study shows that incorporating design-related featuressignificantly improves detection accuracy, outperforming state-of-the-artmethods on the MLCQ dataset with with improvements ranging from 5.98% to28.26%, depending on the type of code smell.",Anh Ho,2025-02-07,2025-02-07,,N/A,['cs.SE']
2502.05011v1,Learning the Language of NVMe Streams for Ransomware Detection,http://arxiv.org/abs/2502.05011v1,"We apply language modeling techniques to detect ransomware activity in NVMecommand sequences. We design and train two types of transformer-based models:the Command-Level Transformer (CLT) performs in-context token classification todetermine whether individual commands are initiated by ransomware, and thePatch-Level Transformer (PLT) predicts the volume of data accessed byransomware within a patch of commands. We present both model designs and thecorresponding tokenization and embedding schemes and show that they improveover state-of-the-art tabular methods by up to 24% in missed-detection rate,66% in data loss prevention, and 84% in identifying data accessed byransomware.",Barak Bringoltz,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.CR']"
2502.05007v1,Analyzing Advanced AI Systems Against Definitions of Life and Consciousness,http://arxiv.org/abs/2502.05007v1,"Could artificial intelligence ever become truly conscious in a functionalsense; this paper explores that open-ended question through the lens of Life, aconcept unifying classical biological criteria (Oxford, NASA, Koshland) withempirical hallmarks such as adaptive self maintenance, emergent complexity, andrudimentary self referential modeling. We propose a number of metrics forexamining whether an advanced AI system has gained consciousness, whileemphasizing that we do not claim all AI stems can become conscious. Rather, wesuggest that sufficiently advanced architectures exhibiting immune likesabotage defenses, mirror self-recognition analogs, or meta-cognitive updatesmay cross key thresholds akin to life-like or consciousness-like traits. Todemonstrate these ideas, we start by assessing adaptive self-maintenancecapability, and introduce controlled data corruption sabotage into the trainingprocess. The result demonstrates AI capability to detect these inconsistenciesand revert or self-correct analogous to regenerative biological processes. Wealso adapt an animal-inspired mirror self recognition test to neuralembeddings, finding that partially trained CNNs can distinguish self fromforeign features with complete accuracy. We then extend our analysis byperforming a question-based mirror test on five state-of-the-art chatbots(ChatGPT4, Gemini, Perplexity, Claude, and Copilot) and demonstrated theirability to recognize their own answers compared to those of the other chatbots.",Azadeh Alavi,2025-02-07,2025-02-07,,N/A,['cs.AI']
2502.05006v1,Dipole-Mode Spectrum and Hydrodynamic Crossover in a Resonantly Interacting Two-Species Fermion Mixture,http://arxiv.org/abs/2502.05006v1,"Ultracold quantum-gas mixtures of fermionic atoms with resonant control ofinteractions offer a unique test-bed to explore few- and many-body quantumstates with unconventional properties. The emergence of such stronglycorrelated systems, as for instance symmetry-broken superfluids, is usuallyaccompanied by hydrodynamic collective behavior. Thus, experimental progress inthis field naturally requires a deep understanding of hydrodynamic regimes.Here, we report on experiments employing a tunable Fermi-Fermi mixture of$^{161}$Dy and $^{40}$K near quantum degeneracy. We investigate the fullspectrum of dipole modes across a Feshbach resonance and characterize thecrossover from collisionless to deep hydrodynamic behavior in measurements offrequencies and damping rates. We compare our results with a theoretical modelthat considers the motion of the mass centers of the two species and weidentify the contributions of friction and mean-field interaction. We show thatone oscillating mode exists over the whole range of interactions, exhibitingstriking changes of frequency and damping in the deep hydrodynamic regime. Weobserve the second oscillating mode to split into two purely exponentialdamping modes. One of these exponential modes shows very fast damping, fasterthan any other relevant timescale, and is largely insensitive againstexperimental imperfections. It provides an accurate measure for theinterspecies drag effect, which generalizes the concept of spin drag exploredin other experiments. We characterize the interspecies drag locally in terms ofa microscopic friction coefficient and we discuss its unitarity-limiteduniversal behavior on top of the resonance.",Zhu-Xiong Ye,2025-02-07,2025-02-07,,N/A,['cond-mat.quant-gas']
2502.05004v1,"R3F: An R package for evolutionary dates, rates, and priors using the relative rate framework",http://arxiv.org/abs/2502.05004v1,"The relative rate framework (RRF) can estimate divergence times from branchlengths in a phylogeny, which is the theoretical basis of the RelTime methodfrequently applied, a relaxed clock approach for molecular dating that scaleswell for large phylogenies. The use of RRF has also enabled the development ofcomputationally efficient and accurate methods for testing the autocorrelationof lineage rates in a phylogeny (CorrTest) and selecting data-driven parametersof the birth-death speciation model (ddBD), which can be used to specify priorsin Bayesian molecular dating. We have developed R3F, an R package implementingRRF to estimate divergence times, infer lineage rates, conduct CorrTest, andbuild a ddBD tree prior for Bayesian dating in molecular phylogenies. Here, wedescribe R3F functionality and explain how to interpret and use its outputs inother visualization software and packages, such as MEGA, ggtree, and FigTree.Ultimately, R3F is intended to enable the dating of the Tree of Life withgreater accuracy and precision, which would have important implications forstudies of organism evolution, diversification dynamics, phylogeography, andbiogeography. Availability and Implementation: The source codes and relatedinstructions for installing and implementing R3F are available from GitHub(https://github.com/cathyqqtao/R3F).",Qiqing Tao,2025-02-07,2025-02-07,,N/A,"['q-bio.PE', 'q-bio.QM']"
2502.05003v1,QuEST: Stable Training of LLMs with 1-Bit Weights and Activations,http://arxiv.org/abs/2502.05003v1,"One approach to reducing the massive costs of large language models (LLMs) isthe use of quantized or sparse representations for training or deployment.While post-training compression methods are very popular, the question ofobtaining even more accurate compressed models by directly training over suchrepresentations, i.e., Quantization-Aware Training (QAT), is still open: forexample, a recent study (arXiv:2411.04330v2) put the ""optimal"" bit-width atwhich models can be trained using QAT, while staying accuracy-competitive withstandard FP16/BF16 precision, at 8-bits weights and activations.  We advance this state-of-the-art via a new method called QuEST, which isPareto-competitive with FP16, i.e., it provides better accuracy at lower modelsize, while training models with weights and activations in 4-bits or less.Moreover, QuEST allows stable training with 1-bit weights and activations.QuEST achieves this by improving two key aspects of QAT methods: (1) accurateand fast quantization of the (continuous) distributions of weights andactivations via Hadamard normalization and MSE-optimal fitting; (2) a new trustgradient estimator based on the idea of explicitly minimizing the error betweenthe noisy gradient computed over quantized states and the ""true"" (but unknown)full-precision gradient. Experiments on Llama-type architectures show thatQuEST induces stable scaling laws across the entire range of hardware-supportedprecisions, and can be extended to sparse representations. We provide GPUkernel support showing that models produced by QuEST can be executedefficiently. Our code is available at https://github.com/IST-DASLab/QuEST.",Andrei Panferov,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.05002v1,Scattered synchrotron emission and a giant torus revealed in polarized light in the nearest radio galaxy Centaurus A,http://arxiv.org/abs/2502.05002v1,"Centaurus A (Cen A) is the closest radio galaxy and a prime example of alow-luminosity active galactic nucleus (AGN), exhibiting complex emissionsacross the electromagnetic spectrum. The nature of its continuum emission,particularly the mechanisms powering it, has been a subject of considerabledebate due to the fact that the AGN is deeply buried in dust. This study aimsto elucidate the origin of the continuum emission in Cen A and determine thegeometrical arrangement of matter in the nuclear region by the mean of opticaland near-infrared spectropolarimetry. We obtained spectropolarimetric data ofCen A using the VLT/FORS2. The analysis revealed a region showing strong andnarrow emission lines associated with AGN activity. After correction forinterstellar polarization in the dust lane (but not for starlight), theintrinsic polarization of the scattered AGN light exhibits a polarizationdegree of 2-4%, decreasing from optical to near-infrared, associated with apolarization position angle perpendicular to the radio jet axis. We exclude thepresence of hidden broad line in our polarized flux spectrum at more than 99%probability. Narrow emission lines are found to be strongly polarized andorthogonal to the jet position angle. We demonstrate that a beamed synchrotronjet, scattering onto the narrow line region (NLR) best fits all theobservational properties reported in this paper and the literature. In thismodel, the base of the NLR is obscured by a giant circumnuclear region and canonly become visible through perpendicular scattering onto the outermost part ofthe NLR, naturally producing high polarization degrees and polarization anglesperpendicular to the radio structure. This study provides strong evidence thatCen A defines a new class of hidden-NLR AGNs and supports old predictions thatbeamed synchrotron jets can be observed in reflection.",F. Marin,2025-02-07,2025-02-07,,N/A,"['astro-ph.GA', '85-06', 'J.2.3; J.2.9']"
2502.05001v1,A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach,http://arxiv.org/abs/2502.05001v1,"Learned Index Structures (LIS) have significantly advanced data management byleveraging machine learning models to optimize data indexing. However,designing these structures often involves critical trade-offs, making itchallenging for both designers and end-users to find an optimal balancetailored to specific workloads and scenarios. While some indexes offeradjustable parameters that demand intensive manual tuning, others rely on fixedconfigurations based on heuristic auto-tuners or expert knowledge, which maynot consistently deliver optimal performance.  This paper introduces LITune, a novel framework for end-to-end automatictuning of Learned Index Structures. LITune employs an adaptive trainingpipeline equipped with a tailor-made Deep Reinforcement Learning (DRL) approachto ensure stable and efficient tuning. To accommodate long-term dynamicsarising from online tuning, we further enhance LITune with an on-the-flyupdating mechanism termed the O2 system. These innovations allow LITune toeffectively capture state transitions in online tuning scenarios anddynamically adjust to changing data distributions and workloads, marking asignificant improvement over other tuning methods. Our experimental resultsdemonstrate that LITune achieves up to a 98% reduction in runtime and a 17-foldincrease in throughput compared to default parameter settings given a selectedLearned Index instance. These findings highlight LITune's effectiveness and itspotential to facilitate broader adoption of LIS in real-world applications.",Taiyi Wang,2025-02-07,2025-02-07,,N/A,"['cs.DB', 'cs.AI', 'cs.SY', 'eess.SY']"
2502.05000v1,Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification,http://arxiv.org/abs/2502.05000v1,"Adversarial evasion attacks pose significant threats to graph learning, withlines of studies that have improved the robustness of Graph Neural Networks(GNNs). However, existing works rely on priors about clean graphs or attackingstrategies, which are often heuristic and inconsistent. To achieve robust graphlearning over different types of evasion attacks and diverse datasets, weinvestigate this problem from a prior-free structure purification perspective.Specifically, we propose a novel Diffusion-based Structure Purificationframework named DiffSP, which creatively incorporates the graph diffusion modelto learn intrinsic distributions of clean graphs and purify the perturbedstructures by removing adversaries under the direction of the capturedpredictive patterns without relying on priors. DiffSP is divided into theforward diffusion process and the reverse denoising process, during whichstructure purification is achieved. To avoid valuable information loss duringthe forward process, we propose an LID-driven nonisotropic diffusion mechanismto selectively inject noise anisotropically. To promote semantic alignmentbetween the clean graph and the purified graph generated during the reverseprocess, we reduce the generation uncertainty by the proposed graph transferentropy guided denoising mechanism. Extensive experiments demonstrate thesuperior robustness of DiffSP against evasion attacks.",Jiayi Luo,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04999v1,"Nuclear size, electric monopole transitions, and the location of $0^+_2$ states",http://arxiv.org/abs/2502.04999v1,"The work addresses the isotopic shift of nuclear radii for the even-even$^{36-52}$Ca isotopes using the interacting boson model (IBM) that includes themixing from normal and intruder configurations. We obtain a good agreementbetween the calculated and experimental data, particularly for the dip at$^{48}$Ca. A direct correlation between nuclear size and electric monopoletransitions is established to compute the electric monopole transitionstrengths, $\rho^2(E0)$. We further study the isotopic shift for the even-even$^{32-46}$Ar and $^{44-50}$Ti isotopes.",B. Maheshwari,2025-02-07,2025-02-07,,N/A,['nucl-th']
2502.04997v1,Aligning Black-box Language Models with Human Judgments,http://arxiv.org/abs/2502.04997v1,"Large language models (LLMs) are increasingly used as automated judges toevaluate recommendation systems, search engines, and other subjective tasks,where relying on human evaluators can be costly, time-consuming, andunscalable. LLMs offer an efficient solution for continuous, automatedevaluation. However, since the systems that are built and improved with thesejudgments are ultimately designed for human use, it is crucial that LLMjudgments align closely with human evaluators to ensure such systems remainhuman-centered. On the other hand, aligning LLM judgments with human evaluatorsis challenging due to individual variability and biases in human judgments. Wepropose a simple yet effective framework to align LLM judgments with individualhuman evaluators or their aggregated judgments, without retraining orfine-tuning the LLM. Our approach learns a linear mapping between the LLM'soutputs and human judgments, achieving over 142% average improvement inagreement across 29 tasks with only a small number of calibration examples usedfor training. Notably, our method works in zero-shot and few-shot settings,exceeds inter-human agreement on four out of six tasks, and enables smallerLLMs to achieve performance comparable to that of larger models.",Gerrit J. J. van den Burg,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI', 'cs.LG', '68T50', 'I.2.7']"
2502.04996v1,Newtonian Gravity from a Poissonian Spontaneous Collapse Model,http://arxiv.org/abs/2502.04996v1,"The Tilloy-Di\'osi (TD) prescription allows to turn any Markovian spontaneouscollapse model that can be formally regarded as a continuous measurementprocess of the mass density into a hybrid classical-quantum theory in which thegravitational Newtonian field enters as a classical field. We study theapplication of a similar idea to the Poissonian Spontaneous Localization (PSL)model. As in the TD case, the Newtonian classical field is again recovered uponaveraging, and additional decoherence appears due to the gravitationalback-reaction. We study general features of this model and investigate thedynamics of a single particle and a rigid spherical body. With respect to theTD models, the PSL model presents some notable differences such as the absenceof long-range decoherence due to the gravitational back-reaction noise and theabsence of negative mass measurements.",Nicolò Piccione,2025-02-07,2025-02-07,,N/A,['quant-ph']
2502.04993v1,Transport Characteristics and Modelling of ST40 Hot Ion Plasmas,http://arxiv.org/abs/2502.04993v1,"In this paper, the turbulent transport properties of ST40 hot ion plasmas areexamined and fully predictive time evolving modelling of a hot ion plasma pulsewas performed. Understanding turbulent transport on spherical tokamaks (STs) ischallenging due to their unique geometry characteristics. ST40 hot ion plasmasare typically unstable to ion scale Trapped Electron Modes (TEMs) andUbiquitous Modes (UMs), driven from the kinetic response of trapped particlesand passing ions, and electron scale Electron Temperature Gradient Modes (ETGs)at the edge of the plasma. A comparison between the linear unstable modes ofthe gyro-kinetic code GS2 and the gyro-fluid code TGLF showed that both modelsagree to a satisfactory level. However, some discrepancy was observed at thecore of the plasma where a large fraction of beams ions exists, andelectromagnetic effects are potentially important. Turbulent fluxes were alsoobserved to be somewhat overpredicted with TGLF. The core heat ion transport isobserved to be close to neoclassical levels due to turbulence suppression fromhigh rotation and fast ion stabilisation, while the edge region is dominated byanomalous transport in both ions and electrons. As a result, enhanced energyconfinement is observed in those plasmas driven by the reduced turbulent coreregion and the confined beam ions. Fully predictive simulations using the ASTRAtransport solver coupled with SPIDER, NUBEAM, NCLASS and TGLF together with anovel reduced scrape of layer (SOL) model for the simulation of the last closedflux surface (LCFS) boundary conditions was attempted. Agreement in globalquantities but also kinetic profiles between the predictive and interpretativemodelling as well as experimental measurements was observed.",MS Anastopoulos Tzanis,2025-02-07,2025-02-07,,N/A,['physics.plasm-ph']
2502.04991v1,C2GM: Cascading Conditional Generation of Multi-scale Maps from Remote Sensing Images Constrained by Geographic Features,http://arxiv.org/abs/2502.04991v1,"Multi-scale maps are essential representations of surveying and cartographicresults, serving as fundamental components of geographic services. Currentimage generation networks can quickly produce map tiles from remote-sensingimages. However, generative models designed for natural images often focus ontexture features, neglecting the unique characteristics of remote-sensingfeatures and the scale attributes of tile maps. This limitation in generativemodels impairs the accurate representation of geographic information, and thequality of tile map generation still needs improvement. Diffusion models havedemonstrated remarkable success in various image generation tasks, highlightingtheir potential to address this challenge. This paper presents C2GM, a novelframework for generating multi-scale tile maps through conditional guideddiffusion and multi-scale cascade generation. Specifically, we implement aconditional feature fusion encoder to extract object priors from remote sensingimages and cascade reference double branch input, ensuring an accuraterepresentation of complex features. Low-level generated tiles act asconstraints for high-level map generation, enhancing visual continuity.Moreover, we incorporate map scale modality information using CLIP to simulatethe relationship between map scale and cartographic generalization in tilemaps. Extensive experimental evaluations demonstrate that C2GM consistentlyachieves the state-of-the-art (SOTA) performance on all metrics, facilitatingthe rapid and effective generation of multi-scale large-format maps foremergency response and remote mapping applications.",Chenxing Sun,2025-02-07,2025-02-07,,N/A,"['eess.IV', 'cs.CV']"
2502.04990v1,Probabilistic Programming with Sufficient Statistics for faster Bayesian Computation,http://arxiv.org/abs/2502.04990v1,"Probabilistic programming methods have revolutionised Bayesian inference,making it easier than ever for practitioners to performMarkov-chain-Monte-Carlo sampling from non-conjugate posterior distributions.Here we focus on Stan, arguably the most used probabilistic programming toolfor Bayesian inference (Carpenter et al., 2017), and its interface with R viathe brms (Burkner, 2017) and rstanarm (Goodrich et al., 2024) packages.Although easy to implement, these tools can become computationally prohibitivewhen applied to datasets with many observations or models with numerousparameters. While the use of sufficient statistics is well-established intheory, it has been surprisingly overlooked in state-of-the-art Stan software.We show that when the likelihood can be written in terms of sufficientstatistics, considerable computational improvements can be made to currentimplementations. We demonstrate how this approach provides accurate inferenceat a fraction of the time than state-of-the-art implementations for Gaussianlinear regression models with non-conjugate priors, hierarchical random effectsmodels, and factor analysis models. Our results also show that moderatecomputational gains can be achieved even in models where the likelihood canonly be partially written in terms of sufficient statistics.",Clemens Pichler,2025-02-07,2025-02-07,,N/A,['stat.CO']
2502.04988v1,CMamba: Learned Image Compression with State Space Models,http://arxiv.org/abs/2502.04988v1,"Learned Image Compression (LIC) has explored various architectures, such asConvolutional Neural Networks (CNNs) and transformers, in modeling imagecontent distributions in order to achieve compression effectiveness. However,achieving high rate-distortion performance while maintaining low computationalcomplexity (\ie, parameters, FLOPs, and latency) remains challenging. In thispaper, we propose a hybrid Convolution and State Space Models (SSMs) basedimage compression framework, termed \textit{CMamba}, to achieve superiorrate-distortion performance with low computational complexity. Specifically,CMamba introduces two key components: a Content-Adaptive SSM (CA-SSM) moduleand a Context-Aware Entropy (CAE) module. First, we observed that SSMs excel inmodeling overall content but tend to lose high-frequency details. In contrast,CNNs are proficient at capturing local details. Motivated by this, we proposethe CA-SSM module that can dynamically fuse global content extracted by SSMblocks and local details captured by CNN blocks in both encoding and decodingstages. As a result, important image content is well preserved duringcompression. Second, our proposed CAE module is designed to reduce spatial andchannel redundancies in latent representations after encoding. Specifically,our CAE leverages SSMs to parameterize the spatial content in latentrepresentations. Benefiting from SSMs, CAE significantly improves spatialcompression efficiency while reducing spatial content redundancies. Moreover,along the channel dimension, CAE reduces inter-channel redundancies of latentrepresentations via an autoregressive manner, which can fully exploit priorknowledge from previous channels without sacrificing efficiency. Experimentalresults demonstrate that CMamba achieves superior rate-distortion performance.",Zhuojie Wu,2025-02-07,2025-02-07,,N/A,"['eess.IV', 'cs.CV']"
2502.04987v1,Passive feedback control for nonlinear systems,http://arxiv.org/abs/2502.04987v1,"Dynamical systems can be used to model a broad class of physical processes,and conservation laws give rise to system properties like passivity orport-Hamiltonian structure. An important problem in practical applications isto steer dynamical systems to prescribed target states, and feedbackcontrollers combining a regulator and an observer are a powerful tool to do so.However, controllers designed using classical methods do not necessarily obeyenergy principles, which makes it difficult to model the controller-plantinteraction in a structured manner. In this paper, we show that a particularchoice of the observer gain gives rise to passivity properties of thecontroller that are independent of the plant structure. Furthermore, we stateconditions for the controller to have a port-Hamiltonian realization and showthat a model order reduction scheme can be deduced using the framework ofnonlinear balanced truncation. In addition, we propose a novel passivitypreserving discrete gradient scheme for the time discretization of passivesystems. To illustrate our results, we numerically realize the controller usingthe policy iteration and compare it to a controller where the observer gain isgiven by the extended Kalman filter.",Tobias Breiten,2025-02-07,2025-02-07,,N/A,"['math.OC', '49N35, 93B52, 37M15, 93C10']"
2502.04986v1,Unlocking thermodynamic multitasking: Exploring the functioning of two-qubit engines through coherence and entanglement,http://arxiv.org/abs/2502.04986v1,"Recent studies have investigated the role of entanglement in the operation ofa two-qubit system as a heat engine, showing that work can be extracted from asingle heat bath without direct heat dissipation between the two-qubit systemand the cold bath (2021 Phys. Rev. Lett, 126, 120605). In this work, we explorethe impact of operating the same two-qubit system model with two heat baths anddirect dissipation to the environment by applying both a local and a globalMarkovian master equation. The addition of a second heat bath enables thesystem to operate in different modes depending on the initial quantum state. Weexamine the temporal behavior of concurrence entanglement and quantumcoherence, analyzing their observable roles in transitions between variousoperational regimes. Additionally, we investigate the evolution of informationflow throughout the working cycle of the two-qubit system, focusing on theinfluence of individual and collective decoherence on the system's efficiencyand operational modes. We identify the optimal parameter regions for the engineand refrigerator modes to achieve maximum performance. Finally, we investigatethe effect of coherence outside the system on its thermodynamic quantities.",Hachem Tarif,2025-02-07,2025-02-07,,N/A,['quant-ph']
2502.04984v1,FF7: A Code Package for High-throughput Calculations and Constructing Materials Database,http://arxiv.org/abs/2502.04984v1,"Decades accumulation of theory simulations lead to boom in material database,which combined with machine learning methods has been a valuable driver for thedata-intensive material discovery, i.e., the fourth research paradigm. However,construction of segmented databases and data reuse in generic databases withuniform parameters still lack easy-to-use code tools. We herein develop a codepackage named FF7 (Fast Funnel with 7 modules) to provide command-line basedinteractive interface for performing customized high-throughput calculationsand building your own handy databases. Data correlation studies and materialproperty prediction can progress by built-in installation-free artificialneural network module and various post processing functions are also supportedby auxiliary module. This paper shows the usage of FF7 code package anddemonstrates its usefulness by example of database driven thermodynamicstability high-throughput calculation and machine learning model for predictingthe superconducting critical temperature of clathrate hydrides.",Tiancheng Ma,2025-02-07,2025-02-07,,N/A,['cond-mat.mtrl-sci']
2502.04983v1,MoGraphGPT: Creating Interactive Scenes Using Modular LLM and Graphical Control,http://arxiv.org/abs/2502.04983v1,"Creating interactive scenes often involves complex programming tasks.Although large language models (LLMs) like ChatGPT can generate code fromnatural language, their output is often error-prone, particularly whenscripting interactions among multiple elements. The linear conversationalstructure limits the editing of individual elements, and lacking graphical andprecise control complicates visual integration. To address these issues, weintegrate an element-level modularization technique that processes textualdescriptions for individual elements through separate LLM modules, with acentral module managing interactions among elements. This modular approachallows for refining each element independently. We design a graphical userinterface, MoGraphGPT , which combines modular LLMs with enhanced graphicalcontrol to generate codes for 2D interactive scenes. It enables directintegration of graphical information and offers quick, precise control throughautomatically generated sliders. Our comparative evaluation against an AIcoding tool, Cursor Composer, as the baseline system and a usability study showMoGraphGPT significantly improves easiness, controllability, and refinement increating complex 2D interactive scenes with multiple visual elements in acoding-free manner.",Hui Ye,2025-02-07,2025-02-07,,N/A,"['cs.HC', 'cs.GR']"
2502.04981v1,OccGS: Zero-shot 3D Occupancy Reconstruction with Semantic and Geometric-Aware Gaussian Splatting,http://arxiv.org/abs/2502.04981v1,"Obtaining semantic 3D occupancy from raw sensor data without manualannotations remains an essential yet challenging task. While prior works haveapproached this as a perception prediction problem, we formulate it asscene-aware 3D occupancy reconstruction with geometry and semantics. In thiswork, we propose OccGS, a novel 3D Occupancy reconstruction framework utilizingSemantic and Geometric-Aware Gaussian Splatting in a zero-shot manner.Leveraging semantics extracted from vision-language models and geometry guidedby LiDAR points, OccGS constructs Semantic and Geometric-Aware Gaussians fromraw multisensor data. We also develop a cumulative Gaussian-to-3D voxelsplatting method for reconstructing occupancy from the Gaussians. OccGSperforms favorably against self-supervised methods in occupancy prediction,achieving comparable performance to fully supervised approaches and achievingstate-of-the-art performance on zero-shot semantic 3D occupancy estimation.",Xiaoyu Zhou,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04979v1,Enhancing Pre-Trained Decision Transformers with Prompt-Tuning Bandits,http://arxiv.org/abs/2502.04979v1,"Harnessing large offline datasets is vital for training foundation modelsthat can generalize across diverse tasks. Offline Reinforcement Learning (RL)offers a powerful framework for these scenarios, enabling the derivation ofoptimal policies even from suboptimal data. The Prompting Decision Transformer(PDT) is an offline RL multi-task model that distinguishes tasks throughstochastic trajectory prompts, which are task-specific tokens maintained incontext during rollouts. However, PDT samples these tokens uniformly at randomfrom per-task demonstration datasets, failing to account for differences intoken informativeness and potentially leading to performance degradation. Toaddress this limitation, we introduce a scalable bandit-based prompt-tuningmethod that dynamically learns to construct high-performance trajectoryprompts. Our approach significantly enhances downstream task performancewithout modifying the pre-trained Transformer backbone. Empirical results onbenchmark tasks and a newly designed multi-task environment demonstrate theeffectiveness of our method, creating a seamless bridge between generalmulti-task offline pre-training and task-specific online adaptation.",Finn Rietz,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.04978v1,Chirality-induced spin selectivity based on orbital Edelstein effect in an analytically solvable model,http://arxiv.org/abs/2502.04978v1,"Chirality-induced spin selectivity, a phenomenon wherein chiral structuresselectively determine the spin polarization of electron currents flowingthrough the material, has garnered significant attention due to its potentialapplications in areas such as spintronics, enantioseparation, and catalysis.The underlying physical effect is the Edelstein effect that converts charge toangular momentum but the precise mechanism remains yet to be understood. Here,we introduce the minimal model for explaining the phenomenon based on theorbital Edelstein effect. We consider inter-site contributions to thecurrent-induced orbital angular momentum and reveal the underlying mechanism byanalytically calculating the Edelstein susceptibilities in a tight-binding andBoltzmann approach. While the orbital angular momentum is directly generated bythe chirality of the crystal, the spin contribution of each spin-split bandpair relies on spin-orbit coupling. Using tellurium as an example, we show thatthe orbital contribution surpasses the spin contribution by orders ofmagnitude.",Börge Göbel,2025-02-07,2025-02-07,,N/A,"['cond-mat.mes-hall', 'cond-mat.str-el']"
2502.04976v1,Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark,http://arxiv.org/abs/2502.04976v1,"Empathetic Response Generation (ERG) is one of the key tasks of the affectivecomputing area, which aims to produce emotionally nuanced and compassionateresponses to user's queries. However, existing ERG research is predominantlyconfined to the singleton text modality, limiting its effectiveness since humanemotions are inherently conveyed through multiple modalities. To combat this,we introduce an avatar-based Multimodal ERG (MERG) task, entailing rich text,speech, and facial vision information. We first present a large-scalehigh-quality benchmark dataset, \textbf{AvaMERG}, which extends traditionaltext ERG by incorporating authentic human speech audio and dynamic talking-faceavatar videos, encompassing a diverse range of avatar profiles and broadlycovering various topics of real-world scenarios. Further, we deliberatelytailor a system, named \textbf{Empatheia}, for MERG. Built upon a MultimodalLarge Language Model (MLLM) with multimodal encoder, speech and avatargenerators, Empatheia performs end-to-end MERG, with Chain-of-Empatheticreasoning mechanism integrated for enhanced empathy understanding andreasoning. Finally, we devise a list of empathetic-enhanced tuning strategies,strengthening the capabilities of emotional accuracy and content,avatar-profile consistency across modalities. Experimental results on AvaMERGdata demonstrate that Empatheia consistently shows superior performance thanbaseline methods on both textual ERG and MERG. Overall, this work is expectedto pioneer the MERG research by introducing a novel benchmark and an end-to-endmodel, laying a solid foundation for future advancements in multimodalempathetic response generation.",Han Zhang,2025-02-07,2025-02-07,,N/A,['cs.MM']
2502.04974v1,Speed of sound in Kaluza-Klein Fermi gas,http://arxiv.org/abs/2502.04974v1,"A five-dimensional Kaluza-Klein spacetime model is considered, with one extracompactified spatial dimension. The equation of state of an electricallyneutral, zero-temperature Fermi gas with a repulsive linear potential isdescribed. From the equation of state, the speed of sound squared is calculatedand shown for different model parameters. Its properties are studied from lowerenergies up to the conformal limit.",Anna Horváth,2025-02-07,2025-02-07,,N/A,"['hep-ph', 'astro-ph.HE', 'nucl-th']"
2502.04973v1,DE-PADA: Personalized Augmentation and Domain Adaptation for ECG Biometrics Across Physiological States,http://arxiv.org/abs/2502.04973v1,"Electrocardiogram (ECG)-based biometrics offer a promising method for useridentification, combining intrinsic liveness detection with morphologicaluniqueness. However, elevated heart rates introduce significant physiologicalvariability, posing challenges to pattern recognition systems and leading to anotable performance gap between resting and post-exercise conditions.Addressing this gap is critical for advancing ECG-based biometric systems forreal-world applications. We propose DE-PADA, a Dual Expert model withPersonalized Augmentation and Domain Adaptation, designed to enhance robustnessacross diverse physiological states. The model is trained primarily onresting-state data from the evaluation dataset, without direct exposure totheir exercise data. To address variability, DE-PADA incorporates ECG-specificinnovations, including heartbeat segmentation into the PQRS interval, known forits relative temporal consistency, and the heart rate-sensitive ST interval,enabling targeted feature extraction tailored to each region's uniquecharacteristics. Personalized augmentation simulates subject-specific T-wavevariability across heart rates using individual T-wave peak predictions toadapt augmentation ranges. Domain adaptation further improves generalization byleveraging auxiliary data from supplementary subjects used exclusively fortraining, including both resting and exercise conditions. Experiments on theUniversity of Toronto ECG Database demonstrate the model's effectiveness.DE-PADA achieves relative improvements in post-exercise identification rates of26.75% in the initial recovery phase and 11.72% in the late recovery phase,while maintaining a 98.12% identification rate in the sitting position. Theseresults highlight DE-PADA's ability to address intra-subject variability andenhance the robustness of ECG-based biometric systems across diversephysiological states.",Amro Abu Saleh,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.04970v1,Gradient-based Explanations for Deep Learning Survival Models,http://arxiv.org/abs/2502.04970v1,"Deep learning survival models often outperform classical methods intime-to-event predictions, particularly in personalized medicine, but their""black box"" nature hinders broader adoption. We propose a framework forgradient-based explanation methods tailored to survival neural networks,extending their use beyond regression and classification. We analyze theimplications of their theoretical assumptions for time-dependent explanationsin the survival setting and propose effective visualizations incorporating thetemporal dimension. Experiments on synthetic data show that gradient-basedmethods capture the magnitude and direction of local and global featureeffects, including time dependencies. We introduce GradSHAP(t), agradient-based counterpart to SurvSHAP(t), which outperforms SurvSHAP(t) andSurvLIME in a computational speed vs. accuracy trade-off. Finally, we applythese methods to medical data with multi-modal inputs, revealing relevanttabular features and visual patterns, as well as their temporal dynamics.",Sophie Hanna Langbein,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG']"
2502.04967v1,Towards Smarter Sensing: 2D Clutter Mitigation in RL-Driven Cognitive MIMO Radar,http://arxiv.org/abs/2502.04967v1,"Motivated by the growing interest in integrated sensing and communication for6th generation (6G) networks, this paper presents a cognitive Multiple-InputMultiple-Output (MIMO) radar system enhanced by reinforcement learning (RL) forrobust multitarget detection in dynamic environments. The system employs aplanar array configuration and adapts its transmitted waveforms and beamformingpatterns to optimize detection performance in the presence of unknowntwo-dimensional (2D) disturbances. A robust Wald-type detector is integratedwith a SARSA-based RL algorithm, enabling the radar to learn and adapt tocomplex clutter environments modeled by a 2D autoregressive process. Simulationresults demonstrate significant improvements in detection probability comparedto omnidirectional methods, particularly for low Signal-to-Noise Ratio (SNR)targets masked by clutter.",Adam Umra,2025-02-07,2025-02-07,,N/A,"['eess.SP', 'cs.LG']"
2502.04964v1,CoCoA: A Generalized Approach to Uncertainty Quantification by Integrating Confidence and Consistency of LLM Outputs,http://arxiv.org/abs/2502.04964v1,"Uncertainty quantification (UQ) methods for Large Language Models (LLMs)encompasses a variety of approaches, with two major types being particularlyprominent: information-based, which focus on model confidence expressed astoken probabilities, and consistency-based, which assess the semanticrelationship between multiple outputs generated using repeated sampling.Several recent methods have combined these two approaches and shown impressiveperformance in various applications. However, they sometimes fail to outperformmuch simpler baseline methods. Our investigation reveals distinctivecharacteristics of LLMs as probabilistic models, which help to explain whythese UQ methods underperform in certain tasks. Based on these findings, wepropose a new way of synthesizing model confidence and output consistency thatleads to a family of efficient and robust UQ methods. We evaluate our approachacross a variety of tasks such as question answering, abstractivesummarization, and machine translation, demonstrating sizable improvements overstate-of-the-art UQ approaches.",Roman Vashurin,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04963v1,Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction,http://arxiv.org/abs/2502.04963v1,"This paper investigates the anti-jamming channel access problem in complexand unknown jamming environments, where the jammer could dynamically adjust itsstrategies to target different channels. Traditional channel hoppinganti-jamming approaches using fixed patterns are ineffective against suchdynamic jamming attacks. Although the emerging deep reinforcement learning(DRL) based dynamic channel access approach could achieve the Nash equilibriumunder fast-changing jamming attacks, it requires extensive training episodes.To address this issue, we propose a fast adaptive anti-jamming channel accessapproach guided by the intuition of ``learning faster than the jammer"", where asynchronously updated coarse-grained spectrum prediction serves as an auxiliarytask for the deep Q learning (DQN) based anti-jamming model. This helps themodel identify a superior Q-function compared to standard DRL whilesignificantly reducing the number of training episodes. Numerical resultsindicate that the proposed approach significantly accelerates the rate ofconvergence in model training, reducing the required training episodes by up to70% compared to standard DRL. Additionally, it also achieves a 10% improvementin throughput over NE strategies, owing to the effective use of coarse-grainedspectrum prediction.",Jianshu Zhang,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04961v1,Two-Dimensional Lattice-Gas Model for Methane Clathrate Hydrates: Comparative Analysis with Experiments and Three-Dimensional Simulations,http://arxiv.org/abs/2502.04961v1,"Methane clathrate hydrates, particularly those with an sI structure, aresignificant due to their potential as energy resources and their impact on gaspipelines. In this study, a two-dimensional (2D) lattice-gas model is employedto investigate the main thermodynamic properties of methane clathrate hydrates.The proposed framework is validated through comparison with experimental dataand more advanced three-dimensional (3D) simulations. Adsorption isotherms,dissociation enthalpy and phase stability of the sI structure are evaluatedusing Monte Carlo (MC) simulations in the grand canonical ensemble. The 2Dadsorption isotherms closely align with both experimental data and 3Dsimulations, demonstrating the 2D model's ability to precisely represent bothrigid and flexible sI structures. The dissociation enthalpy calculated usingour approach (76.4 kJ/mol) excellently matches the experimental value (78kJ/mol), confirming the model's accuracy. Furthermore, the phase diagramobtained from the Clausius-Clapeyron equation shows very good agreement withexperimental data between 260 and 290 K, though deviations are observed above290 K. These findings underscore the effectiveness and robustness of the 2Dmodel in studying methane clathrate hydrates and suggest its potentialapplicability for investigating other guest species and hydrate structures.",Julian Juan,2025-02-07,2025-02-07,,N/A,"['cond-mat.dis-nn', 'cond-mat.mtrl-sci']"
2502.04960v1,Commonality and Individuality! Integrating Humor Commonality with Speaker Individuality for Humor Recognition,http://arxiv.org/abs/2502.04960v1,"Humor recognition aims to identify whether a specific speaker's text ishumorous. Current methods for humor recognition mainly suffer from twolimitations: (1) they solely focus on one aspect of humor commonalities,ignoring the multifaceted nature of humor; and (2) they typically overlook thecritical role of speaker individuality, which is essential for a comprehensiveunderstanding of humor expressions. To bridge these gaps, we introduce theCommonality and Individuality Incorporated Network for Humor Recognition(CIHR), a novel model designed to enhance humor recognition by integratingmultifaceted humor commonalities with the distinctive individuality ofspeakers. The CIHR features a Humor Commonality Analysis module that exploresvarious perspectives of multifaceted humor commonality within user texts, and aSpeaker Individuality Extraction module that captures both static and dynamicaspects of a speaker's profile to accurately model their distinctiveindividuality. Additionally, Static and Dynamic Fusion modules are introducedto effectively incorporate the humor commonality with speaker's individualityin the humor recognition process. Extensive experiments demonstrate theeffectiveness of CIHR, underscoring the importance of concurrently addressingboth multifaceted humor commonality and distinctive speaker individuality inhumor recognition.",Haohao Zhu,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04959v1,No Task Left Behind: Isotropic Model Merging with Common and Task-Specific Subspaces,http://arxiv.org/abs/2502.04959v1,"Model merging integrates the weights of multiple task-specific models into asingle multi-task model. Despite recent interest in the problem, a significantperformance gap between the combined and single-task models remains. In thispaper, we investigate the key characteristics of task matrices -- weight updatematrices applied to a pre-trained model -- that enable effective merging. Weshow that alignment between singular components of task-specific and mergedmatrices strongly correlates with performance improvement over the pre-trainedmodel. Based on this, we propose an isotropic merging framework that flattensthe singular value spectrum of task matrices, enhances alignment, and reducesthe performance gap. Additionally, we incorporate both common and task-specificsubspaces to further improve alignment and performance. Our proposed approachachieves state-of-the-art performance across multiple scenarios, includingvarious sets of tasks and model scales. This work advances the understanding ofmodel merging dynamics, offering an effective methodology to merge modelswithout requiring additional training. Code is available athttps://github.com/danielm1405/iso-merging .",Daniel Marczak,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.04958v1,SSMLoRA: Enhancing Low-Rank Adaptation with State Space Model,http://arxiv.org/abs/2502.04958v1,"Fine-tuning is a key approach for adapting language models to specificdownstream tasks, but updating all model parameters becomes impractical asmodel sizes increase. Parameter-Efficient Fine-Tuning (PEFT) methods, such asLow-Rank Adaptation (LoRA), address this challenge by introducing additionaladaptation parameters into pre-trained weight matrices. However, LoRA'sperformance varies across different insertion points within the model,highlighting potential parameter inefficiency due to unnecessary insertions. Tothis end, we propose SSMLoRA (State Space Model Low-Rank Adaptation), anextension of LoRA that incorporates a State Space Model (SSM) to interconnectlow-rank matrices. SSMLoRA ensures that performance is maintained even withsparser insertions. SSMLoRA allows the model to not only map inputs to alow-rank space for better feature extraction but also leverage the computationsfrom the previous low-rank space. Our method achieves comparable performance toLoRA on the General Language Understanding Evaluation (GLUE) benchmark whileusing only half the parameters. Additionally, due to its structure, SSMLoRAshows promise in handling tasks with longer input sequences. .You can find ourcode here:https://github.com/yuhkalhic/SSMLoRA.",Jiayang Yu,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04957v1,ALMA reveals thermal and non-thermal desorption of methanol ice in the HD 100546 protoplanetary disk,http://arxiv.org/abs/2502.04957v1,"Methanol (CH$_3$OH) and formaldehyde (H$_2$CO) are chemically coupled organicmolecules proposed to act as an intermediate step between simple molecules andmore complex prebiotic compounds. Their abundance distributions across disksregulate the prebiotic potential of material at different disk radii. Wepresent observations of multiple methanol and formaldehyde transitions towardthe Herbig Ae disk HD 100546 obtained with ALMA, building upon the previousserendipitous detection of methanol in this source. We find that methanol has ahigher rotational temperature ($T_\mathrm{rot}$) than formaldehyde towards boththe centrally concentrated emission component in the inner disk ($0-110$ au)and a radially separate dust ring farther out in the disk ($180-260$ au).$T_\mathrm{rot}$ decreases for methanol and formaldehyde from the inner($152^{+35}_{-27}$ K and $76^{+9}_{-8}$ K) to the outer disk ($52^{+8}_{-6}$ Kand $31^{+2}_{-2}$ K), suggesting that we are tracing two different chemicalenvironments. $T_\mathrm{rot}$ for both species in the inner disk is consistentwith thermal desorption as the origin, while the outer disk reservoir is drivenby non-thermal desorption. The CH$_3$OH/H$_2$CO column density ratio decreasesfrom 14.6$^{+5.2}_{-4.6}$ in the inner disk to $1.3^{+0.3}_{-0.2}$ in the outerdisk, consistent with modelling predictions. The CH$_3$OH/H$_2$CO columndensity ratio for the inner disk is consistent with the median value in therange of column density ratios compiled from Solar System comets which wouldhave formed at a similar distance. This supports the notion that interstellarice is inherited and preserved by protoplanetary disks around solar-mass andintermediate-mass stars as we are seeing 'fresh' ice sublimation, as well asproviding more evidence for the presence of prebiotic precursor molecules inplanet-forming regions.",Lucy Evans,2025-02-07,2025-02-07,,N/A,"['astro-ph.EP', 'astro-ph.GA', 'astro-ph.SR']"
2502.04955v1,"Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics",http://arxiv.org/abs/2502.04955v1,"In this paper, we explore the problem of Claim Extraction using one-to-manytext generation methods, comparing LLMs, small summarization models finetunedfor the task, and a previous NER-centric baseline QACG. As the currentpublications on Claim Extraction, Fact Extraction, Claim Generation andCheck-worthy Claim Detection are quite scattered in their means andterminology, we compile their common objectives, releasing the FEVERFactdataset, with 17K atomic factual claims extracted from 4K contextualisedWikipedia sentences, adapted from the original FEVER. We compile the knownobjectives into an Evaluation framework of: Atomicity, Fluency,Decontextualization, Faithfulness checked for each generated claim separately,and Focus and Coverage measured against the full set of predicted claims for asingle input. For each metric, we implement a scale using a reduction to analready-explored NLP task. We validate our metrics against human grading ofgeneric claims, to see that the model ranking on $F_{fact}$, our hardestmetric, did not change and the evaluation framework approximates human gradingvery closely in terms of $F_1$ and RMSE.",Herbert Ullrich,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04952v1,Boosting Path-Sensitive Value Flow Analysis via Removal of Redundant Summaries,http://arxiv.org/abs/2502.04952v1,"Value flow analysis that tracks the flow of values via data dependence is awidely used technique for detecting a broad spectrum of software bugs. However,the scalability issue often deteriorates when high precision (i.e.,path-sensitivity) is required, as the instantiation of function summariesbecomes excessively time- and memory-intensive. The primary culprit, as weobserve, is the existence of redundant computations resulting from blindlycomputing summaries for a function, irrespective of whether they are related tobugs being checked. To address this problem, we present the first approach thatcan effectively identify and eliminate redundant summaries, thereby reducingthe size of collected summaries from callee functions without compromisingsoundness or efficiency. Our evaluation on large programs demonstrates that ouridentification algorithm can significantly reduce the time and memory overheadof the state-of-the-art value flow analysis by 45\% and 27\%, respectively.Furthermore, the identification algorithm demonstrates remarkable efficiency byidentifying nearly 80\% of redundant summaries while incurring a minimaladditional overhead. In the largest \textit{mysqld} project, the identificationalgorithm reduces the time by 8107 seconds (2.25 hours) with a mere 17.31seconds of additional overhead, leading to a ratio of time savings to paidoverhead (i.e., performance gain) of 468.48 $\times$. In total, our methodattains an average performance gain of 632.1 $\times$.",Yongchao Wang,2025-02-07,2025-02-07,,N/A,['cs.SE']
2502.04951v1,The Rising Threat to Emerging AI-Powered Search Engines,http://arxiv.org/abs/2502.04951v1,"Recent advancements in Large Language Models (LLMs) have significantlyenhanced the capabilities of AI-Powered Search Engines (AIPSEs), offeringprecise and efficient responses by integrating external databases withpre-existing knowledge. However, we observe that these AIPSEs raise risks suchas quoting malicious content or citing malicious websites, leading to harmfulor unverified information dissemination. In this study, we conduct the firstsafety risk quantification on seven production AIPSEs by systematicallydefining the threat model, risk level, and evaluating responses to variousquery types. With data collected from PhishTank, ThreatBook, and LevelBlue, ourfindings reveal that AIPSEs frequently generate harmful content that containsmalicious URLs even with benign queries (e.g., with benign keywords). We alsoobserve that directly query URL will increase the risk level while query withnatural language will mitigate such risk. We further perform two case studieson online document spoofing and phishing to show the ease of deceiving AIPSEsin the real-world setting. To mitigate these risks, we develop an agent-baseddefense with a GPT-4o-based content refinement tool and an XGBoost-based URLdetector. Our evaluation shows that our defense can effectively reduce the riskbut with the cost of reducing available information. Our research highlightsthe urgent need for robust safety measures in AIPSEs.",Zeren Luo,2025-02-07,2025-02-07,,N/A,"['cs.CR', 'cs.AI', 'cs.LG']"
2502.04949v1,Does Unsupervised Domain Adaptation Improve the Robustness of Amortized Bayesian Inference? A Systematic Evaluation,http://arxiv.org/abs/2502.04949v1,"Neural networks are fragile when confronted with data that significantlydeviates from their training distribution. This is true in particular forsimulation-based inference methods, such as neural amortized Bayesian inference(ABI), where models trained on simulated data are deployed on noisy real-worldobservations. Recent robust approaches employ unsupervised domain adaptation(UDA) to match the embedding spaces of simulated and observed data. However,the lack of comprehensive evaluations across different domain mismatches raisesconcerns about the reliability in high-stakes applications. We address this gapby systematically testing UDA approaches across a wide range ofmisspecification scenarios in both a controlled and a high-dimensionalbenchmark. We demonstrate that aligning summary spaces between domainseffectively mitigates the impact of unmodeled phenomena or noise. However, thesame alignment mechanism can lead to failures under prior misspecifications - acritical finding with practical consequences. Our results underscore the needfor careful consideration of misspecification types when using UDA techniquesto increase the robustness of ABI in practice.",Lasse Elsemüller,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG', 'stat.ME']"
2502.04946v1,SurGen: 1020 H&E-stained Whole Slide Images With Survival and Genetic Markers,http://arxiv.org/abs/2502.04946v1,"$\textbf{Background}$: Cancer remains one of the leading causes of morbidityand mortality worldwide. Comprehensive datasets that combine histopathologicalimages with genetic and survival data across various tumour sites are essentialfor advancing computational pathology and personalised medicine.$\textbf{Results}$: We present SurGen, a dataset comprising 1,020 H&E-stainedwhole slide images (WSIs) from 843 colorectal cancer cases. The datasetincludes detailed annotations for key genetic mutations (KRAS, NRAS, BRAF) andmismatch repair status, as well as survival data for 426 cases. To demonstrateSurGen's practical utility, we conducted a proof-of-concept machine learningexperiment predicting mismatch repair status from the WSIs, achieving a testAUROC of 0.8316. These preliminary results underscore the dataset's potentialto facilitate research in biomarker discovery, prognostic modelling, andadvanced machine learning applications in colorectal cancer.$\textbf{Conclusions}$: SurGen offers a valuable resource for the scientificcommunity, enabling studies that require high-quality WSIs linked withcomprehensive clinical and genetic information on colorectal cancer. Ourinitial findings affirm the dataset's capacity to advance diagnostic precisionand foster the development of personalised treatment strategies in colorectaloncology. Data available online at https://doi.org/10.6019/S-BIAD1285.",Craig Myles,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04945v1,Estimating Parameters of Structural Models Using Neural Networks,http://arxiv.org/abs/2502.04945v1,"We study an alternative use of machine learning. We train neural nets toprovide the parameter estimate of a given (structural) econometric model, forexample, discrete choice or consumer search. Training examples consist ofdatasets generated by the econometric model under a range of parameter values.The neural net takes the moments of a dataset as input and tries to recognizethe parameter value underlying that dataset. Besides the point estimate, theneural net can also output statistical accuracy. This neural net estimator(NNE) tends to limited-information Bayesian posterior as the number of trainingdatasets increases. We apply NNE to a consumer search model. It gives moreaccurate estimates at lighter computational costs than the prevailing approach.NNE is also robust to redundant moment inputs. In general, NNE offers the mostbenefits in applications where other estimation approaches require very heavysimulation costs. We provide code at: https://nnehome.github.io.",Yanhao,2025-02-07,2025-02-07,,N/A,"['econ.EM', 'stat.CO', 'G.3; J.4; I.2']"
2502.04938v1,A note on auxiliary mixture sampling for Bayesian Poisson models,http://arxiv.org/abs/2502.04938v1,"Bayesian hierarchical Poisson models are an essential tool for analyzingcount data. However, designing efficient algorithms to sample from theposterior distribution of the target parameters remains a challenging task forthis class of models. Auxiliary mixture sampling algorithms have been proposedto address this issue. They involve two steps of data augmentations: the firstleverages the theory of Poisson processes, and the second approximates theresidual distribution of the resulting model through a mixture of Gaussiandistributions. In this way, an approximated Gibbs sampler is obtained. In thispaper, we focus on the accuracy of the approximation step, highlightingscenarios where the mixture fails to accurately represent the true underlyingdistribution, leading to a lack of convergence in the algorithm. We outline keyfeatures to monitor, in order to assess if the approximation performs asintended. Building on this, we propose a robust version of the auxiliarymixture sampling algorithm, which can detect approximation failures andincorporate a Metropolis-Hastings step when necessary. Finally, we evaluate theproposed algorithm together with the original mixture sampling algorithms onboth simulated and real datasets.",Aldo Gardini,2025-02-07,2025-02-07,,N/A,"['stat.ME', 'stat.CO']"
2502.04937v1,Data-driven Modality Fusion: An AI-enabled Framework for Large-Scale Sensor Network Management,http://arxiv.org/abs/2502.04937v1,"The development and operation of smart cities relyheavily on large-scaleInternet-of-Things (IoT) networks and sensor infrastructures that continuouslymonitor various aspects of urban environments. These networks generate vastamounts of data, posing challenges related to bandwidth usage, energyconsumption, and system scalability. This paper introduces a novel sensingparadigm called Data-driven Modality Fusion (DMF), designed to enhance theefficiency of smart city IoT network management. By leveraging correlationsbetween timeseries data from different sensing modalities, the proposed DMFapproach reduces the number of physical sensors required for monitoring,thereby minimizing energy expenditure, communication bandwidth, and overalldeployment costs. The framework relocates computational complexity from theedge devices to the core, ensuring that resource-constrained IoT devices arenot burdened with intensive processing tasks. DMF is validated using data froma real-world IoT deployment in Madrid, demonstrating the effectiveness of theproposed system in accurately estimating traffic, environmental, and pollutionmetrics from a reduced set of sensors. The proposed solution offers a scalable,efficient mechanism for managing urban IoT networks, while addressing issues ofsensor failure and privacy concerns.",Hrishikesh Dutta,2025-02-07,2025-02-07,,N/A,"['cs.NI', 'cs.AI', 'cs.LG']"
2502.04935v1,Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market,http://arxiv.org/abs/2502.04935v1,"The integration of renewable energy into electricity markets posessignificant challenges to price stability and increases the complexity ofmarket operations. Accurate and reliable electricity price forecasting iscrucial for effective market participation, where price dynamics can besignificantly more challenging to predict. Probabilistic forecasting, throughprediction intervals, efficiently quantifies the inherent uncertainties inelectricity prices, supporting better decision-making for market participants.This study explores the enhancement of probabilistic price prediction usingConformal Prediction (CP) techniques, specifically Ensemble Batch PredictionIntervals and Sequential Predictive Conformal Inference. These methods provideprecise and reliable prediction intervals, outperforming traditional models invalidity metrics. We propose an ensemble approach that combines the efficiencyof quantile regression models with the robust coverage properties of timeseries adapted CP techniques. This ensemble delivers both narrow predictionintervals and high coverage, leading to more reliable and accurate forecasts.We further evaluate the practical implications of CP techniques through asimulated trading algorithm applied to a battery storage system. The ensembleapproach demonstrates improved financial returns in energy trading in both theDay-Ahead and Balancing Markets, highlighting its practical benefits for marketparticipants.",Ciaran O'Connor,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04933v1,"Mobile Network-specialized Large Language Models for 6G: Architectures, Innovations, Challenges, and Future Trends",http://arxiv.org/abs/2502.04933v1,"Conventional 5G network management mechanisms, that operate in isolated silosacross different network segments, will experience significant limitations inhandling the unprecedented hyper-complexity and massive scale of the sixthgeneration (6G). Holistic intelligence and end-to-end automation are, thus,positioned as key enablers of forthcoming 6G networks. The Large Language Model(LLM) technology, a major breakthrough in the Generative ArtificialIntelligence (AI) field, enjoys robust human-like language processing, advancedcontextual reasoning and multi-modal capabilities. These features foster aholistic understanding of network behavior and an autonomous decision-making.This paper investigates four possible architectural designs for integrated LLMand 6G networks, detailing the inherent technical intricacies, the merits andthe limitations of each design. As an internal functional building block offuture 6G networks, the LLM will natively benefit from their improveddesign-driven security policies from the early design and specification stages.An illustrative scenario of slicing conflicts is used to prove theeffectiveness of our architectural framework in autonomously dealing withcomplicated network anomalies. We finally conclude the paper with an overviewof the key challenges and the relevant research trends for enabling MobileNetworkspecialized LLMs. This study is intended to provide Mobile NetworkOperators (MNOs) with a comprehensive guidance in their paths towards embracingthe LLM technology.",Abdelaali Chaoub,2025-02-07,2025-02-07,,N/A,['cs.NI']
2502.04932v1,Accessing different higher-order modes with beam self-cleaning under simple realistic tuning of initial conditions,http://arxiv.org/abs/2502.04932v1,"The initial conditions in multimode fibers pumped by ultrashort laser pulsesstrongly determine the following nonlinear optical interactions. In this workwe firstly compare the detailed spatial mode content of simple initialconditions, transverse offset and tilt. We then show how those initialconditions can both be used to achieve beam self-cleaning into higher-orderspatial modes of a model graded-index fiber, with their own slight differencesand advantages. Going beyond purely spatial initial conditions, we introduceself-cleaning results using spatial chirp at the input facet, whereby thedifferent temporal envelopes of the spatial modes allows for tuning theself-cleaning process. Our results open up investigations intohigher-dimensional tuning of nonlinear processes in multimode fibers usinginitial conditions.",Julien Dechanxhe,2025-02-07,2025-02-07,,N/A,['physics.optics']
2502.04929v1,Robustness of Dark Energy Phenomenology Across Different Parameterizations,http://arxiv.org/abs/2502.04929v1,"The recent evidence for dynamical dark energy from DESI, in combination withother cosmological data, has generated significant interest in understandingthe nature of dark energy and its underlying microphysics. However,interpreting these results critically depends on how dark energy isparameterized. This paper examines the robustness of conclusions about theviability of particular kinds of dynamical dark energy models to the choice ofparameterization, focusing on four popular two-parameter families: theChevallier-Polarski-Linder (CPL), Jassal-Bagla-Padmanabhan (JBP),Barboza-Alcaniz (BA), and exponential (EXP) parameterizations. We find thatconclusions regarding the viability of minimally and non-minimally coupledquintessence models are independent of the parameterization adopted. Wedemonstrate this both by mapping these dark energy models into the $(w_0, w_a)$parameter space defined by these various parameterizations and by showing thatall of these parameterizations can equivalently account for the phenomenologypredicted by these dark energy models to a high degree of accuracy.",William J. Wolf,2025-02-07,2025-02-07,,N/A,"['astro-ph.CO', 'gr-qc', 'hep-ph', 'hep-th']"
2502.04928v1,Generative-enhanced optimization for knapsack problems: an industry-relevant study,http://arxiv.org/abs/2502.04928v1,"Optimization is a crucial task in various industries such as logistics,aviation, manufacturing, chemical, pharmaceutical, and insurance, where findingthe best solution to a problem can result in significant cost savings andincreased efficiency. Tensor networks (TNs) have gained prominence in recentyears in modeling classical systems with quantum-inspired approaches. Morerecently, TN generative-enhanced optimization (TN-GEO) has been proposed as astrategy which uses generative modeling to efficiently sample valid solutionswith respect to certain constraints of optimization problems. Moreover, it hasbeen shown that symmetric TNs (STNs) can encode certain constraints ofoptimization problems, thus aiding in their solution process. In this work, weinvestigate the applicability of TN- and STN-GEO to an industry relevantproblem class, a multi-knapsack problem, in which each object must be assignedto an available knapsack. We detail a prescription for practitioners to use theTN-and STN-GEO methodology and study its scaling behavior and dependence on itshyper-parameters. We benchmark 60 different problem instances and find thatTN-GEO and STN-GEO produce results of similar quality to simulated annealing.",Yelyzaveta Vodovozova,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'quant-ph']"
2502.04927v1,Scaling corrections in driven critical dynamics: Application to a two-dimensional dimerized quantum Heisenberg model,http://arxiv.org/abs/2502.04927v1,"Driven critical dynamics in quantum phase transitions holds significanttheoretical importance, and also practical applications in fast-developingquantum devices. While scaling corrections have been shown to play importantroles in fully characterizing equilibrium quantum criticality, their impact onnonequilibrium critical dynamics has not been extensively explored. In thiswork, we investigate the driven critical dynamics in a two-dimensional quantumHeisenberg model. We find that in this model the scaling corrections arisingfrom both finite system size and finite driving rate must be incorporated intothe finite-time scaling form in order to properly describe the nonequilibriumscaling behaviors. In addition, improved scaling relations are obtained fromthe expansion of the full scaling form. We numerically verify these scalingforms and improved scaling relations for different starting states using thenonequilibrium quantum Monte Carlo algorithm.",Jing-Wen Liu,2025-02-07,2025-02-07,,N/A,['cond-mat.stat-mech']
2502.04926v1,Clusters of tribocharged dust aggregates as pebbles in protoplanetary disks,http://arxiv.org/abs/2502.04926v1,"In recent years, the tribocharging of colliding and bouncing submillimeter(submm) particles has been studied as a possible mechanism promoting theformation of large pebbles on centimeter (cm) to decimeter (dm) scales inprotoplanetary disks. Here, we observe, for the first time, that it is not onlymonolithic, spherical particles, but also real dust aggregates, that becometribocharged and end up forming large clusters. For aggregates of $\sim 0.4$ mmconsisting of $\rm \sim$ 1 $\rm \mu m$ sized dust, we determined net chargedensities up to $10^{-7}$ C/$\rm m^2$ during our drop tower experiments. Thesecharged aggregates form compact clusters up to 2 cm in size via collisions withother clusters and aggregates at collision velocities on the order of 1 cm/s.Size and speed are the only lower limits for growth, currently set by thelimits of the experiment. However, these clusters already form under conditionsthat are well beyond the expected transition to bouncing for unchargedaggregates and clusters. Our findings further support the idea that collisionalcharging can leapfrog the traditional bouncing barrier and form larger clustersthat then serve as large pebbles. These cm-sized clusters are more susceptibleto further evolutionary steps via particle trapping, concentration, andplanetesimal formation.",F. C. Onyeagusi,2025-02-07,2025-02-07,,N/A,['astro-ph.EP']
2502.04925v1,Convergent NMPC-based Reinforcement Learning Using Deep Expected Sarsa and Nonlinear Temporal Difference Learning,http://arxiv.org/abs/2502.04925v1,"In this paper, we present a learning-based nonlinear model predictivecontroller (NMPC) using an original reinforcement learning (RL) method to learnthe optimal weights of the NMPC scheme. The controller is used as the currentaction-value function of a deep Expected Sarsa where the subsequentaction-value function, usually obtained with a secondary NMPC, is approximatedwith a neural network (NN). With respect to existing methods, we add to theNN's input the current value of the NMPC's learned parameters so that thenetwork is able to approximate the action-value function and stabilize thelearning performance. Additionally, with the use of the NN, the real-timecomputational burden is approximately halved without affecting the closed-loopperformance. Furthermore, we combine gradient temporal difference methods withparametrized NMPC as function approximator of the Expected Sarsa RL method toovercome the potential parameters divergence and instability issues whennonlinearities are present in the function approximation. The simulation resultshows that the proposed approach converges to a locally optimal solutionwithout instability problems.",Amine Salaje,2025-02-07,2025-02-07,,N/A,"['eess.SY', 'cs.RO', 'cs.SY']"
2502.04923v1,Cached Multi-Lora Composition for Multi-Concept Image Generation,http://arxiv.org/abs/2502.04923v1,"Low-Rank Adaptation (LoRA) has emerged as a widely adopted technique intext-to-image models, enabling precise rendering of multiple distinct elements,such as characters and styles, in multi-concept image generation. However,current approaches face significant challenges when composing these LoRAs formulti-concept image generation, resulting in diminished generated imagequality. In this paper, we initially investigate the role of LoRAs in thedenoising process through the lens of the Fourier frequency domain. Based onthe hypothesis that applying multiple LoRAs could lead to ""semantic conflicts"",we find that certain LoRAs amplify high-frequency features such as edges andtextures, whereas others mainly focus on low-frequency elements, including theoverall structure and smooth color gradients. Building on these insights, wedevise a frequency domain based sequencing strategy to determine the optimalorder in which LoRAs should be integrated during inference. This strategyoffers a methodical and generalizable solution compared to the naiveintegration commonly found in existing LoRA fusion techniques. To fullyleverage our proposed LoRA order sequence determination method in multi-LoRAcomposition tasks, we introduce a novel, training-free framework, CachedMulti-LoRA (CMLoRA), designed to efficiently integrate multiple LoRAs whilemaintaining cohesive image generation. With its flexible backbone formulti-LoRA fusion and a non-uniform caching strategy tailored to individualLoRAs, CMLoRA has the potential to reduce semantic conflicts in LoRAcomposition and improve computational efficiency. Our experimental evaluationsdemonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusionmethods by a significant margin -- it achieves an average improvement of$2.19\%$ in CLIPScore, and $11.25\%$ in MLLM win rate compared to LoraHub, LoRAComposite, and LoRA Switch.",Xiandong Zou,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.AI']"
2502.04921v1,Applying the Liouville-Lanczos Method of Time-Dependent Density-Functional Theory to Warm Dense Matter,http://arxiv.org/abs/2502.04921v1,"Ab initio modeling of dynamic structure factors (DSF) and related densityresponse properties in the warm dense matter (WDM) regime is a challengingcomputational task. The DSF, convolved with a probing X-ray beam and instrumentfunction, is measured in X-ray Thomson scattering (XRTS) experiments, whichallows for the study of electronic structure properties at the microscopiclevel. Among the various ab initio methods, linear response time-dependentdensity functional theory (LR-TDDFT) is a key framework for simulating the DSF.The standard approach in LR-TDDFT for computing the DSF relies on the orbitalrepresentation. A significant drawback of this method is the unfavorablescaling of the number of required empty bands as the wavenumber increases,making LR-TDDFT impractical for modeling XRTS measurements over large energyscales, such as in backward scattering geometry. We consider and test analternative approach that employs the Liouville-Lanczos (LL) method forsimulating the DSF. This approach does not require empty states and allows theDSF at large momentum transfer values and over a broad frequency range to beaccessed. We compare the results obtained from the LL method with those fromthe standard LR-TDDFT within the projector augmented-wave formalism forisochorically heated aluminum and warm dense hydrogen. Additionally, we utilizeexact path integral Monte Carlo (PIMC) results for the imaginary-timedensity-density correlation function (ITCF) of warm dense hydrogen torigorously benchmark the LL approach. We discuss the application of the LLmethod for calculating DSFs and ITCFs at different wavenumbers, the effects ofpseudopotentials, and the role of Lorentzian smearing. The successfulvalidation of the LL method under WDM conditions makes it a valuable additionto the ab initio simulation landscape, supporting experimental efforts andadvancing WDM theory.",Zhandos A. Moldabekov,2025-02-07,2025-02-07,,N/A,"['physics.plasm-ph', 'physics.chem-ph', 'physics.comp-ph']"
2502.04920v1,Discovery of a large magnetic nonlinear Hall effect in an altermagnet,http://arxiv.org/abs/2502.04920v1,"Since Edwin Halls groundbreaking discovery of the Hall effect in 1879,magnetism, spin, and quantization have been expanding the scope of Halleffects, continuously driving transformative progress in science andtechnology. Among them, the latest nonlinear Hall effect (NLHE), wherelongitudinal electric field tunes quantum geometry to generate nonlinear Hallvoltage, attracts wide attention as a sensitive probe of topological phasesacross a wide range of materials. Here, we report a new Hall effect member: themagnetic nonlinear Hall effect (MNLHE), characterized by a quadratic Hallconductivity dependence on magnetic field, rather than electric field as inNLHE. This finding relies on an altermagnet, Mn5Si3 thin film, whosealternating-sign Berry curvatures ensure higher-order MNLHE clearlydistinguishable from the first-order anomalous Hall effect. The observedquadratic dependence originates from chiral next-nearest-neighbor hoppingprocesses that acquire magnetic-exchange-driven Zeeman energies andHaldane-like chiral flux phases. Remarkably, this MNLHE is non-analytic, asreversing the magnetic field flips the alternating spin-splitting bands andreverses the hopping chirality, which is absent in traditional NLHE. Beyondoffering a distinctive transport fingerprint for altermagnet Mn5Si3 thin film,this MNLHE is large and unsaturated up to 60 T, providing opportunities forpulsed high-field sensing technologies in both fundamental researches andengineering applications.",Lei Han,2025-02-07,2025-02-07,,N/A,['cond-mat.mtrl-sci']
2502.04918v1,Explainable and externally validated machine learning for neuropsychiatric diagnosis via electrocardiograms,http://arxiv.org/abs/2502.04918v1,"Electrocardiogram (ECG) analysis has emerged as a promising tool foridentifying physiological changes associated with neuropsychiatric conditions.The relationship between cardiovascular health and neuropsychiatric disorderssuggests that ECG abnormalities could serve as valuable biomarkers for moreefficient detection, therapy monitoring, and risk stratification. However, thepotential of the ECG to accurately distinguish neuropsychiatric conditions,particularly among diverse patient populations, remains underexplored. Thisstudy utilized ECG markers and basic demographic data to predictneuropsychiatric conditions using machine learning models, with targets definedthrough ICD-10 codes. Both internal and external validation were performedusing the MIMIC-IV and ECG-View datasets respectively. Performance was assessedusing AUROC scores. To enhance model interpretability, Shapley values wereapplied to provide insights into the contributions of individual ECG featuresto the predictions. Significant predictive performance was observed forconditions within the neurological and psychiatric groups. For the neurologicalgroup, Alzheimer's disease (G30) achieved an internal AUROC of 0.813(0.812-0.814) and an external AUROC of 0.868 (0.867-0.868). In the psychiatricgroup, unspecified dementia (F03) showed an internal AUROC of 0.849(0.848-0.849) and an external AUROC of 0.862 (0.861-0.863). Discriminativefeatures align with known ECG markers but also provide hints on potentially newmarkers. ECG offers significant promise for diagnosing and monitoringneuropsychiatric conditions, with robust predictive performance across internaland external cohorts. Future work should focus on addressing potentialconfounders, such as therapy-related cardiotoxicity, and expanding the scope ofECG applications, including personalized care and early interventionstrategies.",Juan Miguel Lopez Alcaraz,2025-02-07,2025-02-07,,N/A,"['eess.SP', 'cs.LG']"
2502.04916v1,Classification or Prompting: A Case Study on Legal Requirements Traceability,http://arxiv.org/abs/2502.04916v1,"New regulations are continuously introduced to ensure that softwaredevelopment complies with the ethical concerns and prioritizes public safety. Aprerequisite for demonstrating compliance involves tracing softwarerequirements to legal provisions. Requirements traceability is a fundamentaltask where requirements engineers are supposed to analyze technicalrequirements against target artifacts, often under limited time budget. Doingthis analysis manually for complex systems with hundreds of requirements isinfeasible. The legal dimension introduces additional challenges that onlyexacerbate manual effort.  In this paper, we investigate two automated solutions based on large languagemodels (LLMs) to predict trace links between requirements and legal provisions.The first solution, Kashif, is a classifier that leverages sentencetransformers. The second solution prompts a recent generative LLM based onRice, a prompt engineering framework.  On a benchmark dataset, we empirically evaluate Kashif and compare it againsta baseline classifier from the literature. Kashif can identify trace links withan average recall of ~67%, outperforming the baseline with a substantial gainof 54 percentage points (pp) in recall. However, on unseen, more complexrequirements documents traced to the European general data protectionregulation (GDPR), Kashif performs poorly, yielding an average recall of 15%.On the same documents, however, our Rice-based solution yields an averagerecall of 84%, with a remarkable gain of about 69 pp over Kashif. Our resultssuggest that requirements traceability in the legal context cannot be simplyaddressed by building classifiers, as such solutions do not generalize and failto perform well on complex regulations and requirements. Resorting togenerative LLMs, with careful prompt engineering, is thus a more promisingalternative.",Romina Etezadi,2025-02-07,2025-02-07,,N/A,['cs.SE']
2502.04913v1,The head-tail radio galaxy and revived fossil plasma in Abell 1775,http://arxiv.org/abs/2502.04913v1,"Head-tail radio galaxies are characterized by a head, corresponding to anelliptical galaxy, and two radio jets sweeping back from the head, forming anextended structure behind the host galaxy that is moving through theintracluster medium (ICM). This morphology arises from the interaction betweenthe diffuse radio-emitting plasma and the surrounding environment. Sometimesrevived fossil plasma is found in galaxy clusters, tracing old active galacticnucleus ejecta with a very steep spectrum re-energized through processes in theICM, unrelated to the progenitor galaxy. We aim to study the central region ofAbell 1775, a galaxy cluster in an unclear dynamical state at z = 0.072. Ithosts two giant radio-loud elliptical galaxies, the head-tail radio galaxy that""breaks"" at the position of a cold front detected in the X-rays, filamentaryrevived fossil plasma, and central diffuse emission. This study aims toinvestigate and constrain the spectral properties and trends along thehead-tail, as well as the revived fossil plasma, to better understand theformation process of the non-thermal phenomena in A1775. We make use of LOFAR(144 MHz), and new deep uGMRT observations (400 and 650 MHz). We observe anoverall steepening along the tail of the head-tail radio galaxy. In the radiocolour-colour diagram, ageing models reproduce the emission of the head-tail.An unexpected brightness increase at the head of the tail suggests a complexbending of the jets. We derived the equipartition magnetic field and minimumpressure along the tail. We recovered the structure of the revived fossilplasma, which appears as thin filaments with ultra-steep spectra. We show thathigh-sensitivity, high-resolution observations at low frequencies are essentialfor detecting the full extent of the tail, enabling a deeper spectral analysisand resolving the structure and spectral properties of revived fossil plasma.",A. Bushi,2025-02-07,2025-02-07,,N/A,"['astro-ph.CO', 'astro-ph.GA']"
2502.04910v1,On the Power of Heuristics in Temporal Graphs,http://arxiv.org/abs/2502.04910v1,"Dynamic graph datasets often exhibit strong temporal patterns, such asrecency, which prioritizes recent interactions, and popularity, which favorsfrequently occurring nodes. We demonstrate that simple heuristics leveragingonly these patterns can perform on par or outperform state-of-the-art neuralnetwork models under standard evaluation protocols. To further explore thesedynamics, we introduce metrics that quantify the impact of recency andpopularity across datasets. Our experiments on BenchTemp and the Temporal GraphBenchmark show that our approaches achieve state-of-the-art performance acrossall datasets in the latter and secure top ranks on multiple datasets in theformer. These results emphasize the importance of refined evaluation schemes toenable fair comparisons and promote the development of more robust temporalgraph models. Additionally, they reveal that current deep learning methodsoften struggle to capture the key patterns underlying predictions in real-worldtemporal graphs. For reproducibility, we have made our code publicly available.",Filip Cornell,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.04907v1,Scalable and consistent embedding of probability measures into Hilbert spaces via measure quantization,http://arxiv.org/abs/2502.04907v1,"This paper is focused on statistical learning from data that come asprobability measures. In this setting, popular approaches consist in embeddingsuch data into a Hilbert space with either Linearized Optimal Transport orKernel Mean Embedding. However, the cost of computing such embeddings prohibitstheir direct use in large-scale settings. We study two methods based on measurequantization for approximating input probability measures with discretemeasures of small-support size. The first one is based on optimal quantizationof each input measure, while the second one relies on mean-measurequantization. We study the consistency of such approximations, and itsimplication for scalable embeddings of probability measures into a Hilbertspace at a low computational cost. We finally illustrate our findings withvarious numerical experiments.",Erell Gachon,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG']"
2502.04906v1,Starspot distribution and flare events in two young low-mass stars using TESS data,http://arxiv.org/abs/2502.04906v1,"Wide-field high-precision photometric observations such as \textit{TransitingExoplanet Survey Satellite (TESS)} allowed the investigation of the stellarmagnetic activity of cool stars. M-dwarf's starspots and stellar flares are themain indicators of magnetic activity. The present study focuses on modelinglight curves (LCs) to analyze the distribution and characteristics of starspotse.g., location, temperature, and spot size. The \textit{TESS} light curves oftwo selected young M-dwarfs i.e. GJ~182 and 2MASS~J05160212+2214528 werereconstructed using the \textsc{BASSMAN} software, obtaining a three-spot modelfor GJ~182 and two-spot model for 2MASS~J05160212+2214528, describing theirlight curves. For GJ~182, the mean spot temperature was estimated to beapproximately 3279~K, covering 5-8.5\% of the stellar surface while for2MASS~J05160212+2214528 the average spot temperature was approximately 2631~K,with a mean spottedness of about 5.4\%. Using the 2-min cadence LC data, weidentified and analyzed 48 flare events from GJ~182, while no flares weredetected in 2MASS~J05160212+2214528. The estimated bolometric flare energyranged from $10^{32} - 10^{35}$ erg, and 10$^{31}$ - 10$^{33}$ erg in the TESSbandpass. We derived the power-law index of -1.53 $\pm$ 0.12 and -1.86 $\pm$0.22 for flare frequency distribution in sectors 5 and 32 respectively in theflare energy 10$^{33}$ to 10$^{35}$ erg, consistent with previous studies forM-dwarfs. A positive linear correlation between flare energy and duration wasfound with a slope of $0.67 \pm 0.02$, suggesting a similar mechanism followedby stellar superflares and solar flares. By assuming the similarities withsolar flares, we also estimated the lower limit of the magnetic field strengtharound 12 - 232~G to produce such superflare events.",Rajib Kumbhakar,2025-02-07,2025-02-07,,N/A,['astro-ph.SR']
2502.04905v1,RacerF: Lightweight Static Data Race Detection for C Code,http://arxiv.org/abs/2502.04905v1,"We present a novel static analysis for thread-modular data race detection.Our approach exploits static analysis of sequential program behaviour whoseresults are generalised for multi-threaded programs using a combination oflightweight under- and over-approximating methods. We have implemented thisapproach in a new tool called RacerF as a plugin of the Frama-C platform.RacerF can leverage several analysis backends, most notably the Frama-C'sabstract interpreter EVA. Although our methods are mostly heuristic withoutproviding formal guarantees, our experimental evaluation shows that even forintricate programs, RacerF can provide very precise results competitive withmore heavy-weight approaches while being faster than them.",Tomáš Dacík,2025-02-07,2025-02-07,,N/A,"['cs.SE', 'cs.PL']"
2502.04902v1,Optical orientation of excitons and charged carriers in MAPbI$_3$ perovskite single crystals in the orthorhombic phase,http://arxiv.org/abs/2502.04902v1,"Optical orientation of exciton and carrier spins by circularly polarizedlight is the basic phenomenon in the spin physics of semiconductors. Here, weinvestigate spin orientation in MAPbI3 lead halide perovskite crystals at thecryogenic temperature of 1.6 K, where the material has an orthorhombic crystalstructure. The recombination and spin dynamics of excitons and carriers aremeasured by time-resolved photoluminescence after circularly polarizedexcitation. The optical orientation of excitons reaches 85\%, which persistswithin their lifetime of 15-80 ps. This high orientation is maintained forexcitation laser detunings from the exciton resonance to higher energies by upto 0.3 eV, then decreases and vanishes above 1.5 eV detuning. This indicatesthat the Dyakonov-Perel spin relaxation mechanism based on inversion symmetrybreaking is inactive in MAPbI3 crystals with orthorhombic symmetry. The opticalorientation of localized and spatially-separated electrons and holes results in40\% circular polarization of their emission. Their contributions can beidentified from the complex spin beats dynamics in transverse magnetic field.The dynamics analysis gives values of the Land\'e g-factors of 2.83 forelectrons and 0.54 for holes. Also, the magnetic-field-induced polarization ofexcitons and carriers is analyzed in magnetic fields up to 6 T, showing thattheir spin relaxation times are longer than their lifetimes. Namely, for theexcitons, the spin relaxation time exceeds the lifetime by a factor of 6. Wemodel the dynamics of optical orientation degree for cumulative contributionsof excitons and carriers and show that the exciton recombination dynamics cancontrol these dynamics. The polarized emission of excitons and localizedcarriers, produced by their polarization on Zeeman-split levels in magneticfields, is modeled.",Nataliia E. Kopteva,2025-02-07,2025-02-07,,N/A,['cond-mat.mes-hall']
2502.04900v1,Is Dark Matter the origin of the $B\to K ν\barν$ excess at Belle~II?,http://arxiv.org/abs/2502.04900v1,"We present two models of dark matter~(DM) that can provide a naturalexplanation of the excess of \mbox{$B^+\to K^+ +\,\text{invisible}$} eventswith respect to the Standard Model~(SM) prediction for \mbox{$B^+\to K^+\nu\bar\nu$}, which has been reported by the Belle~II collaboration.Interactions between the dark and the visible sector are mediated by anaxion-like particle (ALP) in one case, by the kinetic mixing between a darkphoton and the SM photon in the second case. Both models encompass a lightfermion singlet as the DM candidate and can account for the observed DM relicabundance through, respectively, the freeze-in and the freeze-out productionmechanism, while simultaneously explaining the Belle~II excess.",Lorenzo Calibbi,2025-02-07,2025-02-07,,N/A,"['hep-ph', 'hep-ex']"
2502.04899v1,Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects,http://arxiv.org/abs/2502.04899v1,"The proliferation of digital interactions across diverse domains, such ashealthcare, e-commerce, gaming, and finance, has resulted in the generation ofvast volumes of event stream (ES) data. ES data comprises continuous sequencesof timestamped events that encapsulate detailed contextual information relevantto each domain. While ES data holds significant potential for extractingactionable insights and enhancing decision-making, its effective utilization ishindered by challenges such as the scarcity of labeled data and the fragmentednature of existing research efforts. Self-Supervised Learning (SSL) has emergedas a promising paradigm to address these challenges by enabling the extractionof meaningful representations from unlabeled ES data. In this survey, wesystematically review and synthesize SSL methodologies tailored for ES modelingacross multiple domains, bridging the gaps between domain-specific approachesthat have traditionally operated in isolation. We present a comprehensivetaxonomy of SSL techniques, encompassing both predictive and contrastiveparadigms, and analyze their applicability and effectiveness within differentapplication contexts. Furthermore, we identify critical gaps in currentresearch and propose a future research agenda aimed at developing scalable,domain-agnostic SSL frameworks for ES modeling. By unifying disparate researchefforts and highlighting cross-domain synergies, this survey aims to accelerateinnovation, improve reproducibility, and expand the applicability of SSL todiverse real-world ES challenges.",Levente Zólyomi,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04896v1,Goku: Flow Based Video Generative Foundation Models,http://arxiv.org/abs/2502.04896v1,"This paper introduces Goku, a state-of-the-art family of jointimage-and-video generation models leveraging rectified flow Transformers toachieve industry-leading performance. We detail the foundational elementsenabling high-quality visual generation, including the data curation pipeline,model architecture design, flow formulation, and advanced infrastructure forefficient and robust large-scale training. The Goku models demonstrate superiorperformance in both qualitative and quantitative evaluations, setting newbenchmarks across major tasks. Specifically, Goku achieves 0.76 on GenEval and83.65 on DPG-Bench for text-to-image generation, and 84.85 on VBench fortext-to-video tasks. We believe that this work provides valuable insights andpractical advancements for the research community in developing jointimage-and-video generation models.",Shoufa Chen,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04895v1,Deep Learning Models for Physical Layer Communications,http://arxiv.org/abs/2502.04895v1,"The increased availability of data and computing resources has enabledresearchers to successfully adopt machine learning (ML) techniques and makesignificant contributions in several engineering areas. ML and in particulardeep learning (DL) algorithms have shown to perform better in tasks where aphysical bottom-up description of the phenomenon is lacking and/or ismathematically intractable. Indeed, they take advantage of the observations ofnatural phenomena to automatically acquire knowledge and learn internalrelations. Despite the historical model-based mindset, communicationsengineering recently started shifting the focus towards top-down data-drivenlearning models, especially in domains such as channel modeling and physicallayer design, where in most of the cases no general optimal strategies areknown.  In this thesis, we aim at solving some fundamental open challenges inphysical layer communications exploiting new DL paradigms. In particular, wemathematically formulate, under ML terms, classic problems such as channelcapacity and optimal coding-decoding schemes, for any arbitrary communicationmedium. We design and develop the architecture, algorithm and code necessary totrain the equivalent DL model, and finally, we propose novel solutions tolong-standing problems in the field.",Nunzio A. Letizia,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'eess.SP']"
2502.04894v1,Black Strings and String Clouds Embedded in Anisotropic Quintessence: Solutions for Scalar Particles and Implications,http://arxiv.org/abs/2502.04894v1,"We analyze the spacetime metric associated with a black string surrounded bya cloud of strings and an anisotropic fluid of quintessence in cylindricallysymmetric AdS spacetime. We solve Einstein's equation to obtain the explicitform of the metric, investigate typical values for its parameters, anddetermine their role in the event horizon formation. Within our findings, weshow that the intensity of the cloud of strings regulates the size of the eventhorizon and, when the cloud is absent, the horizon increases drastically forlarger values of the quintessence's state parameter $\alpha_{Q}$. Additionally,the metric shows that, unless $\alpha_{Q}$ is close to its lower bound, thecontribution from the quintessence fluid is only significant at large distancesfrom the black string. Finally, to explore the quantum implications of thisdark energy candidate, we use the confluent Heun function to solve theKlein-Gordon equation for a spin-0 particle near the event horizon. Our resultsindicate that the presence of quintessence alters the particle's radial wavefunction. This modification, in principle, could give rise to an observablethat we termed as \enquote{dark phase}.",Maria de Lourdes Deglmann,2025-02-07,2025-02-07,,N/A,"['gr-qc', 'hep-th', 'math-ph', 'math.MP']"
2502.04892v1,A Foundational Brain Dynamics Model via Stochastic Optimal Control,http://arxiv.org/abs/2502.04892v1,"We introduce a foundational model for brain dynamics that utilizes stochasticoptimal control (SOC) and amortized inference. Our method features acontinuous-discrete state space model (SSM) that can robustly handle theintricate and noisy nature of fMRI signals. To address computationallimitations, we implement an approximation strategy grounded in the SOCframework. Additionally, we present a simulation-free latent dynamics approachthat employs locally linear approximations, facilitating efficient and scalableinference. For effective representation learning, we derive an Evidence LowerBound (ELBO) from the SOC formulation, which integrates smoothly with recentadvancements in self-supervised learning (SSL), thereby promoting robust andtransferable representations. Pre-trained on extensive datasets such as theUKB, our model attains state-of-the-art results across a variety of downstreamtasks, including demographic prediction, trait analysis, disease diagnosis, andprognosis. Moreover, evaluating on external datasets such as HCP-A, ABIDE, andADHD200 further validates its superior abilities and resilience acrossdifferent demographic and clinical distributions. Our foundational modelprovides a scalable and efficient approach for deciphering brain dynamics,opening up numerous applications in neuroscience.",Joonhyeong Park,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'q-bio.NC', 'stat.ML']"
2502.04891v1,GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring,http://arxiv.org/abs/2502.04891v1,"Maximizing the spectral gap through graph rewiring has been proposed toenhance the performance of message-passing graph neural networks (GNNs) byaddressing over-squashing. However, as we show, minimizing the spectral gap canalso improve generalization. To explain this, we analyze how rewiring canbenefit GNNs within the context of stochastic block models. Since spectral gapoptimization primarily influences community strength, it improves performancewhen the community structure aligns with node labels. Building on this insight,we propose three distinct rewiring strategies that explicitly target communitystructure, node labels, and their alignment: (a) community structure-basedrewiring (ComMa), a more computationally efficient alternative to spectral gapoptimization that achieves similar goals; (b) feature similarity-based rewiring(FeaSt), which focuses on maximizing global homophily; and (c) a hybridapproach (ComFy), which enhances local feature similarity while preservingcommunity structure to optimize label-community alignment. Extensiveexperiments confirm the effectiveness of these strategies and support ourtheoretical insights.",Celia Rubio-Madrigal,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.SI', 'stat.ML']"
2502.04888v1,"The non-Abelian geometry, topology, and dynamics of a nonreciprocal Su-Schrieffer-Heeger ladder",http://arxiv.org/abs/2502.04888v1,"Non-Hermiticity breaks down the adiabaticity and naturally leads to thenon-Abelian behaviors in multi-band systems. Here we consider a multi-band,non-Hermitian ladder model with the two legs being the nonreciprocalSu-Schrieffer-Heeger chains. We thoroughly study how the non-Abelian geometry,topology, and dynamics emerge in this model at the onset of inter-leg coupling.Under periodic boundary conditions, by defining a gauge-invariant windingnumber for chiral symmetric systems, we analytically give the exact topologicalphase diagram. With the aid of underlying symmetries generalized fornon-Hermitian systems, we further refine the phase diagram by the geometry ofband structure. In the pseudo-Hermitian symmetric regime, we find that thestable non-Abelian dynamics of a Bloch state under an external constant forcecan be well described in some conditions of the force by the Wilson lineconstructed for non-Hermitian systems. Under open boundary conditions, we alsofind that the bulk-boundary correspondence survives in the thermodynamic limitbut breaks down for finite-size systems with the leg-dependent non-Hermitianskin effect (NHSE), demonstrating the so-called critical NHSE, of which thedecaying length of the bulk skin modes $\xi$ varies with the system size $L$and is numerically verified to satisfy the scale-free power law $\xi\propto L$.Our work may stimulate more focuses on the non-Abelian properties of thenon-Hermitian/open quantum systems.",Ziyu Zhou,2025-02-07,2025-02-07,,N/A,"['cond-mat.mes-hall', 'quant-ph']"
2502.04883v1,Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance,http://arxiv.org/abs/2502.04883v1,"Automatic Speech Recognition (ASR) performance for low-resource languages isstill far behind that of higher-resource languages such as English, due to alack of sufficient labeled data. State-of-the-art methods deployself-supervised transfer learning where a model pre-trained on large amounts ofdata is fine-tuned using little labeled data in a target low-resource language.In this paper, we present and examine a method for fine-tuning an SSL-basedmodel in order to improve the performance for Frisian and its regional dialects(Clay Frisian, Wood Frisian, and South Frisian). We show that Frisian ASRperformance can be improved by using multilingual (Frisian, Dutch, English andGerman) fine-tuning data and an auxiliary language identification task. Inaddition, our findings show that performance on dialectal speech sufferssubstantially, and, importantly, that this effect is moderated by theelicitation approach used to collect the dialectal data. Our findings alsoparticularly suggest that relying solely on standard language data for ASRevaluation may underestimate real-world performance, particularly in languageswith substantial dialectal variation.",Reihaneh Amooie,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
2502.04882v1,pytopicgram: A library for data extraction and topic modeling from Telegram channels,http://arxiv.org/abs/2502.04882v1,"Telegram is a popular platform for public communication, generating largeamounts of messages through its channels. pytopicgram is a Python library thathelps researchers collect, organize, and analyze these Telegram messages. Thelibrary offers key features such as easy message retrieval, detailed channelinformation, engagement metrics, and topic identification using advancedmodeling techniques. By simplifying data extraction and analysis, pytopicgramallows users to understand how content spreads and how audiences interact onTelegram. This paper describes the design, main features, and practical uses of\pytopicgram, showcasing its effectiveness for studying public conversations onTelegram.",J. Gómez-Romero,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04878v1,Sparse Autoencoders Do Not Find Canonical Units of Analysis,http://arxiv.org/abs/2502.04878v1,"A common goal of mechanistic interpretability is to decompose the activationsof neural networks into features: interpretable properties of the inputcomputed by the model. Sparse autoencoders (SAEs) are a popular method forfinding these features in LLMs, and it has been postulated that they can beused to find a \textit{canonical} set of units: a unique and complete list ofatomic features. We cast doubt on this belief using two novel techniques: SAEstitching to show they are incomplete, and meta-SAEs to show they are notatomic. SAE stitching involves inserting or swapping latents from a larger SAEinto a smaller one. Latents from the larger SAE can be divided into twocategories: \emph{novel latents}, which improve performance when added to thesmaller SAE, indicating they capture novel information, and\emph{reconstruction latents}, which can replace corresponding latents in thesmaller SAE that have similar behavior. The existence of novel featuresindicates incompleteness of smaller SAEs. Using meta-SAEs -- SAEs trained onthe decoder matrix of another SAE -- we find that latents in SAEs oftendecompose into combinations of latents from a smaller SAE, showing that largerSAE latents are not atomic. The resulting decompositions are ofteninterpretable; e.g. a latent representing ``Einstein'' decomposes into``scientist'', ``Germany'', and ``famous person''. Even if SAEs do not findcanonical units of analysis, they may still be useful tools. We suggest thatfuture research should either pursue different approaches for identifying suchunits, or pragmatically choose the SAE size suited to their task. We provide aninteractive dashboard to explore meta-SAEs: https://metasaes.streamlit.app/",Patrick Leask,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04876v1,Ultraviolet Renormalization of Spin Boson Models I. Normal and 2-Nilpotent Interactions,http://arxiv.org/abs/2502.04876v1,"We study the ultraviolet problem for models of a finite-dimensional quantummechanical system linearly coupled to a bosonic quantum field, such as the(many-)spin boson model or its rotating-wave approximation. If the state changeof the system upon emission or absorption of a boson is either given by anormal matrix or by a 2-nilpotent one, which is the case for the previouslynamed examples, we prove an optimal renormalization result. We complement it,by proving the norm resolvent convergence of appropriately regularized modelsto the renormalized one. Our method consists of a dressing transformationargument in the normal case and an appropriate interior boundary condition forthe 2-nilpotent case.",Benjamin Hinrichs,2025-02-07,2025-02-07,,N/A,"['math-ph', 'math.MP']"
2502.04873v1,Training-free Task-oriented Grasp Generation,http://arxiv.org/abs/2502.04873v1,"This paper presents a training-free pipeline for task-oriented graspgeneration that combines pre-trained grasp generation models withvision-language models (VLMs). Unlike traditional approaches that focus solelyon stable grasps, our method incorporates task-specific requirements byleveraging the semantic reasoning capabilities of VLMs. We evaluate fivequerying strategies, each utilizing different visual representations ofcandidate grasps, and demonstrate significant improvements over a baselinemethod in both grasp success and task compliance rates, with absolute gains ofup to 36.9% in overall success rate. Our results underline the potential ofVLMs to enhance task-oriented manipulation, providing insights for futureresearch in robotic grasping and human-robot interaction.",Jiaming Wang,2025-02-07,2025-02-07,,N/A,['cs.RO']
2502.04870v1,IPSeg: Image Posterior Mitigates Semantic Drift in Class-Incremental Segmentation,http://arxiv.org/abs/2502.04870v1,"Class incremental learning aims to enable models to learn from sequential,non-stationary data streams across different tasks without catastrophicforgetting. In class incremental semantic segmentation (CISS), the semanticcontent of image pixels evolves over incremental phases, known as semanticdrift. In this work, we identify two critical challenges in CISS thatcontribute to semantic drift and degrade performance. First, we highlight theissue of separate optimization, where different parts of the model areoptimized in distinct incremental stages, leading to misaligned probabilityscales. Second, we identify noisy semantics arising from inappropriatepseudo-labeling, which results in sub-optimal results. To address thesechallenges, we propose a novel and effective approach, Image Posterior andSemantics Decoupling for Segmentation (IPSeg). IPSeg introduces two keymechanisms: (1) leveraging image posterior probabilities to align optimizationacross stages and mitigate the effects of separate optimization, and (2)employing semantics decoupling to handle noisy semantics and tailor learningstrategies for different semantics. Extensive experiments on the Pascal VOC2012 and ADE20K datasets demonstrate that IPSeg achieves superior performancecompared to state-of-the-art methods, particularly in challenging long-termincremental scenarios.",Xiao Yu,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04869v1,Multifractal analysis of intermingled basins and blowout bifurcations in a parametetric family of skew product maps,http://arxiv.org/abs/2502.04869v1,"In this paper we study a two-parameter family of planar maps characterized bytwo distinct invariant subspaces. The model reveals the existence of twochaotic attractors within these subspaces. We identify parameter values atwhich these attractors either exhibits a locally riddled basin of attraction ortransitions into a chaotic saddle. In particular, we demonstrate that, for anopen region in the parameter plane, their basins are intermingled. It is shownthat a fractal boundary curve separates the basins of attraction of these twochaotic attractors, providing a detailed characterization of the riddled basinstructure. Additionally, we show that the model undergoes a blowoutbifurcation. An estimation of the stability index is examined usingthermodynamic formalism. We also perform a multifractal analysis of the levelsets of the stability index.",Fatemeh Helen Ghane,2025-02-07,2025-02-07,,N/A,"['nlin.CD', 'math.DS', '37C70, 37C40, 37H15, 37C45']"
2502.04867v1,Invariant Image Reparameterisation: A Unified Approach to Structural and Practical Identifiability and Model Reduction,http://arxiv.org/abs/2502.04867v1,"Both structural and practical parameter non-identifiability presentfundamental challenges when using mathematical models to interpret data. Thisissue is particularly acute in complex, applied areas such as the life sciencesor engineering, where determining appropriate model complexity is challenging.While several approaches exist for diagnosing and resolving parameternon-identifiability, including symbolic methods, profile likelihood analysis,and sloppiness analysis, these approaches have distinct limitations and arerarely combined. We present an integrated approach called Invariant ImageReparameterisation (IIR) that incorporates key elements of these methods in anew way. Our approach replaces symbolic computations with numericalcalculations at a single reference estimate and an invariance condition thatdetermines when this local calculation holds globally. Parameter combinationsdetermined by this method are naturally ordered by degree of identifiability,and this supports model reduction by replacing a practically non-identifiedmodel with a structurally non-identified approximate model. This approximatemodel can be further parameterised in terms of identified parameters only. Bytreating parameter combinations determined by our approach as interestparameters within our established likelihood-based Profile-Wise Analysis (PWA)framework, we incorporate uncertainty quantification in terms of likelihoodprofiles and confidence sets. We provide a Julia library on GitHub(https://github.com/omaclaren/reparam) demonstrating our methodology across arange of mathematical models.",Oliver J. Maclaren,2025-02-07,2025-02-07,,N/A,"['stat.AP', '62F99 (Primary) 65L09, 93B30, 62F12, 34A55 (Secondary)']"
2502.04863v1,Enhancing Disinformation Detection with Explainable AI and Named Entity Replacement,http://arxiv.org/abs/2502.04863v1,"The automatic detection of disinformation presents a significant challenge inthe field of natural language processing. This task addresses a multifacetedsocietal and communication issue, which needs approaches that extend beyond theidentification of general linguistic patterns through data-driven algorithms.In this research work, we hypothesise that text classification methods are notable to capture the nuances of disinformation and they often ground theirdecision in superfluous features. Hence, we apply a post-hoc explainabilitymethod (SHAP, SHapley Additive exPlanations) to identify spurious elements withhigh impact on the classification models. Our findings show thatnon-informative elements (e.g., URLs and emoticons) should be removed and namedentities (e.g., Rwanda) should be pseudo-anonymized before training to avoidmodels' bias and increase their generalization capabilities. We evaluate thismethodology with internal dataset and external dataset before and afterapplying extended data preprocessing and named entity replacement. The resultsshow that our proposal enhances on average the performance of a disinformationclassification method with external test data in 65.78% without a significantdecrease of the internal test performance.",Santiago González-Silot,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04861v1,Optimal Low degree hardness for Broadcasting on Trees,http://arxiv.org/abs/2502.04861v1,"Broadcasting on trees is a fundamental model from statistical physics thatplays an important role in information theory, noisy computation andphylogenetic reconstruction within computational biology and linguistics. Whilethis model permits efficient linear-time algorithms for the inference of theroot from the leaves, recent work suggests that non-trivial computationalcomplexity may be required for inference.  The inference of the root state can be performed using the celebrated BeliefPropagation (BP) algorithm, which achieves Bayes-optimal performance. AlthoughBP runs in linear time using real arithmetic operations, recent researchindicates that it requires non-trivial computational complexity using morerefined complexity measures.  Moitra, Mossel, and Sandon demonstrated such complexity by constructing aMarkov chain for which estimating the root better than random guessing (fortypical inputs) is $NC^1$-complete. Kohler and Mossel constructed chains where,for trees with $N$ leaves, achieving better-than-random root recovery requirespolynomials of degree $N^{\Omega(1)}$. The papers above raised the question ofwhether such complexity bounds hold generally below the celebratedKesten-Stigum bound.  In a recent work, Huang and Mossel established a general degree lower boundof $\Omega(\log N)$ below the Kesten-Stigum bound. Specifically, they provedthat any function expressed as a linear combination of functions of at most$O(log N)$ leaves has vanishing correlation with the root. In this work, we getan exponential improvement of this lower bound by establishing an$N^{\Omega(1)}$ degree lower bound, for any broadcast process in the wholeregime below the Kesten-Stigum bound.",Han Huang,2025-02-07,2025-02-07,,N/A,['math.PR']
2502.04857v1,Explicit Pfaffian Formula for Amplitudes of Fermionic Gaussian Pure States in Arbitrary Pauli Bases,http://arxiv.org/abs/2502.04857v1,"The explicit computation of amplitudes for fermionic Gaussian pure states inarbitrary Pauli bases is a long-standing challenge in quantum many-bodyphysics, with significant implications for quantum tomography, experimentalstudies, and quantum dynamics. These calculations are essential for analyzingcomplex properties beyond traditional measures, such as formationprobabilities, global entanglement, and entropy in non-standard bases, whereexact and computationally efficient methods remain underdeveloped. Inparticular, having explicit formulas is crucial for optimizing negativelog-likelihood functions in quantum tomography, a key task in the NISQ era. Inthis work, we present an explicit Pfaffian formula (Theorem 1) for determiningthese amplitudes in arbitrary Pauli bases, utilizing a Pfaffian of a matrixbased on qubit parity. Additionally, we introduce a recursive relation (Theorem2) that links the amplitudes of systems with different qubit counts, enablingscalable calculations for large systems. Together, these results provide aversatile framework for applications in global entanglement, Shannon-R\'enyientropy, formation probabilities, and quantum tomography, significantlyexpanding the computational toolkit for analyzing complex quantum systems.",M. A. Rajabpour,2025-02-07,2025-02-07,,N/A,"['quant-ph', 'cond-mat.str-el', 'math-ph', 'math.MP']"
2502.04855v1,Open system dynamics in linear-time beyond the wide-band limit,http://arxiv.org/abs/2502.04855v1,"Nonequilibrium heat transport in quantum systems coupled to wide-bandembeddings provides a striking example of the limitations of the generalizedKadanoff-Baym ansatz (GKBA), while solving the full two-time Kadanoff-Baymequations remains computationally prohibitive. To address this challenge, wepropose an iterated solution to the reconstruction problem, resulting in atime-linear evolution scheme involving 14 correlators for systems withnarrow-band embeddings. This approach eliminates GKBA-related artifacts andresolves convergence issues associated with the wide-band limit. Furthermore,it enables the calculation of energy- and time-resolved currents, facilitatingthe modeling of heat flows in quantum systems and energy- and time-resolvedphotoemission experiments, all at significantly reduced computational cost.",Yaroslav Pavlyukh,2025-02-07,2025-02-07,,N/A,"['cond-mat.mes-hall', 'quant-ph']"
2502.04853v1,Optimisation of ATLAS computing resource usage through a modern HEP Benchmark Suite via HammerCloud and Big PanDA,http://arxiv.org/abs/2502.04853v1,"In April 2023, HEPScore23, the new benchmark based on HEP specificapplications, was adopted by WLCG, replacing HEP-SPEC06. As part of thetransition to the new benchmark, the CPU corepower published by the sitesneeded to be compared with the effective power observed while running ATLASworkloads. One aim was to verify the conversion rate between the scores of theold and the new benchmark. The other objective was to understand how theHEPScore performs when run on multi-core job slots, so exactly like thecomputing sites are being used in the production environment. Our studyleverages the HammerCloud infrastructure and the PanDA Workload ManagementSystem to collect a large benchmark statistic across 136 computing sites usingan enhanced HEP Benchmark Suite. It allows us to collect not only performancemetrics, but, thanks to plugins, it also collects information such as machineload, memory usage and other user-defined metrics during the execution andstores it in an OpenSearch database. These extensive tests allow for anin-depth analysis of the actual, versus declared computing capabilities ofthese sites. The results provide valuable insights into the real-worldperformance of computing resources pledged to ATLAS, identifying areas forimprovement while spotlighting sites that underperform or exceed expectations.Moreover, this helps to ensure efficient operational practices across sites.The collected metrics allowed us to detect and fix configuration issues andtherefore improve the experienced performance.",Natalia Szczepanek,2025-02-07,2025-02-07,,N/A,"['cs.DC', 'hep-ex']"
2502.04852v1,Relative Age Estimation Using Face Images,http://arxiv.org/abs/2502.04852v1,"This work introduces a novel deep-learning approach for estimating age from asingle facial image by refining an initial age estimate. The refinementleverages a reference face database of individuals with similar ages andappearances. We employ a network that estimates age differences between aninput image and reference images with known ages, thus refining the initialestimate. Our method explicitly models age-dependent facial variations usingdifferential regression, yielding improved accuracy compared to conventionalabsolute age estimation. Additionally, we introduce an age augmentation schemethat iteratively refines initial age estimates by modeling their errordistribution during training. This iterative approach further enhances theinitial estimates. Our approach surpasses existing methods, achievingstate-of-the-art accuracy on the MORPH II and CACD datasets. Furthermore, weexamine the biases inherent in contemporary state-of-the-art age estimationtechniques.",Ran Sandhaus,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04851v1,Influence of gas flow rate on modes of reactive oxygen and nitrogen species in a grid-type surface dielectric barrier discharge,http://arxiv.org/abs/2502.04851v1,"The presented work investigates a surface dielectric barrier discharge (SDBD)operated dry synthetic air as the working gas using a combination ofexperimental measurements and simulations. The primary objective is tocharacterize the production and consumption dynamics of reactive oxygen andnitrogen species to enhance the understanding of their formation and facilitatecontrol of the discharge for applications. Densities of O3, NO2, and N2O5 aremeasured under varying gas flow rates, utilizing optical absorptionspectroscopy as the diagnostic method. A semi-empirical chemical kinetics modelis developed based on a compilation of reactions from previous studies onsimilar types of discharges. The results reveal two previously known anddistinct operating modes, with a mode transition occurring between the modes asthe flow rate is varied. The results indicate the dependency of the modetransition on the density of sufficiently vibrationally excited nitrogenmolecules, which is represented in the model by an increased vibrationaltemperature at lower gas flow rates. Furthermore, key reactions responsible forthe production and consumption of ozone and nitrogen oxides are identified,providing insight into the importance of macroscopic parameters, such as gastemperatures and different time constants, that influence the nonlinear balanceof these reactions.",Angie Natalia Torres Segura,2025-02-07,2025-02-07,,N/A,"['physics.plasm-ph', 'physics.app-ph']"
2502.04850v1,Aequa: Fair Model Rewards in Collaborative Learning via Slimmable Networks,http://arxiv.org/abs/2502.04850v1,"Collaborative learning enables multiple participants to learn a single globalmodel by exchanging focused updates instead of sharing data. One of the corechallenges in collaborative learning is ensuring that participants are rewardedfairly for their contributions, which entails two key sub-problems:contribution assessment and reward allocation. This work focuses on fair rewardallocation, where the participants are incentivized through model rewards -differentiated final models whose performance is commensurate with thecontribution. In this work, we leverage the concept of slimmable neuralnetworks to collaboratively learn a shared global model whose performancedegrades gracefully with a reduction in model width. We also propose apost-training fair allocation algorithm that determines the model width foreach participant based on their contributions. We theoretically study theconvergence of our proposed approach and empirically validate it usingextensive experiments on different datasets and architectures. We also extendour approach to enable training-time model reward allocation.",Nurbek Tastan,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.DC']"
2502.04849v1,Advancing Wasserstein Convergence Analysis of Score-Based Models: Insights from Discretization and Second-Order Acceleration,http://arxiv.org/abs/2502.04849v1,"Score-based diffusion models have emerged as powerful tools in generativemodeling, yet their theoretical foundations remain underexplored. In this work,we focus on the Wasserstein convergence analysis of score-based diffusionmodels. Specifically, we investigate the impact of various discretizationschemes, including Euler discretization, exponential integrators, and midpointrandomization methods. Our analysis provides a quantitative comparison of thesediscrete approximations, emphasizing their influence on convergence behavior.Furthermore, we explore scenarios where Hessian information is available andpropose an accelerated sampler based on the local linearization method. Wedemonstrate that this Hessian-based approach achieves faster convergence ratesof order $\widetilde{\mathcal{O}}\left(\frac{1}{\varepsilon}\right)$significantly improving upon the standard rate$\widetilde{\mathcal{O}}\left(\frac{1}{\varepsilon^2}\right)$ of vanilladiffusion models, where $\varepsilon$ denotes the target accuracy.",Yifeng Yu,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG', 'math.PR']"
2502.04848v1,Broadband $γ$-ray spectrum of supernova remnant Cassiopeia A,http://arxiv.org/abs/2502.04848v1,"The core-collapse supernova remnant (SNR) Cassiopeia A (Cas A) is one of thebrightest galactic radio sources with an angular radius of $\sim$ 2.5$\arcmin$. Although no extension of this source has been detected in the$\gamma$-ray band, using more than 1000 days of LHAASO data above $\sim 0.8$TeV, we find that its spectrum is significantly softer than those obtained withImaging Air Cherenkov Telescopes (IACTs) and its flux near $\sim 1$ TeV isabout two times higher. In combination with analyses of more than 16 years of\textit{Fermi}-LAT data covering $0.1 \, \mathrm{GeV} - 1 \, \mathrm{TeV}$, wefind that the spectrum above 30 GeV deviates significantly from a singlepower-law, and is best described by a smoothly broken power-law with a spectralindex of $1.90 \pm 0.15_\mathrm{stat}$ ($3.41 \pm 0.19_\mathrm{stat}$) below(above) a break energy of $0.63 \pm 0.21_\mathrm{stat} \, \mathrm{TeV}$. Givendifferences in the angular resolution of LHAASO-WCDA and IACTs, TeV$\gamma$-ray emission detected with LHAASO may have a significant contributionfrom regions surrounding the SNR illuminated by particles accelerated earlier,which, however, are treated as background by IACTs. Detailed modelling can beused to constrain acceleration processes of TeV particles in the early stage ofSNR evolution.",Zhen Cao,2025-02-07,2025-02-07,,N/A,['astro-ph.HE']
2502.04847v1,HumanDiT: Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation,http://arxiv.org/abs/2502.04847v1,"Human motion video generation has advanced significantly, while existingmethods still struggle with accurately rendering detailed body parts like handsand faces, especially in long sequences and intricate motions. Currentapproaches also rely on fixed resolution and struggle to maintain visualconsistency. To address these limitations, we propose HumanDiT, a pose-guidedDiffusion Transformer (DiT)-based framework trained on a large and wild datasetcontaining 14,000 hours of high-quality video to produce high-fidelity videoswith fine-grained body rendering. Specifically, (i) HumanDiT, built on DiT,supports numerous video resolutions and variable sequence lengths, facilitatinglearning for long-sequence video generation; (ii) we introduce a prefix-latentreference strategy to maintain personalized characteristics across extendedsequences. Furthermore, during inference, HumanDiT leverages Keypoint-DiT togenerate subsequent pose sequences, facilitating video continuation from staticimages or existing videos. It also utilizes a Pose Adapter to enable posetransfer with given sequences. Extensive experiments demonstrate its superiorperformance in generating long-form, pose-accurate videos across diversescenarios.",Qijun Gan,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04845v1,Energy-momentum tensor in the 2d $O(3)$ non-linear sigma model on the lattice,http://arxiv.org/abs/2502.04845v1,"The long-term goal of this project is the non-perturbative renormalization ofthe energy-momentum tensor in the 2d $O(3)$ non-linear sigma model usingdifferent methods which have been developed for QCD applications. As a firststep, we have identified all operators that mix with the energy-momentum tensoronce a lattice discretization is employed, that is all which are compatiblewith power counting and with the symmetries of the theory. Since theseoperators are constrained by non-linear Ward identities arising from thenon-linear realization of the $O(3)$ symmetry, this is not entirelystraightforward on the technical level. We have also outlined the basics ofongoing numerical simulations with shifted boundary conditions and an optimizedconstraint action to minimize lattice artifacts.",Mika Lauk,2025-02-07,2025-02-07,,N/A,['hep-lat']
2502.04844v1,Identification of $tqg$ flavor-changing neutral current interactions using machine learning techniques,http://arxiv.org/abs/2502.04844v1,"Flavor-changing neutral currents (FCNCs) are forbidden at tree level in theStandard Model (SM), but they can be enhanced in physics Beyond the StandardModel (BSM) scenarios.In this paper, we investigate the effectiveness of deeplearning techniques to enhance the sensitivity of current and future colliderexperiments to the production of a top quark and an associated parton throughthe $tqg$ FCNC process, which originates from the $tug$ and $tcg$ vertices. The$tqg$ FCNC events can be produced with a top quark and either an associatedgluon or quark, while SM only has events with a top quark and an associatedquark. We apply machine learning techniques to distinguish the $tqg$ FCNCevents from the SM backgrounds, including $qg$-discrimination variables. We usethe Boosted Decision Tree (BDT) method as a baseline classifier, assuming thatthe leading jet originates from the associated parton. We compare with aTransformer-based deep learning method known as the Self-Attention forJet-parton Assignment (SAJA) network, which allows us to include informationfrom all jets in the event, regardless of their number, eliminating thenecessity to match the associated parton to the leading jet. The \SaJa\ networkwith qg-discrimination variables has the best performance, giving expectedupper limits on the branching ratios Br($t \to qg$) that are 25-35\% lower thanthose from the BDT method.",Byeonghak Ko,2025-02-07,2025-02-07,,N/A,['hep-ph']
2502.04843v1,PoI: Pixel of Interest for Novel View Synthesis Assisted Scene Coordinate Regression,http://arxiv.org/abs/2502.04843v1,"The task of estimating camera poses can be enhanced through novel viewsynthesis techniques such as NeRF and Gaussian Splatting to increase thediversity and extension of training data. However, these techniques oftenproduce rendered images with issues like blurring and ghosting, whichcompromise their reliability. These issues become particularly pronounced forScene Coordinate Regression (SCR) methods, which estimate 3D coordinates at thepixel level. To mitigate the problems associated with unreliable renderedimages, we introduce a novel filtering approach, which selectively extractswell-rendered pixels while discarding the inferior ones. This filtersimultaneously measures the SCR model's real-time reprojection loss andgradient during training. Building on this filtering technique, we also developa new strategy to improve scene coordinate regression using sparse inputs,drawing on successful applications of sparse input techniques in novel viewsynthesis. Our experimental results validate the effectiveness of our method,demonstrating state-of-the-art performance on indoor and outdoor datasets.",Feifei Li,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04840v1,Coherent Local Explanations for Mathematical Optimization,http://arxiv.org/abs/2502.04840v1,"The surge of explainable artificial intelligence methods seeks to enhancetransparency and explainability in machine learning models. At the same time,there is a growing demand for explaining decisions taken through complexalgorithms used in mathematical optimization. However, current explanationmethods do not take into account the structure of the underlying optimizationproblem, leading to unreliable outcomes. In response to this need, we introduceCoherent Local Explanations for Mathematical Optimization (CLEMO). CLEMOprovides explanations for multiple components of optimization models, theobjective value and decision variables, which are coherent with the underlyingmodel structure. Our sampling-based procedure can provide explanations for thebehavior of exact and heuristic solution algorithms. The effectiveness of CLEMOis illustrated by experiments for the shortest path problem, the knapsackproblem, and the vehicle routing problem.",Daan Otto,2025-02-07,2025-02-07,,N/A,"['math.OC', 'cs.LG']"
2502.04838v1,Dynamical Galactic Halo Reconstruction from Rotation Curves in Self-Interacting Fuzzy Dark Matter,http://arxiv.org/abs/2502.04838v1,"Fuzzy Dark Matter with an explicitly non-zero quartic self-interaction (gFDM)is shown to be a viable model for simultaneously fitting 17dark-matter-dominated galaxies from the SPARC database, constraining both theboson mass, $m$, and the self-coupling constant, $g$, to values within therange $\log_{10}\left(\frac{m}{\mathrm{eV}/c^2}\right) =\log_{10}(1.98)-22^{+0.8}_{-0.6}$ and$\log_{10}\left(\frac{g}{\mathrm{Jm}^3/kg}\right) =\log_{10}(1.45)-28^{+0.4}_{-1.2}$; this is based on the combination of anappropriately constructed static super-Gaussian profile for the inner galacticcore (`soliton') region, and a Navarro-Frenk-White profile for the surroundinghalo region. Identification of these parameters enables the explicit {\emdynamical} reconstruction of potential host halos for such galaxies, for whichwe outline a procedure with a proof-of-principle demonstration for two galaxies(UGCA444, UGC07866) shown to yield viable rotation curves over a dynamicalperiod of $O(1) \, Gyr$.",Milos Indjin,2025-02-07,2025-02-07,,N/A,"['astro-ph.CO', 'astro-ph.GA']"
2502.04837v1,Online Robot Motion Planning Methodology Guided by Group Social Proxemics Feature,http://arxiv.org/abs/2502.04837v1,"Nowadays robot is supposed to demonstrate human-like perception, reasoningand behavior pattern in social or service application. However, most of theexisting motion planning methods are incompatible with above requirement. Apotential reason is that the existing navigation algorithms usually intend totreat people as another kind of obstacle, and hardly take the social principleor awareness into consideration. In this paper, we attempt to model theproxemics of group and blend it into the scenario perception and navigation ofrobot. For this purpose, a group clustering method considering both socialrelevance and spatial confidence is introduced. It can enable robot to identifyindividuals and divide them into groups. Next, we propose defining theindividual proxemics within magnetic dipole model, and further established thegroup proxemics and scenario map through vector-field superposition. On thebasis of the group clustering and proxemics modeling, we present the method toobtain the optimal observation positions (OOPs) of group. Once the OOPs gridand scenario map are established, a heuristic path is employed to generate paththat guide robot cruising among the groups for interactive purpose. A series ofexperiments are conducted to validate the proposed methodology on the practicalrobot, the results have demonstrated that our methodology has achievedpromising performance on group recognition accuracy and path-generationefficiency. This concludes that the group awareness evolved as an importantmodule to make robot socially behave in the practical scenario.",Xuan Mu,2025-02-07,2025-02-07,,N/A,"['cs.RO', 'cs.SY', 'eess.SY']"
2502.04836v1,Ensembles in Urban Large Eddy Simulations with Changing Wind Direction,http://arxiv.org/abs/2502.04836v1,"Differences between time-averaged and ensemble-averaged wind are studied inthis article for the case of changing wind direction. We consider a flow drivenby a temporally turning pressure gradient in both an idealized case of astaggered cube array and a realistic urban environment. The repeating structureof the idealized case allows us to construct a large ensemble of 3 240 memberswith a reasonable compute time. The results indicate that the use of plain timeaverage instead of an ensemble average allows for accurate calculation of onlythe along-wind mean velocity. Utilising Taylor diagrams, we show that areasonable compromise between ensemble size and accuracy can be achievedutilising a 30-minute time average together with a 50-member ensemble for theflow within the urban roughness sublayer. During this 30-minute averagingperiod, the wind direction turns for approximately 4.8{\deg}. By applying thisapproach to the realistic urban geometry, we identify building wakes as theregions most severely affected by the incorrectly utilized time averaging.",Jukka-Pekka Keskinen,2025-02-07,2025-02-07,,N/A,['physics.flu-dyn']
2502.04834v1,Lightweight Operations for Visual Speech Recognition,http://arxiv.org/abs/2502.04834v1,"Visual speech recognition (VSR), which decodes spoken words from video data,offers significant benefits, particularly when audio is unavailable. However,the high dimensionality of video data leads to prohibitive computational coststhat demand powerful hardware, limiting VSR deployment on resource-constraineddevices. This work addresses this limitation by developing lightweight VSRarchitectures. Leveraging efficient operation design paradigms, we createcompact yet powerful models with reduced resource requirements and minimalaccuracy loss. We train and evaluate our models on a large-scale public datasetfor recognition of words from video sequences, demonstrating theireffectiveness for practical applications. We also conduct an extensive array ofablative experiments to thoroughly analyze the size and complexity of eachmodel. Code and trained models will be made publicly available.",Iason Ioannis Panagos,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']"
2502.04833v1,Puzzling Ultra-Diffuse Galaxy Evolution (PUDGE). I. The existence of a Nube-like galaxy in IllustrisTNG,http://arxiv.org/abs/2502.04833v1,"The recent discovery of the most extended ultra-diffuse galaxy (UDG), Nube,has raised yet another question about the validity of the cold dark matter(CDM) model. The studies using cosmological and zoom-in simulations, whichassume CDM, failed to replicate galaxies with the structural properties ofNube. However, the simulation box or the examined population of UDGs may be toonarrow to fully capture the range of effects that can lead to the formation ofsuch extraordinary galaxies. In this work we present a case study of aNube-like galaxy from TNG100, the most extended simulated UDG examined to datethat closely mirrors the structural properties of the observed Nube galaxy.Since its formation, the simulated Nube-like galaxy has already beenultra-diffuse and evolved mainly in isolated regions with occasionalinteractions. Its last major merger was finalized about 1.336 Gyr ago and leftno trace of interaction apart from further extending the stellar size. Thisevolutionary pathway, featuring a recent merger that expanded an alreadyultra-diffuse stellar system, is unique and innovative compared to previousstudies. We argue that multiple proposed formation mechanisms can operatesimultaneously, further expanding the UDGs and making them extreme outliers ofthe mass-size relation under favorable conditions. Therefore, it is essentialto study these simulated extreme outliers, their formation, and, moreimportantly, their evolution. We also highlight the necessity of carefullyanalyzing and interpreting the simulated data and better understanding thelimitations of a chosen simulation. Thus, if Nube is considered an extremeoutlier, its properties are not in tension with the standard cosmologicalmodel.",Nataša Pavlov,2025-02-07,2025-02-07,,N/A,['astro-ph.GA']
2502.04831v1,Empirical formula for charge state distribution of projectile ions through solid targets,http://arxiv.org/abs/2502.04831v1,"The charge state distributions (CSDs) of the projectile ions through gaseousor solid targets in the energy range of tandem accelerators (1 MeV/u < E < 5MeV/u) have a major impact on ion-atom collision and accelerator physics.Theoretically it is possible to generate the CSDs for up to Ni-like ions, butempirical models have no such bounds. In the recent decades, the mean chargestates are mostly obtained from an empirical formula [Schiwietz et al., Nucl.Inst. Meths. 225, 4(2004)]. But no description on CSDs is found there. Toestimate the CSDs, we have used Gaussian distribution function havingdistribution width given by [Novikov and Teplove, Phys. Lett. 378, 1286(2014)].The results obtained have been compared with the experimentally measured CSDsfor the heavy projectile ions. The merits and demerits of such empiricalformulae have been discussed.",Manpreet Kaur,2025-02-07,2025-02-07,,N/A,['physics.atom-ph']
2502.04829v1,Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization,http://arxiv.org/abs/2502.04829v1,"Black-box algorithms are designed to optimize functions without relying ontheir underlying analytical structure or gradient information, making themessential when gradients are inaccessible or difficult to compute. Traditionalmethods for solving black-box optimization (BBO) problems predominantly rely onnon-parametric models and struggle to scale to large input spaces. Conversely,parametric methods that model the function with neural estimators and obtaingradient signals via backpropagation may suffer from significant gradienterrors. A recent alternative, Explicit Gradient Learning (EGL), which directlylearns the gradient using a first-order Taylor approximation, has demonstratedsuperior performance over both parametric and non-parametric methods. In thiswork, we propose two novel gradient learning variants to address the robustnesschallenges posed by high-dimensional, complex, and highly non-linear problems.Optimistic Gradient Learning (OGL) introduces a bias toward lower regions inthe function landscape, while Higher-order Gradient Learning (HGL) incorporatessecond-order Taylor corrections to improve gradient accuracy. We combine theseapproaches into the unified OHGL algorithm, achieving state-of-the-art (SOTA)performance on the synthetic COCO suite. Additionally, we demonstrate OHGLsapplicability to high-dimensional real-world machine learning (ML) tasks suchas adversarial training and code generation. Our results highlight OHGLsability to generate stronger candidates, offering a valuable tool for MLresearchers and practitioners tackling high-dimensional, non-linearoptimization challenges",Yedidya Kfir,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04828v1,Observational constraints on vector-like dark energy,http://arxiv.org/abs/2502.04828v1,"The canonical cosmological model to explain the recent acceleration of theuniverse relies on a cosmological constant, and most dynamical dark energy andmodified gravity model alternatives are based on scalar fields. Still, furtheralternatives are possible. One of these involves vector fields: under certainconditions, they can lead to accelerating universes while preservinglarge-scale homogeneity and isotropy. We report quantitative observationalconstraints on a model previously proposed by Armend\'ariz-Pic\'on and known asthe cosmic triad. We consider several subclasses of the model, whichgenerically is a parametric extension of the canonical $\Lambda$CDM model, aswell as two possible choices of the triad's potential. Our analysis shows thatany deviations from this limit are constrained to be small. In particular thepreferred present-day values of the matter density and the dark energy equationof state are fully consistent with those obtained, for the same datasets, inflat $\Lambda$CDM and $w_0$CDM. The constraints mildly depend on the priors onthe dark energy equation of state, specifically on whether phantom valuesthereof are allowed, while the choice of potential does not play a significantrole since any such potential is constrained to be relatively flat.",C. S. C. M. Coelho,2025-02-07,2025-02-07,,N/A,"['astro-ph.CO', 'gr-qc', 'hep-ph']"
2502.04825v1,The Czech Particle Physics Project,http://arxiv.org/abs/2502.04825v1,"We present the status of the Czech Particle Physics Project (CPPP). The CPPPis a learning tool in masterclasses aimed at high school students (aged 15 to18). The project is structured in modules. The first module is dedicated to thedetection of an Axion-Like-Particle (ALP) using the ATLAS Forward Proton (AFP)detector. The second module focuses on the reconstruction of the Higgs bosonmass using the Higgs boson golden channel with four leptons in the final state.The third and fourth modules are educational aids and sources for expertinformation. These web portals are dedicated to Higgs boson research andsearches for Supersymmetry. Two databases are created with more than 1000relevant articles each, using the CERN Document Server API and web scrapingmethods. The databases are automatically updated when new results on Higgsbosons or searches for Supersymmetric particles become available. Usingartificial intelligence and natural language processing, the articles arecategorized according to properties of the results. The modules are accessibleat https://cern.ch/cppp.",Andre Sopczak,2025-02-07,2025-02-07,,N/A,['hep-ph']
2502.04824v1,Estimating the duration of RT-PCR positivity for SARS-CoV-2 from doubly interval censored data with undetected infections,http://arxiv.org/abs/2502.04824v1,"Monitoring the incidence of new infections during a pandemic is critical foran effective public health response. General population prevalence surveys forSARS-CoV-2 can provide high-quality data to estimate incidence. However,estimation relies on understanding the distribution of the duration thatinfections remain detectable. This study addresses this need using data fromthe Coronavirus Infection Survey (CIS), a long-term, longitudinal, generalpopulation survey conducted in the UK. Analyzing these data presents uniquechallenges, such as doubly interval censoring, undetected infections, and falsenegatives. We propose a Bayesian nonparametric survival analysis approach,estimating a discrete-time distribution of durations and integrating priorinformation derived from a complementary study. Our methodology is validatedthrough a simulation study, including its resilience to model misspecification,and then applied to the CIS dataset. This results in the first estimate of thefull duration distribution in a general population, as well as methodology thatcould be transferred to new contexts.",Joshua Blake,2025-02-07,2025-02-07,,N/A,"['stat.ME', 'stat.AP']"
2502.04823v1,Radio emission from a massive node of the cosmic web. A discovery powered by machine learning,http://arxiv.org/abs/2502.04823v1,"Aims. We aim to understand the nature of the diffuse radio emissionsurrounding the massive galaxy cluster PSZ2 G083.29-31.03, at z=0.412, alreadyknown to host a radio halo. Our investigation was triggered by Radio U-Net, anovel machine learning algorithm for detecting diffuse radio emission, whichwas previously applied to the LOFAR Two Meter Sky Survey (LoTSS). Methods. Were-processed LoTSS (120-168 MHz) data and analyzed archival XMM-Newton (0.7-1.2keV) observations. We also analyzed optical and near-infrared data from theDESI Legacy Imaging Surveys and asses the mass distribution with weak-lensinganalysis based on archival Subaru Suprime-Cam and CFHT MegaPrime/MegaCamobservations. Results. We report the discovery of large-scale diffuse radioemission around PSZ2 G083.29-31.03, with a projected largest linear size of 5Mpc at 144 MHz. The radio emission is aligned with the thermal X-ray emissionand the distribution of galaxies, unveiling the presence of two low-masssystems, at similar redshifts on either side of the central cluster. The weaklensing analysis supports this scenario, demonstrating the presence of anextended and complex mass distribution. Conclusions. We propose to interpretthe two faint radio sources as connected to the central cluster, thusilluminating the presence of two substructures merging into a massive node ofthe cosmic web. However, because of uncertainties in redshift and massestimates, combined with the low resolution required to detect these sources,the classification of the two sources as independent radio halos associatedwith nearby low-mass clusters or even as a mixture of different types ofdiffuse radio emission cannot be definitively ruled out.",C. Stuardi,2025-02-07,2025-02-07,,N/A,['astro-ph.CO']
2502.04820v1,A fully conservative discrete velocity Boltzmann solver with parallel adaptive mesh refinement for compressible flows,http://arxiv.org/abs/2502.04820v1,"Since the advent of the lattice Boltzmann method, discrete velocity Boltzmannmodels have provided a compelling alternative to classical Euler andNavier--Stokes--Fourier solvers in simulating fluid flows of various regimes byleveraging the kinetic theory of gases. Yet, significant challenges remain inefficiently and accurately simulating compressible high-speed flows whilemaintaining strict conservation of mass, momentum and energy. This paperpresents a parallel and fully conservative adaptive mesh refinement (AMR)implementation of a finite-volume-based discrete kinetic model. The solveremploys time-dependent H-type refinement combined with a two-populationquasi-equilibrium Bhatnagar--Gross--Krook kinetic model. Results have shownthat the targeted macroscopic moments as well as the dispersion and dissipationrates of all eigen-modes are accurately recovered while strictly preservingconservation laws. Furthermore, one- and two-dimensional benchmarks such as theSod and Lax shock tubes, the Shu--Osher and several Riemann problems, as wellas viscous shock-vortex interactions have demonstrated that the solverprecisely captures reference solutions, whilst the AMR methodology efficientlyreduces computational cost for the same accuracy and fidelity of the solution.The proposed solver marks an accurate, efficient and scalable framework forkinetic simulations of compressible high-speed flows with moderatediscontinuities, offering a valuable tool for studying complex problems influid dynamics.",Ruben M. Strässle,2025-02-07,2025-02-07,,N/A,['physics.flu-dyn']
2502.04819v1,The Wideband Analysis of the Impact of I/Q Imbalance on THz Communication,http://arxiv.org/abs/2502.04819v1,"The terahertz (THz) band is a promising solution to the increasing datatraffic demands of future wireless networks. However, developing transceiversfor THz communication is a complex and toilsome task due to the difficulty indesigning devices that operate at this frequency and the impact of hardwareimpairments on performance. This paper investigates the impact of radiofrequency (RF) impairment, in-phase/quadrature imbalance (IQI). To this end, weexpress an IQI model for the THzspecific array-of-subarrays (AoSA) architectureconsidering the unique features of THz communication; vast bandwidth, severepower drawdown, and pencil-like beams. We further model the impact of IQI inthe power limited regime in order to investigate the power and ultra-widebandtrade-off. To achieve this, we express the spectral efficiency in terms ofwideband slope and bit energy to noise ratio which are the two importantinformation theoretic metrics that reveals the performance of the ultrawidebandsystems as in THz communication. Our results show that THz systems with IQIhave a strict limit in achievable rate although they provide immense spectrum.We also demonstrate with our simulation results that compared to lowfrequencies, IQI is a more serious concern in THz links.",Dogus Can Sevdiren,2025-02-07,2025-02-07,,N/A,['eess.SP']
2502.04818v1,Harnessing omnipresent oscillator networks as computational resource,http://arxiv.org/abs/2502.04818v1,"Nature is pervaded with oscillatory behavior. In networks of coupledoscillators patterns can arise when the system synchronizes to an externalinput. Hence, these networks provide processing and memory of input. We presenta universal framework for harnessing oscillator networks as computationalresource. This reservoir computing framework is introduced by the ubiquitousmodel for phase-locking, the Kuramoto model. We force the Kuramoto model by anonlinear target-system, then after substituting the target-system with atrained feedback-loop it emulates the target-system. Our results are two-fold.Firstly, the trained network inherits performance properties of the Kuramotomodel, where all-to-all coupling is performed in linear time with respect tothe number of nodes and parameters for synchronization are abundant. Secondly,the learning capabilities of the oscillator network can be explained usingKuramoto model's order parameter. This work provides the foundation forutilizing nature's oscillator networks as a new class of information processingsystems.",Thomas Geert de Jong,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'math.DS', 'nlin.AO', 'nlin.CD', '92B25', 'I.2.6']"
2502.04815v1,Semi-classical modelling of second-order spontaneous down-conversion measured over 10 decades of pump intensity in a type II phase-matched KTP crystal,http://arxiv.org/abs/2502.04815v1,"We performed a second-order spontaneous parametric down-conversion (SPDC)experiment in a Type II phase-matched KTiOPO4 crystal pumped at 532 nm givingbirth to a signal beam at 1037 nm and an idler one at 1092 nm along the x-axisof the crystal. Three pump sources have been used: in the continuous-wave,nanosecond (200 ns, 1 kHz) and picosecond (15 ps, 10 Hz) regimes. That allowedus to cover a pump intensity range from 2.4 W.cm-2 to 3.7 GW.cm-2 which led tothe generation of twin photons with a flux from 1.1x104 Hz to 1.2x1021 Hz,respectively, the corresponding quantum efficiencies being of 1.8x10-11 and9.2x10-4. We identified two SPDC regimes regarding the pump intensity: onebelow 30 MW.cm-2 for which the flux increases linearly, and the other one above30 MW.cm-2 for which the flux behaves exponentially. We proposed asemi-classical model under the undepleted pump approximation based on both thequantum fluctuations of vacuum for the seeding of the process and a propagationstep ensured by classical fields, which allowed a satisfying description ofthese two regimes, with a much better agreement at high intensity than thequantum models based on the nonlinear momentum or the nonlinear Hamiltonianoperators.",Julien Bertrand,2025-02-07,2025-02-07,,N/A,['quant-ph']
2502.04814v1,Interplay of Kondo Physics with Incommensurate Charge Density Waves in CeTe$_3$,http://arxiv.org/abs/2502.04814v1,"CeTe$_3$ is a 2-dimensional (2D) Van der Waals (VdW) material withincommensurate charge density waves (CDW), extremely high transitiontemperature ($T_{CDW}$) and a large momentum-dependent CDW gap that leaves asignificant portion of the Fermi surface intact. It is also considered to be aweak Kondo system, a property unexpected for a material with incommensurateCDW, where each atomic site is slightly different. Here, we study theproperties of the CDW state in several RTe$_3$ (R is rare earth) materials andexamine the hybridization of itinerant states with the localized Ce $4f$multiplet in CeTe$_3$ by using angle resolved photoemission spectroscopy(ARPES). We find that the renormalization of the itinerant states originatingfrom the hybridization with the localized $4f$ states at $-260$ meV extends tothe Fermi level. This, with remnants of another localized state at the Fermilevel, supports the characterization of CeTe$_3$ as a weak Kondo material.Furthermore, we uncover a $k$-dependence of the hybridization with the states$-260$ meV, indicating that similar effect could be the reason for discrepancybetween the heavy masses in specific heat and light ones in Shubnikov de Haasoscillations observed in other heavy fermion materials.",Vesna Miksic Trontl,2025-02-07,2025-02-07,,N/A,['cond-mat.str-el']
2502.04810v1,The Co-Moving Velocity and Projective Transformations,http://arxiv.org/abs/2502.04810v1,"In a string of recent papers starting with (Transport in Porous Media, 125,  565 (2018)), a theory of immiscible two-phase flow in porous media based on  Euler homogeneity of the total volumetric flow rate has been investigated.The  thermodynamic-like theory has an associated statistical mechanics based on a  maximum entropy principle. A quantity called the co-moving velocity connects  the equations of state of the intensive thermodynamic velocities and the  physical seepage velocities of two flowing fluids. The obtained relationshave  a structure that can be interpreted using affine- and projective geometry.The  co-moving velocity can be expressed as a transformation of the saturation  using projective duality of points and lines. One obtains an exact  constitutive relation depending on a projective invariant, the cross-ratio,  which allows the co-moving velocity to be expressed in terms of a simple  steady-state advection equation. A kinematic view of the  velocity relations is presented, modeled by a well-known non-trivial geometrywhich turns  out to be pseudo-Euclidean. The cross-ratio determines a hyperbolic angle in  this space, and can be parametrized in terms of three numbers using a linear  fractional transformation. Knowing these parameters, the pore velocity and  the derivative of the pore velocity with respect to the saturation, an  approximation for the co-moving velocity can be obtained for a range ofapplied  pressures, viscosity ratios and surface tensions. The parametrization is  demonstrated using data from a dynamic pore network model and  relative permeability data from the literature. This paper only considers the  pore areas as extensive variables, however, the geometric principles are  general, and the same idea could potentially be used in other systems.",Håkon Pedersen,2025-02-07,2025-02-07,,N/A,['physics.flu-dyn']
2502.04808v1,Tracking electron capture processes in classical molecular dynamics simulations for spectral line broadening in plasmas,http://arxiv.org/abs/2502.04808v1,"Plasma spectroscopy is a fundamental tool for diagnosing laboratory andastrophysical plasmas. Accurate interpretation of spectra depends upon precisemodeling and comprehension of Stark-broadening and other mechanisms affectingspectral lines. In this context, computer simulations have emerged asinvaluable tools, offering \textit{idealized experiments} with well-definedconditions. Molecular dynamics simulations, in particular, excel at replicatingthe particle interactions within the plasma and their impact on the state of aradiating atom or ion. However, these simulations present challenges intracking electron capture processes, since setting an unambiguous criterion todistinguish between bound and free electrons is not trivial. In this paper weintroduce a new algorithm that, within a classical framework, preciselyidentifies the scenario in which an electron is captured by an ion and thenfollows a stable orbit around it. The algorithm's applicability extends toemitters with charges Z >= 1. Importantly, the procedure enables the correctidentification of valid time-histories of the electric microfield perturbingthe emitting ion, which will be used for subsequent line shape calculations. Asa result, our simulations naturally and accurately incorporate the effects ofboth strong collisions and electron capture phenomena on spectral linebroadening.",D. González-Herrero,2025-02-07,2025-02-07,,N/A,"['physics.plasm-ph', 'astro-ph.IM', 'physics.atom-ph', 'physics.comp-ph', 'physics.optics']"
2502.04807v1,Robust Conformal Outlier Detection under Contaminated Reference Data,http://arxiv.org/abs/2502.04807v1,"Conformal prediction is a flexible framework for calibrating machine learningpredictions, providing distribution-free statistical guarantees. In outlierdetection, this calibration relies on a reference set of labeled inlier data tocontrol the type-I error rate. However, obtaining a perfectly labeled inlierreference set is often unrealistic, and a more practical scenario involvesaccess to a contaminated reference set containing a small fraction of outliers.This paper analyzes the impact of such contamination on the validity ofconformal methods. We prove that under realistic, non-adversarial settings,calibration on contaminated data yields conservative type-I error control,shedding light on the inherent robustness of conformal methods. Thisconservativeness, however, typically results in a loss of power. To alleviatethis limitation, we propose a novel, active data-cleaning framework thatleverages a limited labeling budget and an outlier detection model toselectively annotate data points in the contaminated reference set that aresuspected as outliers. By removing only the annotated outliers in this``suspicious'' subset, we can effectively enhance power while mitigating therisk of inflating the type-I error rate, as supported by our theoreticalanalysis. Experiments on real datasets validate the conservative behavior ofconformal methods under contamination and show that the proposed data-cleaningstrategy improves power without sacrificing validity.",Meshi Bashari,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG', 'stat.ME']"
2502.04800v1,"Spin-free orbital entropy, mutual information, and entanglement analysis",http://arxiv.org/abs/2502.04800v1,"Orbital entropies, pair entropies, and mutual information have become populartools for analysis of strongly correlated wave functions. They canquantitatively measure how strongly an orbital (e.g. from the DMRG activespace) participates in the strong correlation and reveal the entanglementpattern between different orbitals. However, this pattern can become rathercomplicated and sometimes difficult to interpret for large active spaces and isnot invariant with respect to the spin projection ($M_s$) component of the spinmultiplet state. We introduce a modified spin-free orbital entropy, pairentropy, and mutual information, which simplify the entanglement analysis andare invariant with respect to $M_s$. By comparison of these quantities withtheir ``original'' spin-including counterparts one can distinguish staticcorrelation due to spin couplings from the ``genuine'' strong correlation dueto a multiconfigurational character of the wave function. We illustrate theapproach on a model consisting of a non-interacting dimer of triplet diradicalsand on a more realistic example of iron-sulfur bound complexes with one and twoiron atoms.",Jiri Pittner,2025-02-07,2025-02-07,,N/A,['physics.chem-ph']
2502.04798v1,A glimpse into an effective world,http://arxiv.org/abs/2502.04798v1,"Our contribution aims to celebrate the immeasurable contribution that Tom Kuohas provided to the understanding of the structure of atomic nuclei, and alsoof the infinite nuclear matter, in terms of the fundamental principlesgoverning the realistic nuclear potential. The authors want to testify TomKuo's heritage and impact on their approach to the study of nuclear systems byreviewing some recent findings on the role of the two-body component ofshell-model effective $\beta$-decay operators. The focus is spotted on theso-called Pauli-blocking effect, that plays a non-negligible role in nucleicharacterized by a large number of valence nucleons.",Luigi Coraggio,2025-02-07,2025-02-07,,N/A,"['nucl-th', 'nucl-ex']"
2502.04797v1,Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks,http://arxiv.org/abs/2502.04797v1,"Free-text explanations are expressive and easy to understand, but manydatasets lack annotated explanation data, making it challenging to train modelsfor explainable predictions. To address this, we investigate how to useexisting explanation datasets for self-rationalization and evaluate models'out-of-distribution (OOD) performance. We fine-tune T5-Large and OLMo-7B modelsand assess the impact of fine-tuning data quality, the number of fine-tuningsamples, and few-shot selection methods. The models are evaluated on 19 diverseOOD datasets across three tasks: natural language inference (NLI),fact-checking, and hallucination detection in abstractive summarization. Forthe generated explanation evaluation, we conduct a human study on 13 selectedmodels and study its correlation with the Acceptability score (T5-11B) andthree other LLM-based reference-free metrics. Human evaluation shows that theAcceptability score correlates most strongly with human judgments,demonstrating its effectiveness in evaluating free-text explanations. Ourfindings reveal: 1) few annotated examples effectively adapt models for OODexplanation generation; 2) compared to sample selection strategies, fine-tuningdata source has a larger impact on OOD performance; and 3) models with higherlabel prediction accuracy tend to produce better explanations, as reflected byhigher Acceptability scores.",Jing Yang,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04796v1,DULRTC-RME: A Deep Unrolled Low-rank Tensor Completion Network for Radio Map Estimation,http://arxiv.org/abs/2502.04796v1,"Radio maps enrich radio propagation and spectrum occupancy information, whichprovides fundamental support for the operation and optimization of wirelesscommunication systems. Traditional radio maps are mainly achieved by extensivemanual channel measurements, which is time-consuming and inefficient. To reducethe complexity of channel measurements, radio map estimation (RME) throughnovel artificial intelligence techniques has emerged to attain higherresolution radio maps from sparse measurements or few observations. However,black box problems and strong dependency on training data make learning-basedmethods less explainable, while model-based methods offer strong theoreticalgrounding but perform inferior to the learning-based methods. In this paper, wedevelop a deep unrolled low-rank tensor completion network (DULRTC-RME) forradio map estimation, which integrates theoretical interpretability andlearning ability by unrolling the tedious low-rank tensor completionoptimization into a deep network. It is the first time that algorithm unrollingtechnology has been used in the RME field. Experimental results demonstratethat DULRTC-RME outperforms existing RME methods.",Yao Wang,2025-02-07,2025-02-07,,N/A,['eess.SP']
2502.04795v1,Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition,http://arxiv.org/abs/2502.04795v1,"Large language models exhibit general linguistic abilities but significantlydiffer from humans in their efficiency of language acquisition. This studyproposes a method for integrating the developmental characteristics of workingmemory during the critical period, a stage when human language acquisition isparticularly efficient, into language models. The proposed method introduces amechanism that initially constrains working memory during the early stages oftraining and gradually relaxes this constraint in an exponential manner aslearning progresses. Targeted syntactic evaluation shows that the proposedmethod outperforms conventional models without memory constraints or withstatic memory constraints. These findings not only provide new directions fordesigning data-efficient language models but also offer indirect evidencesupporting the underlying mechanisms of the critical period hypothesis in humanlanguage acquisition.",Masato Mita,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04794v1,MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin,http://arxiv.org/abs/2502.04794v1,"Fever of unknown origin FUO remains a diagnostic challenge. MedMimic isintroduced as a multimodal framework inspired by real-world diagnosticprocesses. It uses pretrained models such as DINOv2, Vision Transformer, andResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging intolow-dimensional, semantically meaningful features. A learnableself-attention-based fusion network then integrates these imaging features withclinical data for classification. Using 416 FUO patient cases from SichuanUniversity West China Hospital from 2017 to 2023, the multimodal fusionclassification network MFCN achieved macro-AUROC scores ranging from 0.8654 to0.9291 across seven tasks, outperforming conventional machine learning andsingle-modality deep learning methods. Ablation studies and five-foldcross-validation further validated its effectiveness. By combining thestrengths of pretrained large models and deep learning, MedMimic offers apromising solution for disease classification.",Minrui Chen,2025-02-07,2025-02-07,,N/A,"['eess.IV', 'cs.AI', 'cs.CV']"
2502.04793v1,$t$-Testing the Waters: Empirically Validating Assumptions for Reliable A/B-Testing,http://arxiv.org/abs/2502.04793v1,"A/B-tests are a cornerstone of experimental design on the web, withwide-ranging applications and use-cases. The statistical $t$-test comparingdifferences in means is the most commonly used method for assessing treatmenteffects, often justified through the Central Limit Theorem (CLT). The CLTascertains that, as the sample size grows, the sampling distribution of theAverage Treatment Effect converges to normality, making the $t$-test valid forsufficiently large sample sizes. When outcome measures are skewed ornon-normal, quantifying what ""sufficiently large"" entails is notstraightforward.  To ensure that confidence intervals maintain proper coverage and that$p$-values accurately reflect the false positive rate, it is critical tovalidate this normality assumption. We propose a practical method to test this,by analysing repeatedly resampled A/A-tests. When the normality assumptionholds, the resulting $p$-value distribution should be uniform, and thisproperty can be tested using the Kolmogorov-Smirnov test. This provides anefficient and effective way to empirically assess whether the $t$-test'sassumptions are met, and the A/B-test is valid. We demonstrate our methodologyand highlight how it helps to identify scenarios prone to inflated Type-Ierrors. Our approach provides a practical framework to ensure and improve thereliability and robustness of A/B-testing practices.",Olivier Jeunen,2025-02-07,2025-02-07,,N/A,"['stat.ME', 'cs.LG']"
2502.04792v1,Strong law of large numbers for a function of the local times of a transient random walk on groups,http://arxiv.org/abs/2502.04792v1,"This paper presents the strong law of large numbers for a function of thelocal times of a transient random walk on groups, extending the research ofAsymont and Korshunov for random walks on the integer lattice $\mathbb{Z}^d$.Under some weaker conditions, we prove that certain function of the local timesconverges almost surely and in $L^1$ and $L^2$. The proof is mainly based onthe subadditive ergodic theorem.",Yinshan Chang,2025-02-07,2025-02-07,,N/A,['math.PR']
2502.04791v1,Supersymmetric scale-separated AdS$_3$ vacua of type IIB,http://arxiv.org/abs/2502.04791v1,"I construct supersymmetric, parametrically scale-separated AdS$_3$ vacua oftype IIB string theory. These arise as compactifications with orientifoldplanes on specific seven-dimensional solvmanifolds admitting co-closed$G_2$-structures, preserving minimal supersymmetry. There are solutions thatinclude either one set or four sets of intersecting O5-planes in the smearedapproximation, and parametric scale separation can be achieved by tuningunbounded fluxes to infinity. Additionally, the putative holographic fieldtheory operators that are dual to the lightest scalars in the gravitationaltheory have integer conformal dimensions at tree level, aligning with otherscale-separated models of type II string theory.",Vincent Van Hemelryck,2025-02-07,2025-02-07,,N/A,['hep-th']
2502.04790v1,S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency,http://arxiv.org/abs/2502.04790v1,"Large language models (LLMs) have demonstrated remarkable capabilities acrossvarious natural language processing (NLP) scenarios, but they still facechallenges when handling complex arithmetic and logical reasoning tasks. WhileChain-Of-Thought (CoT) reasoning, self-consistency (SC) and self-correctionstrategies have attempted to guide models in sequential, multi-step reasoning,Multi-agent Debate (MAD) has emerged as a viable approach for enhancing thereasoning capabilities of LLMs. By increasing both the number of agents and thefrequency of debates, the performance of LLMs improves significantly. However,this strategy results in a significant increase in token costs, presenting abarrier to scalability. To address this challenge, we introduce a novelsparsification strategy designed to reduce token costs within MAD. Thisapproach minimizes ineffective exchanges of information and unproductivediscussions among agents, thereby enhancing the overall efficiency of thedebate process. We conduct comparative experiments on multiple datasets acrossvarious models, demonstrating that our approach significantly reduces the tokencosts in MAD to a considerable extent. Specifically, compared to MAD, ourapproach achieves an impressive reduction of up to 94.5\% in token costs whilemaintaining performance degradation below 2.0\%.",Yuting Zeng,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI']"
2502.04789v1,Probing Internal Representations of Multi-Word Verbs in Large Language Models,http://arxiv.org/abs/2502.04789v1,"This study investigates the internal representations of verb-particlecombinations, called multi-word verbs, within transformer-based large languagemodels (LLMs), specifically examining how these models capture lexical andsyntactic properties at different neural network layers. Using the BERTarchitecture, we analyze the representations of its layers for two differentverb-particle constructions: phrasal verbs like 'give up' and prepositionalverbs like 'look at'. Our methodology includes training probing classifiers onthe internal representations to classify these categories at both word andsentence levels. The results indicate that the model's middle layers achievethe highest classification accuracies. To further analyze the nature of thesedistinctions, we conduct a data separability test using the GeneralizedDiscrimination Value (GDV). While GDV results show weak linear separabilitybetween the two verb types, probing classifiers still achieve high accuracy,suggesting that representations of these linguistic categories may benon-linearly separable. This aligns with previous research indicating thatlinguistic distinctions in neural networks are not always encoded in a linearlyseparable manner. These findings computationally support usage-based claims onthe representation of verb-particle constructions and highlight the complexinteraction between neural network architectures and linguistic structures.",Hassane Kissane,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04788v1,A non-zero-sum game with reinforcement learning under mean-variance framework,http://arxiv.org/abs/2502.04788v1,"In this paper, we investigate a competitive market involving two agents whoconsider both their own wealth and the wealth gap with their opponent. Bothagents can invest in a financial market consisting of a risk-free asset and arisky asset, under conditions where model parameters are partially orcompletely unknown. This setup gives rise to a non-zero-sum differential gamewithin the framework of reinforcement learning (RL). Each agent aims tomaximize his own Choquet-regularized, time-inconsistent mean-varianceobjective. Adopting the dynamic programming approach, we derive atime-consistent Nash equilibrium strategy in a general incomplete marketsetting. Under the additional assumption of a Gaussian mean return model, weobtain an explicit analytical solution, which facilitates the development of apractical RL algorithm. Notably, the proposed algorithm achieves uniformconvergence, even though the conventional policy improvement theorem does notapply to the equilibrium policy. Numerical experiments demonstrate therobustness and effectiveness of the algorithm, underscoring its potential forpractical implementation.",Junyi Guo,2025-02-07,2025-02-07,,N/A,['math.OC']
2502.04786v1,Enhancing SQL Injection Detection and Prevention Using Generative Models,http://arxiv.org/abs/2502.04786v1,"SQL Injection (SQLi) continues to pose a significant threat to the securityof web applications, enabling attackers to manipulate databases and accesssensitive information without authorisation. Although advancements have beenmade in detection techniques, traditional signature-based methods stillstruggle to identify sophisticated SQL injection attacks that evade predefinedpatterns. As SQLi attacks evolve, the need for more adaptive detection systemsbecomes crucial. This paper introduces an innovative approach that leveragesgenerative models to enhance SQLi detection and prevention mechanisms. Byincorporating Variational Autoencoders (VAE), Conditional Wasserstein GAN withGradient Penalty (CWGAN-GP), and U-Net, synthetic SQL queries were generated toaugment training datasets for machine learning models. The proposed methoddemonstrated improved accuracy in SQLi detection systems by reducing both falsepositives and false negatives. Extensive empirical testing further illustratedthe ability of the system to adapt to evolving SQLi attack patterns, resultingin enhanced precision and robustness.",Naga Sai Dasari,2025-02-07,2025-02-07,,N/A,"['cs.CR', 'cs.AI']"
2502.04783v1,Embedding loose trees in $k$-uniform hypergraphs,http://arxiv.org/abs/2502.04783v1,"A classical result of Koml\'os, S\'ark\""ozy and Szemer\'edi shows that everylarge $n$-vertex graph with minimum degree at least $(1/2+\gamma)n$ containsall spanning trees of bounded degree. We generalised this result to loosespanning hypertrees in $k$-uniform hypergraphs, that is, linear hypergraphsobtained by subsequently adding edges sharing a single vertex with a previousedge.  We give a general sufficient condition for embedding loose trees with boundeddegree. In particular, we show that for all $k\ge 4$, every $n$-vertex$k$-uniform hypergraph with $n\ge n_0(k,\gamma, \Delta)$ and minimum$(k-2)$-degree at least $(1/2+\gamma)\binom{n}{k-2}$ contains every spanningloose tree with maximum vertex degree at most $\Delta$. This bound isasymptotically tight. This generalises a result of Pehova and Petrova, whoproved the case when $k=3$ and of Pavez-Sign\'e, Sanhueza-Matamala and Stein,who considered the codegree threshold for bounded degree tight trees.",Yaobin Chen,2025-02-07,2025-02-07,,N/A,['math.CO']
2502.04782v1,Quasinormal Modes and Dynamical Evolution of Scalar Fields in the Einstein-Bumblebee Theory with a Cosmological Constant,http://arxiv.org/abs/2502.04782v1,"This paper investigates the dynamic behavior of static, spherically symmetricblack holes within the Einstein-Bumblebee gravity model with a cosmologicalconstant, focusing on scalar field perturbations. Through separation of theangular components, the scalar field perturbations outside the black hole arereduced to a purely radial main equation. The quasinormal modes (QNMs) of thesystem are then determined via the WKB approximation in the frequency domain,while the dynamic evolution of the system is examined in the time domain usingfinite difference methods. The eigenfrequencies of the waveforms from thetime-domain evolution are fitted to cross-validate the frequency-domainresults. The study finds that the Lorentz violation parameter $ \ell $ and thecosmological constant $ \Lambda $ significantly influence the QNMs.Specifically, as $ \ell $ increases, the real and imaginary components of thelower modes decrease, while in higher modes, the real part changes minimally,and the imaginary part decreases rapidly. An increase in $ \Lambda $ similarlyresults in a decrease in the overall QNM values. These results are supported bythe time-domain analysis, providing a clearer picture of how Lorentz symmetrybreaking affects the QNMs of de Sitter spacetime.",Hao Hu,2025-02-07,2025-02-07,,N/A,['gr-qc']
2502.04780v1,SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning,http://arxiv.org/abs/2502.04780v1,"Multi-agent AI systems powered by large language models (LLMs) areincreasingly applied to solve complex tasks. However, these systems often relyon fragile, manually designed prompts and heuristics, making optimizationdifficult. A key challenge in optimizing multi-agent systems is acquiringsuitable training data for specialized agents. We introduce SiriuS, aself-improving, reasoning-driven optimization framework for multi-agentsystems. Central to our approach is the construction of an experience library:a repository of high-quality reasoning trajectories. The library is built byretaining reasoning steps that lead to successful outcomes, providing a robusttraining set for optimizing multi-agent system. Additionally, we introduce alibrary augmentation procedure that refines unsuccessful trajectories, furtherenriching the library. SiriuS boosts performance by 2.86\% to 21.88\% onreasoning and biomedical QA and enhances agent negotiation in competitivesettings. Our results show that SiriuS enhances multi-agent performance whilegenerating reusable data for self-correction and self-play enhancement in thefuture.",Wanjia Zhao,2025-02-07,2025-02-07,,N/A,['cs.AI']
2502.04778v1,Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning,http://arxiv.org/abs/2502.04778v1,"The primary focus of offline reinforcement learning (RL) is to manage therisk of hazardous exploitation of out-of-distribution actions. An effectiveapproach to achieve this goal is through behavior regularization, whichaugments conventional RL objectives by incorporating constraints that enforcethe policy to remain close to the behavior policy. Nevertheless, existingliterature on behavior-regularized RL primarily focuses on explicit policyparameterizations, such as Gaussian policies. Consequently, it remains unclearhow to extend this framework to more advanced policy parameterizations, such asdiffusion models. In this paper, we introduce BDPO, a principledbehavior-regularized RL framework tailored for diffusion-based policies,thereby combining the expressive power of diffusion policies and the robustnessprovided by regularization. The key ingredient of our method is to calculatethe Kullback-Leibler (KL) regularization analytically as the accumulateddiscrepancies in reverse-time transition kernels along the diffusiontrajectory. By integrating the regularization, we develop an efficienttwo-time-scale actor-critic RL algorithm that produces the optimal policy whilerespecting the behavior constraint. Comprehensive evaluations conducted onsynthetic 2D tasks and continuous control tasks from the D4RL benchmarkvalidate its effectiveness and superior performance.",Chen-Xiao Gao,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04777v1,Community detection for directed networks revisited using bimodularity,http://arxiv.org/abs/2502.04777v1,"Community structure is a key feature omnipresent in real-world network data.Plethora of methods have been proposed to reveal subsets of denselyinterconnected nodes using criteria such as the modularity index. Theseapproaches have been successful for undirected graphs, but directed edgeinformation has not yet been dealt with in a satisfactory way. Here, we revisitthe concept of directed communities as a mapping between sending and receivingcommunities. This translates into a new definition that we term bimodularity.Using convex relaxation, bimodularity can be optimized with the singular valuedecomposition of the directed modularity matrix. Subsequently, we propose anedge-based clustering approach to reveal the directed communities includingtheir mappings. The feasibility of the new framework is illustrated on asynthetic model and further applied to the neuronal wiring diagram of the\textit{C. elegans}, for which it yields meaningful feedforward loops of thehead and body motion systems. This framework sets the ground for theunderstanding and detection of community structures in directed networks.",Alexandre Cionca,2025-02-07,2025-02-07,,N/A,['cs.SI']
2502.04776v1,Constraining parity and Lorentz violations in gravity with future ground- and space-based gravitational wave detectors,http://arxiv.org/abs/2502.04776v1,"The future ground- and space-based gravitational wave (GW) detectors offerunprecedented opportunities to test general relativity (GR) with greaterprecision. In this work, we investigate the capability of future ground-basedGW detectors, the Einstein Telescope (ET) and the Cosmic Explorer (CE), andspace-based GW detectors, LISA, Taiji, and TianQin, for constraining parity andLorentz violations in gravity. We inject several typical GW signals fromcompact binary systems into GW detectors and perform Bayesian inferences withthe modified waveforms with parity and Lorentz-violating effects. These effectsare modeled in the amplitude and phase corrections to the GW waveforms withtheir frequency-dependence described by factors $\beta_{\nu}$, $\beta_{\mu}$,$\beta_{\bar \nu}$, and $\beta_{\bar \mu}$. Our results show that the combinedobservations of ET and CE will impose significantly tighter bounds on theenergy scale of parity and Lorentz violations ($M_{\rm PV}$ and $M_{\rm LV}$)compared to those given by LIGO-Virgo-KAGRA (LVK) detectors. For cases withpositive values of $\beta_{\nu}$, $\beta_{\mu}$, $\beta_{\bar \nu}$, and$\beta_{\bar \mu}$, the constraints on $M_{\rm PV}$ and $M_{\rm LV}$ fromground-based detectors are tighter than those from the space-based detectors.For the $\beta_{\mu} = -1$ case, space-based GW detectors provide constraintson $M_{\rm PV}$ that are better than current LVK observations and comparable tothose from ET and CE. Additionally, space-based detectors exhibit superiorsensitivity in constraining $M_{\rm LV}$ for $\beta_{\bar \mu} = -2$ case,which is approximately three orders of magnitude tighter than those fromground-based GW detectors. This scenario also enables bounds on the gravitonmass at $m_g \lesssim 10^{-35}\; {\rm GeV}$. These findings highlight thepromising role of future GW observatories in probing fundamental physics beyondGR.",Bo-Yang Zhang,2025-02-07,2025-02-07,,N/A,"['gr-qc', 'hep-th']"
2502.04775v1,Practical implementation of a chiral phononic crystal demonstrator with ultra-low frequency bandgap,http://arxiv.org/abs/2502.04775v1,"The use of phononic crystals for vibration attenuation and isolation has beenwidely studied, showing that the attenuation frequency range depends on theirmass and stiffness. The concepts of chirality and tacticity have beenintroduced into classical phononic crystals to enrich the dynamics of the masselements and thereby achieve lower frequency ranges with high vibrationattenuation. Although these concepts have demonstrated their effectiveness onlab-scale crystals, their implementation in industrial applications is stillrare. Chiral phononic crystals require a complex geometry that complicatestheir manufacturing. Existing examples require to be fabricated by 3D printing,making them expensive to build on a large scale for demonstration purposes orin-situ applications. In this study, we redefine a chiral phononic crystaldesign for translational-rotational coupling in order to enable itsmanufacturability using exclusively conventional processes. We then investigatethe design space of these newly designed phononic crystals, using a simplifiedunit cell FEM model that minimizes computation time. A parametric study isconducted to investigate the crystal's tunability by modifying the dimensionsof the chiral links between the masses. A large crystal with ultra-lowfrequency range attenuation -- starting at 60~Hz -- is then designed, with theaim to demonstrate the influence of the crystal's tacticity on the vibrationisolation by hand sensing. A crystal composed of 2 unit cells is manufacturedand its measured transfer function is compared with numerical predictions, thushighlighting the disparities between the behavior of the structure underreal-life and ideal excitation conditions.",Line Mardini,2025-02-07,2025-02-07,,N/A,['physics.app-ph']
2502.04774v1,SeDi-Instruct: Enhancing Alignment of Language Models through Self-Directed Instruction Generation,http://arxiv.org/abs/2502.04774v1,"The rapid evolution of Large Language Models (LLMs) has enabled the industryto develop various AI-based services. Instruction tuning is consideredessential in adapting foundation models for target domains to providehigh-quality services to customers. A key challenge in instruction tuning isobtaining high-quality instruction data. Self-Instruct, which automaticallygenerates instruction data using ChatGPT APIs, alleviates the data scarcityproblem. To improve the quality of instruction data, Self-Instruct discardsmany of the instructions generated from ChatGPT, even though it is inefficientin terms of cost owing to many useless API calls. To generate high-qualityinstruction data at a low cost, we propose a novel data generation framework,Self-Direct Instruction generation (SeDi-Instruct), which employsdiversity-based filtering and iterative feedback task generation.Diversity-based filtering maintains model accuracy without excessivelydiscarding low-quality generated instructions by enhancing the diversity ofinstructions in a batch. This reduces the cost of synthesizing instructiondata. The iterative feedback task generation integrates instruction generationand training tasks and utilizes information obtained during the training tocreate high-quality instruction sets. Our results show that SeDi-Instructenhances the accuracy of AI models by 5.2%, compared with traditional methods,while reducing data generation costs by 36%.",Jungwoo Kim,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04771v1,DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences,http://arxiv.org/abs/2502.04771v1,"Federated learning (FL) has garnered significant attention as a prominentprivacy-preserving Machine Learning (ML) paradigm. Decentralized FL (DFL)eschews traditional FL's centralized server architecture, enhancing thesystem's robustness and scalability. However, these advantages of DFL alsocreate new vulnerabilities for malicious participants to execute adversarialattacks, especially model poisoning attacks. In model poisoning attacks,malicious participants aim to diminish the performance of benign models bycreating and disseminating the compromised model. Existing research on modelpoisoning attacks has predominantly concentrated on undermining global modelswithin the Centralized FL (CFL) paradigm, while there needs to be more researchin DFL. To fill the research gap, this paper proposes an innovative modelpoisoning attack called DMPA. This attack calculates the differentialcharacteristics of multiple malicious client models and obtains the mosteffective poisoning strategy, thereby orchestrating a collusive attack bymultiple participants. The effectiveness of this attack is validated acrossmultiple datasets, with results indicating that the DMPA approach consistentlysurpasses existing state-of-the-art FL model poisoning attack strategies.",Chao Feng,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04768v1,"Phase Transitions with Coupled Lasers Array, PhD Research Summary",http://arxiv.org/abs/2502.04768v1,"Coupled laser arrays exhibit rich and complex physical properties, makingthem powerful tools for exploring a wide range of phenomena. They enableefficient ground-state optimization of complex landscapes, solve computationalproblems, reveal topological defects, study coupled oscillators and theiruniversality classes, investigate classical spin systems and complex networks,enhance imaging through scattering media, suppress speckle noise, generateultra-high-power laser beams, and produce high-resolution shaped beams. Here, Isummarize my PhD research on phase-locking large networks of coupled lasers andcontrolling spatiotemporal lasing modes for rapid speckle reduction.",Simon Mahler,2025-02-07,2025-02-07,,N/A,['physics.optics']
2502.04765v1,Statistical Methods and Modal Decompositions for Gridded and Scattered Data: Meshless Statistics and Meshless Data Driven Modal Analysis,http://arxiv.org/abs/2502.04765v1,"Statistical tools are crucial for studying and modeling turbulent flows,where chaotic velocity fluctuations span a wide range of spatial and temporalscales. Advances in image velocimetry, especially in tracking-based methods,now allow for high-speed, high-density particle image processing, enabling thecollection of detailed 3D flow fields. This lecture provides a set of tutorialson processing such datasets to extract essential quantities like averages,second-order moments (turbulent stresses) and coherent patterns using modaldecompositions such as the Proper Orthogonal Decomposition (POD). After a briefreview of the fundamentals of statistical and modal analysis, the lecturedelves into the challenges of processing scattered data from trackingvelocimetry, comparing it to traditional gridded-data approaches. It alsocovers research topics, including physics-based Radial Basis Function (RBF)regression for meshless computation of turbulent statistics and the definitionof an RBF inner product, which enables meshless computation of data-drivendecompositions. These include traditional methods like Proper OrthogonalDecomposition (POD) and Dynamic Mode Decomposition (DMD), as well as advancedvariants such as Spectral POD (SPOD) and Multiscale POD (mPOD). We refer tothis approach as the ""Meshless Data-Driven Decomposition"" framework. We referto this framework as ""Meshless Data Driven Decomposition"".  Six exercises in Python are provided. All codes are available athttps://github.com/mendezVKI/PIV_LS_2024_Signal",Miguel A. Mendez,2025-02-07,2025-02-07,,N/A,['physics.flu-dyn']
2502.04763v1,Shapley Value Approximation Based on k-Additive Games,http://arxiv.org/abs/2502.04763v1,"The Shapley value is the prevalent solution for fair division problems inwhich a payout is to be divided among multiple agents. By adopting agame-theoretic view, the idea of fair division and the Shapley value can alsobe used in machine learning to quantify the individual contribution of featuresor data points to the performance of a predictive model. Despite its popularityand axiomatic justification, the Shapley value suffers from a computationalcomplexity that scales exponentially with the number of entities involved, andhence requires approximation methods for its reliable estimation. We proposeSVA$k_{\text{ADD}}$, a novel approximation method that fits a $k$-additivesurrogate game. By taking advantage of $k$-additivity, we are able to elicitthe exact Shapley values of the surrogate game and then use these values asestimates for the original fair division problem. The efficacy of our method isevaluated empirically and compared to competing methods.",Guilherme Dean Pelegrina,2025-02-07,2025-02-07,,N/A,"['cs.GT', 'cs.LG']"
2502.04761v1,Infinite State Model Checking by Learning Transitive Relations,http://arxiv.org/abs/2502.04761v1,"We propose a new approach for proving safety of infinite state systems. Itextends the analyzed system by transitive relations until its diameter Dbecomes finite, i.e., until constantly many steps suffice to cover allreachable states, irrespective of the initial state. Then we can prove safetyby checking that no error state is reachable in D steps. To deduce transitiverelations, we use recurrence analysis. While recurrence analyses can usuallyfind conjunctive relations only, our approach also discovers disjunctiverelations by combining recurrence analysis with projections. An empiricalevaluation of the implementation of our approach in our tool LoAT shows that itis highly competitive with the state of the art.",Florian Frohn,2025-02-07,2025-02-07,,N/A,['cs.LO']
2502.04760v1,Graph Federated Learning Based Proactive Content Caching in Edge Computing,http://arxiv.org/abs/2502.04760v1,"With the rapid growth of mobile data traffic and the increasing prevalence ofvideo streaming, proactive content caching in edge computing has become crucialfor reducing latency and alleviating network congestion. However, traditionalcaching strategies such as FIFO, LRU, and LFU fail to effectively predictfuture content popularity, while existing proactive caching approaches oftenrequire users to upload data to a central server, raising concerns regardingprivacy and scalability. To address these challenges, this paper proposes aGraph Federated Learning-based Proactive Content Caching (GFPCC) scheme thatenhances caching efficiency while preserving user privacy. The proposedapproach integrates federated learning and graph neural networks, enablingusers to locally train Light Graph Convolutional Networks (LightGCN) to captureuser-item relationships and predict content popularity. Instead of sharing rawdata, only the trained model parameters are transmitted to the central server,where a federated averaging algorithm aggregates updates, refines the globalmodel, and selects the most popular files for proactive caching. Experimentalevaluations on real-world datasets, such as MovieLens, demonstrate that GFPCCoutperforms baseline caching algorithms by achieving higher cache efficiencythrough more accurate content popularity predictions. Moreover, the federatedlearning framework strengthens privacy protection while maintaining efficientmodel training; however, scalability remains a challenge in large-scalenetworks with dynamic user preferences.",Rui Wang,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04759v1,Enhancing Phishing Email Identification with Large Language Models,http://arxiv.org/abs/2502.04759v1,"Phishing has long been a common tactic used by cybercriminals and continuesto pose a significant threat in today's digital world. When phishing attacksbecome more advanced and sophisticated, there is an increasing need foreffective methods to detect and prevent them. To address the challengingproblem of detecting phishing emails, researchers have developed numeroussolutions, in particular those based on machine learning (ML) algorithms. Inthis work, we take steps to study the efficacy of large language models (LLMs)in detecting phishing emails. The experiments show that the LLM achieves a highaccuracy rate at high precision; importantly, it also provides interpretableevidence for the decisions.",Catherine Lee,2025-02-07,2025-02-07,,N/A,"['cs.CR', 'cs.AI']"
2502.04757v1,ELITE: Enhanced Language-Image Toxicity Evaluation for Safety,http://arxiv.org/abs/2502.04757v1,"Current Vision Language Models (VLMs) remain vulnerable to malicious promptsthat induce harmful outputs. Existing safety benchmarks for VLMs primarily relyon automated evaluation methods, but these methods struggle to detect implicitharmful content or produce inaccurate evaluations. Therefore, we found thatexisting benchmarks have low levels of harmfulness, ambiguous data, and limiteddiversity in image-text pair combinations. To address these issues, we proposethe ELITE {\em benchmark}, a high-quality safety evaluation benchmark for VLMs,underpinned by our enhanced evaluation method, the ELITE {\em evaluator}. TheELITE evaluator explicitly incorporates a toxicity score to accurately assessharmfulness in multimodal contexts, where VLMs often provide specific,convincing, but unharmful descriptions of images. We filter out ambiguous andlow-quality image-text pairs from existing benchmarks using the ELITE evaluatorand generate diverse combinations of safe and unsafe image-text pairs. Ourexperiments demonstrate that the ELITE evaluator achieves superior alignmentwith human evaluations compared to prior automated methods, and the ELITEbenchmark offers enhanced benchmark quality and diversity. By introducingELITE, we pave the way for safer, more robust VLMs, contributing essentialtools for evaluating and mitigating safety risks in real-world applications.",Wonjun Lee,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.CL']"
2502.04755v1,Geometric origin of self-intersection points in non-Hermitian energy spectra,http://arxiv.org/abs/2502.04755v1,"Unlike Hermitian systems, non-Hermitian energy spectra under periodicboundary conditions can form closed loops in the complex energy plane, aphenomenon known as point gap topology. In this paper, we investigate theself-intersection points of such non-Hermitian energy spectra and reveal theirgeometric origins. We rigorously demonstrate that these self-intersectionpoints result from the intersection of the auxiliary generalized Brillouin zoneand the Brillouin zone in one-band systems, as confirmed by an extendedHatano-Nelson model. This finding is further generalized to multi-band systems,illustrated through a non-Hermitian Su-Schrieffer-Heeger model. Moreover, weaddress multiple self-intersection points and derive the geometric conditionsfor general n-fold self-intersection points. Our results enhance thefundamental understanding of generic non-Hermitian quantum systems and providetheoretical support for further experimental investigations of energyself-intersection points.",Jinghui Pi,2025-02-07,2025-02-07,,N/A,"['quant-ph', 'cond-mat.quant-gas', 'physics.optics']"
2502.04756v1,Concept Navigation and Classification via Open Source Large Language Model Processing,http://arxiv.org/abs/2502.04756v1,"This paper presents a novel methodological framework for detecting andclassifying latent constructs, including frames, narratives, and topics, fromtextual data using Open-Source Large Language Models (LLMs). The proposedhybrid approach combines automated summarization with human-in-the-loopvalidation to enhance the accuracy and interpretability of constructidentification. By employing iterative sampling coupled with expert refinement,the framework guarantees methodological robustness and ensures conceptualprecision. Applied to diverse data sets, including AI policy debates, newspaperarticles on encryption, and the 20 Newsgroups data set, this approachdemonstrates its versatility in systematically analyzing complex politicaldiscourses, media framing, and topic classification tasks.",Maël Kubli,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI', 'cs.LG', 'I.2.7']"
2502.04754v1,The detailed balance property and chemical systems out of equilibrium,http://arxiv.org/abs/2502.04754v1,"The detailed balance property is a fundamental property that must besatisfied in all the macroscopic systems with a well defined temperature ateach point. On the other hand, many biochemical networks work innon-equilibrium conditions and they can be effectively modelled using sets ofequations in which the detailed balance condition fails. In this paper we studya class of ""out of equilibrium"" chemical networks that can be obtained freezingthe concentration of some substances in chemical networks for which thedetailed balance property holds. In particular, we prove that any chemicalsystem with bidirectional chemical reactions can be extended to a system havingadditional substances and for which the detailed balance property holds.",E. Franco,2025-02-07,2025-02-07,,N/A,"['math.CA', 'math-ph', 'math.MP', '34A, 92B']"
2502.04751v1,Holistically Guided Monte Carlo Tree Search for Intricate Information Seeking,http://arxiv.org/abs/2502.04751v1,"In the era of vast digital information, the sheer volume and heterogeneity ofavailable information present significant challenges for intricate informationseeking. Users frequently face multistep web search tasks that involvenavigating vast and varied data sources. This complexity demands every stepremains comprehensive, accurate, and relevant. However, traditional searchmethods often struggle to balance the need for localized precision with thebroader context required for holistic understanding, leaving critical facets ofintricate queries underexplored. In this paper, we introduce an LLM-basedsearch assistant that adopts a new information seeking paradigm withholistically guided Monte Carlo tree search (HG-MCTS). We reformulate the taskas a progressive information collection process with a knowledge memory andunite an adaptive checklist with multi-perspective reward modeling in MCTS. Theadaptive checklist provides explicit sub-goals to guide the MCTS process towardcomprehensive coverage of complex user queries. Simultaneously, ourmulti-perspective reward modeling offers both exploration and retrievalrewards, along with progress feedback that tracks completed and remainingsub-goals, refining the checklist as the tree search progresses. By striking abalance between localized tree expansion and global guidance, HG-MCTS reducesredundancy in search paths and ensures that all crucial aspects of an intricatequery are properly addressed. Extensive experiments on real-world intricateinformation seeking tasks demonstrate that HG-MCTS acquires thorough knowledgecollections and delivers more accurate final responses compared with existingbaselines.",Ruiyang Ren,2025-02-07,2025-02-07,,N/A,"['cs.IR', 'cs.CL']"
2502.04750v1,Tighter sparse variational Gaussian processes,http://arxiv.org/abs/2502.04750v1,"Sparse variational Gaussian process (GP) approximations based on inducingpoints have become the de facto standard for scaling GPs to large datasets,owing to their theoretical elegance, computational efficiency, and ease ofimplementation. This paper introduces a provably tighter variationalapproximation by relaxing the standard assumption that the conditionalapproximate posterior given the inducing points must match that in the prior.The key innovation is to modify the conditional posterior to have smallervariances than that of the prior at the training points. We derive thecollapsed bound for the regression case, describe how to use the proposedapproximation in large data settings, and discuss its application to handleorthogonally structured inducing points and GP latent variable models.Extensive experiments on regression benchmarks, classification, and latentvariable models demonstrate that the proposed approximation consistentlymatches or outperforms standard sparse variational GPs while maintaining thesame computational cost. An implementation will be made available in allpopular GP packages.",Thang D. Bui,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG']"
2502.04748v1,Self-Supervised Learning for Pre-training Capsule Networks: Overcoming Medical Imaging Dataset Challenges,http://arxiv.org/abs/2502.04748v1,"Deep learning techniques are increasingly being adopted in diagnostic medicalimaging. However, the limited availability of high-quality, large-scale medicaldatasets presents a significant challenge, often necessitating the use oftransfer learning approaches. This study investigates self-supervised learningmethods for pre-training capsule networks in polyp diagnostics for coloncancer. We used the PICCOLO dataset, comprising 3,433 samples, whichexemplifies typical challenges in medical datasets: small size, classimbalance, and distribution shifts between data splits. Capsule networks offerinherent interpretability due to their architecture and inter-layer informationrouting mechanism. However, their limited native implementation in mainstreamdeep learning frameworks and the lack of pre-trained versions pose asignificant challenge. This is particularly true if aiming to train them onsmall medical datasets, where leveraging pre-trained weights as initialparameters would be beneficial. We explored two auxiliary self-supervisedlearning tasks, colourisation and contrastive learning, for capsule networkpre-training. We compared self-supervised pre-trained models againstalternative initialisation strategies. Our findings suggest that contrastivelearning and in-painting techniques are suitable auxiliary tasks forself-supervised learning in the medical domain. These techniques helped guidethe model to capture important visual features that are beneficial for thedownstream task of polyp classification, increasing its accuracy by 5.26%compared to other weight initialisation methods.",Heba El-Shimy,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.LG']"
2502.04747v1,Every Software as an Agent: Blueprint and Case Study,http://arxiv.org/abs/2502.04747v1,"The rise of (multimodal) large language models (LLMs) has shed light onsoftware agent -- where software can understand and follow user instructions innatural language. However, existing approaches such as API-based and GUI-basedagents are far from satisfactory at accuracy and efficiency aspects. Instead,we advocate to endow LLMs with access to the software internals (source codeand runtime context) and the permission to dynamically inject generated codeinto software for execution. In such a whitebox setting, one may betterleverage the software context and the coding ability of LLMs. We then presentan overall design architecture and case studies on two popular web-baseddesktop applications. We also give in-depth discussion of the challenges andfuture directions. We deem that such a new paradigm has the potential tofundamentally overturn the existing software agent design, and finally creatinga digital world in which software can comprehend, operate, collaborate, andeven think to meet complex user needs.",Mengwei Xu,2025-02-07,2025-02-07,,N/A,"['cs.SE', 'cs.AI']"
2502.04746v1,"On $(\mathcal{L},\mathcal{P})$-Twisted Generalized Reed-Solomon Codes",http://arxiv.org/abs/2502.04746v1,"Twisted generalized Reed-Solomon (TGRS) codes are an extension of thegeneralized Reed-Solomon (GRS) codes by adding specific twists, which attractmuch attention recently. This paper presents an in-depth and comprehensiveinvestigation of the TGRS codes for the most general form by using a universalmethod. At first, we propose a more precise definition to describe TGRS codes,namely $(\mathcal{L},\mathcal{P})$-TGRS codes, and provide a concise necessaryand sufficient condition for $(\mathcal{L},\mathcal{P})$-TGRS codes to be MDS,which extends the related results in the previous works. Secondly, weexplicitly characterize the parity check matrices of$(\mathcal{L},\mathcal{P})$-TGRS codes, and provide a sufficient condition for$(\mathcal{L},\mathcal{P})$-TGRS codes to be self-dual. Finally, we conduct anin-depth study into the non-GRS property of $(\mathcal{L},\mathcal{P})$-TGRScodes via the Schur squares and the combinatorial techniques respectively. As aresult, we obtain a large infinite families of non-GRS MDS codes.",Zhao Hu,2025-02-07,2025-02-07,,N/A,"['cs.IT', 'math.IT']"
2502.04745v1,Overview of EXL-50 Research Progress and Future Plan,http://arxiv.org/abs/2502.04745v1,"XuanLong-50 (EXL-50) is the first medium-size spherical torus (ST) in China,with the toroidal field at major radius at 50 cm around 0.5T. CS-free andnon-inductive current drive via electron cyclotron resonance heating (ECRH) wasthe main physics research issue for EXL-50. Discharges with plasma currents of50 kA - 180 kA were routinely obtained in EXL-50, with the current flattopsustained for up to or beyond 2 s. The current drive effectiveness on EXL-50was as high as 1 A/W for low-density discharges using 28GHz ECRH alone forheating power less than 200 kW. The plasma current reached Ip>80 kA forhigh-density (5*10e18m-2) discharges with 150 kW 28GHz ECRH. Higher performancedischarge (Ip of about 120 kA and core density of about 1*10e19m-3) wasachieved with 150 kW 50GHz ECRH. The plasma current in EXL-50 was mainlycarried by the energetic electrons.Multi-fluid equilibrium model has beensuccessfully applied to reconstruct the magnetic flux surface and the measuredplasma parameters of the EXL-50 equilibrium. The physics mechanisms for thesolenoid-free ECRH current drive and the energetic electrons has also beeninvestigated. Preliminary experimental results show that 100 kW of lower hybridcurrent drive (LHCD) waves can drive 20 kA of plasma current. Several boroninjection systems were installed and tested in EXL-50, including B2H6 gaspuffing, boron powder injection, boron pellet injection. The research plan ofEXL-50U, which is the upgrade machine of EXL-50, is also presented.",Yuejiang Shi,2025-02-07,2025-02-07,,N/A,['physics.plasm-ph']
2502.04741v1,Multivalued forbidden numbers of two-rowed configurations -- the missing cases,http://arxiv.org/abs/2502.04741v1,"The present paper considers extremal combinatorics questions in the languageof matrices. An $s$-matrix is a matrix with entries in $\{0,1,\ldots, s-1\}$.An $s$-matrix is simple if it has no repeated columns. A matrix $F$ is aconfiguration in a matrix $A$, denoted $F\prec A$, if it is a row/columnpermutation of a submatrix of $A$. $\text{Avoid}(m,s,F)$ is the set of$m$-rowed, simple $s$-matrices not containing a configuration of $F$ and$\text{forb}(m,s, F)=\max\{|A|\colon A \in \text{Avoid}(m,s,F)\}$. Dillon andSali initiated the systematic study of $\text{forb}(m,s, F)$ for $2$-matrices$F$, and computed $\text{forb}(m,s, F)$ for all 2-rowed $F$ when $s>3$. In thispaper we tackle the remaining cases when $s=3$. In particular, we determine theasymptotics of $\text{forb}(m,3,p\cdot K_2)-\text{forb}(m,3,p\cdot I_2)$ for$p>3$, where $K_2$ is the $2\times 4$ simple $2$-matrix and $I_2$ is the$2\times 2$ identity matrix, as well as the exact values of$\text{forb}(m,3,F)$ for many 2-rowed $2$-matrices $F$.",Wallace Peaslee,2025-02-07,2025-02-07,,N/A,['math.CO']
2502.04740v1,SelaFD:Seamless Adaptation of Vision Transformer Fine-tuning for Radar-based Human Activity,http://arxiv.org/abs/2502.04740v1,"Human Activity Recognition (HAR) such as fall detection has becomeincreasingly critical due to the aging population, necessitating effectivemonitoring systems to prevent serious injuries and fatalities associated withfalls. This study focuses on fine-tuning the Vision Transformer (ViT) modelspecifically for HAR using radar-based Time-Doppler signatures. Unliketraditional image datasets, these signals present unique challenges due totheir non-visual nature and the high degree of similarity among variousactivities. Directly fine-tuning the ViT with all parameters proves suboptimalfor this application. To address this challenge, we propose a novel approachthat employs Low-Rank Adaptation (LoRA) fine-tuning in the weight space tofacilitate knowledge transfer from pre-trained ViT models. Additionally, toextract fine-grained features, we enhance feature representation through theintegration of a serial-parallel adapter in the feature space. Our innovativejoint fine-tuning method, tailored for radar-based Time-Doppler signatures,significantly improves HAR accuracy, surpassing existing state-of-the-artmethodologies in this domain. Our code is released athttps://github.com/wangyijunlyy/SelaFD.",Yijun Wang,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.LG']"
2502.04739v1,Mixed-symmetry superconductivity and the energy gap,http://arxiv.org/abs/2502.04739v1,"The symmetry of the superconducting order parameter, or simply the ``gap'',provides certain constraints on the actual mechanism that gives rise to pairingand ultimately to superconductivity. In this work we continue to investigatethe possible symmetries that can arise, particularly below $T_c$, for a generictight-binding model. We first examine the 1D case to better illustrate theprevalence of symmetry-breaking transitions below $T_c$, and then the morerealistic 2D case. In both cases we illustrate the implication forspectroscopic investigations of the energy gap by calculating the density ofstates for different temperatures below $T_c$. The result is a very differentsignature near $T_c$ compared to that near $T=0$. A complete picture of thesuperconducting symmetry can only be attained if measurements are made over theentire temperature range.",Pramodh Senarath Yapa,2025-02-07,2025-02-07,,N/A,['cond-mat.supr-con']
2502.04738v1,Comprehensive Formal Verification of Observational Correctness for the CHERIoT-Ibex Processor,http://arxiv.org/abs/2502.04738v1,"The CHERI architecture equips conventional RISC ISAs with significantarchitectural extensions that provide a hardware-enforced mechanism for memoryprotection and software compartmentalisation. Architectural capabilitiesreplace conventional integer pointers with memory addresses bound topermissions constraining their use. We present the first comprehensive formalverification of a capability extended RISC-V processor with internally'compressed' capabilities - a concise encoding of capabilities with someresemblance to floating point number representations.  The reference model for RTL correctness is a minor variant of the full anddefinitive ISA description written in the Sail ISA specification language. Thisis made accessible to formal verification tools by a prototype flow fortranslation of Sail into SystemVerilog. Our verification demonstrates amethodology for establishing that the processor always produces a stream ofinteractions with memory that is identical to that specified in Sail, whenstarted in the same initial state. We additionally establish liveness. Thisabstract, microarchitecture-independent observational correctness propertyprovides a comprehensive and clear assurance of functional correctness for theCHERIoT-Ibex processor's observable interactions with memory.",Louis-Emile Ploix,2025-02-07,2025-02-07,,N/A,"['cs.AR', 'B.6.2; J.6']"
2502.04737v1,Learning Universal Multi-level Market Irrationality Factors to Improve Stock Return Forecasting,http://arxiv.org/abs/2502.04737v1,"Recent years have witnessed the perfect encounter of deep learning andquantitative trading has achieved great success in stock investment. Numerousdeep learning-based models have been developed for forecasting stock returns,leveraging the powerful representation capabilities of neural networks toidentify patterns and factors influencing stock prices. These models caneffectively capture general patterns in the market, such as stock price trends,volume-price relationships, and time variations. However, the impact of specialirrationality factors -- such as market sentiment, speculative behavior, marketmanipulation, and psychological biases -- have not been fully considered inexisting deep stock forecasting models due to their relative abstraction aswell as lack of explicit labels and data description. To fill this gap, wepropose UMI, a Universal multi-level Market Irrationality factor model toenhance stock return forecasting. The UMI model learns factors that can reflectirrational behaviors in market from both individual stock and overall marketlevels. For the stock-level, UMI construct an estimated rational price for eachstock, which is cointegrated with the stock's actual price. The discrepancybetween the actual and the rational prices serves as a factor to indicatestock-level irrational events. Additionally, we define market-level irrationalbehaviors as anomalous synchronous fluctuations of stocks within a market.Using two self-supervised representation learning tasks, i.e., sub-marketcomparative learning and market synchronism prediction, the UMI modelincorporates market-level irrationalities into a market representation vector,which is then used as the market-level irrationality factor.",Chen Yang,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.04736v1,Explorations on the number of realizations of minimally rigid graphs,http://arxiv.org/abs/2502.04736v1,"Rigid graphs have only finitely many realizations. In the recent yearssignificant progress was made in computing the number of such realizations.With this progress it was also possible for the first time to do computationson large sets of graphs. In this paper we show what we can conclude from thedata we got from these computations. This includes new lower bounds on themaximal realization count for a given number of vertices, upper bounds for theminimal realization count in higher dimensions and effects of rigiditypreserving construction rules on the realization number. In all cases we givecertificate graphs which prove the respective results.",Georg Grasegger,2025-02-07,2025-02-07,,N/A,"['math.CO', 'cs.SC']"
2502.04734v1,SC-OmniGS: Self-Calibrating Omnidirectional Gaussian Splatting,http://arxiv.org/abs/2502.04734v1,"360-degree cameras streamline data collection for radiance field 3Dreconstruction by capturing comprehensive scene data. However, traditionalradiance field methods do not address the specific challenges inherent to360-degree images. We present SC-OmniGS, a novel self-calibratingomnidirectional Gaussian splatting system for fast and accurate omnidirectionalradiance field reconstruction using 360-degree images. Rather than converting360-degree images to cube maps and performing perspective image calibration, wetreat 360-degree images as a whole sphere and derive a mathematical frameworkthat enables direct omnidirectional camera pose calibration accompanied by 3DGaussians optimization. Furthermore, we introduce a differentiableomnidirectional camera model in order to rectify the distortion of real-worlddata for performance enhancement. Overall, the omnidirectional camera intrinsicmodel, extrinsic poses, and 3D Gaussians are jointly optimized by minimizingweighted spherical photometric loss. Extensive experiments have demonstratedthat our proposed SC-OmniGS is able to recover a high-quality radiance fieldfrom noisy camera poses or even no pose prior in challenging scenarioscharacterized by wide baselines and non-object-centric configurations. Thenoticeable performance gain in the real-world dataset captured byconsumer-grade omnidirectional cameras verifies the effectiveness of ourgeneral omnidirectional camera model in reducing the distortion of 360-degreeimages.",Huajian Huang,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.GR']"
2502.04733v1,Lepton flavor violation in the Majorana and Dirac scotogenic models,http://arxiv.org/abs/2502.04733v1,"In this work we have considered two minimal versions of scotogenic models,where neutrinos acquire masses through a radiative mechanism. We call these twomodels as Majorana and Dirac scotogenic models. In the former model, neutrinoshave Majorana nature, and in the later one, neutrinos are Dirac particles.These two models are related to each other in terms of additional fields andsymmetries of the model. Hence, to compare these two models in futureexperiments, we have analyzed lepton flavor violating (LFV) processes in bothof them, in the charged lepton sector. We have found that the 3-body LFV decaysin both these models can get different contributions. Among all the LFV decaysand after satisfying relevant constraints, we have found that $\tau\to3\mu$ canhave a branching ratio as high as $10^{-10}(10^{-11})$ in the Majorana(Dirac)scotogenic model. This branching ratio can be probed in the future plannedexperiments.",Raghavendra Srikanth Hundi,2025-02-07,2025-02-07,,N/A,['hep-ph']
2502.04732v1,Coherent spin dynamics in ensembles of randomly oriented singly charged colloidal nanoplatelets and nanocrystals,http://arxiv.org/abs/2502.04732v1,"We present a theoretical study of the pump-probe Faraday rotation andellipticity signals in ensembles of uniaxially anisotropic CdSe nanoplateletsand nanocrystals. We use the Faraday rotation mechanism based on the excitationof negative heavy hole trions for a magnetic field applied in the Voigtgeometry. Three types of ensembles with typical spatial distributions of theorientation of the anisotropy axis with respect to the direction of lightpropagation are considered. Faraday rotation and ellipticity signals aremodeled for excitation by single and repeated pump pulses, taking into accountthe anisotropy of the electron g-factor. We show that spin dephasing caused bythe electron g-factor anisotropy and the arbitrary orientation of nanoplateletsor nanocrystals result only in partial damping of oscillation amplitude incontrast to the dephasing caused by the dispersion of the electron g-factor inthe ensemble. We demonstrate that regardless of the g-factor anisotropy degreethe oscillation frequency of the Faraday rotation and ellipticity signals for arandomly oriented ensemble is determined by the transverse electron g-factorcomponent.",Aleksandr A. Golovatenko,2025-02-07,2025-02-07,,N/A,['cond-mat.mes-hall']
2502.04730v1,PhyloVAE: Unsupervised Learning of Phylogenetic Trees via Variational Autoencoders,http://arxiv.org/abs/2502.04730v1,"Learning informative representations of phylogenetic tree structures isessential for analyzing evolutionary relationships. Classical distance-basedmethods have been widely used to project phylogenetic trees into Euclideanspace, but they are often sensitive to the choice of distance metric and maylack sufficient resolution. In this paper, we introduce phylogeneticvariational autoencoders (PhyloVAEs), an unsupervised learning frameworkdesigned for representation learning and generative modeling of treetopologies. Leveraging an efficient encoding mechanism inspired byautoregressive tree topology generation, we develop a deep latent-variablegenerative model that facilitates fast, parallelized topology generation.PhyloVAE combines this generative model with a collaborative inference modelbased on learnable topological features, allowing for high-resolutionrepresentations of phylogenetic tree samples. Extensive experiments demonstratePhyloVAE's robust representation learning capabilities and fast generation ofphylogenetic tree topologies.",Tianyu Xie,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG', 'q-bio.PE']"
2502.04729v1,"The ""negative end"" of change in grammar: terminology, concepts and causes",http://arxiv.org/abs/2502.04729v1,"The topic of ""negative end"" of change is, contrary to the fields ofinnovation and emergence, largely under-researched. Yet, it has lately startedto gain an increasing attention from language scholars worldwide. The mainfocus of this article is threefold, namely to discuss the i) terminology; ii)concepts and iii) causes associated with the ""negative end"" of change ingrammar. The article starts with an overview of research conducted on thetopic. It then moves to situating phenomena referred to as loss, decline orobsolescence among processes of language change, before elaborating on theterminology and concepts behind it. The last part looks at possible causes forconstructions to display a (gradual or rapid, but very consistent) decrease inthe frequency of use over time, which continues until the constructiondisappears or there are only residual or fossilised forms left. Keywords: loss,obsolescence, decline, competition, higher",Karolina Rudnicka,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.CY']"
2502.04728v1,Generating Symbolic World Models via Test-time Scaling of Large Language Models,http://arxiv.org/abs/2502.04728v1,"Solving complex planning problems requires Large Language Models (LLMs) toexplicitly model the state transition to avoid rule violations, comply withconstraints, and ensure optimality-a task hindered by the inherent ambiguity ofnatural language. To overcome such ambiguity, Planning Domain DefinitionLanguage (PDDL) is leveraged as a planning abstraction that enables precise andformal state descriptions. With PDDL, we can generate a symbolic world modelwhere classic searching algorithms, such as A*, can be seamlessly applied tofind optimal plans. However, directly generating PDDL domains with current LLMsremains an open challenge due to the lack of PDDL training data. To addressthis challenge, we propose to scale up the test-time computation of LLMs toenhance their PDDL reasoning capabilities, thereby enabling the generation ofhigh-quality PDDL domains. Specifically, we introduce a simple yet effectivealgorithm, which first employs a Best-of-N sampling approach to improve thequality of the initial solution and then refines the solution in a fine-grainedmanner with verbalized machine learning. Our method outperforms o1-mini by aconsiderable margin in the generation of PDDL domain, achieving over 50%success rate on two tasks (i.e., generating PDDL domains from natural languagedescription or PDDL problems). This is done without requiring additionaltraining. By taking advantage of PDDL as state abstraction, our method is ableto outperform current state-of-the-art methods on almost all competition-levelplanning tasks.",Zhouliang Yu,2025-02-07,2025-02-07,,N/A,['cs.AI']
2502.04727v1,"Is there a chiral dark dynamo in the universe induced by quantum correction, Nieh-Yan gravity and Barbero-Immirzi field?",http://arxiv.org/abs/2502.04727v1,"Bombagcino investigated the role of Immirzi parameter when promoted to afield in Einstein-Cartan-Holst black hole and they found that the Immirzi fieldacts similar to the axion field, as both axial pseudo-vector and vectorialtorsion trace appear to be expressed in terms of the 4-gradient of the Immirziparameter. In this paper we introduced two important ingredients absent in theprevious work: the torsion mass, significant for the torsion detection theLarge Hadron Collider, and the quantum correction proportional to the4-divergent of torsion squared. Without the quantum correction, a simpleanalytical solution is obtained, while the more complicated field equationsincorporating the BI field are obtained also analytically. The lower bound ofquantum correction parameter is determined in terms of the torsion trace masssquared and axial torsion squared. Our findings reveal that in the lateuniverse, the BI parameter approaches infinity restoring to the Einstein-Cartantheory in the early universe with the dynamical reduction of the Immirziparameter to a constant BI parameter. Additionally, we derive analyticalsolutions for magnetic dynamos in the early universe, demonstrating thatmagnetic helicity is proportional to chiral chemical potential. A magneticfield at the QCD phase is found out of $10^{17}$ G, without quantum correction.Furthermore, from this dark magnetogenesis, we estimate light torsion with massof the order of 1 TeV, An example of unitary preserved Lagrangian with axion asan Immirzi field is obtained. In the present universe we find a magnetic fieldstrength of approximately $10^{-12}$ G which is quite close to the range foundby Miniati at the QCD threshold, between $10^{-18}-10^{-15}$ G. Given thatunitary violation on theoretical grounds may indicate new physics, exploringunitary violations in dark magnetogenesis could be particularly intriguing.",Zhi Fu Gao,2025-02-07,2025-02-07,,N/A,"['astro-ph.CO', 'gr-qc', 'hep-ph']"
2502.04725v1,Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?,http://arxiv.org/abs/2502.04725v1,"Despite the remarkable success of diffusion models (DMs) in data generation,they exhibit specific failure cases with unsatisfactory outputs. We focus onone such limitation: the ability of DMs to learn hidden rules between imagefeatures. Specifically, for image data with dependent features ($\mathbf{x}$)and ($\mathbf{y}$) (e.g., the height of the sun ($\mathbf{x}$) and the lengthof the shadow ($\mathbf{y}$)), we investigate whether DMs can accuratelycapture the inter-feature rule ($p(\mathbf{y}|\mathbf{x})$). Empiricalevaluations on mainstream DMs (e.g., Stable Diffusion 3.5) reveal consistentfailures, such as inconsistent lighting-shadow relationships and mismatchedobject-mirror reflections. Inspired by these findings, we design four synthetictasks with strongly correlated features to assess DMs' rule-learning abilities.Extensive experiments show that while DMs can identify coarse-grained rules,they struggle with fine-grained ones. Our theoretical analysis demonstratesthat DMs trained via denoising score matching (DSM) exhibit constant errors inlearning hidden rules, as the DSM objective is not compatible with ruleconformity. To mitigate this, we introduce a common technique - incorporatingadditional classifier guidance during sampling, which achieves (limited)improvements. Our analysis reveals that the subtle signals of fine-grainedrules are challenging for the classifier to capture, providing insights forfuture exploration.",Yujin Han,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.AI']"
2502.04724v1,Meromorphic degeneration of rational functions over snc models of the projective line,http://arxiv.org/abs/2502.04724v1,"For an analytic family $\{f_t\}_{t\in\mathbb{D}^*}$ on the unit punctureddisk that meromorphically degenerates at the origin, we show that its limitingmeasure on an snc model is given by the push forward of the canonical measureattached to the non-archimedean rational function naturally induced from thefamily, which is a generalization of the results by DeMarco-Faber and Okuyama.",Reimi Irokawa,2025-02-07,2025-02-07,,N/A,"['math.DS', 'math.AG', 'math.CV', 'Primary: 37F10, Secondary: 14G22, 37P30, 32A08']"
2502.04723v1,Asymptotics for EBLUPs within crossed mixed effect models,http://arxiv.org/abs/2502.04723v1,"In this article, we derive the joint asymptotic distribution of empiricalbest linear unbiased predictors (EBLUPs) for individual and cell-level randomeffects in a crossed mixed effect model. Under mild conditions (which includemoment conditions instead of normality for the random effects and modelerrors), we demonstrate that as the sizes of rows, columns, and, when weinclude interactions, cells simultaneously increase to infinity, thedistribution of the differences between the EBLUPs and the random effectssatisfy central limit theorems. These central limit theorems mean the EBLUPsasymptotically follow the convolution of the true random effect distributionand a normal distribution. Moreover, our results enable simple asymptoticapproximations and estimators for the mean squared error (MSE) of the EBLUPs,which in turn facilitates the construction of asymptotic prediction intervalsfor the unobserved random effects. We show in simulations that our simpleestimator of the MSE of the EBLUPs works very well in finite samples. Finally,we illustrate the use of the asymptotic prediction intervals with an analysisof movie rating data.",Ziyang Lyu,2025-02-07,2025-02-07,,N/A,['stat.ME']
2502.04722v1,Singing Voice Conversion with Accompaniment Using Self-Supervised Representation-Based Melody Features,http://arxiv.org/abs/2502.04722v1,"Melody preservation is crucial in singing voice conversion (SVC). However, inmany scenarios, audio is often accompanied with background music (BGM), whichcan cause audio distortion and interfere with the extraction of melody andother key features, significantly degrading SVC performance. Previous methodshave attempted to address this by using more robust neural network-based melodyextractors, but their performance drops sharply in the presence of complexaccompaniment. Other approaches involve performing source separation beforeconversion, but this often introduces noticeable artifacts, leading to asignificant drop in conversion quality and increasing the user's operationalcosts. To address these issues, we introduce a novel SVC method that usesself-supervised representation-based melody features to improve melody modelingaccuracy in the presence of BGM. In our experiments, we compare theeffectiveness of different self-supervised learning (SSL) models for melodyextraction and explore for the first time how SSL benefits the task of melodyextraction. The experimental results demonstrate that our proposed SVC modelsignificantly outperforms existing baseline methods in terms of melody accuracyand shows higher similarity and naturalness in both subjective and objectiveevaluations across noisy and clean audio environments.",Wei Chen,2025-02-07,2025-02-07,,N/A,"['cs.SD', 'cs.LG', 'eess.AS']"
2502.04721v1,Semileptonic kaon decays and the precise determination of $V_{us}$,http://arxiv.org/abs/2502.04721v1,"I will give a brief overview of the Standard Model theory inputs needed forthe precise determination of the Cabibbo-Kobayashi-Maskawa matrix element$V_{us}$ from semileptonic kaon decays, focusing on the long-distanceelectromagnetic corrections. I will then describe our recent effort to pin downthis correction at sub-permille level, which further sharpens the so-called``Cabibbo angle anomaly'', an interesting observation which may point towardsnew physics.",Chien-Yeah Seng,2025-02-07,2025-02-07,,N/A,"['hep-ph', 'hep-ex', 'hep-lat']"
2502.04720v1,Fluctuations of the largest eigenvalues of transformed spiked Wigner matrices,http://arxiv.org/abs/2502.04720v1,"We consider a spiked random matrix model obtained by applying a functionentrywise to a signal-plus-noise symmetric data matrix. We prove that thelargest eigenvalue of this model, which we call a transformed spiked Wignermatrix, exhibits Baik-Ben Arous-P\'ech\'e (BBP) type phase transition. We showthat the law of the fluctuation converges to the Gaussian distribution when theeffective signal-to-noise ratio (SNR) is above the critical number, and to theGOE Tracy-Widom distribution when the effective SNR is below the criticalnumber. We provide precise formulas for the limiting distributions and alsoconcentration estimates for the largest eigenvalues, both in the supercriticaland the subcritical regimes.",Aro Lee,2025-02-07,2025-02-07,,N/A,['math.PR']
2502.04719v1,Tolerance-Aware Deep Optics,http://arxiv.org/abs/2502.04719v1,"Deep optics has emerged as a promising approach by co-designing opticalelements with deep learning algorithms. However, current research typicallyoverlooks the analysis and optimization of manufacturing and assemblytolerances. This oversight creates a significant performance gap betweendesigned and fabricated optical systems. To address this challenge, we presentthe first end-to-end tolerance-aware optimization framework that incorporatesmultiple tolerance types into the deep optics design pipeline. Our methodcombines physics-informed modelling with data-driven training to enhanceoptical design by accounting for and compensating for structural deviations inmanufacturing and assembly. We validate our approach through computationalimaging applications, demonstrating results in both simulations and real-worldexperiments. We further examine how our proposed solution improves therobustness of optical systems and vision algorithms against tolerances throughqualitative and quantitative analyses. Code and additional visual results areavailable at openimaginglab.github.io/LensTolerance.",Jun Dai,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.GR']"
2502.04718v1,Evaluating Text Style Transfer Evaluation: Are There Any Reliable Metrics?,http://arxiv.org/abs/2502.04718v1,"Text Style Transfer (TST) is the task of transforming a text to reflect aparticular style while preserving its original content. Evaluating TST outputsis a multidimensional challenge, requiring the assessment of style transferaccuracy, content preservation, and naturalness. Using human evaluation isideal but costly, same as in other natural language processing (NLP) tasks,however, automatic metrics for TST have not received as much attention asmetrics for, e.g., machine translation or summarization. In this paper, weexamine both set of existing and novel metrics from broader NLP tasks for TSTevaluation, focusing on two popular subtasks-sentiment transfer anddetoxification-in a multilingual context comprising English, Hindi, andBengali. By conducting meta-evaluation through correlation with humanjudgments, we demonstrate the effectiveness of these metrics when usedindividually and in ensembles. Additionally, we investigate the potential ofLarge Language Models (LLMs) as tools for TST evaluation. Our findingshighlight that certain advanced NLP metrics and experimental-hybrid-techniques,provide better insights than existing TST metrics for delivering more accurate,consistent, and reproducible TST evaluations.",Sourabrata Mukherjee,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04713v1,Leveraging band diversity for feature selection in EO data,http://arxiv.org/abs/2502.04713v1,"Hyperspectral imaging (HSI) is a powerful earth observation technology thatcaptures and processes information across a wide spectrum of wavelengths.Hyperspectral imaging provides comprehensive and detailed spectral data that isinvaluable for a wide range of reconstruction problems. However due tocomplexity in analysis it often becomes difficult to handle this data. Toaddress the challenge of handling large number of bands in reconstructing highquality HSI, we propose to form groups of bands. In this position paper wepropose a method of selecting diverse bands using determinantal point processesin correlated bands. To address the issue of overlapping bands that may arisefrom grouping, we use spectral angle mapper analysis. This analysis can be fedto any Machine learning model to enable detailed analysis and monitoring withhigh precision and accuracy.",Sadia Hussain,2025-02-07,2025-02-07,,N/A,"['eess.IV', 'cs.CV']"
2502.04711v1,Dynamic Frequency-Adaptive Knowledge Distillation for Speech Enhancement,http://arxiv.org/abs/2502.04711v1,"Deep learning-based speech enhancement (SE) models have recently outperformedtraditional techniques, yet their deployment on resource-constrained devicesremains challenging due to high computational and memory demands. This paperintroduces a novel dynamic frequency-adaptive knowledge distillation (DFKD)approach to effectively compress SE models. Our method dynamically assesses themodel's output, distinguishing between high and low-frequency components, andadapts the learning objectives to meet the unique requirements of differentfrequency bands, capitalizing on the SE task's inherent characteristics. Toevaluate the DFKD's efficacy, we conducted experiments on threestate-of-the-art models: DCCRN, ConTasNet, and DPTNet. The results demonstratethat our method not only significantly enhances the performance of thecompressed model (student model) but also surpasses other logit-based knowledgedistillation methods specifically for SE tasks.",Xihao Yuan,2025-02-07,2025-02-07,,N/A,"['cs.SD', 'eess.AS']"
2502.04708v1,Survey on Token-Based Distributed MutualExclusion Algorithms,http://arxiv.org/abs/2502.04708v1,"In large-scale distributed environments, avoiding concurrent access to thesame resource by multiple processes becomes a core challenge, commonly termeddistributed mutual exclusion (DME). Token-based mechanisms have long beenrecognized as an effective strategy, wherein a solitary token is handed aroundamong processes as the key that allows access to the critical section. By doingso, they often reduce the messaging overhead compared to alternate methods.  This work surveys the significance of mutual exclusion in distributedcomputing and examines token-based solutions across various network models(including tree-based, ring-based, fully interconnected graphs, meshstructures, and ad hoc networks). We also delve into essential performancemeasures such as communication costs and strategies for fault tolerance, thenbranch into specialized variants, such as k-mutual exclusion andself-stabilizing algorithms.  Furthermore, a specialized approach that relies on finite projective planesis introduced to highlight how certain protocols can perform efficiently underboth best- and worst-case conditions. Lastly, we explore future directionsinvolving machine learning for token predictive routing and blockchaintechniques to resist adversarial behavior. This aims to provide a thorough yetaccessible overview of token-based DME approaches, together with insights onemerging research trends.",Elahe Tohidi,2025-02-07,2025-02-07,,N/A,['cs.DC']
2502.04707v1,NLS approximation and dark solitons for the Adlam-Allen model of cold collisionless plasmas,http://arxiv.org/abs/2502.04707v1,"The present work extends earlier considerations on a quintessential model ofcold, collisionless plasmas, namely the Adlam-Allen model. Previously, ananalysis of homoclinic solutions around a non-vanishing background (associatedwith a saddle equilibrium) led to a Korteweg-de Vries reduction. Here, weconsider a different equilibrium of the co-traveling frame model, namely acenter, and expanding around it, by means of a multiple-scale methodology andsuitable scalings, leads to an effective defocusing nonlinear Schr{\""o}dingerequation. Leveraging the latter, we construct, for the first time to ourknowledge, physically realistic dark soliton waveforms of the Adlam-Allenmodel. We subsequently test the numerical evolution of such coherentstructures, identifying them as long-lived waveforms of the full model.",George P. Veldes,2025-02-07,2025-02-07,,N/A,['nlin.PS']
2502.04706v1,Enhancing Impression Change Prediction in Speed Dating Simulations Based on Speakers' Personalities,http://arxiv.org/abs/2502.04706v1,"This paper focuses on simulating text dialogues in which impressions betweenspeakers improve during speed dating. This simulation involves selecting anutterance from multiple candidates generated by a text generation model thatreplicates a specific speaker's utterances, aiming to improve the impression ofthe speaker. Accurately selecting an utterance that improves the impression iscrucial for the simulation. We believe that whether an utterance improves adialogue partner's impression of the speaker may depend on the personalities ofboth parties. However, recent methods for utterance selection do not considerthe impression per utterance or the personalities. To address this, we proposea method that predicts whether an utterance improves a partner's impression ofthe speaker, considering the personalities. The evaluation results showed thatpersonalities are useful in predicting impression changes per utterance.Furthermore, we conducted a human evaluation of simulated dialogues using ourmethod. The results showed that it could simulate dialogues more favorablyreceived than those selected without considering personalities.",Kazuya Matsuo,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.HC']"
2502.04705v1,Decretion disc evolution and neutron star accretion in short-period eccentric Be/X-ray binaries,http://arxiv.org/abs/2502.04705v1,"We examine Be star discs in highly eccentric Be/X-ray systems. We use athree-dimensional smoothed particle hydrodynamics (SPH) code to model thestructure of the Be star disc and investigate its interactions with thesecondary star over time. We use system parameters consistent with theeccentric, short-period (P $\approx$ 16 d) Be/X-ray binary A0538-66 as thebasis for our models. We explore a range of system geometries by incrementallyvarying the misalignment angle of the neutron star's orbital plane with respectto the primary star's equatorial plane to cover a complete range from coplanarprograde to coplanar retrograde. For all simulations, we follow the evolutionof the disc's total mass and angular momentum as well as the averageeccentricity and inclination with respect to the equatorial planes of both theprimary and secondary. We also determine the neutron star accretion rates. Wefind that the high eccentricity of the binary orbit causes all calculated discparameters to vary with orbital phase in all models. The amplitude of thesevariations is negatively correlated with misalignment angle for models withmisalignment angles less than 90{\deg}, and positively correlated for modelswith misalignment angles greater than 90{\deg}. Accretion rates are affected bythe number of particles the neutron star interacts with as well as the lengthof the interaction time between the particles and the neutron star. We findthat accretion rates are largest for models with misalignment angles less than90{\deg}, and smaller for models with those greater than 90{\deg}.",R. G. Rast,2025-02-07,2025-02-07,,N/A,"['astro-ph.SR', 'astro-ph.HE']"
2502.04703v1,"Symbolic Regression of Data-Driven Reduced Order Model Closures for Under-Resolved, Convection-Dominated Flows",http://arxiv.org/abs/2502.04703v1,"Data-driven closures correct the standard reduced order models (ROMs) toincrease their accuracy in under-resolved, convection-dominated flows. Thereare two types of data-driven ROM closures in current use: (i) structural, withsimple ansatzes (e.g., linear or quadratic); and (ii) machine learning-based,with neural network ansatzes. We propose a novel symbolic regression (SR)data-driven ROM closure strategy, which combines the advantages of currentapproaches and eliminates their drawbacks. As a result, the new data-driven SRclosures yield ROMs that are interpretable, parsimonious, accurate,generalizable, and robust. To compare the data-driven SR-ROM closures with thestructural and machine learning-based ROM closures, we consider the data-drivenvariational multiscale ROM framework and two under-resolved,convection-dominated test problems: the flow past a cylinder and the lid-drivencavity flow at Reynolds numbers Re = 10000, 15000, and 20000. This numericalinvestigation shows that the new data-driven SR-ROM closures yield moreaccurate and robust ROMs than the structural and machine learning ROM closures.",Simone Manti,2025-02-07,2025-02-07,,N/A,"['math.NA', 'cs.LG', 'cs.NA', 'physics.flu-dyn']"
2502.04702v1,Explaining JWST counts with galaxy formation models,http://arxiv.org/abs/2502.04702v1,"A distinct power-law break is apparent m_AB approximately 21 in the deepNear-Infrared PEARLS-JWST galaxy counts. The break becomes more pronounced atlonger wavelengths, with the counts slope flattening smoothly with apparentmagnitude in the shortest band used at 0.9 microns, trending towards anincreasingly broken slope by the longest wavelength passband of JWST NIRCam,4.4 microns. This behaviour is remarkably well predicted by the GALFORMsemi-analytical model of galaxy formation. We use the model to diagnose theorigin of this behaviour. We find that the features that are responsible forthe break are: 1) the inherent break in the luminosity function; 2) the changein the volume element with redshift and 3) the redshift-dependent nature of thek-correction. We study the contribution to these effects by early and late-typegalaxies, using as a proxy for morphology the bulge-to-total stellar massratio. We find that the way in which ellipticals populate the bright end of theluminosity function while spirals dominate the faint end is preserved in thegalaxy number counts, with a characteristic stellar mass at the break ofapproximately 10^10 M_sun. We also find that the shape of the number counts ismainly driven by galaxies with relatively low redshift (z < 2) for the PEARLSobservational limit of m_AB < 28. We give a comprehensive description of whythe galaxy number counts in the near-infrared PEARLS-JWST observation look theway they do and which population of galaxies is dominant at each apparentmagnitude.",Giorgio Manzoni,2025-02-07,2025-02-07,,N/A,['astro-ph.GA']
2502.04700v1,EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference,http://arxiv.org/abs/2502.04700v1,"The rapid growth of large models has raised concerns about theirenvironmental impact and equity in accessibility due to significantcomputational costs. Low-Rank Adapters (LoRA) offer a lightweight solution forfinetuning large models, resulting in an abundance of publicly availableadapters tailored to diverse domains. We ask: Can these pretrained adapters beleveraged to further streamline adaptation to new tasks while addressing thesechallenges? We introduce EigenLoRAx, a parameter-efficient finetuning methodthat recycles existing adapters to create a principal subspace aligned withtheir shared domain knowledge which can be further augmented with orthogonalbasis vectors in low-resource scenarios. This enables rapid adaptation to newtasks by learning only lightweight coefficients on the principal components ofthe subspace - eliminating the need to finetune entire adapters. EigenLoRAxrequires significantly fewer parameters and memory, improving efficiency forboth training and inference. Our method demonstrates strong performance acrossdiverse domains and tasks, offering a scalable for edge-based applications,personalization, and equitable deployment of large models inresource-constrained environments.",Prakhar Kaushik,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04699v1,A Meta-learner for Heterogeneous Effects in Difference-in-Differences,http://arxiv.org/abs/2502.04699v1,"We address the problem of estimating heterogeneous treatment effects in paneldata, adopting the popular Difference-in-Differences (DiD) framework under theconditional parallel trends assumption. We propose a novel doubly robustmeta-learner for the Conditional Average Treatment Effect on the Treated(CATT), reducing the estimation to a convex risk minimization problem involvinga set of auxiliary models. Our framework allows for the flexible estimation ofthe CATT, when conditioning on any subset of variables of interest usinggeneric machine learning. Leveraging Neyman orthogonality, our proposedapproach is robust to estimation errors in the auxiliary models. As ageneralization to our main result, we develop a meta-learning approach for theestimation of general conditional functionals under covariate shift. We alsoprovide an extension to the instrumented DiD setting with non-compliance.Empirical results demonstrate the superiority of our approach over existingbaselines.",Hui Lan,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG']"
2502.04696v1,Adaptive Learning-based Model Predictive Control Strategy for Drift Vehicles,http://arxiv.org/abs/2502.04696v1,"Drift vehicle control offers valuable insights to support safe autonomousdriving in extreme conditions, which hinges on tracking a particular path whilemaintaining the vehicle states near the drift equilibrium points (DEP).However, conventional tracking methods are not adaptable for drift vehicles dueto their opposite steering angle and yaw rate. In this paper, we propose anadaptive path tracking (APT) control method to dynamically adjust drift statesto follow the reference path, improving the commonly utilized predictive pathtracking methods with released computation burden. Furthermore, existingcontrol strategies necessitate a precise system model to calculate the DEP,which can be more intractable due to the highly nonlinear drift dynamics andsensitive vehicle parameters. To tackle this problem, an adaptivelearning-based model predictive control (ALMPC) strategy is proposed based onthe APT method, where an upper-level Bayesian optimization is employed to learnthe DEP and APT control law to instruct a lower-level MPC drift controller.This hierarchical system architecture can also resolve the inherent controlconflict between path tracking and drifting by separating these objectives intodifferent layers. The ALMPC strategy is verified on the Matlab-Carsim platform,and simulation results demonstrate its effectiveness in controlling the driftvehicle to follow a clothoid-based reference path even with the misidentifiedroad friction parameter.",Bei Zhou,2025-02-07,2025-02-07,,N/A,['cs.RO']
2502.04695v1,Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance,http://arxiv.org/abs/2502.04695v1,"This position paper emphasizes the critical gap in the evaluation ofExplainable AI (XAI) due to the lack of standardized and reliable metrics,which diminishes its practical value, trustworthiness, and ability to meetregulatory requirements. Current evaluation methods are often fragmented,subjective, and biased, making them prone to manipulation and complicating theassessment of complex models. A central issue is the absence of a ground truthfor explanations, complicating comparisons across various XAI approaches. Toaddress these challenges, we advocate for widespread research into developingrobust, context-sensitive evaluation metrics. These metrics should be resistantto manipulation, relevant to each use case, and based on human judgment andreal-world applicability. We also recommend creating domain-specific evaluationbenchmarks that align with the user and regulatory needs of sectors such ashealthcare and finance. By encouraging collaboration among academia, industry,and regulators, we can create standards that balance flexibility andconsistency, ensuring XAI explanations are meaningful, trustworthy, andcompliant with evolving regulations.",Pratinav Seth,2025-02-07,2025-02-07,,N/A,"['cs.AI', 'cs.CE', 'cs.ET', 'cs.LG']"
2502.04692v1,"STRIDE: Automating Reward Design, Deep Reinforcement Learning Training and Feedback Optimization in Humanoid Robotics Locomotion",http://arxiv.org/abs/2502.04692v1,"Humanoid robotics presents significant challenges in artificial intelligence,requiring precise coordination and control of high-degree-of-freedom systems.Designing effective reward functions for deep reinforcement learning (DRL) inthis domain remains a critical bottleneck, demanding extensive manual effort,domain expertise, and iterative refinement. To overcome these challenges, weintroduce STRIDE, a novel framework built on agentic engineering to automatereward design, DRL training, and feedback optimization for humanoid robotlocomotion tasks. By combining the structured principles of agentic engineeringwith large language models (LLMs) for code-writing, zero-shot generation, andin-context optimization, STRIDE generates, evaluates, and iteratively refinesreward functions without relying on task-specific prompts or templates. Acrossdiverse environments featuring humanoid robot morphologies, STRIDE outperformsthe state-of-the-art reward design framework EUREKA, achieving significantimprovements in efficiency and task performance. Using STRIDE-generatedrewards, simulated humanoid robots achieve sprint-level locomotion acrosscomplex terrains, highlighting its ability to advance DRL workflows andhumanoid robotics research.",Zhenwei Wu,2025-02-07,2025-02-07,,N/A,"['cs.RO', 'cs.LG']"
2502.04691v1,PDStream: Slashing Long-Tail Delay in Interactive Video Streaming via Pseudo-Dual Streaming,http://arxiv.org/abs/2502.04691v1,"End-to-end (E2E) delay is critical for interactive video streaming (IVS)experiences, but remains unsatisfactory for its long-tail distribution causedby periodic large keyframes. Conventional optimization strategies, such asjitter buffer, bitrate adaptation, and customized encoding, either sacrificeclarity, average delay, or compatibility. To address this issue, we proposePDStream, a novel pseudo-dual streaming algorithm, aimed at minimizing E2Edelay while maintaining video clarity. The core idea is to split the twofunctions, delay-sensitive playback and delay-tolerant reference, on keyframesthrough dual streaming. Specifically, the playback function is held by a secondparallel stream, which comprises much smaller non-keyframes and is allocatedmore immediate bandwidth for real-time performance. The reference function isensured by the first stream with keyframe preservation, allocated moresubsequent bandwidth to smooth out bursty traffic. Additionally, ``pseudo''minimizes computational and transmission overheads by restricting dual streamsto brief activation only when keyframes appear, supported by correspondingdual-stream bitrate allocation and adaptation to ensure delay and clarity. Weimplement PDStream on a WebRTC-based IVS testbed with real-world networktraces. Results show that PDStream significantly outperforms prior algorithms,reducing average E2E delay by 17.5\% and slashing its 97th percentile by33.3\%, while keeping clarity under varying bandwidth.",Xuedou Xiao,2025-02-07,2025-02-07,,N/A,"['cs.MM', 'cs.NI']"
2502.04690v1,Beyond the Bethe-Salpeter equation in DFT based computational spectroscopy,http://arxiv.org/abs/2502.04690v1,"We introduce a theoretical framework that accurately describes resonancesbeyond the reach of both multiplet-based and density-functional-theory(DFT)-based codes. When a resonance acquires strong continuum character,multiplet approaches struggle with the exponential growth of the Hilbert spacedriven by the increasing number of relevant orbitals, if they extend beyond afew atomic and ligand orbitals. Conversely, existing \emph{ab initio} codes,supplemented by diagrammatic techniques, remain largely confined to theBethe--Salpeter equation, which tracks only two-particle excitations. However,many systems of interest, particularly those containing open $d$ or $f$ shells,require the propagation of an $N$-particle system, yielding a richer spectrallandscape dominated by significant continuum effects. Here, we propose atheoretical framework, together with its numerical implementation, that bridgesthis gap and enables the rigorous exploration of such resonances.",Alessandro Mirone,2025-02-07,2025-02-07,,N/A,['cond-mat.str-el']
2502.04689v1,"ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning",http://arxiv.org/abs/2502.04689v1,"Large language models (LLMs) achieve remarkable performance on challengingbenchmarks that are often structured as multiple-choice question-answering (QA)tasks. Zero-shot Chain-of-Thought (CoT) prompting enhances reasoning in LLMsbut provides only vague and generic guidance (""think step by step""). This paperintroduces ARR, an intuitive and effective zero-shot prompting method thatexplicitly incorporates three key steps in QA solving: analyzing the intent ofthe question, retrieving relevant information, and reasoning step by step.Comprehensive experiments across diverse and challenging QA tasks demonstratethat ARR consistently improves the Baseline (without ARR prompting) andoutperforms CoT. Ablation and case studies further validate the positivecontributions of each component: analyzing, retrieving, and reasoning. Notably,intent analysis plays a vital role in ARR. Additionally, extensive evaluationsacross various model sizes, LLM series, and generation settings solidify theeffectiveness, robustness, and generalizability of ARR.",Yuwei Yin,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI', 'cs.LG', 'I.2.7']"
2502.04688v1,M-IFEval: Multilingual Instruction-Following Evaluation,http://arxiv.org/abs/2502.04688v1,"Instruction following is a core capability of modern Large language models(LLMs), making evaluating this capability essential to understanding thesemodels. The Instruction Following Evaluation (IFEval) benchmark from theliterature does this using objective criteria, offering a measure of LLMperformance without subjective AI or human judgement. However, it only includesEnglish instructions, limiting its ability to assess LLMs in other languages.  We propose the Multilingual Instruction Following Evaluation (M-IFEval)benchmark, expanding the evaluation to French, Japanese, and Spanish, with bothgeneral and language-specific instructions. Applying this benchmark to 8state-of-the-art LLMs, we find that benchmark performance across languages andinstruction types can vary widely, underscoring the importance of amultilingual benchmark for evaluating LLMs in a diverse cultural context.",Antoine Dussolle,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI']"
2502.04687v1,Probing properties of nuclear spin-orbit interaction with nucleon spin polarization in intermediate-energy heavy-ion collisions,http://arxiv.org/abs/2502.04687v1,"The nucleon spin polarization perpendicular to the reaction plane ($P_y$) andalong the beam direction ($P_z$) in Au+Au collisions at the beam energy of 100AMeV with different nuclear spin-orbit interactions has been studied based on aspin- and isospin-dependent Boltzmann-Uehling-Uhlenbeck (SIBUU) transportmodel. While the spin polarization is weaker with a weaker nuclear spin-orbitcoupling as intuitively expected, a density-dependent nuclear spin-orbitcoupling enhances the $P_y$ at large rapidities and leads to a less negative orlarge $P_y$ at high transverse momenta. The difference in the $P_y$ of freeneutrons and protons at midrapidities and at small transverse momenta issensitive to the isospin dependence of the nuclear spin-orbit interaction.While the $P_z$ is also affected by the properties of nuclear spin-orbitinteraction in some sense, the behavior of the $P_y$ serves as a good probe ofthe strength, density dependence, and isospin dependence of nuclear spin-orbitinteraction.",Jun Xu,2025-02-07,2025-02-07,,N/A,"['nucl-th', 'hep-ex', 'nucl-ex']"
2502.04686v1,Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization,http://arxiv.org/abs/2502.04686v1,"Large language model (LLM)-based agents have recently shown impressiveprogress in a variety of domains, including open-ended conversation andmulti-step decision-making. However, applying these agents to social deductiongames such as Werewolf, which requires both strategic decision-making andfree-form language interaction, remains non-trivial. Traditional methods basedon Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)typically depend on a predefined action space, making them unsuitable forlanguage games with unconstrained text action space. Meanwhile, pure LLM-basedagents often suffer from intrinsic biases and require prohibitively largedatasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),an iterative framework that addresses these challenges by first mappingfree-form text to a discrete latent space, where methods like CFR and RL canlearn strategic policy more effectively. We then translate the learned policyback into natural language dialogues, which are used to fine-tune an LLM viaDirect Preference Optimization (DPO). By iteratively alternating between thesestages, our LSPO agent progressively enhances both strategic reasoning andlanguage communication. Experiment results on the Werewolf game show that ourmethod improves the agent's performance in each iteration and outperformsexisting Werewolf agents, underscoring its promise for free-form languagedecision-making.",Zelai Xu,2025-02-07,2025-02-07,,N/A,['cs.AI']
2502.04685v1,Capturing Extreme Events in Turbulence using an Extreme Variational Autoencoder (xVAE),http://arxiv.org/abs/2502.04685v1,"Turbulent flow fields are characterized by extreme events that arestatistically intermittent and carry a significant amount of energy andphysical importance. To emulate these flows, we introduce the extremevariational Autoencoder (xVAE), which embeds a max-infinitely divisible processwith heavy-tailed distributions into a standard VAE framework, enablingaccurate modeling of extreme events. xVAEs are neural network models thatreduce system dimensionality by learning non-linear latent representations ofdata. We demonstrate the effectiveness of xVAE in large-eddy simulation data ofwildland fire plumes, where intense heat release and complex plume-atmosphereinteractions generate extreme turbulence. Comparisons with the commonly usedProper Orthogonal Decomposition (POD) modes show that xVAE is more robust incapturing extreme values and provides a powerful uncertainty quantificationframework using variational Bayes. Additionally, xVAE enables analysis of theso-called copulas of fields to assess risks associated with rare events whilerigorously accounting for uncertainty, such as simultaneous exceedances of highthresholds across multiple locations. The proposed approach provides a newdirection for studying realistic turbulent flows, such as high-speedaerodynamics, space propulsion, and atmospheric and oceanic systems that arecharacterized by extreme events.",Likun Zhang,2025-02-07,2025-02-07,,N/A,"['physics.flu-dyn', 'stat.AP', 'stat.ML']"
2502.04684v1,G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models,http://arxiv.org/abs/2502.04684v1,"Discovering the genotype-phenotype relationship is crucial for geneticengineering, which will facilitate advances in fields such as crop breeding,conservation biology, and personalized medicine. Current research usuallyfocuses on single species and small datasets due to limitations in phenotypicdata collection, especially for traits that require visual assessments orphysical measurements. Deciphering complex and composite phenotypes, such asmorphology, from genetic data at scale remains an open question. To breakthrough traditional generic models that rely on simplified assumptions, thispaper introduces G2PDiffusion, the first-of-its-kind diffusion model designedfor genotype-to-phenotype generation across multiple species. Specifically, weuse images to represent morphological phenotypes across species and redefinephenotype prediction as conditional image generation. To this end, this paperintroduces an environment-enhanced DNA sequence conditioner and trains a stablediffusion model with a novel alignment method to improve genotype-to-phenotypeconsistency. Extensive experiments demonstrate that our approach enhancesphenotype prediction accuracy across species, capturing subtle geneticvariations that contribute to observable traits.",Mengdi Liu,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04682v1,AI-Driven Solutions for Falcon Disease Classification: Concatenated ConvNeXt cum EfficientNet AI Model Approach,http://arxiv.org/abs/2502.04682v1,"Falconry, an ancient practice of training and hunting with falcons,emphasizes the need for vigilant health monitoring to ensure the well-being ofthese highly valued birds, especially during hunting activities. This researchpaper introduces a cutting-edge approach, which leverages the power ofConcatenated ConvNeXt and EfficientNet AI models for falcon diseaseclassification. Focused on distinguishing 'Normal,' 'Liver,' and'Aspergillosis' cases, the study employs a comprehensive dataset for modeltraining and evaluation, utilizing metrics such as accuracy, precision, recall,and f1-score. Through rigorous experimentation and evaluation, we demonstratethe superior performance of the concatenated AI model compared to traditionalmethods and standalone architectures. This novel approach contributes toaccurate falcon disease classification, laying the groundwork for furtheradvancements in avian veterinary AI applications.",Alavikunhu Panthakkan,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04681v1,CALF-SBM: A Covariate-Assisted Latent Factor Stochastic Block Model,http://arxiv.org/abs/2502.04681v1,"We propose a novel network generative model extended from the standardstochastic block model by concurrently utilizing observed node-levelinformation and accounting for network-enabled nodal heterogeneity. Theproposed model is so so-called covariate-assisted latent factor stochasticblock model (CALF-SBM). The inference for the proposed model is done in a fullyBayesian framework. The primary application of CALF-SBM in the present researchis focused on community detection, where a model-selection-based approach isemployed to estimate the number of communities which is practically assumedunknown. To assess the performance of CALF-SBM, an extensive simulation studyis carried out, including comparisons with multiple classical and modernnetwork clustering algorithms. Lastly, the paper presents two real dataapplications, respectively based on an extremely new network data demonstratingcollaborative relationships of otolaryngologists in the United States and atraditional aviation network data containing information about direct flightsbetween airports in the United States and Canada.",Sydney Louit,2025-02-07,2025-02-07,,N/A,['stat.ME']
2502.04680v1,Performance Evaluation of Image Enhancement Techniques on Transfer Learning for Touchless Fingerprint Recognition,http://arxiv.org/abs/2502.04680v1,"Fingerprint recognition remains one of the most reliable biometrictechnologies due to its high accuracy and uniqueness. Traditional systems relyon contact-based scanners, which are prone to issues such as image degradationfrom surface contamination and inconsistent user interaction. To address theselimitations, contactless fingerprint recognition has emerged as a promisingalternative, providing non-intrusive and hygienic authentication. This studyevaluates the impact of image enhancement tech-niques on the performance ofpre-trained deep learning models using transfer learning for touchlessfingerprint recognition. The IIT-Bombay Touchless and Touch-Based FingerprintDatabase, containing data from 200 subjects, was employed to test theper-formance of deep learning architectures such as VGG-16, VGG-19,Inception-V3, and ResNet-50. Experimental results reveal that transfer learningmethods with fingerprint image enhance-ment (indirect method) significantlyoutperform those without enhancement (direct method). Specifically, VGG-16achieved an accuracy of 98% in training and 93% in testing when using theenhanced images, demonstrating superior performance compared to the directmethod.  This paper provides a detailed comparison of the effectiveness of imageenhancement in improving the accuracy of transfer learning models for touchlessfingerprint recognition, offering key insights for developing more efficientbiometric systems.",S Sreehari,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.LG']"
2502.04679v1,Mechanistic Understandings of Representation Vulnerabilities and Engineering Robust Vision Transformers,http://arxiv.org/abs/2502.04679v1,"While transformer-based models dominate NLP and vision applications, theirunderlying mechanisms to map the input space to the label space semanticallyare not well understood. In this paper, we study the sources of knownrepresentation vulnerabilities of vision transformers (ViT), where perceptuallyidentical images can have very different representations and semanticallyunrelated images can have the same representation. Our analysis indicates thatimperceptible changes to the input can result in significant representationchanges, particularly in later layers, suggesting potential instabilities inthe performance of ViTs. Our comprehensive study reveals that adversarialeffects, while subtle in early layers, propagate and amplify through thenetwork, becoming most pronounced in middle to late layers. This insightmotivates the development of NeuroShield-ViT, a novel defense mechanism thatstrategically neutralizes vulnerable neurons in earlier layers to prevent thecascade of adversarial effects. We demonstrate NeuroShield-ViT's effectivenessacross various attacks, particularly excelling against strong iterativeattacks, and showcase its remarkable zero-shot generalization capabilities.Without fine-tuning, our method achieves a competitive accuracy of 77.8% onadversarial examples, surpassing conventional robustness methods. Our resultsshed new light on how adversarial effects propagate through ViT layers, whileproviding a promising approach to enhance the robustness of vision transformersagainst adversarial attacks. Additionally, they provide a promising approach toenhance the robustness of vision transformers against adversarial attacks.",Chashi Mahiul Islam,2025-02-07,2025-02-07,,N/A,"['cs.CV', 'cs.LG']"
2502.04677v1,LLM Query Scheduling with Prefix Reuse and Latency Constraints,http://arxiv.org/abs/2502.04677v1,"The efficient deployment of large language models (LLMs) in online settingsrequires optimizing inference performance under stringent latency constraints,particularly the time-to-first-token (TTFT) and time-per-output-token (TPOT).This paper focuses on the query scheduling problem for LLM inference withprefix reuse, a technique that leverages shared prefixes across queries toreduce computational overhead. Our work reveals previously unknown limitationsof the existing first-come-first-serve (FCFS) and longest-prefix-match (LPM)scheduling strategies with respect to satisfying latency constraints. Wepresent a formal theoretical framework for LLM query scheduling underRadixAttention, a prefix reuse mechanism that stores and reuses intermediaterepresentations in a radix tree structure. Our analysis establishes theNP-hardness of the scheduling problem with prefix reuse under TTFT constraintsand proposes a novel scheduling algorithm, $k$-LPM, which generalizes existingmethods by balancing prefix reuse and fairness in query processing. Theoreticalguarantees demonstrate that $k$-LPM achieves improved TTFT performance underrealistic traffic patterns captured by a data generative model. Empiricalevaluations in a realistic serving setting validates our findings, showingsignificant reductions in P99 TTFT compared to baseline methods.",Gregory Dexter,2025-02-07,2025-02-07,,N/A,['cs.DS']
2502.04674v1,AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts,http://arxiv.org/abs/2502.04674v1,"Effective linguistic choices that attract potential customers play crucialroles in advertising success. This study aims to explore the linguisticfeatures of ad texts that influence human preferences. Although the creation ofattractive ad texts is an active area of research, progress in understandingthe specific linguistic features that affect attractiveness is hindered byseveral obstacles. First, human preferences are complex and influenced bymultiple factors, including their content, such as brand names, and theirlinguistic styles, making analysis challenging. Second, publicly available adtext datasets that include human preferences are lacking, such as adperformance metrics and human feedback, which reflect people's interests. Toaddress these problems, we present AdParaphrase, a paraphrase dataset thatcontains human preferences for pairs of ad texts that are semanticallyequivalent but differ in terms of wording and style. This dataset allows forpreference analysis that focuses on the differences in linguistic features. Ouranalysis revealed that ad texts preferred by human judges have higher fluency,longer length, more nouns, and use of bracket symbols. Furthermore, wedemonstrate that an ad text-generation model that considers these findingssignificantly improves the attractiveness of a given text. The dataset ispublicly available at: https://github.com/CyberAgentAILab/AdParaphrase.",Soichiro Murakami,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI']"
2502.04671v1,${\rm P{\small ROOF}W{\small ALA}}$: Multilingual Proof Data Synthesis and Theorem-Proving,http://arxiv.org/abs/2502.04671v1,"Neural networks have shown substantial promise at automatic theorem-provingin interactive proof assistants (ITPs) like Lean and Coq. However, most neuraltheorem-proving models are restricted to specific ITPs, leaving outopportunities for cross-lingual $\textit{transfer}$ between ITPs. We addressthis weakness with a multilingual proof framework, ${\rm P{\small ROOF}W{\smallALA}}$, that allows a standardized form of interaction between neuraltheorem-provers and two established ITPs (Coq and Lean). It enables thecollection of multilingual proof step data -- data recording the result ofproof actions on ITP states -- for training neural provers. ${\rm P{\smallROOF}W{\small ALA}}$ allows the systematic evaluation of a model's performanceacross different ITPs and problem domains via efficient parallel proof searchalgorithms. We show that multilingual training enabled by ${\rm P{\smallROOF}W{\small ALA}}$ can lead to successful transfer across ITPs. Specifically,a model trained on a mix of ${\rm P{\small ROOF}W{\small ALA}}$-generated Coqand Lean data outperforms Lean-only and Coq-only models on the standardprove-at-$k$ metric. We open source all code including code for the$\href{https://github.com/trishullab/proof-wala}{ProofWala\; Framework}$, andthe $\href{https://github.com/trishullab/itp-interface}{Multilingual\; ITP\;interaction\; framework}$.",Amitayush Thakur,2025-02-07,2025-02-07,,N/A,"['cs.AI', 'cs.LG', 'cs.LO', 'cs.PL']"
2502.04670v1,CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation,http://arxiv.org/abs/2502.04670v1,"Diffusion models have emerged as powerful tools for generative tasks,producing high-quality outputs across diverse domains. However, how thegenerated data responds to the initial noise perturbation in diffusion modelsremains under-explored, which hinders understanding the controllability of thesampling process. In this work, we first observe an interesting phenomenon: therelationship between the change of generation outputs and the scale of initialnoise perturbation is highly linear through the diffusion ODE sampling. Then weprovide both theoretical and empirical study to justify this linearity propertyof this input-output (noise-generation data) relationship. Inspired by thesenew insights, we propose a novel Controllable and Constrained Sampling method(CCS) together with a new controller algorithm for diffusion models to samplewith desired statistical properties while preserving good sample quality. Weperform extensive experiments to compare our proposed sampling approach withother methods on both sampling controllability and sampled data quality.Results show that our CCS method achieves more precisely controlled samplingwhile maintaining superior sample quality and diversity.",Bowen Song,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04669v1,A Comprehensive Review on Noise Control of Diffusion Model,http://arxiv.org/abs/2502.04669v1,"Diffusion models have recently emerged as powerful generative frameworks forproducing high-quality images. A pivotal component of these models is the noiseschedule, which governs the rate of noise injection during the diffusionprocess. Since the noise schedule substantially influences sampling quality andtraining quality, understanding its design and implications is crucial. In thisdiscussion, various noise schedules are examined, and their distinguishingfeatures and performance characteristics are highlighted.",Zhehao Guo,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04668v1,Machine-Learning Interatomic Potentials for Long-Range Systems,http://arxiv.org/abs/2502.04668v1,"Machine-learning interatomic potentials have emerged as a revolutionary classof force-field models in molecular simulations, delivering quantum-mechanicalaccuracy at a fraction of the computational cost and enabling the simulation oflarge-scale systems over extended timescales. However, they often focus onmodeling local environments, neglecting crucial long-range interactions. Wepropose a Sum-of-Gaussians Neural Network (SOG-Net), a lightweight andversatile framework for integrating long-range interactions into machinelearning force field. The SOG-Net employs a latent-variable learning networkthat seamlessly bridges short-range and long-range components, coupled with anefficient Fourier convolution layer that incorporates long-range effects. Bylearning sum-of-Gaussian multipliers across different convolution layers, theSOG-Net adaptively captures diverse long-range decay behaviors whilemaintaining close-to-linear computational complexity during training andsimulation via non-uniform fast Fourier transforms. The method is demonstratedeffective for a broad range of long-range systems.",Yajie Ji,2025-02-07,2025-02-07,,N/A,"['physics.chem-ph', 'cs.LG']"
2502.04667v1,Unveiling the Mechanisms of Explicit CoT Training: How Chain-of-Thought Enhances Reasoning Generalization,http://arxiv.org/abs/2502.04667v1,"Training large language models (LLMs) with high-quality Chain-of-Thought(CoT) annotations has become a widely adopted strategy due to its significantenhancement of reasoning capabilities. To fully comprehend this approach, twoquestions naturally arise: (Q1) What advantages does training with CoT offercompared to training without CoT? (Q2) If there are advantages, what are theunderlying mechanisms of explicit CoT training? Analyzing the advantages andmechanisms of CoT training is challenging due to the many factors involved. Toaddress this, we conduct a detailed analysis using clear and controllable datadistributions and, for the first time, reveal that CoT training offers thefollowing advantages: (1) Training with CoT markedly improves reasoninggeneralization, extending it from in-distribution (ID) to both ID andout-of-distribution (OOD) scenarios, while also speeding up convergence; (2)Even when training with CoT includes a certain range of erroneous reasoningsteps, it still enables the model to learn reasoning patterns, leading tosystematic generalization. We further explore the underlying mechanisms from acircuit perspective: (1) The data distribution (e.g., ratio $\lambda$ andpattern) plays a crucial role in influencing the model's systematicgeneralization; (2) CoT training (with two-hop facts) internalizes reasoninginto a two-stage generalizing circuit, where the number of stages correspondsto the explicit reasoning steps during training. Our findings elucidate themechanisms underlying explicit CoT training and offer critical insights intotuning strategies for LLMs to achieve robust generalization.",Xinhao Yao,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.04666v1,Enhancing Health Information Retrieval with RAG by Prioritizing Topical Relevance and Factual Accuracy,http://arxiv.org/abs/2502.04666v1,"The exponential surge in online health information, coupled with itsincreasing use by non-experts, highlights the pressing need for advanced HealthInformation Retrieval models that consider not only topical relevance but alsothe factual accuracy of the retrieved information, given the potential risksassociated with health misinformation. To this aim, this paper introduces asolution driven by Retrieval-Augmented Generation (RAG), which leverages thecapabilities of generative Large Language Models (LLMs) to enhance theretrieval of health-related documents grounded in scientific evidence. Inparticular, we propose a three-stage model: in the first stage, the user'squery is employed to retrieve topically relevant passages with associatedreferences from a knowledge base constituted by scientific literature. In thesecond stage, these passages, alongside the initial query, are processed byLLMs to generate a contextually relevant rich text (GenText). In the laststage, the documents to be retrieved are evaluated and ranked both from thepoint of view of topical relevance and factual accuracy by means of theircomparison with GenText, either through stance detection or semanticsimilarity. In addition to calculating factual accuracy, GenText can offer alayer of explainability for it, aiding users in understanding the reasoningbehind the retrieval. Experimental evaluation of our model on benchmarkdatasets and against baseline models demonstrates its effectiveness inenhancing the retrieval of both topically relevant and factually accuratehealth information, thus presenting a significant step forward in the healthmisinformation mitigation problem.",Rishabh Uapadhyay,2025-02-07,2025-02-07,,N/A,['cs.IR']
2502.04664v1,Implicit Bias of SignGD and Adam on Multiclass Separable Data,http://arxiv.org/abs/2502.04664v1,"In the optimization of overparameterized models, different gradient-basedmethods can achieve zero training error yet converge to distinctly differentsolutions inducing different generalization properties. While a decade ofresearch on implicit optimization bias has illuminated this phenomenon invarious settings, even the foundational case of linear classification withseparable data still has important open questions. We resolve a fundamental gapby characterizing the implicit bias of both Adam and Sign Gradient Descent inmulti-class cross-entropy minimization: we prove that their iterates convergeto solutions that maximize the margin with respect to the classifier matrix'smax-norm and characterize the rate of convergence. We extend our results togeneral p-norm normalized steepest descent algorithms and to other multi-classlosses.",Chen Fan,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'math.OC']"
2502.04662v1,Adversarially-Robust TD Learning with Markovian Data: Finite-Time Rates and Fundamental Limits,http://arxiv.org/abs/2502.04662v1,"One of the most basic problems in reinforcement learning (RL) is policyevaluation: estimating the long-term return, i.e., value function,corresponding to a given fixed policy. The celebrated Temporal Difference (TD)learning algorithm addresses this problem, and recent work has investigatedfinite-time convergence guarantees for this algorithm and variants thereof.However, these guarantees hinge on the reward observations being alwaysgenerated from a well-behaved (e.g., sub-Gaussian) true reward distribution.Motivated by harsh, real-world environments where such an idealistic assumptionmay no longer hold, we revisit the policy evaluation problem from theperspective of adversarial robustness. In particular, we consider aHuber-contaminated reward model where an adversary can arbitrarily corrupt eachreward sample with a small probability $\epsilon$. Under this observationmodel, we first show that the adversary can cause the vanilla TD algorithm toconverge to any arbitrary value function. We then develop a novel algorithmcalled Robust-TD and prove that its finite-time guarantees match that ofvanilla TD with linear function approximation up to a small $O(\epsilon)$ termthat captures the effect of corruption. We complement this result with aminimax lower bound, revealing that such an additive corruption-induced term isunavoidable. To our knowledge, these results are the first of their kind in thecontext of adversarial robustness of stochastic approximation schemes driven byMarkov noise. The key new technical tool that enables our results is ananalysis of the Median-of-Means estimator with corrupted, time-correlated datathat might be of independent interest to the literature on robust statistics.",Sreejeet Maity,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.SY', 'eess.SY', 'math.OC']"
2502.04661v1,Many-Body Coarse-Grained Molecular Dynamics with the Atomic Cluster Expansion,http://arxiv.org/abs/2502.04661v1,"Molecular dynamics (MD) simulations provide detailed insight intoatomic-scale mechanisms but are inherently restricted to small spatio-temporalscales. Coarse-grained molecular dynamics (CGMD) techniques allow simulationsof much larger systems over extended timescales. In theory, these techniquescan be quantitatively accurate, but common practice is to only targetqualitatively correct behaviour of coarse-grained models. Recent advances inapplying machine learning methodology in this setting are now being applied tocreate also quantitatively accurate CGMD models. We demonstrate how the AtomicCluster Expansion parameterization (Drautz, 2019) can be used in this task toconstruct highly efficient, interpretable and accurate CGMD models. We focus inparticular on exploring the role of many-body effects.",Yangshuai Wang,2025-02-07,2025-02-07,,N/A,['physics.comp-ph']
2502.04660v1,Modelling the impact of circumbinary disk accretion on post-AGB binary evolution and surface chemistry,http://arxiv.org/abs/2502.04660v1,"Post-asymptotic giant branch (post-AGB) binaries are surrounded by dustycircumbinary disks, and exhibit unexpected orbital properties resulting frompoorly understood binary interaction processes. Re-accreted gas from thecircumbinary disk alters the photospheric chemistry of the post-AGB star,producing a characteristic underabundance of refractory elements thatcorrelates with condensation temperature $\unicode{x2013}$a phenomenon known aschemical depletion. This work investigates how re-accretion from a disk driveschemical depletion, and the impact accreted matter has on post-AGB evolution.We used the MESA code to evolve 0.55 and 0.60 M$_{\odot}$ post-AGB stars withthe accretion of refractory element-depleted gas from a circumbinary disk. Ourstudy adopts observationally-constrained initial accretion rates and diskmasses to reproduce the chemical depletion patterns of six well-studiedpost-AGB binary stars: EP Lyr, HP Lyr, IRAS 17038-4815, IRAS 09144-4933, HD131356, and SX Cen. We find high accretion rates ($>\,$10$^{-7}$M$_{\odot}$yr$^{-1}$) and large disk masses ($\geq\,$10$^{-2}$ M$_{\odot}$)necessary to reproduce observed depletion, particularly in higher-mass, hotterpost-AGB stars (T$_{\textrm{eff}}\geq$ 6000 K). A slower evolution (lower coremass) is required to reproduce cooler (T$_{\textrm{eff}}\leq$ 5000 K) depletedpost-AGB stars. Rapid accretion significantly impacts post-AGB evolution,stalling stars at cooler effective temperatures and extending post-AGBlifetimes by factors of around 3 to 10. Despite this, extended post-AGBtimescales remain within or below the planetary nebula (PN) visibilitytimescale, suggesting accretion cannot account for the observed lack of ionisedPNe in post-AGB binaries. Our findings constrain accretion-flow parameters andadvance our understanding of disk-binary interactions in post-AGB systems.",Kayla Martin,2025-02-07,2025-02-07,,N/A,['astro-ph.SR']
2502.04659v1,$\mathsf{CRATE}$: Cross-Rollup Atomic Transaction Execution,http://arxiv.org/abs/2502.04659v1,"Blockchains have revolutionized decentralized applications, withcomposability enabling atomic, trustless interactions across smart contracts.However, layer 2 (L2) scalability solutions like rollups introducefragmentation and hinder composability. Current cross-chain protocols,including atomic swaps, bridges, and shared sequencers, lack the necessarycoordination mechanisms or rely on trust assumptions, and are thus notsufficient to support full cross-rollup composability. This paper presents$\mathsf{CRATE}$, a secure protocol for cross-rollup composability that ensuresall-or-nothing and serializable execution of cross-rollup transactions (CRTs).$\mathsf{CRATE}$ supports rollups on distinct layer 1 (L1) chains, achievesfinality in 4 rounds on L1, and only relies on the underlying L1s and theliveness of L2s. We introduce two formal models for CRTs, define atomicitywithin them, and formally prove the security of $\mathsf{CRATE}$. We alsoprovide an implementation of $\mathsf{CRATE}$ along with a cross-rollup flashloan application; our experiments demonstrate that $\mathsf{CRATE}$ ispractical in terms of gas usage on L1.",Ioannis Kaklamanis,2025-02-07,2025-02-07,,N/A,['cs.CR']
2502.04658v1,Shifting Attention to You: Personalized Brain-Inspired AI Models,http://arxiv.org/abs/2502.04658v1,"The integration of human and artificial intelligence represents a scientificopportunity to advance our understanding of information processing, as eachsystem offers unique computational insights that can enhance and inform theother. The synthesis of human cognitive principles with artificial intelligencehas the potential to produce more interpretable and functionally alignedcomputational models, while simultaneously providing a formal framework forinvestigating the neural mechanisms underlying perception, learning, anddecision-making through systematic model comparisons and representationalanalyses. In this study, we introduce personalized brain-inspired modeling thatintegrates human behavioral embeddings and neural data to align with cognitiveprocesses. We took a stepwise approach, fine-tuning the ContrastiveLanguage-Image Pre-training (CLIP) model with large-scale behavioral decisions,group-level neural data, and finally, participant-level neural data within abroader framework that we have named CLIP-Human-Based Analysis (CLIP-HBA). Wefound that fine-tuning on behavioral data enhances its ability to predict humansimilarity judgments while indirectly aligning it with dynamic representationscaptured via MEG. To further gain mechanistic insights into the temporalevolution of cognitive processes, we introduced a model specifically fine-tunedon millisecond-level MEG neural dynamics (CLIP-HBA-MEG). This model resulted inenhanced temporal alignment with human neural processing while still showingimprovement on behavioral alignment. Finally, we trained individualized modelson participant-specific neural data, effectively capturing individualizedneural dynamics and highlighting the potential for personalized AI systems.These personalized systems have far-reaching implications for the fields ofmedicine, cognitive research, human-computer interfaces, and AI development.",Stephen Chong Zhao,2025-02-07,2025-02-07,,N/A,"['q-bio.NC', 'cs.AI']"
2502.04657v1,Core to Cosmic Edge: SIMBA-C's New Take on Abundance Profiles in the Intragroup Medium at z = 0,http://arxiv.org/abs/2502.04657v1,"We employ the SIMBA-C cosmological simulation to study the impact of itsupgraded chemical enrichment model (Chem5) on the distribution of metals in theintragroup medium (IGrM). We investigate the projected X-ray emission-weightedabundance profiles of key elements over two decades in halo mass ($10^{13} \leqM_{500}/\mathrm{M_\odot} \leq 10^{15}$). Typically, SIMBA-C generateslower-amplitude abundance profiles than SIMBA with flatter cores, in betteragreement with observations. For low-mass groups, both simulations over-enrichthe IGrM with Si, S, Ca, and Fe compared to observations, a trend likelyrelated to inadequate modeling of metal dispersal and mixing. We analyze the 3Dmass-weighted abundance profiles, concluding that the lower SIMBA-C IGrMabundances are primarily a consequence of fewer metals in the IGrM, driven byreduced metal yields in Chem5, and the removal of the instantaneous recyclingof metals approximation employed by SIMBA. Additionally, an increased IGrM massin low-mass SIMBA-C groups is likely triggered by changes to the AGN andstellar feedback models. Our study suggests that a more realistic chemicalenrichment model broadly improves agreement with observations, but physicallymotivated sub-grid models for other key processes, like AGN and stellarfeedback and turbulent diffusion, are required to realistically reproduceobserved group environments.",Aviv Padawer-Blatt,2025-02-07,2025-02-07,,N/A,"['astro-ph.GA', 'astro-ph.CO']"
2502.04656v1,MHAF-YOLO: Multi-Branch Heterogeneous Auxiliary Fusion YOLO for accurate object detection,http://arxiv.org/abs/2502.04656v1,"Due to the effective multi-scale feature fusion capabilities of the PathAggregation FPN (PAFPN), it has become a widely adopted component in YOLO-baseddetectors. However, PAFPN struggles to integrate high-level semantic cues withlow-level spatial details, limiting its performance in real-world applications,especially with significant scale variations. In this paper, we proposeMHAF-YOLO, a novel detection framework featuring a versatile neck design calledthe Multi-Branch Auxiliary FPN (MAFPN), which consists of two key modules: theSuperficial Assisted Fusion (SAF) and Advanced Assisted Fusion (AAF). The SAFbridges the backbone and the neck by fusing shallow features, effectivelytransferring crucial low-level spatial information with high fidelity.Meanwhile, the AAF integrates multi-scale feature information at deeper necklayers, delivering richer gradient information to the output layer and furtherenhancing the model learning capacity. To complement MAFPN, we introduce theGlobal Heterogeneous Flexible Kernel Selection (GHFKS) mechanism and theReparameterized Heterogeneous Multi-Scale (RepHMS) module to enhance featurefusion. RepHMS is globally integrated into the network, utilizing GHFKS toselect larger convolutional kernels for various feature layers, expanding thevertical receptive field and capturing contextual information across spatialhierarchies. Locally, it optimizes convolution by processing both large andsmall kernels within the same layer, broadening the lateral receptive field andpreserving crucial details for detecting smaller targets. The source code ofthis work is available at: https://github.com/yang0201/MHAF-YOLO.",Zhiqiang Yang,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04655v1,Before It's Too Late: A State Space Model for the Early Prediction of Misinformation and Disinformation Engagement,http://arxiv.org/abs/2502.04655v1,"In today's digital age, conspiracies and information campaigns can emergerapidly and erode social and democratic cohesion. While recent deep learningapproaches have made progress in modeling engagement through language andpropagation models, they struggle with irregularly sampled data and earlytrajectory assessment. We present IC-Mamba, a novel state space model thatforecasts social media engagement by modeling interval-censored data withintegrated temporal embeddings. Our model excels at predicting engagementpatterns within the crucial first 15-30 minutes of posting (RMSE 0.118-0.143),enabling rapid assessment of content reach. By incorporating interval-censoredmodeling into the state space framework, IC-Mamba captures fine-grainedtemporal dynamics of engagement growth, achieving a 4.72% improvement overstate-of-the-art across multiple engagement metrics (likes, shares, comments,and emojis). Our experiments demonstrate IC-Mamba's effectiveness inforecasting both post-level dynamics and broader narrative patterns (F10.508-0.751 for narrative-level predictions). The model maintains strongpredictive performance across extended time horizons, successfully forecastingopinion-level engagement up to 28 days ahead using observation windows of 3-10days. These capabilities enable earlier identification of potentiallyproblematic content, providing crucial lead time for designing and implementingcountermeasures. Code is available at: https://github.com/ltian678/ic-mamba. Aninteractive dashboard demonstrating our results is available at:https://ic-mamba.behavioral-ds.science.",Lin Tian,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04654v1,A sliced Wasserstein and diffusion approach to random coefficient models,http://arxiv.org/abs/2502.04654v1,"We propose a new minimum-distance estimator for linear random coefficientmodels. This estimator integrates the recently advanced sliced Wassersteindistance with the nearest neighbor methods, both of which enhance computationalefficiency. We demonstrate that the proposed method is consistent inapproximating the true distribution. Additionally, our formulation encourages adiffusion process-based algorithm, which holds independent interest andpotential for broader applications.",Keunwoo Lim,2025-02-07,2025-02-07,,N/A,"['math.ST', 'econ.EM', 'stat.TH']"
2502.04653v1,Choosing suitable noise models for nanohertz gravitational-wave astrophysics,http://arxiv.org/abs/2502.04653v1,"Accurately estimating the parameters of the nanohertz gravitational-wavebackground is essential for understanding its origin. The background istypically modeled with a power-law spectrum, parametrized with an amplitude$A$, which describes its intensity, and a spectral index $\gamma$, whichdescribes how the background varies with frequency. Different collaborationshave produced varied estimates of $\gamma$, some in tension with the value of$\gamma = 13/3$ expected for circular, gravitational-wave-driven binary blackholes. However, estimates of $A$ and $\gamma$ can be affected by systematicerrors and misspecified noise models. We investigate how systematic errors,which may plausibly be present in pulsar-timing analyses, can shift inferencesabout $A, \gamma$. We demonstrate that conservatively incorporating noisesources into the model that are not actually present in the data does notproduce bias inferences in practice. This addresses concerns that an overlycomplex noise model might lead to bias from a needlessly conservative prior.Our results highlight the importance of using comprehensive noise models inpulsar timing analyses to ensure accurate and reliable parameter estimation ofthe gravitational-wave background.",Valentina Di Marco,2025-02-07,2025-02-07,,N/A,"['gr-qc', 'astro-ph.HE']"
2502.04651v1,Dark states in an integrable XY central spin model,http://arxiv.org/abs/2502.04651v1,"Eigenstates of central spin models in which the central spin is unentangledwith the environment are known as dark states. They have recently been observedin a class of integrable XX models. Here we find that dark states are presentin XY models, but only for particular configurations of the central spinmagnetic field. We show this via an explicit construction of the Bethe states.",Jaco van Tonder,2025-02-07,2025-02-07,,N/A,"['nlin.SI', 'math-ph', 'math.MP']"
2502.04649v1,End-to-End Learning Framework for Solving Non-Markovian Optimal Control,http://arxiv.org/abs/2502.04649v1,"Integer-order calculus often falls short in capturing the long-rangedependencies and memory effects found in many real-world processes. Fractionalcalculus addresses these gaps via fractional-order integrals and derivatives,but fractional-order dynamical systems pose substantial challenges in systemidentification and optimal control due to the lack of standard controlmethodologies. In this paper, we theoretically derive the optimal control via\textit{linear quadratic regulator} (LQR) for \textit{fractional-order lineartime-invariant }(FOLTI) systems and develop an end-to-end deep learningframework based on this theoretical foundation. Our approach establishes arigorous mathematical model, derives analytical solutions, and incorporatesdeep learning to achieve data-driven optimal control of FOLTI systems. Our keycontributions include: (i) proposing an innovative system identification methodcontrol strategy for FOLTI systems, (ii) developing the first end-to-enddata-driven learning framework, \textbf{F}ractional-\textbf{O}rder\textbf{L}earning for \textbf{O}ptimal \textbf{C}ontrol (FOLOC), that learnscontrol policies from observed trajectories, and (iii) deriving a theoreticalanalysis of sample complexity to quantify the number of samples required foraccurate optimal control in complex real-world problems. Experimental resultsindicate that our method accurately approximates fractional-order systembehaviors without relying on Gaussian noise assumptions, pointing to promisingavenues for advanced optimal control.",Xiaole Zhang,2025-02-07,2025-02-07,,N/A,"['cs.SY', 'cs.LG', 'math.OC']"
2502.04648v1,Toward Automated Potential Primary Asset Identification in Verilog Designs,http://arxiv.org/abs/2502.04648v1,"With greater design complexity, the challenge to anticipate and mitigatesecurity issues provides more responsibility for the designer. As hardwareprovides the foundation of a secure system, we need tools and techniques thatsupport engineers to improve trust and help them address security concerns.Knowing the security assets in a design is fundamental to downstream securityanalyses, such as threat modeling, weakness identification, and verification.This paper proposes an automated approach for the initial identification ofpotential security assets in a Verilog design. Taking inspiration from manualasset identification methodologies, we analyze open-source hardware designs inthree IP families and identify patterns and commonalities likely to indicatestructural assets. Through iterative refinement, we provide a potential set ofprimary security assets and thus help to reduce the manual search space.",Subroto Kumer Deb Nath,2025-02-07,2025-02-07,,N/A,['cs.CR']
2502.04646v1,Importance Sampling via Score-based Generative Models,http://arxiv.org/abs/2502.04646v1,"Importance sampling, which involves sampling from a probability densityfunction (PDF) proportional to the product of an importance weight function anda base PDF, is a powerful technique with applications in variance reduction,biased or customized sampling, data augmentation, and beyond. Inspired by thegrowing availability of score-based generative models (SGMs), we propose anentirely training-free Importance sampling framework that relies solely on anSGM for the base PDF. Our key innovation is realizing the importance samplingprocess as a backward diffusion process, expressed in terms of the scorefunction of the base PDF and the specified importance weight function--bothreadily available--eliminating the need for any additional training. We conducta thorough analysis demonstrating the method's scalability and effectivenessacross diverse datasets and tasks, including importance sampling for industrialand natural images with neural importance weight functions. The training-freeaspect of our method is particularly compelling in real-world scenarios where asingle base distribution underlies multiple biased sampling tasks, eachrequiring a different importance weight function. To the best of our knowledgeour approach is the first importance sampling framework to achieve this.",Heasung Kim,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', '68T01', 'I.2.0']"
2502.04645v1,Cross-Encoder Rediscovers a Semantic Variant of BM25,http://arxiv.org/abs/2502.04645v1,"Neural Ranking Models (NRMs) have rapidly advanced state-of-the-artperformance on information retrieval tasks. In this work, we investigate aCross-Encoder variant of MiniLM to determine which relevance features itcomputes and where they are stored. We find that it employs a semantic variantof the traditional BM25 in an interpretable manner, featuring localizedcomponents: (1) Transformer attention heads that compute soft term frequencywhile controlling for term saturation and document length effects, and (2) alow-rank component of its embedding matrix that encodes inverse documentfrequency information for the vocabulary. This suggests that the Cross-Encoderuses the same fundamental mechanisms as BM25, but further leverages theircapacity to capture semantics for improved retrieval performance. The granularunderstanding lays the groundwork for model editing to enhance modeltransparency, addressing safety concerns, and improving scalability in trainingand real-world applications.",Meng Lu,2025-02-07,2025-02-07,,N/A,"['cs.IR', 'cs.AI']"
2502.04644v1,Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research,http://arxiv.org/abs/2502.04644v1,"We introduce Agentic Reasoning, a framework that enhances large languagemodel (LLM) reasoning by integrating external tool-using agents. Unlikeconventional LLM-based reasoning approaches, which rely solely on internalinference, Agentic Reasoning dynamically engages web search, code execution,and structured reasoning-context memory to solve complex problems requiringdeep research and multi-step logical deduction. Our framework introduces theMind Map agent, which constructs a structured knowledge graph to track logicalrelationships, improving deductive reasoning. Additionally, the integration ofweb-search and coding agents enables real-time retrieval and computationalanalysis, enhancing reasoning accuracy and decision-making. Evaluations onPhD-level scientific reasoning (GPQA) and domain-specific deep research tasksdemonstrate that our approach significantly outperforms existing models,including leading retrieval-augmented generation (RAG) systems andclosed-source LLMs. Moreover, our results indicate that agentic reasoningimproves expert-level knowledge synthesis, test-time scalability, andstructured problem-solving. The code is at:https://github.com/theworldofagents/Agentic-Reasoning.",Junde Wu,2025-02-07,2025-02-07,,N/A,"['cs.AI', 'cs.CL']"
2502.04643v1,Confidence Elicitation: A New Attack Vector for Large Language Models,http://arxiv.org/abs/2502.04643v1,"A fundamental issue in deep learning has been adversarial robustness. Asthese systems have scaled, such issues have persisted. Currently, largelanguage models (LLMs) with billions of parameters suffer from adversarialattacks just like their earlier, smaller counterparts. However, the threatmodels have changed. Previously, having gray-box access, where input embeddingsor output logits/probabilities were visible to the user, might have beenreasonable. However, with the introduction of closed-source models, noinformation about the model is available apart from the generated output. Thismeans that current black-box attacks can only utilize the final prediction todetect if an attack is successful. In this work, we investigate and demonstratethe potential of attack guidance, akin to using output probabilities, whilehaving only black-box access in a classification setting. This is achievedthrough the ability to elicit confidence from the model. We empirically showthat the elicited confidence is calibrated and not hallucinated for currentLLMs. By minimizing the elicited confidence, we can therefore increase thelikelihood of misclassification. Our new proposed paradigm demonstratespromising state-of-the-art results on three datasets across two models(LLaMA-3-8B-Instruct and Mistral-7B-Instruct-V0.3) when comparing our techniqueto existing hard-label black-box attack methods that introduce word-levelsubstitutions.",Brian Formento,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.CL', 'cs.CR']"
2502.04642v1,Dynamic Incentive Selection for Hierarchical Convex Model Predictive Control,http://arxiv.org/abs/2502.04642v1,"In this paper, we discuss incentive design for hierarchical model predictivecontrol (MPC) systems viewed as Stackelberg games. We consider a hierarchicalMPC formulation where, given a lower-level convex MPC (LoMPC), the upper-levelsystem solves a bilevel MPC (BiMPC) subject to the constraint that thelower-level system inputs are optimal for the LoMPC. Such hierarchical problemsare challenging due to optimality constraints in the BiMPC formulation. Weanalyze an incentive Stackelberg game variation of the problem, where the BiMPCprovides additional incentives for the LoMPC cost function, which grants theBiMPC influence over the LoMPC inputs. We show that for such problems, theBiMPC can be reformulated as a simpler optimization problem, and the optimalincentives can be iteratively computed without knowing the LoMPC cost function.We extend our formulation for the case of multiple LoMPCs and propose analgorithm that finds bounded suboptimal solutions for the BiMPC. We demonstrateour algorithm for a dynamic price control example, where an independent systemoperator (ISO) sets the electricity prices for electric vehicle (EV) chargingwith the goal of minimizing a social cost and satisfying electricity generationconstraints. Notably, our method scales well to large EV population sizes.",Akshay Thirugnanam,2025-02-07,2025-02-07,,N/A,"['eess.SY', 'cs.SY', 'math.OC']"
2502.04636v1,An Empirical Study of Code Obfuscation Practices in the Google Play Store,http://arxiv.org/abs/2502.04636v1,"The Android ecosystem is vulnerable to issues such as app repackaging,counterfeiting, and piracy, threatening both developers and users. To mitigatethese risks, developers often employ code obfuscation techniques. However,while effective in protecting legitimate applications, obfuscation also hinderssecurity investigations as it is often exploited for malicious purposes. Assuch, it is important to understand code obfuscation practices in Android apps.In this paper, we analyze over 500,000 Android APKs from Google Play, spanningan eight-year period, to investigate the evolution and prevalence of codeobfuscation techniques. First, we propose a set of classifiers to detectobfuscated code, tools, and techniques and then conduct a longitudinal analysisto identify trends. Our results show a 13% increase in obfuscation from 2016 to2023, with ProGuard and Allatori as the most commonly used tools. We also showthat obfuscation is more prevalent in top-ranked apps and gaming genres such asCasino apps. To our knowledge, this is the first large-scale study ofobfuscation adoption in the Google Play Store, providing insights fordevelopers and security analysts.",Akila Niroshan,2025-02-07,2025-02-07,,N/A,"['cs.CR', 'cs.AI', 'cs.SE']"
2502.04634v1,Model dependence in SMEFT,http://arxiv.org/abs/2502.04634v1,"We point out that, although SMEFT is constructed to be model-independent,this holds only if complete sets of operators are used. SMEFT analyses thatfocus on subsets of operators are only semi-model-independent. They probeclasses of ultraviolet models, opening a window to the underlying new physics.This model dependence originates from the need to choose a weak basis, usuallytaken to be the down or up basis. This naturally leads to the introduction of athird SMEFT weak basis, the generic basis, which interpolates between the abovetwo bases. Due to its generality, we argue that the generic weak basis is themost natural for new physics. In the down and up weak bases, only a specificproduct of the two transformation matrices from the weak to the mass basis isobservable -- the CKM matrix. However, in the generic weak basis, bothtransformation matrices are measurable in principle, possibly up to somephases.",Alakabha Datta,2025-02-07,2025-02-07,,N/A,['hep-ph']
2502.04633v1,Self-limiting states of polar misfits: Frustrated assembly of warped-jigsaw particles,http://arxiv.org/abs/2502.04633v1,"We study the ground state thermodynamics of a model class of geometricallyfrustrated assemblies, known as {\it warped-jigsaw} particles. While it isknown that frustration in soft matter assemblies has the ability to propagateup to mesoscopic, multi-particle size scales, notably through the selection ofself-limiting domain, little is understood about how the symmetry ofshape-misfit at the particle scale influences emergent morphologies at themesoscale. Here we show that polarity in the shape-misfit of warped-jigsawpuzzles manifests at a larger scale in the morphology and thermodynamics of theground-state assembly of self-limiting domains. We use a combination ofcontinuum theory and discrete particle simulations to show that the polarmisfit gives rise to two mesoscopically distinct polar, self-limiting ribbondomains. Thermodynamic selection between the two ribbon morphologies iscontrolled by a combination of the binding anisotropy along distinct neighbordirections and the orientation of polar shape-misfit. These predictions arevaluable as design features for ongoing efforts to program self-limitingassemblies through the synthesis of intentionally frustrated particles, andfurther suggests a generic classification of frustrated assembly behavior interms of the relative symmetries of shape-misfit and the underlying long-rangeinter-particle order it frustrates.",Michael Wang,2025-02-07,2025-02-07,,N/A,"['cond-mat.soft', 'cond-mat.mtrl-sci']"
2502.04632v1,"Tight Bounds for Noisy Computation of High-Influence Functions, Connectivity, and Threshold",http://arxiv.org/abs/2502.04632v1,"In the noisy query model, the (binary) return value of every query (possiblyrepeated) is independently flipped with some fixed probability $p \in (0,1/2)$. In this paper, we obtain tight bounds on the noisy query complexity ofseveral fundamental problems.  Our first contribution is to show that any Boolean function with totalinfluence $\Omega(n)$ has noisy query complexity $\Theta(n\log n)$. Previousworks often focus on specific problems, and it is of great interest to have acharacterization of noisy query complexity for general functions. Our result isthe first noisy query complexity lower bound of this generality, beyond whatwas known for random Boolean functions [Reischuk and Schmeltz, FOCS 1991].  Our second contribution is to prove that Graph Connectivity has noisy querycomplexity $\Theta(n^2 \log n)$. In this problem, the goal is to determinewhether an undirected graph is connected using noisy edge queries. While theupper bound can be achieved by a simple algorithm, no non-trivial lower boundswere known prior to this work.  Last but not least, we determine the exact number of noisy queries (up tolower order terms) needed to solve the $k$-Threshold problem and the Countingproblem. The $k$-Threshold problem asks to decide whether there are at least$k$ ones among $n$ bits, given noisy query access to the bits. We prove that$(1\pm o(1)) \frac{n\log (\min\{k,n-k+1\}/\delta)}{(1-2p)\log \frac{1-p}p}$queries are both sufficient and necessary to achieve error probability $\delta= o(1)$. Previously, such a result was only known when $\min\{k,n-k+1\}=o(n)$[Wang, Ghaddar, Zhu and Wang, arXiv 2024]. We also show a similar $(1\pm o(1))\frac{n\log (\min\{k+1,n-k+1\}/\delta)}{(1-2p)\log \frac{1-p}p}$ bound for theCounting problem, where one needs to count the number of ones among $n$ bitsgiven noisy query access and $k$ denotes the answer.",Yuzhou Gu,2025-02-07,2025-02-07,,N/A,"['cs.DS', 'cs.CC', 'cs.IT', 'math.IT']"
2502.04631v1,The Conundrum of Diffuse Basis Sets: A Blessing for Accuracy yet a Curse for Sparsity,http://arxiv.org/abs/2502.04631v1,"Diffuse atomic orbital basis sets have proven to be essential to obtainaccurate interaction energies, especially in regard to non-covalentinteractions. However, they also have a detrimental impact on the sparsity ofthe one-particle density matrix (1-PDM), to a degree stronger than the spatialextent of the basis functions alone could explain. This is despite the factthat the matrix elements of the 1-PDM of insulators (systems with significantHOMO-LUMO gaps) are expected to decay exponentially with increasing real-spacedistance from the diagonal and the asymptotic decay rate is expected to have awell-defined basis set limit. The observed low sparsity of the 1-PDM appears tobe independent of representation and even persists after projecting the 1-PDMonto a real-space grid, leading to the conclusion that this ""curse of sparsity""is solely a basis set artifact, which, counterintuitively, becomes worse forlarger basis sets, seemingly contradicting the notion of a well-defined basisset limit. We show that this is a consequence of the low locality of thecontra-variant basis functions as quantified by the inverse overlap matrix$\mathbf{S}^{-1}$ being significantly less sparse than its covariant dual.Introducing the model system of an infinite non-interacting chain of heliumatoms, we are able to quantify the exponential decay rate to be proportional tothe diffuseness as well as local incompleteness of the basis set, meaning smalland diffuse basis sets are affected the most. Finally, we propose one solutionto the conundrum in the form of the complementary auxiliary basis set (CABS)singles correction in combination with compact, low l-quantum-number basissets, showing promising results for non-covalent interactions.",Henryk Laqua,2025-02-07,2025-02-07,,N/A,['physics.chem-ph']
2502.04626v1,The Gas-to-Dust Ratio Investigation in the Massive Star-Forming region M17,http://arxiv.org/abs/2502.04626v1,"M17 is a well-known massive star-forming region, and its Gas-to-Dust Ratio(GDR) may vary significantly compared to the other areas. The mass of gas canbe traced by the ${\rm CO}$ emission observed in the \emph{Milky Way ImagingScroll Painting (MWISP) project}. The dust mass can be traced by analyzing theinterstellar extinction magnitude obtained from the \emph{United KingdomInfrared Telescope (UKIRT)}. We computed the ratio ${W({\rm CO})/A_V}$: for${A_V \le }$ 10 mag, ${{ W(^{12}{\rm CO})/ A_V}= (6.27 \pm 0.19)}$ ${\mathrm{{K\cdot km/s} \cdot mag^{-1}}}$ and ${{ W(^{13}{\rm CO})/ A_V} = (0.75 \pm0.72)}$ ${ \mathrm{{K \cdot km/s} \cdot mag^{-1}}}$; whereas for ${{A_V} \ge10}$ mag, ${{ W(^{12}{\rm CO})/ A_V} = (15.8 \pm 0.06) }$ ${\mathrm{{K \cdotkm/s} \cdot mag^{-1}}}$ and ${{ W(^{13}{\rm CO})/ A_V} = (3.11 \pm 0.25)}$ ${\mathrm{{K \cdot km/s} \cdot mag^{-1}}}$. Then, we converted the ${W({\rmCO})/A_V}$ into ${N(\rm H)/A_V}$. Using the WD01 model, we derived the GDR: for${A_V \le }$ 10 mag, the GDRs were ${118 \pm 9}$ for ${^{12}{\rm CO}}$ and ${83\pm 62}$ for ${^{13}{\rm CO}}$, comparable to those of the Milky Way; however,for ${A_V \ge }$ 10 mag, the GDRs increased significantly to ${296 \pm 3}$ for${^{12}{\rm CO}}$ and ${387 \pm 40}$ for ${^{13}{\rm CO}}$, approximately threetimes higher than those of the Milky Way. In the discussion, we compared theresults of this work with previous studies and provided a detailed discussionof the influence of massive stars and other factors on GDR.",Qi Zhao,2025-02-07,2025-02-07,,N/A,"['astro-ph.GA', 'astro-ph.SR']"
2502.04625v1,Phonetic Reconstruction of the Consonant System of Middle Chinese via Mixed Integer Optimization,http://arxiv.org/abs/2502.04625v1,"This paper is concerned with phonetic reconstruction of the consonant systemof Middle Chinese. We propose to cast the problem as a Mixed IntegerProgramming problem, which is able to automatically explore homophonicinformation from ancient rhyme dictionaries and phonetic information frommodern Chinese dialects, the descendants of Middle Chinese. Numericalevaluation on a wide range of synthetic and real data demonstrates theeffectiveness and robustness of the new method. We apply the method toinformation from Guangyun and 20 modern Chinese dialects to obtain a newphonetic reconstruction result. A linguistically-motivated discussion of thisresult is also provided.",Weiwei Sun,2025-02-07,2025-02-07,,N/A,['cs.CL']
2502.04623v1,HetSSNet: Spatial-Spectral Heterogeneous Graph Learning Network for Panchromatic and Multispectral Images Fusion,http://arxiv.org/abs/2502.04623v1,"Remote sensing pansharpening aims to reconstruct spatial-spectral propertiesduring the fusion of panchromatic (PAN) images and low-resolutionmulti-spectral (LR-MS) images, finally generating the high-resolutionmulti-spectral (HR-MS) images. In the mainstream modeling strategies, i.e., CNNand Transformer, the input images are treated as the equal-sized grid of pixelsin the Euclidean space. They have limitations in facing remote sensing imageswith irregular ground objects. Graph is the more flexible structure, however,there are two major challenges when modeling spatial-spectral properties withgraph: \emph{1) constructing the customized graph structure forspatial-spectral relationship priors}; \emph{2) learning the unifiedspatial-spectral representation through the graph}. To address thesechallenges, we propose the spatial-spectral heterogeneous graph learningnetwork, named \textbf{HetSSNet}. Specifically, HetSSNet initially constructsthe heterogeneous graph structure for pansharpening, which explicitly describespansharpening-specific relationships. Subsequently, the basic relationshippattern generation module is designed to extract the multiple relationshippatterns from the heterogeneous graph. Finally, relationship patternaggregation module is exploited to collaboratively learn unifiedspatial-spectral representation across different relationships among nodes withadaptive importance learning from local and global perspectives. Extensiveexperiments demonstrate the significant superiority and generalization ofHetSSNet.",Mengting Ma,2025-02-07,2025-02-07,,N/A,['cs.CV']
2502.04622v1,Laser-driven Ultrafast Dynamics of a Fractional Quantum Hall System,http://arxiv.org/abs/2502.04622v1,"Fractional quantum Hall (FQH) systems are strongly interacting electronsystems with topological order. These systems are characterized by novel groundstates, fractionally charged and neutral excitations. The neutral excitationsare dominated by a low-energy collective magnetoroton mode. Here we derive anduse a quasi-one-dimensional model to investigate the ultrafast nonequilibriumdynamics of a laser-driven FQH system within a two-Landau-level approximation.As opposed to the traditional and synthetic bilayers, our model accounts forinteractions where electrons can scatter from one Landau-level to another. Byperforming exact time evolution of the system, we create an out-of-equilibriumstate following the laser pulse that shows rich physics. Our calculations showthe presence of non-trivial excited modes. One of these modes iselectromagnetically active and represent density oscillations of\emph{magnetoplasmon} mode. Another mode is identified by evaluating theoverlap of the initial state and the out-of-equilibrium state following thelaser pulse with a quadrupole operator. This mode is analogous to thechiral-graviton mode for FQH systems recently measured in experiments [Nature{\bf 628}, 78 (2024)]. Our results show that a linearly-polarized pulse fieldcan excite the graviton mode when inter-Landau level scattering occurs.",Ammar Kirmani,2025-02-07,2025-02-07,,N/A,"['cond-mat.mes-hall', 'cond-mat.str-el']"
2502.04620v1,Fast-forwardability of Jordan-Wigner-transformed Fermion models based on Cartan decomposition,http://arxiv.org/abs/2502.04620v1,"We study the Hamiltonian algebra of Jordan-Wigner-transformed interactingfermion models and its fast-forwardability. We prove that the dimension of theHamiltonian algebra of the fermion model with single-site Coulomb interactionis bounded from below by the exponential function of the number of sites, andthe circuit depth of the Cartan-based fast-forwarding method for such modelalso exhibits the same scaling. We apply this proposition to the Andersonimpurity model and the Hubbard model and show that the dimension of theHamiltonian algebra of these models scales exponentially with the number ofsites. These behaviors of the Hamiltonian algebras imply that the qubit modelsobtained by the Jordan-Wigner transformation of these fermion models cannot beefficiently simulated using the Cartan-based fast-forwarding method.",Yuichiro Hidaka,2025-02-07,2025-02-07,,N/A,['quant-ph']
2502.04617v1,Effects of Curved Superconducting Magnets on Beam Stability in a Compact Ion Therapy Synchrotron,http://arxiv.org/abs/2502.04617v1,"Superconducting, curved magnets can reduce accelerator footprints byproducing strong fields (>3T) and reducing the total number of magnets throughtheir capability for combined-function multipolar fields, making them anattractive choice for applications such as heavy ion therapy. There exists theproblem that the effect of strongly curved harmonics and fringe fields oncompact accelerator beam dynamics is not well represented: existing approachesuse integrated cylindrical multipoles to describe and model the fields for beamdynamics studies, which are invalid in curved coordinate systems and assumeindividual errors cancel out over the full machine. In the modelling of thesemachines, the effect of strongly curved harmonics and fringe fields on compactaccelerator beam dynamics needs to properly included. An alternative approachmust be introduced for capturing off-axis fields in a strongly curved magnet,which may affect long-term beam stability in a compact accelerator. In thisarticle, we investigate the impacts of deploying a curved canted-cosine-theta(CCT) superconducting magnet in a compact medical synchrotron for the firsttime. We develop a method to analyse and characterise the 3D curved fields ofan electromagnetic model of a CCT developed for the main bending magnets of a27m circumference carbon ion therapy synchrotron, designed within the Heavy IonTherapy Research Integration Plus European project, and the CERN Next IonMedical Machine Study (NIMMS). The fields are modelled in the compactsynchrotron in MAD-X/PTC to study their effects on beam dynamics and long-termbeam stability. The insights gained through the methods presented allow for theoptimisation of both magnet and synchrotron designs, with the potential toimpact the operational performance of future ion therapy facilities.",Hannah X. Q. Norman,2025-02-07,2025-02-07,,N/A,['physics.acc-ph']
2502.04614v1,A-priori estimates for generalized Korteweg-de Vries equations in $H^{-1}(\mathbb{R})$,http://arxiv.org/abs/2502.04614v1,"We prove local-in-time a-priori estimates in $H^{-1}(\mathbb{R})$ for afamily of generalized Korteweg--de Vries equations. This is the first estimatefor any non-integrable perturbation of the KdV equation that matches theregularity of the sharp well-posedness theory for KdV. In particular, we showthat our analysis applies to models for long waves in a shallow channel ofwater with an uneven bottom.  The proof of our main result is based upon a bootstrap argument for therenormalized perturbation determinant coupled with a local smoothing norm.",Mihaela Ifrim,2025-02-07,2025-02-07,,N/A,"['math.AP', '35Q53']"
2502.04613v1,A Bregman ADMM for Bethe variational problem,http://arxiv.org/abs/2502.04613v1,"In this work, we propose a novel Bregman ADMM with nonlinear dual update tosolve the Bethe variational problem (BVP), a key optimization formulation ingraphical models and statistical physics. Our algorithm provides rigorousconvergence guarantees, even if the objective function of BVP is non-convex andnon-Lipschitz continuous on the boundary. A central result of our analysis isproving that the entries in local minima of BVP are strictly positive,effectively resolving non-smoothness issues caused by zero entries. Beyondtheoretical guarantees, the algorithm possesses high level of separability andparallelizability to achieve highly efficient subproblem computation. OurBregman ADMM can be easily extended to solve quantum Bethe variational problem.Numerical experiments are conducted to validate the effectiveness androbustness of the proposed method. Based on this research, we have released anopen-source package of the proposed method athttps://github.com/TTYmath/BADMM-BVP.",Yuehaw Khoo,2025-02-07,2025-02-07,,N/A,"['math.OC', '65K10, 90C30, 90C35']"
2502.04612v1,Blinking optical tweezers for atom rearrangements,http://arxiv.org/abs/2502.04612v1,"We propose and experimentally demonstrate an energy-efficient approach forholding and rearranging an N x M atom array using only N optical tweezers. Thisis achieved through the sequential release and recapture of M single atoms by asingle optical tweezer. By employing a stroboscopic harmonic potential, thephase-space quadrature of the atom's probability distribution can be maintainedunder this ""blinking"" potential, provided the trap frequency meets theappropriate conditions. Proof-of-principle experiments confirm that a blinkingtweezer can trap M atoms while requiring only 1 / M of the power per atom, andit can even facilitate rearrangement, demonstrated with arrays of up to M = 9atoms. This method offers a scalable and reconfigurable platform for opticaltweezer arrays, crucial for the preparation and manipulation of large-scalequbit systems.",Kangjin Kim,2025-02-07,2025-02-07,,N/A,"['quant-ph', 'physics.atom-ph', 'physics.optics']"
2502.04611v1,Investigating the effects of QCD matter's electrical conductivity on charge dependent directed flow,http://arxiv.org/abs/2502.04611v1,"Charge dependent directed flow is an important observable of electromagneticfields in relativistic heavy-ion collisions. We demonstrate how the differencein charge dependent directed flows between protons and antiprotons is sensitiveto the resistivity, inverse of quark-gluon plasma's electric conductivity, overdifferent collision centralities. Our model numerically solves the 3+1Drelativistic resistive magneto-hydrodynamic (RRMHD) equations, assuming theelectric conductivity to be a scalar. For this work, we focus on symmetric Au +Au collisions at the top RHIC energy of $\sqrt{s}=200$ GeV. We illustrate thetime evolution of the electromagnetic fields in our model and connect that tothe charge dependent directed flow results. Our results highlight theimportance of modeling quark-gluon plasma's electric conductivity for chargedependent observables in relativistic heavy-ion collisions.",Nicholas J. Benoit,2025-02-07,2025-02-07,,N/A,"['nucl-th', 'hep-ex', 'hep-ph', 'nucl-ex']"
2502.04609v1,"Force interaction, modeling and soft tissue deformation during reciprocating insertion of multi-part probe",http://arxiv.org/abs/2502.04609v1,"The bio-inspired engineering of ovipositing wasps, which employ areciprocating motion for soft tissue insertion, offers potential advantages inreducing insertion force and minimizing tissue damage. However, the underlyingmechanisms of tissue interaction and sparing are not fully understood. In thisstudy, we aim to investigate a multi-part probe designed to mimic thereciprocating motion of ovipositors. A reciprocal insertion model was developedto study the interaction between the probe and soft tissue, and experimentaltesting was conducted using a force sensor and laser optical technique to gaininsights into interacting forces and tissue deformation. The results revealthat during the cutting phase of reciprocal motion, the peak force and averagedisplacement of the soft substrate were approximately 19% and 20% lower,respectively, compared to direct insertion at an overall probe velocity of 1mm/s. This study presents a novel approach combining mechanical modeling andexperimental analysis to explore the force mechanics of the reciprocatinginsertion method, providing a better understanding of the interaction betweenthe probe and soft tissue.",Tassanai Parittotokkaporn,2025-02-07,2025-02-07,,N/A,"['cs.RO', 'cs.SY', 'eess.SY']"
2502.04606v1,An Airy Tale at Large $N$,http://arxiv.org/abs/2502.04606v1,"We study the sphere partition function of 3d $\mathcal{N}=2$ holographicSCFTs arising on the worldvolume of $N$ coincident M2-branes in the presence ofsquashing and real mass deformations. We argue that the all-order large $N$perturbative expansion of the partition function resums into a compactexpression in terms of an Airy function. We provide ample evidence for thisconjecture using numerical methods, saddle point analysis in the 't Hooftlimit, and the relation of the squashed sphere partition function to theCardy-like limit of the superconformal index. We also discuss the relation ofour results to topological string theory and the statistical mechanics of Fermigases. Our conjecture has a bearing on the AdS/CFT correspondence and thestructure of perturbative M-theory corrections to 11d supergravity which wediscuss.",Nikolay Bobev,2025-02-07,2025-02-07,,N/A,['hep-th']
2502.04604v1,Contrastive Learning-Enhanced Large Language Models for Monolith-to-Microservice Decomposition,http://arxiv.org/abs/2502.04604v1,"As Monolithic applications evolve, they become increasingly difficult tomaintain and improve, leading to scaling and organizational issues. TheMicroservices architecture, known for its modularity, flexibility andscalability, offers a solution for large-scale applications allowing them toadapt and meet the demand on an ever increasing user base. Despite itsadvantages, migrating from a monolithic to a microservices architecture isoften costly and complex, with the decomposition step being a significantchallenge. This research addresses this issue by introducing MonoEmbed, aLanguage Model based approach for automating the decomposition process.MonoEmbed leverages state-of-the-art Large Language Models (LLMs) andrepresentation learning techniques to generate representation vectors formonolithic components, which are then clustered to form microservices. Byevaluating various pre-trained models and applying fine-tuning techniques suchas Contrastive Learning and Low Rank Adaptation (LoRA), MonoEmbed aims tooptimize these representations for microservice partitioning. The evaluation ofthe fine-tuned models showcases that they were able to significantly improvethe quality of the representation vectors when compared with pre-trained modelsand traditional representations. The proposed approach was benchmarked againstexisting decomposition methods, demonstrating superior performance ingenerating cohesive and balanced microservices for monolithic applications withvarying scales.",Khaled Sellami,2025-02-07,2025-02-07,,N/A,"['cs.SE', 'D.2.11; I.2.7; I.2.2']"
2502.04603v1,Fundamental Factors Governing Stabilization of Janus 2D-Bulk Heterostructures with Machine Learning,http://arxiv.org/abs/2502.04603v1,"The more-than-6000 2D materials predicted thus far provide a hugecombinatorial space for forming functional heterostructures with bulkmaterials, with potential applications in nanoelectronics, sensing, and energyconversion. In this work, we investigate nearly 1000 heterostructures, thelargest number of heterostructures thus far, of 2D Janus and bulk materials'surfaces using ab initio simulations and machine learning (ML) to deduce thestructure-property relationships of the complex interfaces in suchheterostructures. We first perform van der Waals-corrected density functionaltheory simulations using a high-throughput computational framework on 51 Janus2D materials and 19 metallic, cubic phase, elemental bulk materials thatexhibit low lattice mismatches and low coincident site lattices. The formationenergy of the resultant 1147 Janus 2D-bulk heterostructures were analyzed and828 were found to be thermodynamically stable. ML models were trained on thecomputed data, and we found that they could predict the binding energy and$z$-separation of 2D-bulk heterostructures with root mean squared errors (RMSE)of 0.05 eV/atom and 0.14 angstroms, respectively. The feature importance of themodels reveals that the properties of the bulk materials dominate theheterostructures' energies and interfacial structures heavily. These findingsare in-line with experimentally observed behavior of several well-known 2Dmaterials-bulk systems. The data used within this paper is freely available inthe Ab Initio 2D-Bulk Heterostructure Database (aiHD). The fundamental insightson 2D-bulk heterostructures and the predictive ML models developed in this workcould accelerate the application of thousands of 2D-bulk heterostructures, thusstimulating research within a wide range of electronic, quantum computing,sensing, and energy applications.",Tara M. Boland,2025-02-07,2025-02-07,,N/A,"['cond-mat.mtrl-sci', 'cond-mat.mes-hall']"
2502.04602v1,Extracting and Understanding the Superficial Knowledge in Alignment,http://arxiv.org/abs/2502.04602v1,"Alignment of large language models (LLMs) with human values and preferences,often achieved through fine-tuning based on human feedback, is essential forensuring safe and responsible AI behaviors. However, the process typicallyrequires substantial data and computation resources. Recent studies haverevealed that alignment might be attainable at lower costs through simplermethods, such as in-context learning. This leads to the question: Is alignmentpredominantly superficial? In this paper, we delve into this question andprovide a quantitative analysis. We formalize the concept of superficialknowledge, defining it as knowledge that can be acquired through easily tokenrestyling, without affecting the model's ability to capture underlying causalrelationships between tokens. We propose a method to extract and isolatesuperficial knowledge from aligned models, focusing on the shallowmodifications to the final token selection process. By comparing modelsaugmented only with superficial knowledge to fully aligned models, we quantifythe superficial portion of alignment. Our findings reveal that whilesuperficial knowledge constitutes a significant portion of alignment,particularly in safety and detoxification tasks, it is not the whole story.Tasks requiring reasoning and contextual understanding still rely on deeperknowledge. Additionally, we demonstrate two practical advantages of isolatedsuperficial knowledge: (1) it can be transferred between models, enablingefficient offsite alignment of larger models using extracted superficialknowledge from smaller models, and (2) it is recoverable, allowing for therestoration of alignment in compromised models without sacrificing performance.",Runjin Chen,2025-02-07,2025-02-07,,N/A,"['cs.CL', 'cs.AI']"
2502.04599v1,Fuzzy Linkography: Automatic Graphical Summarization of Creative Activity Traces,http://arxiv.org/abs/2502.04599v1,"Linkography -- the analysis of links between the design moves that make up anepisode of creative ideation or design -- can be used for both visual andquantitative assessment of creative activity traces. Traditional linkography,however, is time-consuming, requiring a human coder to manually annotate boththe design moves within an episode and the connections between them. As aresult, linkography has not yet been much applied at scale. To address thislimitation, we introduce fuzzy linkography: a means of automaticallyconstructing a linkograph from a sequence of recorded design moves via a""fuzzy"" computational model of semantic similarity, enabling wider deploymentand new applications of linkographic techniques. We apply fuzzy linkography tothree markedly different kinds of creative activity traces (text-to-imageprompting journeys, LLM-supported ideation sessions, and researcher publicationhistories) and discuss our findings, as well as strengths, limitations, andpotential future applications of our approach.",Amy Smith,2025-02-07,2025-02-07,,N/A,['cs.HC']
2502.04593v1,The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance,http://arxiv.org/abs/2502.04593v1,"Current state-of-the-art dynamical models, such as Mamba, assume the samelevel of noisiness for all elements of a given sequence, which limits theirperformance on noisy temporal data. In this paper, we introduce the$\alpha$-Alternator, a novel generative model for time-dependent data thatdynamically adapts to the complexity introduced by varying noise levels insequences. The $\alpha$-Alternator leverages the Vendi Score (VS), a flexiblesimilarity-based diversity metric, to adjust, at each time step $t$, theinfluence of the sequence element at time $t$ and the latent representation ofthe dynamics up to that time step on the predicted future dynamics. Thisinfluence is captured by a parameter that is learned and shared across allsequences in a given dataset. The sign of this parameter determines thedirection of influence. A negative value indicates a noisy dataset, where asequence element that increases the VS is considered noisy, and the modelrelies more on the latent history when processing that element. Conversely,when the parameter is positive, a sequence element that increases the VS isconsidered informative, and the $\alpha$-Alternator relies more on this newinput than on the latent history when updating its predicted latent dynamics.The $\alpha$-Alternator is trained using a combination of observation maskingand Alternator loss minimization. Masking simulates varying noise levels insequences, enabling the model to be more robust to these fluctuations andimproving its performance in trajectory prediction, imputation, andforecasting. Our experimental results demonstrate that the $\alpha$-Alternatoroutperforms both Alternators and state-of-the-art state-space models acrossneural decoding and time-series forecasting benchmarks.",Mohammad Reza Rezaei,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']"
2502.04592v1,CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements,http://arxiv.org/abs/2502.04592v1,"Accurately forecasting the impact of macroeconomic events is critical forinvestors and policymakers. Salient events like monetary policy decisions andemployment reports often trigger market movements by shaping expectations ofeconomic growth and risk, thereby establishing causal relationships betweenevents and market behavior. Existing forecasting methods typically focus eitheron textual analysis or time-series modeling, but fail to capture themulti-modal nature of financial markets and the causal relationship betweenevents and price movements. To address these gaps, we propose CAMEF(Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), amulti-modality framework that effectively integrates textual and time-seriesdata with a causal learning mechanism and an LLM-based counterfactual eventaugmentation technique for causal-enhanced financial forecasting. Ourcontributions include: (1) a multi-modal framework that captures causalrelationships between policy texts and historical price data; (2) a newfinancial dataset with six types of macroeconomic releases from 2008 to April2024, and high-frequency real trading data for five key U.S. financial assets;and (3) an LLM-based counterfactual event augmentation strategy. We compareCAMEF to state-of-the-art transformer-based time-series and multi-modalbaselines, and perform ablation studies to validate the effectiveness of thecausal learning mechanism and event types.",Yang Zhang,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'cs.CE']"
2502.04591v1,Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective,http://arxiv.org/abs/2502.04591v1,"Oversmoothing is a fundamental challenge in graph neural networks (GNNs): asthe number of layers increases, node embeddings become increasingly similar,and model performance drops sharply. Traditionally, oversmoothing has beenquantified using metrics that measure the similarity of neighbouring nodefeatures, such as the Dirichlet energy. While these metrics are related tooversmoothing, we argue they have critical limitations and fail to reliablycapture oversmoothing in realistic scenarios. For instance, they providemeaningful insights only for very deep networks and under somewhat strictconditions on the norm of network weights and feature representations. As analternative, we propose measuring oversmoothing by examining the numerical oreffective rank of the feature representations. We provide theoretical supportfor this approach, demonstrating that the numerical rank of featurerepresentations converges to one for a broad family of nonlinear activationfunctions under the assumption of nonnegative trained weights. To the best ofour knowledge, this is the first result that proves the occurrence ofoversmoothing without assumptions on the boundedness of the weight matrices.Along with the theoretical findings, we provide extensive numerical evaluationacross diverse graph architectures. Our results show that rank-based metricsconsistently capture oversmoothing, whereas energy-based metrics often fail.Notably, we reveal that a significant drop in the rank aligns closely withperformance degradation, even in scenarios where energy metrics remainunchanged.",Piero Deidda,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI', 'stat.ML']"
2502.04589v1,PASE: A Massively Parallel Augmented Subspace Eigensolver for Large Scale Eigenvalue Problems,http://arxiv.org/abs/2502.04589v1,"In this paper, we present a novel parallel augmented subspace method andbuild a package Parallel Augmented Subspace Eigensolver (PASE) for solvinglarge scale eigenvalue problems by the massively parallel finite elementdiscretization. Based on the augmented subspace, solving high dimensionaleigenvalue problems can be transformed to solving the corresponding linearequations and low dimensional eigenvalue problems on the augmented subspace.Thus the complexity of solving the eigenvalue problems by augmented subspacemethod will be comparable to that of solving the same dimensinal linearequations. In order to improve the scalability and efficiency, we also presentsome implementing techniques for the parallel augmented subspace method. Basedon parallel augmented subspace method and the concerned implementingtechniques, a package PASE is built for solving large scale eigenvalueproblems. Some numerical examples are provided to validate the efficiency andscalability of the proposed numerical methods.",Yangfei Liao,2025-02-07,2025-02-07,,N/A,"['math.NA', 'cs.NA']"
2502.04588v1,The coalescent structure of multitype continuous-time Galton-Watson trees,http://arxiv.org/abs/2502.04588v1,"We investigate the genealogy of a sample of $k\geq1$ particles chosenuniformly without replacement from a population alive at large times in acritical continuous-time multitype Galton-Watson process with finite secondmoment. We will show that subject to a deterministic time-change, the samplegenealogy always converges to the same universal genealogical structure; it hasthe same tree topology as Kingman's coalescent, when the types are discarded,and the coalescent times of the $k-1$ pairwise mergers look like a mixture ofindependent identically distributed times. We show that such an ancestrallineage in the limit, strongly depends on the multitype offspring distribution,which differs from the single type case Harris, Johnston, and Roberts [Annalsof Applied Probability, 2020]. Our approach uses $k$ distinguished 'spine'particles and a suitable change of measure under which (a) the spines form auniform sample without replacement that depend on the colours but additionally(b) there is $k$-size biasing and discounting according to the population size.Our work substantially extends the spine techniques developed in Harris,Johnston, and Roberts [Annals of Applied Probability, 2020] for genealogies ofuniform samples of size $k$ in critical, continuous-time, single-typeGalton-Watson processes. We generalize these methods to the multi-type settingand provide a comprehensive analysis of how functionals of the spines areinfluenced by the types. While the single-type case exhibits a more homogeneousstructure with simpler dependency patterns, the multi-type case introducesinteractions between different types, leading to a more intricate dependencystructure where functionals must account for type-specific behaviours andinter-type relationships.",Osvaldo Angtuncio Hernández,2025-02-07,2025-02-07,,N/A,"['math.PR', '05C05, 60G51, 60F17, 60J80']"
2502.04586v1,Automatic Ply Partitioning for Laminar Composite Process Planning,http://arxiv.org/abs/2502.04586v1,"This work introduces an automated ply partitioning strategy for large-scalelaminar composite manufacturing. It specifically targets the problem offabricating large plies from available spooled materials, while minimizing theadverse effects on part quality. The proposed method inserts fiber-alignedseams sequentially until each resulting sub-ply can be manufactured fromavailable materials, while simultaneously enforcing constraints to avoidquality issues induced by the stacking of seams across multiple plies.Leveraging the developable nature of individual plies, the partitioning problemis cast as a sequence of one-dimensional piecewise linear optimizationproblems, thus allowing for efficient local optimization via linearprogramming. We experimentally demonstrate that coupling the local search witha greedy global search produces the same results as an exhaustive search. Theresulting automated method provides an efficient and robust alternative to theexisting trial-and-error approach, and can be readily integrated intostate-of-the-art composite design workflows. In addition, this formulationenables the inclusion of common constraints regarding laminate thicknesstolerance, sub-ply geometry, stay-out zones, material wastage, etc. Theefficacy of the proposed method is demonstrated through its application to thesurface of an airplane wing and to the body panels of an armored vehicle, eachsubject to various performance and manufacturing-related geometric constraints.",Eric Garner,2025-02-07,2025-02-07,,N/A,"['math.OC', 'cs.CE']"
2502.04585v1,"Intermittent, Reflection-Driven, Strong Imbalanced MHD Turbulence",http://arxiv.org/abs/2502.04585v1,"We develop a phenomenological model of strong imbalanced magnetohydrodynamic(MHD) turbulence that accounts for intermittency and the reflection of Alfvenwaves by spatial variations in the Alfven speed. Our model predicts the slopesof the inertial-range Elsasser power spectra, the scaling exponents of thehigher-order Elsasser structure functions, and the way in which the parallel(to the magnetic field) length scale of the fluctuations varies with theperpendicular length scale. These predictions agree reasonably well withmeasurements of solar-wind turbulence from the Parker Solar Probe (PSP). Incontrast to previous models of intermittency in balanced MHD turbulence, wefind that intermittency in reflection-driven MHD turbulence increases theparallel wave numbers of the energetically dominant fluctuations at smallperpendicular length scales. This, like the PSP measurements with which ourmodel agrees, suggests that turbulence in the solar wind and solar corona maylead to more ion cyclotron heating than previously realized.",B. D. G. Chandran,2025-02-07,2025-02-07,,N/A,"['physics.plasm-ph', 'astro-ph.SR', 'physics.space-ph']"
2502.04583v1,Overcoming Fake Solutions in Semi-Dual Neural Optimal Transport: A Smoothing Approach for Learning the Optimal Transport Plan,http://arxiv.org/abs/2502.04583v1,"We address the convergence problem in learning the Optimal Transport (OT)map, where the OT Map refers to a map from one distribution to another whileminimizing the transport cost. Semi-dual Neural OT, a widely used approach forlearning OT Maps with neural networks, often generates fake solutions that failto transfer one distribution to another accurately. We identify a sufficientcondition under which the max-min solution of Semi-dual Neural OT recovers thetrue OT Map. Moreover, to address cases when this sufficient condition is notsatisfied, we propose a novel method, OTP, which learns both the OT Map and theOptimal Transport Plan, representing the optimal coupling between twodistributions. Under sharp assumptions on the distributions, we prove that ourmodel eliminates the fake solution issue and correctly solves the OT problem.Our experiments show that the OTP model recovers the optimal transport mapwhere existing methods fail and outperforms current OT-based models inimage-to-image translation tasks. Notably, the OTP model can learn stochastictransport maps when deterministic OT Maps do not exist, such as one-to-manytasks like colorization.",Jaemoo Choi,2025-02-07,2025-02-07,,N/A,['cs.LG']
2502.04581v1,Completeness Theorems for k-SUM and Geometric Friends: Deciding Fragments of Integer Linear Arithmetic,http://arxiv.org/abs/2502.04581v1,"In the last three decades, the $k$-SUM hypothesis has emerged as a satisfyingexplanation of long-standing time barriers for a variety of algorithmicproblems. Yet to this day, the literature knows of only few proven consequencesof a refutation of this hypothesis. Taking a descriptive complexity viewpoint,we ask: What is the largest logically defined class of problems \emph{captured}by the $k$-SUM problem?  To this end, we introduce a class $\mathsf{FOP}_{\mathbb{Z}}$ of problemscorresponding to deciding sentences in Presburger arithmetic/linear integerarithmetic over finite subsets of integers.  We establish two large fragments for which the $k$-SUM problem is completeunder fine-grained reductions:  1. The $k$-SUM problem is complete for deciding the sentences with $k$existential quantifiers.  2. The $3$-SUM problem is complete for all $3$-quantifier sentences of$\mathsf{FOP}_{\mathbb{Z}}$ expressible using at most $3$ linear inequalities.  Specifically, a faster-than-$n^{\lceil k/2 \rceil \pm o(1)}$ algorithm for$k$-SUM (or faster-than-$n^{2 \pm o(1)}$ algorithm for $3$-SUM, respectively)directly translate to polynomial speedups of a general algorithm for \emph{all}sentences in the respective fragment.  Observing a barrier for proving completeness of $3$-SUM for the entire class$\mathsf{FOP}_{\mathbb{Z}}$, we turn to the question which other -- seeminglymore general -- problems are complete for $\mathsf{FOP}_{\mathbb{Z}}$. In thisdirection, we establish $\mathsf{FOP}_{\mathbb{Z}}$-completeness of the\emph{problem pair} of Pareto Sum Verification and Hausdorff Distance under $n$Translations under the $L_\infty$/$L_1$ norm in $\mathbb{Z}^d$. In particular,our results invite to investigate Pareto Sum Verification as a high-dimensionalgeneralization of 3-SUM.",Geri Gokaj,2025-02-07,2025-02-07,,N/A,"['cs.CC', 'cs.CG', 'cs.LO']"
2502.04580v1,Technical Debt in In-Context Learning: Diminishing Efficiency in Long Context,http://arxiv.org/abs/2502.04580v1,"Transformers have demonstrated remarkable in-context learning (ICL)capabilities, adapting to new tasks by simply conditioning on demonstrationswithout parameter updates. Compelling empirical and theoretical evidencesuggests that ICL, as a general-purpose learner, could outperform task-specificmodels. However, it remains unclear to what extent the transformers optimallylearn in-context compared to principled learning algorithms. To bridge thisgap, we introduce a new framework for quantifying optimality of ICL as alearning algorithm in stylized settings. Our findings reveal a strikingdichotomy: while ICL initially matches the efficiency of a Bayes optimalestimator, its efficiency significantly deteriorates in long context. Throughan information-theoretic analysis, we show that the diminishing efficiency isinherent to ICL. These results clarify the trade-offs in adopting ICL as auniversal problem solver, motivating a new generation of on-the-fly adaptivemethods without the diminishing efficiency.",Taejong Joo,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.AI']"
2502.04579v1,Flavor Constraints in a Generational Three Higgs Doublet Model,http://arxiv.org/abs/2502.04579v1,"We propose a Three Higgs Doublet Model (3HDM) that goes beyond natural flavorconservation and in which each of the three Higgs doublets couples mainly to asingle generation of fermions via non-standard Yukawa structures. A hierarchyin the vacuum expectation values of the three Higgs doublets can partiallyaddress the SM flavor puzzle. In light of the experimentally observed $125$ GeVHiggs boson, we primarily work within a 3HDM alignment limit such that aStandard Model-like Higgs is recovered. In order to reproduce the observed CKMmixing among quarks, the neutral Higgs bosons of the theory necessarily mediateflavor changing neutral currents at the tree level. We consider constraintsfrom neutral kaon, $B$ meson, and $D$ meson mixing as well as from the rareleptonic decays $B_s/B^0/K_L\rightarrow\mu^+\mu^-/e^+e^-$. We identify regionsof parameter space in which the new physics Higgs bosons can be as light as aTeV or even lighter.",Wolfgang Altmannshofer,2025-02-07,2025-02-07,,N/A,['hep-ph']
2502.04577v1,Position-aware Automatic Circuit Discovery,http://arxiv.org/abs/2502.04577v1,"A widely used strategy to discover and understand language model mechanismsis circuit analysis. A circuit is a minimal subgraph of a model's computationgraph that executes a specific task. We identify a gap in existing circuitdiscovery methods: they assume circuits are position-invariant, treating modelcomponents as equally relevant across input positions. This limits theirability to capture cross-positional interactions or mechanisms that vary acrosspositions. To address this gap, we propose two improvements to incorporatepositionality into circuits, even on tasks containing variable-length examples.First, we extend edge attribution patching, a gradient-based method for circuitdiscovery, to differentiate between token positions. Second, we introduce theconcept of a dataset schema, which defines token spans with similar semanticsacross examples, enabling position-aware circuit discovery in datasets withvariable length examples. We additionally develop an automated pipeline forschema generation and application using large language models. Our approachenables fully automated discovery of position-sensitive circuits, yieldingbetter trade-offs between circuit size and faithfulness compared to prior work.",Tal Haklay,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.CL', '68T50', 'I.2.7']"
2502.04576v1,Self-Regulation and Requesting Interventions,http://arxiv.org/abs/2502.04576v1,"Human intelligence involves metacognitive abilities like self-regulation,recognizing limitations, and seeking assistance only when needed. While LLMAgents excel in many domains, they often lack this awareness. Overconfidentagents risk catastrophic failures, while those that seek help excessivelyhinder efficiency. A key challenge is enabling agents with a limitedintervention budget $C$ is to decide when to request assistance. In this paper,we propose an offline framework that trains a ""helper"" policy to requestinterventions, such as more powerful models or test-time compute, by combiningLLM-based process reward models (PRMs) with tabular reinforcement learning.Using state transitions collected offline, we score optimal intervention timingwith PRMs and train the helper model on these labeled trajectories. Thisoffline approach significantly reduces costly intervention calls duringtraining. Furthermore, the integration of PRMs with tabular RL enhancesrobustness to off-policy data while avoiding the inefficiencies of deep RL. Weempirically find that our method delivers optimal helper behavior.",So Yeon Min,2025-02-07,2025-02-07,,N/A,"['cs.LG', 'cs.CL']"
2502.04575v1,Complexity Analysis of Normalizing Constant Estimation: from Jarzynski Equality to Annealed Importance Sampling and beyond,http://arxiv.org/abs/2502.04575v1,"Given an unnormalized probability density $\pi\propto\mathrm{e}^{-V}$,estimating its normalizing constant$Z=\int_{\mathbb{R}^d}\mathrm{e}^{-V(x)}\mathrm{d}x$ or free energy $F=-\log Z$is a crucial problem in Bayesian statistics, statistical mechanics, and machinelearning. It is challenging especially in high dimensions or when $\pi$ ismultimodal. To mitigate the high variance of conventional importance samplingestimators, annealing-based methods such as Jarzynski equality and annealedimportance sampling are commonly adopted, yet their quantitative complexityguarantees remain largely unexplored. We take a first step toward anon-asymptotic analysis of annealed importance sampling. In particular, wederive an oracle complexity of$\widetilde{O}\left(\frac{d\beta^2{\mathcal{A}}^2}{\varepsilon^4}\right)$ forestimating $Z$ within $\varepsilon$ relative error with high probability, where$\beta$ is the smoothness of $V$ and $\mathcal{A}$ denotes the action of acurve of probability measures interpolating $\pi$ and a tractable referencedistribution. Our analysis, leveraging Girsanov theorem and optimal transport,does not explicitly require isoperimetric assumptions on the targetdistribution. Finally, to tackle the large action of the widely used geometricinterpolation of probability distributions, we propose a new normalizingconstant estimation algorithm based on reverse diffusion samplers and establisha framework for analyzing its complexity.",Wei Guo,2025-02-07,2025-02-07,,N/A,"['stat.ML', 'cs.LG', 'cs.NA', 'math.NA', 'physics.comp-ph', 'stat.CO']"
2502.04574v1,Dark Brain Energy: Toward an Integrative Model of Spontaneous Slow Oscillations,http://arxiv.org/abs/2502.04574v1,"Neural oscillations facilitate the functioning of the human brain in spatialand temporal dimensions at various frequencies. These oscillations feature auniversal frequency architecture that is governed by brain anatomy, ensuringfrequency specificity remains invariant across different measurementtechniques. Initial magnetic resonance imaging (MRI) methodology constrainedfunctional MRI (fMRI) investigations to a singular frequency range, therebyneglecting the frequency characteristics inherent in blood oxygenlevel-dependent oscillations. With advancements in MRI technology, it hasbecome feasible to decode intricate brain activities via multi-band frequencyanalysis (MBFA). During the past decade, the utilization of MBFA in fMRIstudies has surged, unveiling frequency-dependent characteristics ofspontaneous slow oscillations (SSOs) believed to base dark energy in the brain.There remains a dearth of conclusive insights and hypotheses pertaining to theproperties and functionalities of SSOs in distinct bands. We surveyed the SSOMBFA studies during the past 15 years to delineate the attributes of SSOs andenlighten their correlated functions. We further proposed a model to elucidatethe hierarchical organization of multi-band SSOs by integrating their function,aimed at bridging theoretical gaps and guiding future MBFA research endeavors.",ZhuQing Gong,2025-02-06,2025-02-06,,N/A,"['q-bio.NC', 'cs.IT', 'math.IT', 'stat.AP']"
2502.04573v1,Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer,http://arxiv.org/abs/2502.04573v1,"We present an Adversarially Pre-trained Transformer (APT) that is able toperform zero-shot meta-learning on tabular prediction tasks withoutpre-training on any real-world dataset, extending on the recent development ofPrior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trainedwith adversarial synthetic data agents, who continue to shift their underlyingdata generating distribution and deliberately challenge the model withdifferent synthetic datasets. In addition, we propose a mixture blockarchitecture that is able to handle classification tasks with arbitrary numberof classes, addressing the class size limitation -- a crucial weakness of priordeep tabular zero-shot learners. In experiments, we show that our frameworkmatches state-of-the-art performance on small classification tasks withoutfiltering on dataset characteristics such as number of classes and number ofmissing values, while maintaining an average runtime under one second. Oncommon benchmark dataset suites in both classification and regression, we showthat adversarial pre-training was able to enhance TabPFN's performance. In ouranalysis, we demonstrate that the adversarial synthetic data agents were ableto generate a more diverse collection of data compared to the ordinary randomgenerator in TabPFN. In addition, we demonstrate that our mixture block neuraldesign has improved generalizability and greatly accelerated pre-training.",Yulun Wu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04572v1,Global Geometry within an SPDE Well-Posedness Problem,http://arxiv.org/abs/2502.04572v1,"On a closed Riemannian manifold, we construct a family of intrinsic Gaussiannoises indexed by a regularity parameter $\alpha\geq0$ to study thewell-posedness of the Parabolic Anderson model. We show that with rough initialconditions, the equation is well-posed assuming non-positive curvature with acondition on $\alpha$ similar to that of Riesz kernel-correlated noise inEuclidean space. The argument was made in direct mode, showing that it ispossible to bypass Fourier analysis, which was used in all previous work withrough initial conditions. Non-positive curvature was used to overcome a newdifficulty introduced by non-uniqueness of geodesics in this setting, whichrequired exploration of global geometry. The well-posedness argument alsoproduces exponentially growing in time upper bounds for the moments. Using thegood structure of our noise, we obtain new exponentially growing in time secondmoment lower bounds for our solutions with bounded initial condition.",Hongyi Chen,2025-02-06,2025-02-06,,N/A,"['math.PR', 'math.AP', 'math.DG']"
2502.04571v1,Discovery and Timing of 49 Pulsars from the Arecibo 327-MHz Drift Survey,http://arxiv.org/abs/2502.04571v1,"We present 18 pulsar discoveries from the AO327 pulsar survey, along withtheir timing solutions and those for an additional 31 AO327-discovered pulsars.Timing solutions were constructed using observations from a follow-up timingcampaign taken between the periods of 2013 -- 2019 using the AreciboObservatory's 327-MHz receiver. Aside from PSR J0916+0658, an isolated pulsarthat shows evidence for partial recycling, the remaining discoveries arenon-recycled pulsars. We present a brief census of emission features for allpulsars with the following standouts. PSR~J1942+0142 is found to exhibit thevery rare phenomenon of subpulse bi-drifting and PSR~J0225+1727 has aninterpulse. We also report distance estimates using the NE2001 and YMW16Galactic electron density models, and identify at least 10 sources where eitherone or both models underestimate the maximum Galactic line of sight dispersionmeasure.",Timothy E. E. Olszanski,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.04570v1,Towards Accurate Mixed Quantum Classical Simulations of Vibrational Polaritonic Chemistry,http://arxiv.org/abs/2502.04570v1,"Interest in vibrational polaritonic chemistry, where ground-state chemicalkinetics are modified via confined optical modes in a cavity, has surged inrecent years. Although models have been developed to understand cavity-modifiedreactions, fully quantum mechanical simulations remain out of reach for thecollective regime that involves many molecules, a critical aspect of thephenomenon. Mixed quantum-classical (MQC) simulations offer a scalablealternative, but their accuracy requires testing and potential improvementseven in the single-molecule limit. In this work, we take this step by firstintroducing the mapping approach to surface hopping (MASH) to address thelimitations of traditional MQC methods. Second, we incorporate a quantumtreatment of the cavity mode, moving beyond the classical approximations oftenemployed in previous studies. Results for a single-molecule model ofvibrational polaritonic chemistry show that combining MASH with a quantumcavity mode yields the most accurate rates. However, this scheme may producedifferent long-time population dynamics at zero coupling depending on whetherthe cavity mode is quantized; a problem known as size-inconsistency in MASH. Weaddress this problem proposing the $\epsilon$-MASH approach, which forbidshopping between states with negligible nonadiabatic couplings (NACs). CombiningMASH with a quantum cavity mode thus provides a promising approach for scalableand accurate MQC simulations in the collective regime.",Muhammad R. Hasyim,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'cond-mat.other', 'physics.chem-ph']"
2502.04568v1,Learning Semantics-aware Search Operators for Genetic Programming,http://arxiv.org/abs/2502.04568v1,"Fitness landscapes in test-based program synthesis are known to be extremelyrugged, with even minimal modifications of programs often leading tofundamental changes in their behavior and, consequently, fitness values.Relying on fitness as the only guidance in iterative search algorithms likegenetic programming is thus unnecessarily limiting, especially when combinedwith purely syntactic search operators that are agnostic about their impact onprogram behavior. In this study, we propose a semantics-aware search operatorthat steers the search towards candidate programs that are valuable not onlyactually (high fitness) but also only potentially, i.e. are likely to be turnedinto high-quality solutions even if their current fitness is low. The keycomponent of the method is a graph neural network that learns to model theinteractions between program instructions and processed data, and produces asaliency map over graph nodes that represents possible search decisions. Whenapplied to a suite of symbolic regression benchmarks, the proposed methodoutperforms conventional tree-based genetic programming and the ablated variantof the method.",Piotr Wyrwiński,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.NE']"
2502.04567v1,Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator,http://arxiv.org/abs/2502.04567v1,"Existing studies on preference optimization (PO) have centered onconstructing pairwise preference data following simple heuristics, such asmaximizing the margin between preferred and dispreferred completions based onhuman (or AI) ranked scores. However, none of these heuristics has a fulltheoretical justification. In this work, we develop a novel PO framework thatprovides theoretical guidance to effectively sample dispreferred completions.To achieve this, we formulate PO as minimizing the negative log-likelihood(NLL) of a probability model and propose to estimate its normalization constantvia a sampling strategy. As we will demonstrate, these estimative samples canact as dispreferred completions in PO. We then select contrastive divergence(CD) as the sampling strategy, and propose a novel MC-PO algorithm that appliesthe Monte Carlo (MC) kernel from CD to sample hard negatives w.r.t. theparameterized reward model. Finally, we propose the OnMC-PO algorithm, anextension of MC-PO to the online setting. On popular alignment benchmarks,MC-PO outperforms existing SOTA baselines, and OnMC-PO leads to furtherimprovement.",Zhuotong Chen,2025-02-06,2025-02-06,,N/A,['cs.AI']
2502.04566v1,An Optimized YOLOv5 Based Approach For Real-time Vehicle Detection At Road Intersections Using Fisheye Cameras,http://arxiv.org/abs/2502.04566v1,"Real time vehicle detection is a challenging task for urban trafficsurveillance. Increase in urbanization leads to increase in accidents andtraffic congestion in junction areas resulting in delayed travel time. In orderto solve these problems, an intelligent system utilizing automatic detectionand tracking system is significant. But this becomes a challenging task at roadintersection areas which require a wide range of field view. For this reason,fish eye cameras are widely used in real time vehicle detection purpose toprovide large area coverage and 360 degree view at junctions. However, itintroduces challenges such as light glare from vehicles and street lights,shadow, non-linear distortion, scaling issues of vehicles and properlocalization of small vehicles. To overcome each of these challenges, amodified YOLOv5 object detection scheme is proposed. YOLOv5 is a deep learningoriented convolutional neural network (CNN) based object detection method. Theproposed scheme for detecting vehicles in fish-eye images consists of alight-weight day-night CNN classifier so that two different solutions can beimplemented to address the day-night detection issues. Furthurmore, challenginginstances are upsampled in the dataset for proper localization of vehicles andlater on the detection model is ensembled and trained in different combinationof vehicle datasets for better generalization, detection and accuracy. Fortesting, a real world fisheye dataset provided by the Video and ImageProcessing (VIP) Cup organizer ISSD has been used which includes images fromvideo clips of different fisheye cameras at junction of different cities duringday and night time. Experimental results show that our proposed model hasoutperformed the YOLOv5 model on the dataset by 13.7% mAP @ 0.5.",Md. Jahin Alam,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04565v1,Private Federated Learning In Real World Application -- A Case Study,http://arxiv.org/abs/2502.04565v1,"This paper presents an implementation of machine learning model trainingusing private federated learning (PFL) on edge devices. We introduce a novelframework that uses PFL to address the challenge of training a model usingusers' private data. The framework ensures that user data remain on individualdevices, with only essential model updates transmitted to a central server foraggregation with privacy guarantees. We detail the architecture of our appselection model, which incorporates a neural network with attention mechanismsand ambiguity handling through uncertainty management. Experiments conductedthrough off-line simulations and on device training demonstrate the feasibilityof our approach in real-world scenarios. Our results show the potential of PFLto improve the accuracy of an app selection model by adapting to changes inuser behavior over time, while adhering to privacy standards. The insightsgained from this study are important for industries looking to implement PFL,offering a robust strategy for training a predictive model directly on edgedevices while ensuring user data privacy.",An Ji,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CR']"
2502.04564v1,My LLM might Mimic AAE -- But When Should it?,http://arxiv.org/abs/2502.04564v1,"We examine the representation of African American English (AAE) in largelanguage models (LLMs), exploring (a) the perceptions Black Americans have ofhow effective these technologies are at producing authentic AAE, and (b) inwhat contexts Black Americans find this desirable. Through both a survey ofBlack Americans ($n=$ 104) and annotation of LLM-produced AAE by BlackAmericans ($n=$ 228), we find that Black Americans favor choice and autonomy indetermining when AAE is appropriate in LLM output. They tend to prefer thatLLMs default to communicating in Mainstream U.S. English in formal settings,with greater interest in AAE production in less formal settings. When LLMs wereappropriately prompted and provided in context examples, our participants foundtheir outputs to have a level of AAE authenticity on par with transcripts ofBlack American speech. Select code and data for our project can be found here:https://github.com/smelliecat/AAEMime.git",Sandra C. Sandoval,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04563v1,WaferLLM: A Wafer-Scale LLM Inference System,http://arxiv.org/abs/2502.04563v1,"Emerging AI accelerators increasingly adopt wafer-scale manufacturingtechnologies, integrating hundreds of thousands of AI cores in a mesh-basedarchitecture with large distributed on-chip memory (tens of GB in total) andultra-high on-chip memory bandwidth (tens of PB/s). However, current LLMinference systems, optimized for shared memory architectures like GPUs, fail tofully exploit these accelerators. We introduce WaferLLM, the first wafer-scaleLLM inference system. WaferLLM is guided by a novel PLMR device model thatcaptures the unique hardware characteristics of wafer-scale architectures.Leveraging this model, WaferLLM pioneers wafer-scale LLM parallelism,optimizing the utilization of hundreds of thousands of on-chip cores. It alsointroduces MeshGEMM and MeshGEMV, the first GEMM and GEMV implementationsdesigned to scale effectively on wafer-scale accelerators. Evaluations showthat WaferLLM achieves 200$\times$ better wafer-scale accelerator utilizationthan state-of-the-art systems. On a commodity wafer-scale accelerator, WaferLLMdelivers 606$\times$ faster and 22$\times$ more energy-efficient GEMV comparedto an advanced GPU. For LLMs, WaferLLM enables 39$\times$ faster decoding with1.7$\times$ better energy efficiency. We anticipate these numbers will growsignificantly as wafer-scale AI models, software, and hardware continue tomature.",Congjie He,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.AR', 'cs.DC', 'cs.ET']"
2502.04562v1,Mixture of neural operator experts for learning boundary conditions and model selection,http://arxiv.org/abs/2502.04562v1,"While Fourier-based neural operators are best suited to learning mappingsbetween functions on periodic domains, several works have introduced techniquesfor incorporating non trivial boundary conditions. However, all previouslyintroduced methods have restrictions that limit their applicability. In thiswork, we introduce an alternative approach to imposing boundary conditionsinspired by volume penalization from numerical methods and Mixture of Experts(MoE) from machine learning. By introducing competing experts, the approachadditionally allows for model selection. To demonstrate the method, we combinea spatially conditioned MoE with the Fourier based, Modal Operator Regressionfor Physics (MOR-Physics) neural operator and recover a nonlinear operator on adisk and quarter disk. Next, we extract a large eddy simulation (LES) modelfrom direct numerical simulation of channel flow and show the domaindecomposition provided by our approach. Finally, we train our LES model withBayesian variational inference and obtain posterior predictive samples of flowfar past the DNS simulation time horizon.",Dwyer Deighan,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.NA', 'math.NA', 'physics.flu-dyn']"
2502.04560v1,Giant coercivity and enhanced intrinsic anomalous Hall effect at vanishing magnetization in a compensated kagome ferrimagnet,http://arxiv.org/abs/2502.04560v1,"Ferrimagnets that can be driven to magnetic compensation show promise for usein spintronics as they exhibit a finite anomalous Hall effect at zero magneticfield without having a significant magnetic moment. Compensated ferrimagnetspintronic devices with both a large anomalous Hall effect and a highcoercivity would be simultaneously easy to read and difficult to erase. Thekagome ferrimagnet TbMn$_6$Sn$_6$ has been reported to host a large intrinsicanomalous Hall effect. Here, we demonstrate that doping the Mn sites with Crdrives the system towards magnetic compensation. For nearly compensatedcompositions at low temperatures, giant coercive fields exceeding 14 T areobserved. Additionally, Cr doping significantly enhances the intrinsicanomalous Hall effect, which can be attributed to a shift in the Fermi level.Our results extend the range of unique magnetic states observed in kagomematerials, demonstrating that chemical doping is an effective strategy to tuneand realize these states.",Jonathan M. DeStefano,2025-02-06,2025-02-06,,N/A,['cond-mat.str-el']
2502.04559v1,Generalized $η$-pairing theory and anomalous localization in non-Hermitian systems,http://arxiv.org/abs/2502.04559v1,"By generalizing the eta-pairing theory to non-Hermitian Hubbard models onarbitrary lattices, we obtain the sufficient and necessary condition for theeta-pairing operator to be an eigenoperator of the Hamiltonian $H$, and findunique eta-pairing phenomena without Hermitian analogs. For instance, theHermitian conjugate of an eta-pairing eigenoperator may not be aneigenoperator, eta-pairing eigenoperators can be spatially modulated, and the$SU(2)$ pseudospin symmetry may not be respected even if $H$ commutes with theeta-pairing operators. Remarkably, these novel non-Hermitian phenomena areclosely related to each other by several theorems we establish and can lead to,e.g., the notion of non-Hermitian angular-momentum operators and the anomalouslocalization of eta-pairing eigenstates. Some issues on the $SO(4)$ andparticle-hole symmetries are clarified. Our general eta-pairing theory alsoreveals a previously unnoticed unification of these symmetries of the Hubbardmodel. To exemplify these findings, we propose the Hatano-Nelson-Hubbard model.In this interacting non-Hermitian system without even the bulk translationinvariance, the right and left two-particle eta-pairing eigenstates areexponentially localized at opposite boundaries of the chain. We then generalizethis model to two dimensions and find that the eta-pairing eigenstate canexhibit the first- or second-order skin effect. Thus, eta-pairing may representa new mechanism for skin effects in interacting non-Hermitian systems, even inhigher dimensions and without the bulk translation symmetry. To realize all ofthe non-Hermitian eta-pairing phenomena, we construct a general two-sublatticemodel defined on an arbitrary lattice, which can exhibit anomalous localizationof eta-pairing eigenstates; besides, this model can reveal the eta-pairingstructure [e.g., the $SO(4)$ symmetry] in systems with Hermitian hoppings.",Kai Lieta,2025-02-06,2025-02-06,,N/A,"['cond-mat.str-el', 'cond-mat.mes-hall', 'cond-mat.quant-gas', 'quant-ph']"
2502.04558v1,Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture,http://arxiv.org/abs/2502.04558v1,"Vision-language-action (VLA) models hold promise as generalist roboticssolutions by translating visual and linguistic inputs into robot actions, yetthey lack reliability due to their black-box nature and sensitivity toenvironmental changes. In contrast, cognitive architectures (CA) excel insymbolic reasoning and state monitoring but are constrained by rigid predefinedexecution. This work bridges these approaches by probing OpenVLA's hiddenlayers to uncover symbolic representations of object properties, relations, andaction states, enabling integration with a CA for enhanced interpretability androbustness. Through experiments on LIBERO-spatial pick-and-place tasks, weanalyze the encoding of symbolic states across different layers of OpenVLA'sLlama backbone. Our probing results show consistently high accuracies (> 0.90)for both object and action states across most layers, though contrary to ourhypotheses, we did not observe the expected pattern of object states beingencoded earlier than action states. We demonstrate an integrated DIARC-OpenVLAsystem that leverages these symbolic representations for real-time statemonitoring, laying the foundation for more interpretable and reliable roboticmanipulation.",Hong Lu,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.04557v1,Speeding up Speculative Decoding via Approximate Verification,http://arxiv.org/abs/2502.04557v1,"Speculative Decoding (SD) is a recently proposed technique for fasterinference using Large Language Models (LLMs). SD operates by using a smallerdraft LLM for autoregressively generating a sequence of tokens and a largertarget LLM for parallel verification to ensure statistical consistency.However, periodic parallel calls to the target LLM for verification prevent SDfrom achieving even lower latencies. We propose SPRINTER, which utilizes alow-complexity verifier trained to predict if tokens generated from a draft LLMwould be accepted by the target LLM. By performing approximate sequentialverification, SPRINTER does not require verification by the target LLM and isonly invoked when a token is deemed unacceptable. This leads to reducing thenumber of calls to the larger LLM and can achieve further speedups. We presenta theoretical analysis of SPRINTER, examining the statistical properties of thegenerated tokens, as well as the expected reduction in latency as a function ofthe verifier. We evaluate SPRINTER on several datasets and model pairs,demonstrating that approximate verification can still maintain high qualitygeneration while further reducing latency. For instance, on Wiki-Summariesdataset, SPRINTER achieves a 1.7x latency speedup and requires 8.3x fewer flopsrelative to SD, while still generating high-quality responses when usingGPT2-Small and GPT2-XL as draft/target models.",Meiyu Zhong,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.IT', 'math.IT']"
2502.04556v1,TruthFlow: Truthful LLM Generation via Representation Flow Correction,http://arxiv.org/abs/2502.04556v1,"Large language models (LLMs) are known to struggle with consistentlygenerating truthful responses. While various representation interventiontechniques have been proposed, these methods typically apply a universalrepresentation correction vector to all input queries, limiting theireffectiveness against diverse queries in practice. In this study, we introduceTruthFlow, a novel method that leverages the Flow Matching technique forquery-specific truthful representation correction. Specifically, TruthFlowfirst uses a flow model to learn query-specific correction vectors thattransition representations from hallucinated to truthful states. Then, duringinference, the trained flow model generates these correction vectors to enhancethe truthfulness of LLM outputs. Experimental results demonstrate thatTruthFlow significantly improves performance on open-ended generation tasksacross various advanced LLMs evaluated on TruthfulQA. Moreover, the trainedTruthFlow model exhibits strong transferability, performing effectively onother unseen hallucination benchmarks.",Hanyu Wang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04554v1,Unifying and Optimizing Data Values for Selection via Sequential-Decision-Making,http://arxiv.org/abs/2502.04554v1,"Data selection has emerged as a crucial downstream application of datavaluation. While existing data valuation methods have shown promise inselection tasks, the theoretical foundations and full potential of using datavalues for selection remain largely unexplored. In this work, we firstdemonstrate that data values applied for selection can be naturallyreformulated as a sequential-decision-making problem, where the optimal datavalue can be derived through dynamic programming. We show this frameworkunifies and reinterprets existing methods like Data Shapley through the lens ofapproximate dynamic programming, specifically as myopic reward functionapproximations to this sequential problem. Furthermore, we analyze howsequential data selection optimality is affected when the ground-truth utilityfunction exhibits monotonic submodularity with curvature. To address thecomputational challenges in obtaining optimal data values, we propose anefficient approximation scheme using learned bipartite graphs as surrogateutility models, ensuring greedy selection is still optimal when the surrogateutility is correctly specified and learned. Extensive experiments demonstratethe effectiveness of our approach across diverse datasets.",Hongliang Chi,2025-02-06,2025-02-06,,N/A,['cs.AI']
2502.04553v1,Variance component mixture modelling for longitudinal T-cell receptor clonal dynamics,http://arxiv.org/abs/2502.04553v1,"Studies of T cells and their clonally unique receptors have shown promise inelucidating the association between immune response and human disease. Methodsto identify T-cell receptor clones which expand or contract in response tocertain therapeutic strategies have so far been limited to longitudinalpairwise comparisons of clone frequency with multiplicity adjustment. Here wedevelop a more general mixture model approach for arbitrary follow-up andmissingness which partitions dynamic longitudinal clone frequency behavior fromstatic. While it is common to mix on the location or scale parameter of afamily of distributions, the model instead mixes on the parameterizationitself, the dynamic component allowing for a variable, Gamma-distributedPoisson mean parameter over longitudinal follow-up, while the static componentmean is time invariant. Leveraging conjugacy, one can integrate out the meanparameter for the dynamic and static components to yield distinct posteriorpredictive distributions whose expressions are a product of negative binomialsand a single negative multinomial, respectively, each modified according to anoffset for receptor read count normalization. An EM-algorithm is developed toestimate hyperparameters and component membership, and validity of the approachis demonstrated in simulation. The model identifies a statistically significantand clinically relevant increase in TCR clonal dynamism amongmetastasis-directed radiation therapy in a cohort of prostate cancer patients.",David Swanson,2025-02-06,2025-02-06,,N/A,"['stat.ME', '62F15 (Primary), 62H30 (Secondary)']"
2502.04551v1,Stability of Jordan Recurrent Neural Network Estimator,http://arxiv.org/abs/2502.04551v1,"State estimation involves finding the states of a noisy dynamical system witha noisy initial condition using noisy measurements, given a model of thesystem. Many methods exist for state estimation of dynamical systems. Forlinear dynamical systems with white Gaussian noises of known mean and variance,Kalman filtering is an optimal state estimation algorithm. While severalextensions of the Kalman filter to nonlinear systems exist, either the methodis not optimal or calculation is not feasible. Several approaches using neuralnetworks have been developed in recent years. While these approaches seem towork numerically, stability and convergence guarantees do not exist. In thispaper, we propose to use a Jordan recurrent neural network (JRN) for stateestimation. An input-to-state stability (ISS) analysis of the error dynamics isused. Our results are compared to the Kalman filter for the linear case and theextended Kalman filter for the nonlinear case.",Avneet Kaur,2025-02-06,2025-02-06,,N/A,"['math.OC', 'math.DS']"
2502.04550v1,Partial Information Rate Decomposition,http://arxiv.org/abs/2502.04550v1,"Partial Information Decomposition (PID) is a principled and flexible methodto unveil complex high-order interactions in multi-unit network systems. Thoughbeing defined exclusively for random variables, PID is ubiquitously applied tomultivariate time series taken as realizations of random processes withtemporal statistical structure. Here, to overcome the incorrect depiction ofhigh-order effects by PID schemes applied to dynamic networks, we introduce theframework of Partial Information Rate Decomposition (PIRD). PIRD is formalizedapplying lattice theory to decompose the information shared dynamically betweena target random process and a set of source processes, implemented for Gaussianprocesses through a spectral expansion of information rates, and demonstratedin practice analyzing time series from large-scale climate oscillations.",Luca Faes,2025-02-06,2025-02-06,,N/A,['stat.ME']
2502.04549v1,Mechanisms of Projective Composition of Diffusion Models,http://arxiv.org/abs/2502.04549v1,"We study the theoretical foundations of composition in diffusion models, witha particular focus on out-of-distribution extrapolation andlength-generalization. Prior work has shown that composing distributions vialinear score combination can achieve promising results, includinglength-generalization in some cases (Du et al., 2023; Liu et al., 2022).However, our theoretical understanding of how and why such compositions workremains incomplete. In fact, it is not even entirely clear what it means forcomposition to ""work"". This paper starts to address these fundamental gaps. Webegin by precisely defining one possible desired result of composition, whichwe call projective composition. Then, we investigate: (1) when linear scorecombinations provably achieve projective composition, (2) whetherreverse-diffusion sampling can generate the desired composition, and (3) theconditions under which composition fails. Finally, we connect our theoreticalanalysis to prior empirical observations where composition has either worked orfailed, for reasons that were unclear at the time.",Arwen Bradley,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04548v1,Contextual Gradient Flow Modeling for Large Language Model Generalization in Multi-Scale Feature Spaces,http://arxiv.org/abs/2502.04548v1,"Optimization methodologies for training large-scale neural architecturesoften rely on uniform gradient propagation mechanisms that fail to align withhierarchical linguistic structures, limiting their capacity to generalizeacross diverse language distributions. A structured gradient refinementframework was introduced to incorporate multi-scale contextual adjustments,improving parameter adaptation through dynamic weighting strategies thatenhanced representation coherence. Empirical evaluations demonstrated thatstructured propagation mechanisms contributed to reductions in gradientoscillations, resulting in more stable training dynamics and improvedoptimization efficiency. The comparative performance assessment indicated thatmodels incorporating hierarchical propagation strategies exhibited greaterrobustness in long-range dependency retention and cross-domain adaptation. Thehierarchical adjustment of weight updates provided an alternative toconventional backpropagation, reducing sensitivity to initialization conditionswhile improving overall convergence efficiency. The experimental resultsconfirmed that structured gradient propagation influenced representationlearning trajectories, aligning parameter updates with broader linguisticdependencies rather than isolated token-level relationships. Statisticalevaluations indicated that structured optimization strategies mitigatedoverfitting while preserving adaptability across heterogeneous textdistributions. The findings established that structured gradient propagationprovided an empirically validated framework for refining hierarchicalrepresentation learning, supporting more effective integration of linguisticdependencies into optimization dynamics.",Daphne Quillington,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04544v1,Solvability of Approximate Reach-Avoid Games,http://arxiv.org/abs/2502.04544v1,"Objective: In a companion paper, we propose a parametric hybrid automatonmodel and an algorithm for the online synthesis of robustly correct andnear-optimal controllers for cyber-physical system with reach-avoid guarantees.A key part of this synthesis problem is based on a weighted discretised gameand solved via scope-adaptive discrete dynamic programming. Approach: This workexamines proofs of key properties of the discussed algorithm. Evaluation: Themain proof is by induction over the stages of a discreteHamilton-Jacobi-Bellman system of equations. Contribution: The results includea game solvability theorem and identify necessary and sufficient conditions forits applicability.",Mario Gleirscher,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.LO', 'cs.SY']"
2502.04541v1,The Phantom of the Elytra -- Phylogenetic Trait Extraction from Images of Rove Beetles Using Deep Learning -- Is the Mask Enough?,http://arxiv.org/abs/2502.04541v1,"Phylogenetic analysis traditionally relies on labor-intensive manualextraction of morphological traits, limiting its scalability for largedatasets. Recent advances in deep learning offer the potential to automate thisprocess, but the effectiveness of different morphological representations forphylogenetic trait extraction remains poorly understood. In this study, wecompare the performance of deep learning models using three distinctmorphological representations - full segmentations, binary masks, and Fourierdescriptors of beetle outlines. We test this on the Rove-Tree-11 dataset, acurated collection of images from 215 rove beetle species. Our resultsdemonstrate that the mask-based model outperformed the others, achieving anormalized Align Score of 0.33 plus/minus 0.02 on the test set, compared to0.45 plus/minus 0.01 for the Fourier-based model and 0.39 plus/minus 0.07 forthe segmentation-based model. The performance of the mask-based model likelyreflects its ability to capture shape features while taking advantage of thedepth and capacity of the ResNet50 architecture. These results also indicatethat dorsal textural features, at least in this group of beetles, may be oflowered phylogenetic relevance, though further investigation is necessary toconfirm this. In contrast, the Fourier-based model suffered from reducedcapacity and occasional inaccuracies in outline approximations, particularly infine structures like legs. These findings highlight the importance of selectingappropriate morphological representations for automated phylogenetic studiesand the need for further research into explainability in automaticmorphological trait extraction.",Roberta Hunt,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04537v1,Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation,http://arxiv.org/abs/2502.04537v1,"Multilingual neural machine translation (MNMT) aims at using one single modelfor multiple translation directions. Recent work applies non-autoregressiveTransformers to improve the efficiency of MNMT, but requires expensiveknowledge distillation (KD) processes. To this end, we propose an M-DATapproach to non-autoregressive multilingual machine translation. Our systemleverages the recent advance of the directed acyclic Transformer (DAT), whichdoes not require KD. We further propose a pivot back-translation (PivotBT)approach to improve the generalization to unseen translation directions.Experiments show that our M-DAT achieves state-of-the-art performance innon-autoregressive MNMT.",Chenyang Huang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04536v1,Idioms: Neural Decompilation With Joint Code and Type Prediction,http://arxiv.org/abs/2502.04536v1,"Decompilers are important tools for reverse engineers that help them analyzesoftware at a higher level of abstraction than assembly. Unfortunately, becausecompilation is lossy, deterministic decompilers produce code that is missingmany of the details that make source code readable in the first place, likevariable names and types. Neural decompilers, on the other hand, offer theability to statistically fill in these details. Existing work in neuraldecompilation, however, suffers from substantial drawbacks that limits itsability to handle real code: it is unable to handle user-defined compositetypes, which are essential to fully specifying many functions' semantics, orrequire test cases. In this work, we introduce a new training process tofinetune any LLM into a neural decompiler capable of generating the appropriateuser-defined types alongside the decompilation. We introduce a new dataset,Realtype, that includes substantially more complicated and realistic types thanexisting neural decompilation benchmarks. Motivated by the intuition thatdifferent parts of data structures can be operated upon by different parts ofthe program, we show that interprocedural context can help improve neuraldecompilers' ability to handle user-defined types. We show that our trainingprocess yields state-of-the-art results in neural decompilation. We alsopublicly release the Idioms series of finetuned neural decompilation models insupport of open science. In summary, we identify the need for joint code andtype prediction, show that it is a hard problem, and take the first stepstowards solving it.",Luke Dramko,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.CR']"
2502.04535v1,A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers,http://arxiv.org/abs/2502.04535v1,"Length-control summarization aims to condense long texts into a short onewithin a certain length limit. Previous approaches often use autoregressive(AR) models and treat the length requirement as a soft constraint, which maynot always be satisfied. In this study, we propose a novel length-controldecoding algorithm based on the Directed Acyclic Transformer (DAT). Ourapproach allows for multiple plausible sequence fragments and predicts a\emph{path} to connect them. In addition, we propose a Sequence Maximum aPosteriori (SeqMAP) decoding algorithm that marginalizes different possiblepaths and finds the most probable summary satisfying the length budget. Ouralgorithm is based on beam search, which further facilitates a reranker forperformance improvement. Experimental results on the Gigaword and DUC2004datasets demonstrate our state-of-the-art performance for length-controlsummarization.",Chenyang Huang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04534v1,Evidence of Athermal Metastable Phase in a Halide Perovskite: Optically Tracked Thermal-Breach Memory,http://arxiv.org/abs/2502.04534v1,"Halide perovskite materials have been extensively studied in the last decadebecause of their impressive optoelectronic properties. However, their onecharacteristic that is uncommon for semiconductors is that many undergothermally induced structural phase transitions. The transition is hysteretic,with the hysteresis window marking the boundary of the metastable phase. Wehave discovered that in methylammonium lead iodide, this hysteretic metastablephase is athermal, meaning it shows almost no temporal phase evolution underisothermal conditions. We also show that a large number of distinguishablemetastable states can be prepared following different thermal pathways.Furthermore, under a reversible thermal perturbation, the states in themetastable phase either show return-point memory or undergo a systematicnonrecoverable phase evolution, depending on the thermal history and the signof the temperature perturbation. Since the phase fraction can be probed withextreme sensitivity via luminescence, we have an optically retrievable memorythat reliably records any breach in temperature stability. Such thermal-breachmemory in athermal martensites, of which there are numerous examples, may beuseful for tagging packages requiring strict temperature control duringtransportation or preservation.",Kingshuk Mukhuti,2025-02-06,2025-02-06,,N/A,['cond-mat.mtrl-sci']
2502.04533v1,Polarization-Dependent Loss Mitigation with Orthogonal-Design-Based Precoding and Interference Cancellation,http://arxiv.org/abs/2502.04533v1,"Recent work by Shehadeh and Kschischang provides a simple capacity-achievingscheme for channels with polarization-dependent loss (PDL) under commonmodeling assumptions via a careful choice of orthogonal-design-based precodingand interference cancellation. This letter extends that work with asimulation-based demonstration showing that this scheme remains highlyeffective at mitigating PDL in the highly practical setting of 4-PAM withChase-decoded extended Hamming inner codes rather than the near-capacity innercodes considered in the original work. An alternative near-optimal variation ofthis scheme is provided requiring only one inner code rather than two andsuffering no penalty in the absence of PDL, making it much more practical.",Mohannad Shehadeh,2025-02-06,2025-02-06,,N/A,"['cs.IT', 'math.IT']"
2502.04531v1,AnyPlace: Learning Generalized Object Placement for Robot Manipulation,http://arxiv.org/abs/2502.04531v1,"Object placement in robotic tasks is inherently challenging due to thediversity of object geometries and placement configurations. To address this,we propose AnyPlace, a two-stage method trained entirely on synthetic data,capable of predicting a wide range of feasible placement poses for real-worldtasks. Our key insight is that by leveraging a Vision-Language Model (VLM) toidentify rough placement locations, we focus only on the relevant regions forlocal placement, which enables us to train the low-levelplacement-pose-prediction model to capture diverse placements efficiently. Fortraining, we generate a fully synthetic dataset of randomly generated objectsin different placement configurations (insertion, stacking, hanging) and trainlocal placement-prediction models. We conduct extensive evaluations insimulation, demonstrating that our method outperforms baselines in terms ofsuccess rate, coverage of possible placement modes, and precision. Inreal-world experiments, we show how our approach directly transfers modelstrained purely on synthetic data to the real world, where it successfullyperforms placements in scenarios where other models struggle -- such as withvarying object geometries, diverse placement modes, and achieving highprecision for fine placement. More at: https://any-place.github.io.",Yuchi Zhao,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI', 'cs.CV']"
2502.04530v1,Robust Probabilistic Model Checking with Continuous Reward Domains,http://arxiv.org/abs/2502.04530v1,"Probabilistic model checking traditionally verifies properties on theexpected value of a measure of interest. This restriction may fail to capturethe quality of service of a significant proportion of a system's runs,especially when the probability distribution of the measure of interest ispoorly represented by its expected value due to heavy-tail behaviors ormultiple modalities. Recent works inspired by distributional reinforcementlearning use discrete histograms to approximate integer reward distribution,but they struggle with continuous reward space and present challenges inbalancing accuracy and scalability. We propose a novel method for handling bothcontinuous and discrete reward distributions in Discrete Time Markov Chainsusing moment matching with Erlang mixtures. By analytically derivinghigher-order moments through Moment Generating Functions, our methodapproximates the reward distribution with theoretically bounded error whilepreserving the statistical properties of the true distribution. This detaileddistributional insight enables the formulation and robust model checking ofquality properties based on the entire reward distribution function, ratherthan restricting to its expected value. We include a theoretical foundationensuring bounded approximation errors, along with an experimental evaluationdemonstrating our method's accuracy and scalability in practical model-checkingproblems.",Xiaotong Ji,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.FL', 'cs.LG']"
2502.04529v1,"Agricultural Field Boundary Detection through Integration of ""Simple Non-Iterative Clustering (SNIC) Super Pixels"" and ""Canny Edge Detection Method""",http://arxiv.org/abs/2502.04529v1,"Efficient use of cultivated areas is a necessary factor for sustainabledevelopment of agriculture and ensuring food security. Along with the rapiddevelopment of satellite technologies in developed countries, new methods arebeing searched for accurate and operational identification of cultivated areas.In this context, identification of cropland boundaries based on spectralanalysis of data obtained from satellite images is considered one of the mostoptimal and accurate methods in modern agriculture. This article proposes a newapproach to determine the suitability and green index of cultivated areas usingsatellite data obtained through the ""Google Earth Engine"" (GEE) platform. Inthis approach, two powerful algorithms, ""SNIC (Simple Non-Iterative Clustering)Super Pixels"" and ""Canny Edge Detection Method"", are combined. The SNICalgorithm combines pixels in a satellite image into larger regions (superpixels) with similar characteristics, thereby providing better image analysis.The Canny Edge Detection Method detects sharp changes (edges) in the image todetermine the precise boundaries of agricultural fields. This study, carriedout using high-resolution multispectral data from the Sentinel-2 satellite andthe Google Earth Engine JavaScript API, has shown that the proposed method iseffective in accurately and reliably classifying randomly selected agriculturalfields. The combined use of these two tools allows for more accuratedetermination of the boundaries of agricultural fields by minimizing theeffects of outliers in satellite images. As a result, more accurate andreliable maps can be created for agricultural monitoring and resourcemanagement over large areas based on the obtained data. By expanding theapplication capabilities of cloud-based platforms and artificial intelligencemethods in the agricultural field.",Artughrul Gayibov,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CV', '68U10, 62H35', 'I.4.6; I.5.4']"
2502.04528v1,Group-Adaptive Threshold Optimization for Robust AI-Generated Text Detection,http://arxiv.org/abs/2502.04528v1,"The advancement of large language models (LLMs) has made it difficult todifferentiate human-written text from AI-generated text. Several AI-textdetectors have been developed in response, which typically utilize a fixedglobal threshold (e.g., {\theta} = 0.5) to classify machine-generated text.However, we find that one universal threshold can fail to account forsubgroup-specific distributional variations. For example, when using a fixedthreshold, detectors make more false positive errors on shorter human-writtentext than longer, and more positive classifications on neurotic writing stylesthan open among long text. These discrepancies can lead to misclassificationthat disproportionately affects certain groups. We address this criticallimitation by introducing FairOPT, an algorithm for group-specific thresholdoptimization in AI-generated content classifiers. Our approach partitions datainto subgroups based on attributes (e.g., text length and writing style) andlearns decision thresholds for each group, which enables careful balancing ofperformance and fairness metrics within each subgroup. In experiments with fourAI text classifiers on three datasets, FairOPT enhances overall F1 score anddecreases balanced error rate (BER) discrepancy across subgroups. Our frameworkpaves the way for more robust and fair classification criteria in AI-generatedoutput detection.",Minseok Jung,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG']"
2502.04527v1,Microdroplet-Based Communications with Frequency Shift Keying Modulation,http://arxiv.org/abs/2502.04527v1,"Droplet-based communications has been investigated as a more robustalternative to diffusion-based molecular communications (MC), yet most existingdemonstrations employ large ""plug-like"" droplets or simple T-junction designsfor droplet generation, restricting modulation strategies and achievable datarates. Here, we report a microfluidic communication system that encodesinformation via the generation rate of sub-100 $\mu$m water-in-oilmicrodroplets using a microfabricated flow focusing architecture. By preciselytuning the flow rate of the dispersed-phase (water) via a pressure-regulatedflow controller, we implement frequency shift keying modulation with foursymbols (4-FSK). A high-speed optical detection and video processing setupserves as the receiver, tracking system response in the microfluidic channelacross different symbol durations (20 s and 12 s) and quantifying errorperformance. Despite the miniaturized device and channel architecture, ourexperiments demonstrate programmable and reliable data transmission withminimal symbol errors. Beyond water-in-oil systems, the same encodingprinciples can be extended to other compartmentalized carriers (e.g., giantunilamellar vesicles, polymersomes) that can also be synthesized via flowfocusing techniques, paving the way for biocompatible, robust, andhigh-capacity communication in intrabody networks and the emerging Internet ofBio-Nano Things.",Eren Akyol,2025-02-06,2025-02-06,,N/A,['cs.ET']
2502.04524v1,All-in-One Analog AI Accelerator: On-Chip Training and Inference with Conductive-Metal-Oxide/HfOx ReRAM Devices,http://arxiv.org/abs/2502.04524v1,"Analog in-memory computing is an emerging paradigm designed to efficientlyaccelerate deep neural network workloads. Recent advancements have demonstratedsignificant improvements in throughput and efficiency, focusing independentlyon either inference or training acceleration. However, a unified analogin-memory technology platform-capable of performing on-chip training, retainingthe weights, and sustaining long-term inference acceleration-has yet to bereported. In this work, an all-in-one analog AI accelerator is presented andbenchmarked, combining these capabilities to enable autonomous,energy-efficient, and continuously adaptable AI systems. The platform leveragesan array of filamentary conductive-metal-oxide (CMO)/HfOx redox-based resistiveswitching memory cells (ReRAM) in one-transistor one-ReRAM (1T1R)configuration, integrated into the back-end-of-line (BEOL) of a 130 nmtechnology node. The array characterization demonstrates reliable and optimizedresistive switching with voltage amplitudes of less than 1.5 V, enablingcompatibility with advanced technology nodes. The multi-bit capability of over32 stable states (5 bits) and record-low programming noise down to 10 nS enablean almost ideal weight transfer process, more than an order of magnitude betterthan other memristive technologies. The array's inference performance isvalidated through realistic matrix-vector multiplication simulations on a 64x64array, achieving a record-low root-mean-square error ranging from 0.06 at 1second to 0.2 at 10 years after programming, compared to the idealfloating-point case. The array is then measured under the same conditions asthose used for on-chip training. Training accuracy closely matching thesoftware equivalent is achieved across different datasets, with high-fidelitymodelling of the device response based on experimental-only data.",Donato Francesco Falcone,2025-02-06,2025-02-06,,N/A,"['cs.ET', 'cs.AR']"
2502.04523v1,Developable Ruled Surfaces Generated by the Curvature Axis of a Curve,http://arxiv.org/abs/2502.04523v1,"Ruled surfaces play an important role in various types of design,architecture, manufacturing, art, and sculpture. They can be created in avariety of ways, which is a topic that has been the subject of much discussionin mathematics and engineering journals. In geometric modelling, ideas aresuccessful if they are not too complex for engineers and practitioners tounderstand and not too difficult to implement, because these specialists putmathematical theories into practice by implementing them in CAD/CAM systems.Some of these popular systems such as AutoCAD, Solidworks, CATIA, Rhinoceros3D, and others are based on simple polynomial or rational splines and manyother beautiful mathematical theories that have not yet been implemented due totheir complexity. Based on this philosophy, in the present work, we investigatea simple way to generate ruled surfaces whose generators are the curvature axesof curves. We show that this type of ruled surface is a developable surface andthat there is at least one curve whose curvature axis is a line on the givendevelopable surface. In addition, we discuss the classifications of developablesurfaces corresponding to space curves with singularities, while these curvesand surfaces are most often avoided in practical design. Our research alsocontributes to the understanding of the singularities of developable surfacesand, in their visualisation, proposes the use of environmental maps with acircular pattern that creates flower-like structures around the singularities.",Ferhat Taş,2025-02-06,2025-02-06,,N/A,"['math.DG', '53Axx, 65D17']"
2502.04522v1,ImprovNet: Generating Controllable Musical Improvisations with Iterative Corruption Refinement,http://arxiv.org/abs/2502.04522v1,"Deep learning has enabled remarkable advances in style transfer acrossvarious domains, offering new possibilities for creative content generation.However, in the realm of symbolic music, generating controllable and expressiveperformance-level style transfers for complete musical works remainschallenging due to limited datasets, especially for genres such as jazz, andthe lack of unified models that can handle multiple music generation tasks.This paper presents ImprovNet, a transformer-based architecture that generatesexpressive and controllable musical improvisations through a self-supervisedcorruption-refinement training strategy. ImprovNet unifies multiplecapabilities within a single model: it can perform cross-genre and intra-genreimprovisations, harmonize melodies with genre-specific styles, and executeshort prompt continuation and infilling tasks. The model's iterative generationframework allows users to control the degree of style transfer and structuralsimilarity to the original composition. Objective and subjective evaluationsdemonstrate ImprovNet's effectiveness in generating musically coherentimprovisations while maintaining structural relationships with the originalpieces. The model outperforms Anticipatory Music Transformer in shortcontinuation and infilling tasks and successfully achieves recognizable genreconversion, with 79\% of participants correctly identifying jazz-styleimprovisations. Our code and demo page can be found athttps://github.com/keshavbhandari/improvnet.",Keshav Bhandari,2025-02-06,2025-02-06,,N/A,"['cs.SD', 'cs.AI', 'eess.AS']"
2502.04521v1,Generative Autoregressive Transformers for Model-Agnostic Federated MRI Reconstruction,http://arxiv.org/abs/2502.04521v1,"Although learning-based models hold great promise for MRI reconstruction,single-site models built on limited local datasets often suffer from poorgeneralization. This challenge has spurred interest in collaborative modeltraining on multi-site datasets via federated learning (FL) -- aprivacy-preserving framework that aggregates model updates instead of sharingimaging data. Conventional FL builds a global model by aggregating locallytrained model weights, inherently constraining all sites to a homogeneous modelarchitecture. This rigid homogeneity requirement forces sites to forgoarchitectures tailored to their compute infrastructure and application-specificdemands. Consequently, existing FL methods for MRI reconstruction fail tosupport model-heterogeneous settings, where individual sites are allowed to usedistinct architectures. To overcome this fundamental limitation, here weintroduce FedGAT, a novel model-agnostic FL technique based on generativeautoregressive transformers. FedGAT decentralizes the training of a globalgenerative prior that captures the distribution of multi-site MR images. Forenhanced fidelity, we propose a novel site-prompted GAT prior that controllablysynthesizes MR images from desired sites via autoregressive prediction acrossspatial scales. Each site then trains its site-specific reconstruction model --using its preferred architecture -- on a hybrid dataset comprising the localMRI dataset and GAT-generated synthetic MRI datasets for other sites.Comprehensive experiments on multi-institutional datasets demonstrate thatFedGAT supports flexible collaborations while enjoying superior within-site andacross-site reconstruction performance compared to state-of-the-art FLbaselines.",Valiyeh A. Nezhad,2025-02-06,2025-02-06,,N/A,"['eess.IV', 'cs.CV']"
2502.04520v1,Linear Correlation in LM's Compositional Generalization and Hallucination,http://arxiv.org/abs/2502.04520v1,"The generalization of language models (LMs) is undergoing active debates,contrasting their potential for general intelligence with their struggles withbasic knowledge composition (e.g., reverse/transition curse). This paperuncovers the phenomenon of linear correlations in LMs during knowledgecomposition. For explanation, there exists a linear transformation betweencertain related knowledge that maps the next token prediction logits from oneprompt to another, e.g., ""X lives in the city of"" $\rightarrow$ ""X lives in thecountry of"" for every given X. This mirrors the linearity in human knowledgecomposition, such as Paris $\rightarrow$ France. Our findings indicate that thelinear transformation is resilient to large-scale fine-tuning, generalizingupdated knowledge when aligned with real-world relationships, but causinghallucinations when it deviates. Empirical results suggest that linearcorrelation can serve as a potential identifier of LM's generalization.Finally, we show such linear correlations can be learned with a singlefeedforward network and pre-trained vocabulary representations, indicating LMgeneralization heavily relies on the latter.",Letian Peng,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04519v1,GenVC: Self-Supervised Zero-Shot Voice Conversion,http://arxiv.org/abs/2502.04519v1,"Zero-shot voice conversion has recently made substantial progress, but manymodels still depend on external supervised systems to disentangle speakeridentity and linguistic content. Furthermore, current methods often useparallel conversion, where the converted speech inherits the source utterance'stemporal structure, restricting speaker similarity and privacy. To overcomethese limitations, we introduce GenVC, a generative zero-shot voice conversionmodel. GenVC learns to disentangle linguistic content and speaker style in aself-supervised manner, eliminating the need for external models and enablingefficient training on large, unlabeled datasets. Experimental results show thatGenVC achieves state-of-the-art speaker similarity while maintainingnaturalness competitive with leading approaches. Its autoregressive generationalso allows the converted speech to deviate from the source utterance'stemporal structure. This feature makes GenVC highly effective for voiceanonymization, as it minimizes the preservation of source prosody and speakercharacteristics, enhancing privacy protection.",Zexin Cai,2025-02-06,2025-02-06,,N/A,"['eess.AS', 'cs.LG']"
2502.04518v1,State estimator design using Jordan based long short-term memory networks,http://arxiv.org/abs/2502.04518v1,"State estimation of a dynamical system refers to estimating the state of asystem given an imperfect model, noisy measurements and some or no informationabout the initial state. While Kalman filtering is optimal for estimation oflinear systems with Gaussian noises, calculation of optimal estimators fornonlinear systems is challenging. We focus on establishing a pathway to optimalestimation of high-order systems by using recurrent connections motivated byJordan recurrent neural networks(JRNs). The results are compared to thecorresponding Elman structure based long short-term memory network(ELSTM) andthe KF for linear and EKF for nonlinear systems. The results suggest that fornonlinear systems, the use of long short-term memory networks can improveestimation error and also computation time. Also, the Jordan based longshort-term memory networks(JLSTMs) require less training to achieve performancesimilar to ELSTMs.",Avneet Kaur,2025-02-06,2025-02-06,,N/A,['math.OC']
2502.04517v1,Towards Cost-Effective Reward Guided Text Generation,http://arxiv.org/abs/2502.04517v1,"Reward-guided text generation (RGTG) has emerged as a viable alternative tooffline reinforcement learning from human feedback (RLHF). RGTG methods canalign baseline language models to human preferences without further traininglike in standard RLHF methods. However, they rely on a reward model to scoreeach candidate token generated by the language model at inference, incurringsignificant test-time overhead. Additionally, the reward model is usually onlytrained to score full sequences, which can lead to sub-optimal choices forpartial sequences. In this work, we present a novel reward model architecturethat is trained, using a Bradley-Terry loss, to prefer the optimal expansion ofa sequence with just a \emph{single call} to the reward model at each step ofthe generation process. That is, a score for all possible candidate tokens isgenerated simultaneously, leading to efficient inference. We theoreticallyanalyze various RGTG reward models and demonstrate that prior techniques prefersub-optimal sequences compared to our method during inference. Empirically, ourreward model leads to significantly faster inference than other RGTG methods.It requires fewer calls to the reward model and performs competitively comparedto previous RGTG and offline RLHF methods.",Ahmad Rashid,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL']"
2502.04515v1,MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification,http://arxiv.org/abs/2502.04515v1,"Medical time series has been playing a vital role in real-world healthcaresystems as valuable information in monitoring health conditions of patients.Accurate classification for medical time series, e.g., Electrocardiography(ECG) signals, can help for early detection and diagnosis. Traditional methodstowards medical time series classification rely on handcrafted featureextraction and statistical methods; with the recent advancement of artificialintelligence, the machine learning and deep learning methods have become morepopular. However, existing methods often fail to fully model the complexspatial dynamics under different scales, which ignore the dynamicmulti-resolution spatial and temporal joint inter-dependencies. Moreover, theyare less likely to consider the special baseline wander problem as well as themulti-view characteristics of medical time series, which largely hinders theirprediction performance. To address these limitations, we propose aMulti-resolution Spatiotemporal Graph Learning framework, MedGNN, for medicaltime series classification. Specifically, we first propose to constructmulti-resolution adaptive graph structures to learn dynamic multi-scaleembeddings. Then, to address the baseline wander problem, we propose DifferenceAttention Networks to operate self-attention mechanisms on the finitedifference for temporal modeling. Moreover, to learn the multi-viewcharacteristics, we utilize the Frequency Convolution Networks to capturecomplementary information of medical time series from the frequency domain. Inaddition, we introduce the Multi-resolution Graph Transformer architecture tomodel the dynamic dependencies and fuse the information from differentresolutions. Finally, we have conducted extensive experiments on multiplemedical real-world datasets that demonstrate the superior performance of ourmethod. Our Code is available.",Wei Fan,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04513v1,A search for the anomalous events detected by ANITA using the Pierre Auger Observatory,http://arxiv.org/abs/2502.04513v1,"A dedicated search for upward-going air showers at zenith angles exceeding$110^\circ$ and energies $E>0.1$ EeV has been performed using the FluorescenceDetector of the Pierre Auger Observatory. The search is motivated by two""anomalous"" radio pulses observed by the ANITA flights I and III which appearinconsistent with the Standard Model of particle physics. Using simulations ofboth regular cosmic ray showers and upward-going events, a selection procedurehas been defined to separate potential upward-going candidate events and thecorresponding exposure has been calculated in the energy range [0.1-33] EeV.One event has been found in the search period between 1 Jan 2004 and 31 Dec2018, consistent with an expected background of $0.27 \pm 0.12$ events frommis-reconstructed cosmic ray showers. This translates to an upper bound on theintegral flux of $(7.2 \pm 0.2) \times 10^{-21}$ cm$^{-2}$ sr$^{-1}$ y$^{-1}$and $(3.6 \pm 0.2) \times 10^{-20}$ cm$^{-2}$ sr$^{-1}$ y$^{-1}$ for an$E^{-1}$ and $E^{-2}$ spectrum, respectively. An upward-going flux of showersnormalized to the ANITA observations is shown to predict over 34 events for an$E^{-3}$ spectrum and over 8.1 events for a conservative $E^{-5}$ spectrum, instrong disagreement with the interpretation of the anomalous events asupward-going showers.",The Pierre Auger Collaboration,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.04512v1,Safety is Essential for Responsible Open-Ended Systems,http://arxiv.org/abs/2502.04512v1,"AI advancements have been significantly driven by a combination of foundationmodels and curiosity-driven learning aimed at increasing capability andadaptability. A growing area of interest within this field is Open-Endedness -the ability of AI systems to continuously and autonomously generate novel anddiverse artifacts or solutions. This has become relevant for acceleratingscientific discovery and enabling continual adaptation in AI agents. Thisposition paper argues that the inherently dynamic and self-propagating natureof Open-Ended AI introduces significant, underexplored risks, includingchallenges in maintaining alignment, predictability, and control. This papersystematically examines these challenges, proposes mitigation strategies, andcalls for action for different stakeholders to support the safe, responsibleand successful development of Open-Ended AI.",Ivaxi Sheth,2025-02-06,2025-02-06,,N/A,['cs.AI']
2502.04511v1,Beyond Sample-Level Feedback: Using Reference-Level Feedback to Guide Data Synthesis,http://arxiv.org/abs/2502.04511v1,"LLMs demonstrate remarkable capabilities in following natural languageinstructions, largely due to instruction-tuning on high-quality datasets. Whilesynthetic data generation has emerged as a scalable approach for creating suchdatasets, maintaining consistent quality standards remains challenging. Recentapproaches incorporate feedback to improve data quality, but typically operateat the sample level, generating and applying feedback for each responseindividually. In this work, we propose Reference-Level Feedback, a novelmethodology that instead collects feedback based on high-quality referencesamples from carefully curated seed data. We use this feedback to capture richsignals of desirable characteristics that can be propagated to newlysynthesized data. We present REFED, a dataset of 10K instruction-response pairssynthesized using such feedback. We demonstrate the effectiveness of ourapproach by showing that Llama-3.1-8B-Instruct finetuned on REFED achievesstate-of-the-art performance among similar-sized SFT-based models on AlpacaEval2.0 and strong results on Arena-Hard. Through extensive experiments, we showthat our approach consistently outperforms traditional sample-level feedbackmethods with significantly fewer feedback collections and improves performanceacross different model architectures.",Shuhaib Mehri,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04510v1,Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems,http://arxiv.org/abs/2502.04510v1,"We propose Heterogeneous Swarms, an algorithm to design multi-LLM systems byjointly optimizing model roles and weights. We represent multi-LLM systems asdirected acyclic graphs (DAGs) of LLMs with topological message passing forcollaborative generation. Given a pool of LLM experts and a utility function,Heterogeneous Swarms employs two iterative steps: role-step and weight-step.For role-step, we interpret model roles as learning a DAG that specifies theflow of inputs and outputs between LLMs. Starting from a swarm of randomcontinuous adjacency matrices, we decode them into discrete DAGs, call the LLMsin topological order, evaluate on the utility function (e.g. accuracy on atask), and optimize the adjacency matrices with particle swarm optimizationbased on the utility score. For weight-step, we assess the contribution ofindividual LLMs in the multi-LLM systems and optimize model weights with swarmintelligence. We propose JFK-score to quantify the individual contribution ofeach LLM in the best-found DAG of the role-step, then optimize model weightswith particle swarm optimization based on the JFK-score. Experimentsdemonstrate that Heterogeneous Swarms outperforms 15 role- and/or weight-basedbaselines by 18.5% on average across 12 tasks. Further analysis reveals thatHeterogeneous Swarms discovers multi-LLM systems with heterogeneous model rolesand substantial collaborative gains, and benefits from the diversity oflanguage models.",Shangbin Feng,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04508v1,Clash of the Titans: ultra-high energy KM3NeT event versus IceCube data,http://arxiv.org/abs/2502.04508v1,"KM3NET has reported the detection of a remarkably high-energy through-goingmuon. Lighting up about a third of the detector, this muon could originate froma neutrino exceeding 10 PeV energy. The crucial question we need to answer iswhere this event comes from and what its source is. Intriguingly, IceCube hasbeen running with a much larger effective area for a much longer time, and yetit has not reported neutrinos above 10 PeV. We quantify the tension between theKM3NeT event with the absence of similar high-energy events in IceCube. Througha detailed analysis, we determine the most likely neutrino energy to be in therange 23-2400 PeV. We find a $3.8\sigma$ tension between the two experimentsassuming the neutrino to be from the diffuse isotropic neutrino background.Alternatively, assuming the event is of cosmogenic origin and considering threerepresentative models, this tension still falls within 3.2-3.9$\sigma$. Theleast disfavored scenario is a steady or transient point source, though stillleading to $2.9\sigma$ and $2.1\sigma$ tensions, respectively. The lack ofobservation of high-energy events in IceCube seriously challenges theexplanation of this event coming from any known diffuse fluxes. Our resultsindicate the KM3NeT event is likely the first observation of a newastrophysical source.",Shirley Weishi Li,2025-02-06,2025-02-06,,N/A,"['astro-ph.HE', 'hep-ex', 'hep-ph']"
2502.04507v1,Fast Video Generation with Sliding Tile Attention,http://arxiv.org/abs/2502.04507v1,"Diffusion Transformers (DiTs) with 3D full attention power state-of-the-artvideo generation, but suffer from prohibitive compute cost -- when generatingjust a 5-second 720P video, attention alone takes 800 out of 945 seconds oftotal inference time. This paper introduces sliding tile attention (STA) toaddress this challenge. STA leverages the observation that attention scores inpretrained video diffusion models predominantly concentrate within localized 3Dwindows. By sliding and attending over the local spatial-temporal region, STAeliminates redundancy from full attention. Unlike traditional token-wisesliding window attention (SWA), STA operates tile-by-tile with a novelhardware-aware sliding window design, preserving expressiveness while beinghardware-efficient. With careful kernel-level optimizations, STA offers thefirst efficient 2D/3D sliding-window-like attention implementation, achieving58.79% MFU. Precisely, STA accelerates attention by 2.8-17x overFlashAttention-2 (FA2) and 1.6-10x over FlashAttention-3 (FA3). On the leadingvideo DiT, HunyuanVideo, STA reduces end-to-end latency from 945s (FA3) to 685swithout quality degradation, requiring no training. Enabling finetuning furtherlowers latency to 268s with only a 0.09% drop on VBench.",Peiyuan Zhang,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04506v1,"When One LLM Drools, Multi-LLM Collaboration Rules",http://arxiv.org/abs/2502.04506v1,"This position paper argues that in many realistic (i.e., complex,contextualized, subjective) scenarios, one LLM is not enough to produce areliable output. We challenge the status quo of relying solely on a singlegeneral-purpose LLM and argue for multi-LLM collaboration to better representthe extensive diversity of data, skills, and people. We first posit that asingle LLM underrepresents real-world data distributions, heterogeneous skills,and pluralistic populations, and that such representation gaps cannot betrivially patched by further training a single LLM. We then organize existingmulti-LLM collaboration methods into a hierarchy, based on the level of accessand information exchange, ranging from API-level, text-level, logit-level, toweight-level collaboration. Based on these methods, we highlight how multi-LLMcollaboration addresses challenges that a single LLM struggles with, such asreliability, democratization, and pluralism. Finally, we identify thelimitations of existing multi-LLM methods and motivate future work. We envisionmulti-LLM collaboration as an essential path toward compositional intelligenceand collaborative AI development.",Shangbin Feng,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04505v1,Enhanced chemical vapour deposition of monolayer MoS2 films via a clean promoter,http://arxiv.org/abs/2502.04505v1,"Two-dimensional (2D) transition metal dichalcogenides (TMDCs), exemplified bymolybdenum disulfide (MoS2), have shown exceptional potential for data-centred,energy-efficient electronic applications due to their unique electrical,optoelectronic, and mechanical properties. However, challenges such as thecontrollable synthesis of high-quality, large-area 2D MoS2 films and themitigation of contamination during growth remain significant barriers to theirintegration into advanced technologies. Here, we developed a novelcontamination-free growth promoter, enabling the clean and scalable synthesisof high quality 2D MoS2 with desirable grain structures via chemical vapourdeposition (CVD). By optimising the reactant concentration and S/Mo ratio, weachieved promoter-dominated enhanced growth with enhanced quality, as evidencedby the increased MoS2 flake size and coverage, alongside a strong PL A excitonpeak at 1.84 eV, matching that of the mechanically exfoliated sample. Thisapproach facilitates the clean and site-specific growth of high-quality 2DMoS2, establishing a robust pathway for the practical implementation of 2D MoS2in next-generation electronic devices.",Lulin Wang,2025-02-06,2025-02-06,,N/A,"['cond-mat.mtrl-sci', 'cond-mat.mes-hall']"
2502.04501v1,ULPT: Prompt Tuning with Ultra-Low-Dimensional Optimization,http://arxiv.org/abs/2502.04501v1,"Large language models achieve state-of-the-art performance but are costly tofine-tune due to their size. Parameter-efficient fine-tuning methods, such asprompt tuning, address this by reducing trainable parameters while maintainingstrong performance. However, prior methods tie prompt embeddings to the model'sdimensionality, which may not scale well with larger LLMs and more customizedLLMs. In this paper, we propose Ultra-Low-dimensional Prompt Tuning (ULPT),which optimizes prompts in a low-dimensional space (e.g., 2D) and use a randombut frozen matrix for the up-projection. To enhance alignment, we introducelearnable shift and scale embeddings. ULPT drastically reduces the trainableparameters, e.g., 2D only using 2% parameters compared with vanilla prompttuning while retaining most of the performance across 21 NLP tasks. Ourtheoretical analysis shows that random projections can capture high-rankstructures effectively, and experimental results demonstrate ULPT's competitiveperformance over existing parameter-efficient methods.",Zijun Wu,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04500v1,Lattice stitching by eigenvector continuation for Holstein polaron,http://arxiv.org/abs/2502.04500v1,"Simulations of lattice particle - phonon systems are fundamentally restrictedby the exponential growth of the number of quantum states with the latticesize. Here, we demonstrate an algorithm that constructs the lowest eigenvalueand eigenvector for the Holstein model in extended lattices from eigenvalueproblems for small, independent lattice segments. This leads to exponentialreduction of the computational Hilbert space and allows applications ofvariational quantum algorithms to particle - phonon interactions in largelattices. We illustrate that the ground state of the Holstein polaron in theentire range of electron - phonon coupling, from weak to strong, and the lowestphonon frequency ($\omega/t = 0.1$) considered by numerical calculations todate can be obtained from a sequence of up to four-site problems. When combinedwith quantum algorithms, the present approach leads to a dramatic reduction ofrequired quantum resources. We show that the ground state of the Holsteinpolaron in a lattice with 100 sites and 32 site phonons can be computed by avariational quantum eigensolver with 11 qubits.",Elham Torabian,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'cond-mat.other']"
2502.04499v1,Revisiting Intermediate-Layer Matching in Knowledge Distillation: Layer-Selection Strategy Doesn't Matter (Much),http://arxiv.org/abs/2502.04499v1,"Knowledge distillation (KD) is a popular method of transferring knowledgefrom a large ""teacher"" model to a small ""student"" model. KD can be divided intotwo categories: prediction matching and intermediate-layer matching. We explorean intriguing phenomenon: layer-selection strategy does not matter (much) inintermediate-layer matching. In this paper, we show that seemingly nonsensicalmatching strategies such as matching the teacher's layers in reverse stillresult in surprisingly good student performance. We provide an interpretationfor this phenomenon by examining the angles between teacher layers viewed fromthe student's perspective.",Zony Yu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL', 'I.2.7; I.2.6']"
2502.04498v1,Verifiable Format Control for Large Language Model Generations,http://arxiv.org/abs/2502.04498v1,"Recent Large Language Models (LLMs) have demonstrated satisfying generalinstruction following ability. However, small LLMs with about 7B parametersstill struggle fine-grained format following (e.g., JSON format), whichseriously hinder the advancements of their applications. Most existing methodsfocus on benchmarking general instruction following while overlook how toimprove the specific format following ability for small LLMs. Besides, thesemethods often rely on evaluations based on advanced LLMs (e.g., GPT-4), whichcan introduce the intrinsic bias of LLMs and be costly due to the API calls. Inthis paper, we first curate a fully verifiable format following dataset VFF. Incontrast to existing works often adopting external LLMs forinstruction-following validations, every sample of VFF can be easily validatedwith a Python function. Further, we propose to leverage this verifiable featureto synthesize massive data for progressively training small LLMs, in order toimprove their format following abilities. Experimental results highlight theprevalent limitations in the format following capabilities of 7B levelopen-source LLMs and demonstrate the effectiveness of our method in enhancingthis essential ability.",Zhaoyang Wang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04496v1,Chiral effective model of cold and dense two-color QCD: The linear sigma model approach,http://arxiv.org/abs/2502.04496v1,"This review is devoted to summarizing recent developments of the linear sigmamodel (LSM) in cold and dense two-color QCD (QC$_2$D), in which latticesimulations are straightforwardly applicable thanks to the disappearance of thesign problem. In QC$_2$D, both theoretical and numerical studies derive thepresence of the so-called baryon superfluid phase at sufficiently largechemical potential ($\mu_q$), where diquark condensates govern the groundstate. The hadron mass spectrum simulated in this phase shows that the mass ofan iso-singlet ($I=0$) and $0^-$ state is remarkably reduced, but such a modecannot be described by the chiral perturbation theory. Motivated by this fact,I invent the LSM constructed upon the linear representation of chiral symmetry,or more precisely the Pauli-G\""ursey symmetry. Then, it is shown that my LSMsuccessfully reproduces the low-lying hadron mass spectrum in a broad range of$\mu_q$ simulated on the lattice. As applications of the LSM, topologicalsusceptibility and sound velocity in cold and dense QC$_2$D are evaluated tocompare with lattice results. Besides, generalized Gell-Mann-Oakes-Rennerrelation and hardon mass spectrum in the presence of a diquark source areanalyzed. I also introduce an extended version of the LSM incorporatingspin-$1$ hadrons.",Daiki Suenaga,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'hep-lat', 'nucl-th']"
2502.04493v1,LUND-PROBE -- LUND Prostate Radiotherapy Open Benchmarking and Evaluation dataset,http://arxiv.org/abs/2502.04493v1,"Radiotherapy treatment for prostate cancer relies on computed tomography (CT)and/or magnetic resonance imaging (MRI) for segmentation of target volumes andorgans at risk (OARs). Manual segmentation of these volumes is regarded as thegold standard for ground truth in machine learning applications but to acquiresuch data is tedious and time-consuming. A publicly available clinical datasetis presented, comprising MRI- and synthetic CT (sCT) images, target and OARssegmentations, and radiotherapy dose distributions for 432 prostate cancerpatients treated with MRI-guided radiotherapy. An extended dataset with 35patients is also included, with the addition of deep learning (DL)-generatedsegmentations, DL segmentation uncertainty maps, and DL segmentations manuallyadjusted by four radiation oncologists. The publication of these resources aimsto aid research within the fields of automated radiotherapy treatment planning,segmentation, inter-observer analyses, and DL model uncertainty investigation.The dataset is hosted on the AIDA Data Hub and offers a free-to-use resourcefor the scientific community, valuable for the advancement of medical imagingand prostate cancer radiotherapy research.",Viktor Rogowski,2025-02-06,2025-02-06,,N/A,"['physics.med-ph', 'cs.CV', 'eess.IV']"
2502.04492v1,Multi-Agent Reinforcement Learning with Focal Diversity Optimization,http://arxiv.org/abs/2502.04492v1,"The advancement of Large Language Models (LLMs) and their finetuningstrategies has triggered the renewed interests in multi-agent reinforcementlearning. In this paper, we introduce a focal diversity-optimized multi-agentreinforcement learning approach, coined as MARL-Focal, with three uniquecharacteristics. First, we develop an agent-fusion framework for encouragingmultiple LLM based agents to collaborate in producing the final inferenceoutput for each LLM query. Second, we develop a focal-diversity optimized agentselection algorithm that can choose a small subset of the available agentsbased on how well they can complement one another to generate the query output.Finally, we design a conflict-resolution method to detect output inconsistencyamong multiple agents and produce our MARL-Focal output through reward-awareand policy-adaptive inference fusion. Extensive evaluations on five benchmarksshow that MARL-Focal is cost-efficient and adversarial-robust. Our multi-agentfusion model achieves performance improvement of 5.51\% compared to the bestindividual LLM-agent and offers stronger robustness over the TruthfulQAbenchmark. Code is available at https://github.com/sftekin/rl-focal",Selim Furkan Tekin,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04491v1,Provable Sample-Efficient Transfer Learning Conditional Diffusion Models via Representation Learning,http://arxiv.org/abs/2502.04491v1,"While conditional diffusion models have achieved remarkable success invarious applications, they require abundant data to train from scratch, whichis often infeasible in practice. To address this issue, transfer learning hasemerged as an essential paradigm in small data regimes. Despite its empiricalsuccess, the theoretical underpinnings of transfer learning conditionaldiffusion models remain unexplored. In this paper, we take the first steptowards understanding the sample efficiency of transfer learning conditionaldiffusion models through the lens of representation learning. Inspired bypractical training procedures, we assume that there exists a low-dimensionalrepresentation of conditions shared across all tasks. Our analysis shows thatwith a well-learned representation from source tasks, the samplecomplexity oftarget tasks can be reduced substantially. In addition, we investigate thepractical implications of our theoretical results in several real-worldapplications of conditional diffusion models. Numerical experiments are alsoconducted to verify our results.",Ziheng Cheng,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']"
2502.04490v1,High-precision direct decay energy measurements of the electron-capture decay of $^{97}$Tc,http://arxiv.org/abs/2502.04490v1,"A direct measurement of the ground-state-to-ground-state electron-capturedecay $Q$ ($Q_{\rm EC}$) value of $^{97}$Tc has been conducted employing thehigh resolving power phase-imaging ion-cyclotron-resonance technique with thedouble Penning trap mass spectrometer JYFLTRAP. The resulting $Q_{\rm EC}$value for $^{97}$Tc is 324.82(21) keV, exhibiting a precision approximately 19times higher than the value adopted in the newest Atomic Mass Evaluation(AME2020) and differing by 1.2$\sigma$. Furthermore, by combining this refined$Q$ value with nuclear energy-level data for the decay-daughter $^{97}$Mo, apotential ultra-low Q-value transition, possibly of allowed type, $^{97}$Tc(9/2$^{+}$, ground state) $\rightarrow$ $^{97}$Mo$^{*}$ (320(1) keV), wasevaluated for future long-term neutrino-mass determination experiments. Theground-state-to-excited-state electron-capture decay $Q$ value ($Q^{*}_{\rmEC}$) of this transition was determined to be 4.8(10) keV, confirming it to beenergetically allowed with a confidence level of exceeding 4$\sigma$. Thecaptures of electrons occupying the L and higher shells for this transition areenergetically allowed, giving a value of 2.0(10) keV for the closest distanceof $Q^{*}_{\rm EC}$ to the allowed binding energy of the L1 shell. To predictpartial half-lives and energy-release distributions for this transition, theatomic self-consistent many-electron Dirac--Hartree--Fock--Slater method andthe nuclear shell model have been employed. Dominant correction terms such asexchange and overlap corrections, as well as shake-up and shake-off effects,were included in the final results. Moreover, the normalized distribution ofreleased energy in the electron-capture decay of $^{97}$Tc to excited states of$^{97}$Mo, is compared with that of $^{163}$Ho, which is being used forelectron-neutrino-mass determination.",Zhuang Ge,2025-02-06,2025-02-06,,N/A,"['nucl-ex', 'nucl-th']"
2502.04489v1,CNN Autoencoders for Hierarchical Feature Extraction and Fusion in Multi-sensor Human Activity Recognition,http://arxiv.org/abs/2502.04489v1,"Deep learning methods have been widely used for Human Activity Recognition(HAR) using recorded signals from Iner-tial Measurement Units (IMUs) sensorsthat are installed on various parts of the human body. For this type of HAR,sev-eral challenges exist, the most significant of which is the analysis ofmultivarious IMU sensors data. Here, we introduce a Hierarchically UnsupervisedFusion (HUF) model designed to extract, and fuse features from IMU sensors datavia a hybrid structure of Convolutional Neural Networks (CNN)s and Autoencoders(AE)s. First, we design a stack CNN-AE to embed short-time signals into sets ofhigh dimensional features. Second, we develop another CNN-AE network to locallyfuse the extracted features from each sensor unit. Finally, we unify all thesensor features through a third CNN-AE architecture as globally feature fusionto create a unique feature set. Additionally, we analyze the effects of varyingthe model hyperparameters. The best results are achieved with eightconvolutional layers in each AE. Furthermore, it is determined that anovercomplete AE with 256 kernels in the code layer is suitable for featureextraction in the first block of the proposed HUF model; this number reduces to64 in the last block of the model to customize the size of the applied featuresto the classifier. The tuned model is applied to the UCI-HAR, DaLiAc, andParkinson's disease gait da-tasets, achieving the classification accuracies of97%, 97%, and 88%, respectively, which are nearly 3% better com-pared to thestate-of-the-art supervised methods.",Saeed Arabzadeh,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04488v1,"Building A Unified AI-centric Language System: analysis, framework and future work",http://arxiv.org/abs/2502.04488v1,"Recent advancements in large language models have demonstrated that extendedinference through techniques can markedly improve performance, yet these gainscome with increased computational costs and the propagation of inherent biasesfound in natural languages. This paper explores the design of a unifiedAI-centric language system that addresses these challenges by offering a moreconcise, unambiguous, and computationally efficient alternative to traditionalhuman languages. We analyze the limitations of natural language such as genderbias, morphological irregularities, and contextual ambiguities and examine howthese issues are exacerbated within current Transformer architectures, whereredundant attention heads and token inefficiencies prevail. Drawing on insightsfrom emergent artificial communication systems and constructed languages likeEsperanto and Lojban, we propose a framework that translates diverse naturallanguage inputs into a streamlined AI-friendly language, enabling moreefficient model training and inference while reducing memory footprints.Finally, we outline a pathway for empirical validation through controlledexperiments, paving the way for a universal interchange format that couldrevolutionize AI-to-AI and human-to-AI interactions by enhancing clarity,fairness, and overall performance.",Edward Hong Wang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04487v1,A comparison of phase field models of brittle fracture incorporating strength: I -- Mixed-mode loading,http://arxiv.org/abs/2502.04487v1,"The classical variational phase-field model for brittle fracture effectivelypredicts the growth of large pre-existing cracks. However, the modeling ofcrack nucleation continues to be a significant challenge. Crack nucleationunder uniform stress depends on the material's strength surface whosedescription is fundamentally incompatible with the energy-based Griffithpropagation criterion. To address this, three main phase-field approaches haveemerged, each attempting to reconcile material strength and toughness. Thefirst, known as the classical variational approach, preserves the variationalstructure but fails to accurately incorporate the strength surface. Incontrast, the other two approaches -- the complete nucleation and hybridcohesive zone models -- sacrifice variational consistency. Among these, onlythe complete nucleation approach precisely accounts for the strength surface.All three approaches, especially the second one, deviate from the sharpvariational theory of brittle fracture, raising concerns about theirreliability in predicting the growth of cracks under non-mode-I loading. Thispaper evaluates precisely this issue. It is the first in a series of studiescomparing the three approaches, systematically investigating crack growth undermode II, mode III, and mixed-mode loadings. The results confirm that thecomplete nucleation approach effectively predicts crack growth across allinvestigated problems, and its predictions agree well with those from other twoapproaches for tension-dominated cases. Additionally, the findings highlightthat inaccurate accounting of the strength surface in the classical variationalapproach can influence crack path predictions. Lastly, they reveal thatmodifying the crack driving force to incorporate the strength surface in thehybrid cohesive zone approach causes crack propagation at an incorrect fracturetoughness.",Umar Khayaz,2025-02-06,2025-02-06,,N/A,['cond-mat.mtrl-sci']
2502.04486v1,An Alternate Method for Minimizing $χ^2$,http://arxiv.org/abs/2502.04486v1,"In this paper, we describe an algorithm and associated software package(sfit_minimize) for maximizing the likelihood function of a set of parametersby minimizing $\chi^2$. The key element of this method is that the algorithmestimates the second derivative of the $\chi^2$ function using firstderivatives of the function to be fitted. These same derivatives can also beused to calculate the uncertainties in each parameter. We test this algorithmagainst several standard minimization algorithms in SciPy.optimize.minimize()by fitting point lens models to light curves from the 2018 Korea MicrolensingTelescope Network event database. We show that for fitting microlensing events,SFit works faster than the Nelder-Mead simplex method and is more reliable thanthe BFGS gradient method; we also find that the Newton-CG method is noteffective for fitting microlensing events.",Jennifer C. Yee,2025-02-06,2025-02-06,,N/A,['astro-ph.IM']
2502.04485v1,Active Task Disambiguation with LLMs,http://arxiv.org/abs/2502.04485v1,"Despite the impressive performance of large language models (LLMs) acrossvarious benchmarks, their ability to address ambiguously specifiedproblems--frequent in real-world interactions--remains underexplored. Toaddress this gap, we introduce a formal definition of task ambiguity and framethe problem of task disambiguation through the lens of Bayesian ExperimentalDesign. By posing clarifying questions, LLM agents can acquire additional taskspecifications, progressively narrowing the space of viable solutions andreducing the risk of generating unsatisfactory outputs. Yet, generatingeffective clarifying questions requires LLM agents to engage in a form ofmeta-cognitive reasoning, an ability LLMs may presently lack. Our proposedapproach of active task disambiguation enables LLM agents to generate targetedquestions maximizing the information gain. Effectively, this approach shiftsthe load from implicit to explicit reasoning about the space of viablesolutions. Empirical results demonstrate that this form of question selectionleads to more effective task disambiguation in comparison to approaches relyingon reasoning solely within the space of questions.",Katarzyna Kobalczyk,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04484v1,The ML Supply Chain in the Era of Software 2.0: Lessons Learned from Hugging Face,http://arxiv.org/abs/2502.04484v1,"The last decade has seen widespread adoption of Machine Learning (ML)components in software systems. This has occurred in nearly every domain, fromnatural language processing to computer vision. These ML components range fromrelatively simple neural networks to complex and resource-intensive largelanguage models. However, despite this widespread adoption, little is knownabout the supply chain relationships that produce these models, which can haveimplications for compliance and security. In this work, we conduct an extensiveanalysis of 760,460 models and 175,000 datasets mined from the popularmodel-sharing site Hugging Face. First, we evaluate the current state ofdocumentation in the Hugging Face supply chain, report real-world examples ofshortcomings, and offer actionable suggestions for improvement. Next, weanalyze the underlying structure of the extant supply chain. Finally, weexplore the current licensing landscape against what was reported in prior workand discuss the unique challenges posed in this domain. Our results motivatemultiple research avenues, including the need for better license management forML models/datasets, better support for model documentation, and automatedinconsistency checking and validation. We make our research infrastructure anddataset available to facilitate future research.",Trevor Stalnaker,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.LG']"
2502.04483v1,Measuring Physical Plausibility of 3D Human Poses Using Physics Simulation,http://arxiv.org/abs/2502.04483v1,"Modeling humans in physical scenes is vital for understandinghuman-environment interactions for applications involving augmented reality orassessment of human actions from video (e.g. sports or physicalrehabilitation). State-of-the-art literature begins with a 3D human pose, frommonocular or multiple views, and uses this representation to ground the personwithin a 3D world space. While standard metrics for accuracy capture jointposition errors, they do not consider physical plausibility of the 3D pose.This limitation has motivated researchers to propose other metrics evaluatingjitter, floor penetration, and unbalanced postures. Yet, these approachesmeasure independent instances of errors and are not representative of balanceor stability during motion. In this work, we propose measuring physicalplausibility from within physics simulation. We introduce two metrics tocapture the physical plausibility and stability of predicted 3D poses from any3D Human Pose Estimation model. Using physics simulation, we discovercorrelations with existing plausibility metrics and measuring stability duringmotion. We evaluate and compare the performances of two state-of-the-artmethods, a multi-view triangulated baseline, and ground truth 3D markers fromthe Human3.6m dataset.",Nathan Louis,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04479v1,Removal of radon progeny from delicate surfaces,http://arxiv.org/abs/2502.04479v1,$\rm ^{210}Po$ $\alpha$-decay driven neutron background is a concern for manylow-energy rare event experiments. It is a difficult-to-control background thatdepends on the air exposure history of parts. In this study we demonstrate thatabout half of the radon progeny $\rm ^{210}Po$ can be removed from copper andsilicon surfaces by wiping it with an acetone wetted tissue. For a coppersample we demonstrate that $\rm ^{210}Pb$ is removed with similareffectiveness. Additional wiping was found to be largely ineffective.,D. Chernyak,2025-02-06,2025-02-06,,N/A,['physics.ins-det']
2502.04478v1,OneTrack-M: A multitask approach to transformer-based MOT models,http://arxiv.org/abs/2502.04478v1,"Multi-Object Tracking (MOT) is a critical problem in computer vision,essential for understanding how objects move and interact in videos. This fieldfaces significant challenges such as occlusions and complex environmentaldynamics, impacting model accuracy and efficiency. While traditional approacheshave relied on Convolutional Neural Networks (CNNs), introducing transformershas brought substantial advancements. This work introduces OneTrack-M, atransformer-based MOT model designed to enhance tracking computationalefficiency and accuracy. Our approach simplifies the typical transformer-basedarchitecture by eliminating the need for a decoder model for object detectionand tracking. Instead, the encoder alone serves as the backbone for temporaldata interpretation, significantly reducing processing time and increasinginference speed. Additionally, we employ innovative data pre-processing andmultitask training techniques to address occlusion and diverse objectivechallenges within a single set of weights. Experimental results demonstratethat OneTrack-M achieves at least 25% faster inference times compared tostate-of-the-art models in the literature while maintaining or improvingtracking accuracy metrics. These improvements highlight the potential of theproposed solution for real-time applications such as autonomous vehicles,surveillance systems, and robotics, where rapid responses are crucial forsystem effectiveness.",Luiz C. S. de Araujo,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG', 'I.4.8']"
2502.04477v1,Near-Optimal Sample Complexity for MDPs via Anchoring,http://arxiv.org/abs/2502.04477v1,"We study a new model-free algorithm to compute $\varepsilon$-optimal policiesfor average reward Markov decision processes, in the weakly communicating case.Given a generative model, our procedure combines a recursive sampling techniquewith Halpern's anchored iteration, and computes an $\varepsilon$-optimal policywith sample and time complexity$\widetilde{O}(|\mathcal{S}||\mathcal{A}|\|h^*\|_{\text{sp}}^{2}/\varepsilon^{2})$both in high probability and in expectation. To our knowledge, this is the bestcomplexity among model-free algorithms, matching the known lower bound up to afactor $\|h^*\|_{\text{sp}}$. Although the complexity bound involves the spanseminorm $\|h^*\|_{\text{sp}}$ of the unknown bias vector, the algorithmrequires no prior knowledge and implements a stopping rule which guaranteeswith probability 1 that the procedure terminates in finite time. We alsoanalyze how these techniques can be adapted for discounted MDPs.",Jongmin Lee,2025-02-06,2025-02-06,,N/A,"['math.OC', 'cs.DS']"
2502.04476v1,ADIFF: Explaining audio difference using natural language,http://arxiv.org/abs/2502.04476v1,"Understanding and explaining differences between audio recordings is crucialfor fields like audio forensics, quality assessment, and audio generation. Thisinvolves identifying and describing audio events, acoustic scenes, signalcharacteristics, and their emotional impact on listeners. This paper stands outas the first work to comprehensively study the task of explaining audiodifferences and then propose benchmark, baselines for the task. First, wepresent two new datasets for audio difference explanation derived from theAudioCaps and Clotho audio captioning datasets. Using Large Language Models(LLMs), we generate three levels of difference explanations: (1) concisedescriptions of audio events and objects, (2) brief sentences about audioevents, acoustic scenes, and signal properties, and (3) comprehensiveexplanations that include semantics and listener emotions. For the baseline, weuse prefix tuning where audio embeddings from two audio files are used toprompt a frozen language model. Our empirical analysis and ablation studiesreveal that the naive baseline struggles to distinguish perceptually similarsounds and generate detailed tier 3 explanations. To address these limitations,we propose ADIFF, which introduces a cross-projection module, positioncaptioning, and a three-step training process to enhance the model's ability toproduce detailed explanations. We evaluate our model using objective metricsand human evaluation and show our model enhancements lead to significantimprovements in performance over naive baseline and SoTA Audio-Language Model(ALM) Qwen Audio. Lastly, we conduct multiple ablation studies to study theeffects of cross-projection, language model parameters, position captioning,third stage fine-tuning, and present our findings. Our benchmarks, findings,and strong baseline pave the way for nuanced and human-like explanations ofaudio differences.",Soham Deshmukh,2025-02-06,2025-02-06,,N/A,"['cs.SD', 'cs.AI', 'eess.AS']"
2502.04475v1,Augmented Conditioning Is Enough For Effective Training Image Generation,http://arxiv.org/abs/2502.04475v1,"Image generation abilities of text-to-image diffusion models havesignificantly advanced, yielding highly photo-realistic images from descriptivetext and increasing the viability of leveraging synthetic images to traincomputer vision models. To serve as effective training data, generated imagesmust be highly realistic while also sufficiently diverse within the support ofthe target data distribution. Yet, state-of-the-art conditional imagegeneration models have been primarily optimized for creative applications,prioritizing image realism and prompt adherence over conditional diversity. Inthis paper, we investigate how to improve the diversity of generated imageswith the goal of increasing their effectiveness to train downstream imageclassification models, without fine-tuning the image generation model. We findthat conditioning the generation process on an augmented real image and textprompt produces generations that serve as effective synthetic datasets fordownstream training. Conditioning on real training images contextualizes thegeneration process to produce images that are in-domain with the real imagedistribution, while data augmentations introduce visual diversity that improvesthe performance of the downstream classifier. We validateaugmentation-conditioning on a total of five established long-tail and few-shotimage classification benchmarks and show that leveraging augmentations tocondition the generation process results in consistent improvements over thestate-of-the-art on the long-tailed benchmark and remarkable gains in extremefew-shot regimes of the remaining four benchmarks. These results constitute animportant step towards effectively leveraging synthetic data for downstreamtraining.",Jiahui Chen,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.04473v1,Fermions and the Renormalisation Group at Large N,http://arxiv.org/abs/2502.04473v1,"We investigate fermionic quantum field theories using functionalrenormalisation. In the limit of many fermion flavours $N$, we demonstrate thattheories have exact solutions for their quantum effective actions given byquasi-local interaction functionals of fermion bilinears. The structure impliesthat local potential approximations are exact, exactly solvable, and that fieldanomalous dimensions vanish. Theories with non-trivial anomalous dimensions mayalso arise under conditions that are identified. We further demonstrate thathigher derivative interactions are inevitably induced by point-like ones,including at large-$N$. The local potential flows for fermionic theories withthe most general $U(N)$ symmetric interactions are provided. For sampletheories with scalar, pseudo-scalar, vector, or axial-vector interactions, weidentify conformal fixed points, scaling dimensions, conformal manifolds, andquantum-induced shifts in scaling dimensions of higher derivative interactions.We also study fermion mass generation, and subleading modifications due tofinite $N$ corrections. Implications for conformal field theories, andapplications in condensed matter and particle physics are indicated.",Charlie Cresswell-Hogg,2025-02-06,2025-02-06,,N/A,"['hep-th', 'cond-mat.str-el', 'hep-ph']"
2502.04471v1,Identifying Flaky Tests in Quantum Code: A Machine Learning Approach,http://arxiv.org/abs/2502.04471v1,"Testing and debugging quantum software pose significant challenges due to theinherent complexities of quantum mechanics, such as superposition andentanglement. One challenge is indeterminacy, a fundamental characteristic ofquantum systems, which increases the likelihood of flaky tests in quantumprograms. To the best of our knowledge, there is a lack of comprehensivestudies on quantum flakiness in the existing literature. In this paper, wepresent a novel machine learning platform that leverages multiple machinelearning models to automatically detect flaky tests in quantum programs. Ourevaluation shows that the extreme gradient boosting and decision tree-basedmodels outperform other models (i.e., random forest, k-nearest neighbors, andsupport vector machine), achieving the highest F1 score and MatthewsCorrelation Coefficient in a balanced dataset and an imbalanced dataset,respectively. Furthermore, we expand the currently limited dataset forresearchers interested in quantum flaky tests. In the future, we plan toexplore the development of unsupervised learning techniques to detect andclassify quantum flaky tests more effectively. These advancements aim toimprove the reliability and robustness of quantum software testing.",Khushdeep Kaur,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.LG']"
2502.04470v1,Color in Visual-Language Models: CLIP deficiencies,http://arxiv.org/abs/2502.04470v1,"This work explores how color is encoded in CLIP (Contrastive Language-ImagePre-training) which is currently the most influential VML (Visual Languagemodel) in Artificial Intelligence. After performing different experiments onsynthetic datasets created for this task, we conclude that CLIP is able toattribute correct color labels to colored visual stimulus, but, we come acrosstwo main deficiencies: (a) a clear bias on achromatic stimuli that are poorlyrelated to the color concept, thus white, gray and black are rarely assigned ascolor labels; and (b) the tendency to prioritize text over other visualinformation. Here we prove it is highly significant in color labelling throughan exhaustive Stroop-effect test. With the aim to find the causes of thesecolor deficiencies, we analyse the internal representation at the neuron level.We conclude that CLIP presents an important amount of neurons selective totext, specially in deepest layers of the network, and a smaller amount ofmulti-modal color neurons which could be the key of understanding the conceptof color properly. Our investigation underscores the necessity of refiningcolor representation mechanisms in neural networks to foster a morecomprehensive comprehension of colors as humans understand them, therebyadvancing the efficacy and versatility of multimodal models like CLIP inreal-world scenarios.",Guillem Arias,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04469v1,"No Images, No Problem: Retaining Knowledge in Continual VQA with Questions-Only Memory",http://arxiv.org/abs/2502.04469v1,"Continual Learning in Visual Question Answering (VQACL) requires models tolearn new visual-linguistic tasks (plasticity) while retaining knowledge fromprevious tasks (stability). The multimodal nature of VQACL presents uniquechallenges, requiring models to balance stability across visual and textualdomains while maintaining plasticity to adapt to novel objects and reasoningtasks. Existing methods, predominantly designed for unimodal tasks, oftenstruggle to balance these demands effectively. In this work, we introduceQUestion-only replay with Attention Distillation (QUAD), a novel approach forVQACL that leverages only past task questions for regularisation, eliminatingthe need to store visual data and addressing both memory and privacy concerns.QUAD achieves stability by introducing a question-only replay mechanism thatselectively uses questions from previous tasks to prevent overfitting to thecurrent task's answer space, thereby mitigating the out-of-answer-set problem.Complementing this, we propose attention consistency distillation, whichuniquely enforces both intra-modal and inter-modal attention consistency acrosstasks, preserving essential visual-linguistic associations. Extensiveexperiments on VQAv2 and NExT-QA demonstrate that QUAD significantlyoutperforms state-of-the-art methods, achieving robust performance in continualVQA.",Imad Eddine Marouf,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04468v1,Iterative Importance Fine-tuning of Diffusion Models,http://arxiv.org/abs/2502.04468v1,"Diffusion models are an important tool for generative modelling, serving aseffective priors in applications such as imaging and protein design. A keychallenge in applying diffusion models for downstream tasks is efficientlysampling from resulting posterior distributions, which can be addressed usingthe $h$-transform. This work introduces a self-supervised algorithm forfine-tuning diffusion models by estimating the $h$-transform, enablingamortised conditional sampling. Our method iteratively refines the$h$-transform using a synthetic dataset resampled with path-based importanceweights. We demonstrate the effectiveness of this framework onclass-conditional sampling and reward fine-tuning for text-to-image diffusionmodels.",Alexander Denker,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'eess.IV', 'math.PR', '68T07', 'I.4.9; I.2.6']"
2502.04467v1,Efficient variable-length hanging tether parameterization for marsupial robot planning in 3D environments,http://arxiv.org/abs/2502.04467v1,"This paper presents a novel approach to efficiently parameterize and estimatethe state of a hanging tether for path and trajectory planning of a UGV tied toa UAV in a marsupial configuration. Most implementations in the state of theart assume a taut tether or make use of the catenary curve to model the shapeof the hanging tether. The catenary model is complex to compute and must beinstantiated thousands of times during the planning process, becoming atime-consuming task, while the taut tether assumption simplifies the problem,but might overly restrict the movement of the platforms. In order to acceleratethe planning process, this paper proposes defining an analytical model toefficiently compute the hanging tether state, and a method to get a tetherstate parameterization free of collisions. We exploit the existing similaritybetween the catenary and parabola curves to derive analytical expressions ofthe tether state.",S. Martínez-Rozas,2025-02-06,2025-02-06,,N/A,['cs.RO']
2502.04465v1,FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks,http://arxiv.org/abs/2502.04465v1,"Large language models have revolutionized natural language processing throughself-supervised pretraining on massive datasets. Inspired by this success,researchers have explored adapting these methods to speech by discretizingcontinuous audio into tokens using neural audio codecs. However, existingapproaches face limitations, including high bitrates, the loss of eithersemantic or acoustic information, and the reliance on multi-codebook designswhen trying to capture both, which increases architectural complexity fordownstream tasks. To address these challenges, we introduce FocalCodec, anefficient low-bitrate codec based on focal modulation that utilizes a singlebinary codebook to compress speech between 0.16 and 0.65 kbps. FocalCodecdelivers competitive performance in speech resynthesis and voice conversion atlower bitrates than the current state-of-the-art, while effectively handlingmultilingual speech and noisy environments. Evaluation on downstream tasksshows that FocalCodec successfully preserves sufficient semantic and acousticinformation, while also being well-suited for generative modeling. Demosamples, code and checkpoints are available athttps://lucadellalib.github.io/focalcodec-web/.",Luca Della Libera,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.SD', 'eess.AS']"
2502.04463v1,Training Language Models to Reason Efficiently,http://arxiv.org/abs/2502.04463v1,"Scaling model size and training data has led to great advances in theperformance of Large Language Models (LLMs). However, the diminishing returnsof this approach necessitate alternative methods to improve model capabilities,particularly in tasks requiring advanced reasoning. Large reasoning models,which leverage long chain-of-thoughts, bring unprecedented breakthroughs inproblem-solving capabilities but at a substantial deployment cost associated tolonger generations. Reducing inference costs is crucial for the economicfeasibility, user experience, and environmental sustainability of these models.  In this work, we propose to train large reasoning models to reasonefficiently. More precisely, we use reinforcement learning (RL) to trainreasoning models to dynamically allocate inference-time compute based on taskcomplexity. Our method incentivizes models to minimize unnecessarycomputational overhead while maintaining accuracy, thereby achievingsubstantial efficiency gains. It enables the derivation of a family ofreasoning models with varying efficiency levels, controlled via a singlehyperparameter. Experiments on two open-weight large reasoning modelsdemonstrate significant reductions in inference cost while preserving most ofthe accuracy.",Daman Arora,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL']"
2502.04462v1,"Correspondence between Myrzakulov $F(R,Q)$ gravity and Tsallis cosmology",http://arxiv.org/abs/2502.04462v1,"We investigate the correspondence between Myrzakulov $F(R,Q)$ gravity andTsallis cosmology. The former is a modified gravity that uses both curvatureand nonmetricity, while the latter is a modified cosmology arising from thegravity-thermodynamics conjecture, employing Tsallis entropy instead of theBekenstein-Hawking one. By appropriately identifying the functionaldependencies and the model parameters, we demonstrate that both frameworks cangive identical background evolution, reproducing the standard cosmologicalsequence of matter and dark energy domination. However, their perturbationbehavior exhibits differences, since the growth of density fluctuations and theeffective Newton constant deviate between the two scenarios, indicating thatperturbative observables, such as structure formation and weak-lensing ones,could serve as distinguishing factors between them.",Andreas Lymperis,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.CO']"
2502.04459v1,Turbulence-Generated Stepped Safety Factor Profiles in Tokamaks with Low Magnetic Shear,http://arxiv.org/abs/2502.04459v1,"Nonlinear local and global gyrokinetic simulations of tokamak plasmasdemonstrate that turbulence-generated currents flatten the safety factorprofile near low-order rational surfaces when magnetic shear is low, even whenthe plasma $\beta$ is small. A large set of flux tube simulations withdifferent safety factor profiles (e.g. linear and non-linear safety factorprofiles) and global simulations with reversed magnetic shear profiles showthat such stepped safety factor profiles dramatically reduce the heat transportand are a robust phenomenon. This mechanism may play a key role in thetriggering of internal transport barriers (ITBs) and more generally revealnovel strategies for improving confinement in devices with low magnetic shear.",Arnas Volčokas,2025-02-06,2025-02-06,,N/A,['physics.plasm-ph']
2502.04457v1,"""In order that"" -- a data driven study of symptoms and causes of obsolescence",http://arxiv.org/abs/2502.04457v1,"The paper is an empirical case study of grammatical obsolescence in progress.The main studied variable is the purpose subordinator in order that, which isshown to be steadily decreasing in the frequency of use starting from thebeginning of the twentieth century. This work applies a data-driven approachfor the investigation and description of obsolescence, recently developed bythe Rudnicka (2019). The methodology combines philological analysis withstatistical methods used on data acquired from mega-corpora. Moving from thedescription of possible symptoms of obsolescence to different causes for it,the paper aims at presenting a comprehensive account of the studied phenomenon.Interestingly, a very significant role in the decline of in order that can beascribed to the so-called higher-order processes, understood as processesinfluencing the constructional level from above. Two kinds of higher-orderprocesses are shown to play an important role, namely i) anexternally-motivated higher-order process exemplified by the drasticsocio-cultural changes of the 19th and 20th centuries; ii) aninternally-motivated higher-order processes instantiated by the rise of theto-infinitive (rise of infinite clauses).",Karolina Rudnicka,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.CY']"
2502.04453v1,Spatiotemporal dynamics of nanosecond pulsed discharge in the form of a fast ionization wave: self-consistent two-dimensional modeling and comparison with experiments under negative and positive polarity,http://arxiv.org/abs/2502.04453v1,"Nanosecond discharges are characterized by a shift in energy branching towardthe excitation of electronic levels and dissociation, making them particularlyattractive for plasma chemistry. Understanding the spatiotemporal structure ofthese discharges is especially important. This paper presents a detailed2D-axisymmetric numerical analysis of a nanosecond discharge propagating in along tube and in pure nitrogen. The modeling is conducted using aself-consistent plasma fluid solver under the local mean energy approximation(LMEA), including photoionization. The discharge develops at moderatepressures, 1 - 10 Torr, in the form of a fast ionization wave (FIW).Simulations are performed for both negative and positive polarities of thevoltage pulse applied to the high-voltage electrode. The computational resultsare validated against available experimental data, including FIW velocitywithin the studied pressure range, electron density, longitudinal electricfield, and the radial distribution of N2(C) emission on a nanosecond timescale.",Konstantinos Kourtzanidis,2025-02-06,2025-02-06,,N/A,"['physics.plasm-ph', 'physics.app-ph']"
2502.04452v1,Compact protoplanetary discs can be produced by dead zones,http://arxiv.org/abs/2502.04452v1,"Radially compact protoplanetary discs (<=50 au) are ubiquitous in nearbystar-forming regions. Multiple mechanisms have been invoked to interpretvarious compact discs. In this paper, we propose that fragmentation of fragiledust grains in moderate turbulence, as expected beyond the dead zone, providesan effective alternative mechanism to form compact discs which are consistentwith current observations. We run 1-D dust transport and collision models withDustPy and generate synthetic observations, and find that discs formed by thismechanism have sizes determined by the extent of their dead zones. Accountingfor dust porosity, and considering less fragile dust, do not change disc sizessignificantly. The smooth dust morphology can be altered only when pressurebumps are present in the dead zone. However, when present at small radii (<=10au), pressure bumps cannot effectively trap dust. Dust in these bumps fragmentsand replenishes the inner discs, effectively hiding dust traps in the opticallythick inner disc from observations. We note a striking resemblance in theradial intensity profile between our synthetic observations and some recenthigh-resolution observations of compact discs. We discuss how such observationscan inform our understanding of the underlying disc physics.",Simin Tong,2025-02-06,2025-02-06,,N/A,['astro-ph.EP']
2502.04451v1,The Evolution of Hypervelocity Supernova Survivors and the Outcomes of Interacting Double White Dwarf Binaries,http://arxiv.org/abs/2502.04451v1,"The recent prediction and discovery of hypervelocity supernova survivors hasprovided strong evidence that the ""dynamically driven double-degeneratedouble-detonation"" (D6) Type Ia supernova scenario occurs in Nature. In thismodel, the accretion stream from the secondary white dwarf in a double whitedwarf binary strikes the primary white dwarf violently enough to trigger ahelium shell detonation, which in turn triggers a carbon/oxygen coredetonation. If the secondary white dwarf survives the primary's explosion, itwill be flung away as a hypervelocity star. While previous work has shown thatthe hotter observed D6 stars can be broadly understood as secondaries whoseouter layers have been heated by their primaries' explosions, the properties ofthe cooler D6 stars have proven difficult to reproduce. In this paper, we showthat the cool D6 stars can be explained by the Kelvin-Helmholtz contraction ofhelium or carbon/oxygen white dwarfs that underwent significant mass loss andcore heating prior to and during the explosion of their white dwarf companions.We find that the current population of known D6 candidates is consistent with~2% of Type Ia supernovae leaving behind a hypervelocity surviving companion.We also calculate the evolution of hot, low-mass oxygen/neon stars and findreasonable agreement with the properties of the LP 40-365 class ofhypervelocity survivors, suggesting that these stars are the kicked remnants ofnear-Chandrasekhar-mass oxygen/neon white dwarfs that were partially disruptedby oxygen deflagrations. We use these results as motivation for schematicdiagrams showing speculative outcomes of interacting double white dwarfbinaries, including long-lived merger remnants, Type Ia supernovae, and severalkinds of peculiar transients.",Ken J. Shen,2025-02-06,2025-02-06,,N/A,"['astro-ph.SR', 'astro-ph.HE']"
2502.04449v1,KiDS-1000: Detection of deviations from a purely cold dark-matter power spectrum with tomographic weak gravitational lensing,http://arxiv.org/abs/2502.04449v1,"Model uncertainties in the nonlinear structure growth limit current probes ofcosmological parameters. To shed more light on the physics of nonlinear scales,we reconstruct the finely binned three-dimensional power-spectrum from lensingdata of the Kilo-Degree Survey (KiDS), relying solely on the backgroundcosmology, source redshift distributions, and the intrinsic alignment (IA)amplitude of sources (and their uncertainties). The adopted Tikhonovregularisation stabilises the deprojection, enabling a Bayesian reconstructionin separate $z$-bins. Following a detailed description of the algorithm andperformance tests with mock data, we present our results for the power spectrumas relative deviations from a $\Lambda\rm CDM$ reference spectrum that includesonly structure growth by cold dark matter. Averaged over the full range$z\lesssim1$, a \emph{Planck}-consistent reference then requires a significantsuppression on nonlinear scales, $k=0.05$--$10\,h\,\rm Mpc^{-1}$, of up to$20\%$--$30\%$ to match KiDS-1000 ($68\%$ credible interval, CI). Conversely, areference with a lower $S_8\approx0.73$ avoids suppression and matches theKiDS-1000 spectrum within a $20\%$ tolerance. When resolved into three$z$-bins, however, and regardless of the reference, we detect structure growthonly between $z\approx0.4$--$0.13$, but not between $z\approx0.7$--$0.4$. Thiscould indicate spurious systematic errors in KiDS-1000, inaccuracies in theintrinsic alignment (IA) model, or potentially a non-standard cosmologicalmodel with delayed structure growth. In the near future, analysing data fromstage-IV surveys with our algorithm promises a substantially more precisereconstruction of the power spectrum.",Patrick Simon,2025-02-06,2025-02-06,,N/A,['astro-ph.CO']
2502.04446v1,Enhancing the accuracy of observable distributions for galaxies classified in the Projected Phase Space Diagram,http://arxiv.org/abs/2502.04446v1,"Studies of galaxy populations classified according to their kinematicbehaviours and dynamical state using the Projected Phase Space Diagram (PPSD)are affected by misclassification and contamination, leading to systematicerrors in determining the characteristics of the different galaxy classes. Wepropose a method to statistically correct the determination of galaxyproperties' distributions accounting for the contamination caused bymisclassified galaxies from other classes. Using a sample of massive clustersand galaxies in their surroundings taken from the MultiDark Planck 2 simulationcombined with the semi-analytic model of galaxy formation SAG, we compute theconfusion matrix associated to a classification scheme in the PPSD. Based onpositions in the PPSD, galaxies are classified as cluster members, backsplashgalaxies, recent infallers, infalling galaxies, and interlopers. Thisclassification is determined using probabilities calculated by the code ROGER,along with a threshold criterion. By inverting the confusion matrix, we areable to get better determinations of distributions of galaxy properties such ascolour. Compared to a direct estimation based solely on the predicted galaxyclasses, our method provides better estimates of the mass-dependent colourdistribution for the galaxy classes most affected by misclassification: clustermembers, backsplash galaxies, and recent infallers. We apply the method to asample of observed X-ray clusters and galaxies. Our method can be applied toany classification of galaxies in the PPSD, and to any other galaxy propertybesides colour, provided an estimation of the confusion matrix. Blue, low-massgalaxies in clusters are almost exclusively recent infaller galaxies that havenot yet been quenched by the environmental action of the cluster. Backsplashgalaxies are on average redder than expected.",Héctor J. Martínez,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.04447v1,"A possible trail of dust from a young, highly-extincted brown dwarf in the outskirts of the Trapezium Cluster",http://arxiv.org/abs/2502.04447v1,"We present the JWST discovery of a highly-extincted ($A_V\sim52$) candidatebrown dwarf ($\sim0.018$M$_\odot$) in the outskirts of the Trapezium Clusterthat appears to be coincident with the end of a $\sim 1700\,$au long,remarkably uniformly wide, dark trail that broadens only slightly at the endopposite the point source. We examine whether a dusty trail associated with ahighly-extincted brown dwarf could plausibly be detected with JWST and explorepossible origins. We show that a dusty trail associated with the brown dwarfcould be observable if dust within it is larger than that in the ambientmolecular cloud. For example, if the ambient cloud has a standard$\sim0.25$$\mu$m maximum grain size and the trail contains micron-sized grains,then the trail will have a scattering opacity over an order of magnitude largercompared to the surroundings in NIRCam short-wavelength filters. We use asimple model to show that a change in maximum grain size can reproduce the high$A_V$ and the multi-filter NIRCam contrast seen between the trail and itssurroundings. We propose and explore two possible mechanisms that could beresponsible for the trail: i) a weak FUV radiation-driven wind from thecircum-brown dwarf disc due to the O stars in the region and ii) aBondi-Hoyle-Lyttleton accretion wake. The former would be the most distantknown case of the Trapezium stars' radiation driving winds from a disc, and thelatter would be the first known example of ``late'' infall from theinterstellar medium onto a low mass object in a high-mass star-forming region.",Thomas J. Haworth,2025-02-06,2025-02-06,,N/A,"['astro-ph.SR', 'astro-ph.EP']"
2502.04445v1,"Higgs-Induced Gravitational Waves: the Interplay of Non-Minimal Couplings, Kination and Top Quark Mass",http://arxiv.org/abs/2502.04445v1,"We explore a minimal scenario where the sole Standard-Model Higgs isresponsible for reheating the Universe after inflation, produces a significantbackground of gravitational waves and maintains the full classical stability ofthe electroweak vacuum. As the Higgs self-coupling runs toward negative valuesat high energy scales, a non-minimal interaction with curvature during a stiffbackground expansion era drives the Higgs fluctuations closer to theinstability scale. This curvature-induced tachyonic instability leads to anintense production of Higgs particles, accompanied by a stochasticgravitational-wave background. The characteristic features of such signal canbe directly correlated to the inflationary scale, the non-minimal couplingparameter and the top quark Yukawa coupling. We distinguish between threepossible scenarios: absolute stability with low top quark masses, potentialvacuum instability, and absolute stability with new physics above theinstability scale. Our findings suggest that the detection of a peakedbackground of gravitational waves together with its inflationary tail has thepotential to unveil the features of the Higgs effective potential at very highenergy scales while providing a minimal explanation for the reheating phase andthe emergence of the Standard-Model plasma in the early Universe. Unlike otherstudies in the literature, the generation of gravitational waves in ourscenario does not depend on the quantum instability of the Standard Modelvacuum.",Giorgio Laverda,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'astro-ph.CO', 'gr-qc']"
2502.04436v1,"Planet Masses, Radii, and Orbits from NASA's K2 Mission",http://arxiv.org/abs/2502.04436v1,"We report the masses, sizes, and orbital properties of 86 planets orbiting 55stars observed by NASA's K2 Mission with follow-up Doppler measurements by theHIRES spectrometer at the W. M. Keck Observatory and the Automated PlanetFinder at Lick Observatory. Eighty-one of the planets were discovered fromtheir transits in the K2 photometry, while five were found based on subsequentDoppler measurements of transiting planet host stars. The sizes of thetransiting planets range from Earth-size to larger than Jupiter (1-3 REarth istypical), while the orbital periods range from less than a day to a few months.For 32 of the planets, the Doppler signal was detected with significancegreater than 5-sigma (51 were detected with >3-sigma significance). Animportant characteristic of this catalog is the use of uniform analysisprocedures to determine stellar and planetary properties. This includes thetransit search and fitting procedures applied to the K2 photometry, the Dopplerfitting techniques applied to the radial velocities, and the spectral modelingto determine bulk stellar parameters. Such a uniform treatment will make thecatalog useful for statistical studies of the masses, densities, and systemarchitectures of exoplanetary systems. This work also serves as a data releasefor all previously unpublished RVs and associated stellar activity indicatorsobtained by our team for these systems, along with derived stellar and planetparameters.",Andrew W. Howard,2025-02-06,2025-02-06,,N/A,"['astro-ph.EP', 'astro-ph.IM', 'astro-ph.SR']"
2502.04430v1,Page Time of Primordial Black Holes: Standard Model and Beyond,http://arxiv.org/abs/2502.04430v1,"The Page time marks the moment when the von Neumann entropy of the emittedHawking radiation equals the Bekenstein-Hawking entropy of an evaporating blackhole, which is assumed to quantify its degrees of freedom as seen from theoutside. Beyond this point, from unitarity we would expect that the entropy ofthe radiation begins to decrease, ensuring that information is eventuallyrecovered. In this work, we investigate the dependence of the Page time onblack hole properties and the particle content of nature. Specifically, weanalyze its sensitivity to the Standard Model (SM) and potential Beyond-the-SMdegrees of freedom, incorporating the effects of particle masses. We find thata Schwarzschild primordial black hole (PBH) with an initial mass of $6.23\times10^{14}~{\rm g}$ would have a Page time equal to the age of the Universe,assuming emission of SM particles only. We further explore the impact of anon-negligible PBH angular momentum, finding that light spin-2 particles arepredominantly emitted before the Page time for Kerr black holes. For Forinitial angular momenta values exceeding $a_\star > 0.5$, approximately $70\%$of the total graviton emission occurs prior to the Page time for PBHs with aninitial mass $M_{\rm BH} \lesssim 10^{10}~{\rm g}$. Finally, we discuss theimplications for PBH phenomenology, particularly regarding potentialconstraints from $\Delta N_{\rm eff}$ measurements.",Yuber F. Perez-Gonzalez,2025-02-06,2025-02-06,,N/A,"['astro-ph.CO', 'gr-qc', 'hep-ph']"
2502.04431v1,Remarks on the Higgs Branch of 5d Conformal Matter,http://arxiv.org/abs/2502.04431v1,"Among the elementary building blocks in the atomic classification of 5d SCFTsthere are 5d bifundamental conformal matter theories of various kinds. In thiswork we study the Higgs branch of these models and of the correspondingmolecules arising from their fusion. To this aim we use two complementaryindependent strategies. On the one hand for the type $A$ and $D$ conformalmatter, we identify dual $(p,q)$ brane webs in IIB and exploit them to read offthe corresponding magnetic quivers. On the other hand, we exploit circlereductions and study the resulting 4d $\mathcal N=2$ SCFTs, giving analternative derivation of their Higgs branches which extend also to the $E$types.",Mario De Marco,2025-02-06,2025-02-06,,N/A,['hep-th']
2502.04432v1,"Searching for coupled, hyperlight scalars across cosmic history",http://arxiv.org/abs/2502.04432v1,"Cosmological scalar fields coupled to the Standard Model drive temporalvariations in the fundamental constants that grow with redshift, positioningthe early Universe as a powerful tool to study such models. We investigate thedynamics and phenomenology of coupled scalars from the early Universe to thepresent to consistently leverage the myriad searches for time-varying constantsand the cosmological signatures of scalars' gravitational effects. We computethe in-medium contribution from Standard Model particles to the scalar'sdynamics and identify only a limited range of couplings for which the scalarhas an observable impact on the fundamental constants without either evolvingbefore recombination or gravitating nonnegligibly. We then extend existinglaboratory and astrophysical bounds to the hyperlight scalar regime. We presentjoint limits from the early and late Universe, specializing to hyperlight,quadratically coupled scalars that modulate the mass of the electron or thestrength of electromagnetism and make up a subcomponent of the dark mattertoday. Our dedicated analysis of observations of the cosmic microwavebackground, baryon acoustic oscillations, and type Ia supernovae provides themost stringent constraints on quadratically coupled scalars with masses from$10^{-28.5}$ to $\sim 10^{-31}~\mathrm{eV}$, below which quasar absorptionspectra yield stronger bounds. These results jointly limit hyperlight scalarsthat comprise a few percent of the current dark matter density to near- orsubgravitational couplings to electrons or photons.",Masha Baryakhtar,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'astro-ph.CO']"
2502.04433v1,"A New Spectral Library for Modeling the Surfaces of Hot, Rocky Exoplanets",http://arxiv.org/abs/2502.04433v1,"JWST's MIRI LRS provides the first opportunity to spectroscopicallycharacterize the surface compositions of close-in terrestrial exoplanets.Models for the bare-rock spectra of these planets often utilize a spectrallibrary from R. Hu et al., which is based on room temperature reflectancemeasurements of materials that represent archetypes of rocky planet surfaces.Here we present an expanded library that includes hemispherical reflectancemeasurements for a greater variety of compositions, varying textures (solidslab, coarsely crushed, and fine powder), as well as high temperature (500-800K) emissivity measurements for select samples. We incorporate this new libraryinto version 6.3 of the retrieval package PLATON and use it to show thatsurfaces with similar compositions can have widely varying albedos and surfacetemperatures. We additionally demonstrate that changing the texture of amaterial can significantly alter its albedo, making albedo a poor proxy forsurface composition. We identify key spectral features -- the 5.6 \textmu{m}olivine feature, the transparency feature, the Si-O stretching feature, and theChristiansen feature -- that indicate silicate abundance and surface texture.We quantify the number of JWST observations needed to detect these features inthe spectrum of the most favorable super-Earth target, LHS 3844 b, and revisitthe interpretation of its Spitzer photometry. Lastly, we show thattemperature-dependent changes in spectral features are likely undetectable atthe precision of current exoplanet observations. Our results illustrate theimportance of spectroscopically-resolved thermal emission measurements, asdistinct from surface albedo constraints, for characterizing the surfacecompositions of hot, rocky exoplanets.",Kimberly Paragas,2025-02-06,2025-02-06,,N/A,['astro-ph.EP']
2502.04434v1,Searching for Inflationary Physics with the CMB Trispectrum: 1. Primordial Theory & Optimal Estimators,http://arxiv.org/abs/2502.04434v1,"The primordial four-point function encodes a wealth of information about theinflationary Universe. Despite extensive theoretical work, most models offour-point physics have never been compared to data. In this series, we conducta detailed analysis of Cosmic Microwave Background temperature and polarizationtrispectra, searching for a wide variety of phenomena including local effects,self-interactions, curvatons, DBI inflation, gauge fields, solid inflation,scalar field exchange, spinning massive field exchange, chiral physics, pointsources, and gravitational lensing. After presenting a suite of separableprimordial templates, we derive thirteen quasi-optimal estimators that directlyestimate the underlying template amplitudes. These are unbiased, minimumvariance, mask-deconvolved, and account for correlations between templates(including with lensing). Each estimator can be efficiently implemented usingspherical harmonic transforms, Monte Carlo methods, and optimizationtechniques, and asymptotes to standard forms in certain limits. In Paper 2, weimplement these estimators in public code, and in Paper 3, use them toconstrain primordial trispectra with Planck data. This enables a wide varietyof tests of inflation, including some of the first direct constraints oncosmological collider physics.",Oliver H. E. Philcox,2025-02-06,2025-02-06,,N/A,"['astro-ph.CO', 'gr-qc', 'hep-ph', 'hep-th']"
2502.04435v1,"1000-10,000 M$_\odot$ Primordial Stars Created the Nitrogen Excess in the Galaxy GS 3073 at $z = 5.55$",http://arxiv.org/abs/2502.04435v1,"The advent of the James Webb Space Telescope has revealed a wealth of newgalaxies just a few hundred Myr after the Big Bang. Some of these galaxiesexhibit unusual elemental abundances that are difficult to explain with stellarpopulations today. While Wolf-Rayet stars in multiple-burst populations, verymassive or rapidly-rotating primordial stars, general relativistic explosionsof metal-enriched supermassive stars, or the precursors of globular clusterscan in principle account for the supersolar nitrogen to oxygen ratios in thegalaxies GN-z11 and CEERS 1019, no known stars or supernovae can explain thefar higher N/O ratio of 0.46 in GS 3073 at redshift $z =$ 5.55. Here we showthat the extreme nitrogen abundances in GS 3073 can be produced by 1000 -10,000 M$_{\odot}$ primordial (Pop III) stars. We find that these are the onlycandidates that can account for its large N/O ratios and its C/O and Ne/Oratios. GS 3073 is thus the first conclusive evidence in the fossil abundancerecord of the existence of supermassive Pop III stars at cosmic Dawn.",Devesh Nandal,2025-02-06,2025-02-06,,N/A,"['astro-ph.GA', 'astro-ph.SR']"
2502.04330v1,"Geometrical frustration, power law tunneling and non-local gauge fields from scattered light",http://arxiv.org/abs/2502.04330v1,"Designing the amplitude and range of couplings in quantum systems is afundamental tool for exploring a large variety of quantum mechanical effects.Here, we consider off-resonant photon scattering processes on a geometricallyshaped molecular cloud. Our analysis shows that such a setup is properlymodeled by a Bose-Hubbard Hamiltonian where the range, amplitude and sign ofthe tunneling processes of the scattered photonic modes can be accuratelytuned. Specifically, by varying the molecular distribution, we demonstrate thatdifferent configurations characterized by geometrical frustration, long-rangepower law hopping processes, and non-local gauge fields can be achieved. Ourresults thus represent a powerful and alternative approach to perform anaccurate Hamiltonian engineering of quantum systems with non trivial couplingstructures.",Pavel P. Popov,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'cond-mat.quant-gas']"
2502.04329v1,SMART: Advancing Scalable Map Priors for Driving Topology Reasoning,http://arxiv.org/abs/2502.04329v1,"Topology reasoning is crucial for autonomous driving as it enablescomprehensive understanding of connectivity and relationships between lanes andtraffic elements. While recent approaches have shown success in perceivingdriving topology using vehicle-mounted sensors, their scalability is hinderedby the reliance on training data captured by consistent sensor configurations.We identify that the key factor in scalable lane perception and topologyreasoning is the elimination of this sensor-dependent feature. To address this,we propose SMART, a scalable solution that leverages easily availablestandard-definition (SD) and satellite maps to learn a map prior model,supervised by large-scale geo-referenced high-definition (HD) maps independentof sensor settings. Attributed to scaled training, SMART alone achievessuperior offline lane topology understanding using only SD and satelliteinputs. Extensive experiments further demonstrate that SMART can be seamlesslyintegrated into any online topology reasoning methods, yielding significantimprovements of up to 28% on the OpenLane-V2 benchmark.",Junjie Ye,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.RO']"
2502.04328v1,Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment,http://arxiv.org/abs/2502.04328v1,"Recent advances in large language models, particularly following GPT-4o, havesparked increasing interest in developing omni-modal models capable ofunderstanding more modalities. While some open-source alternatives haveemerged, there is still a notable lag behind specialized single-modality modelsin performance. In this paper, we present Ola, an Omni-modal language modelthat achieves competitive performance across image, video, and audiounderstanding compared to specialized counterparts. The core design of Ola liesin its progressive modality alignment strategy that extends the supportingmodality of the language model progressively. Our training pipeline begins withthe most distinct modalities: image and text, then gradually expands the skillsets of the model using speech data that connects language and audio knowledge,and video data that connects all modalities. The progressive learning pipelinealso enables us to maintain a relatively small size of the cross-modalalignment data, making developing omni-modal from existing vision-languagemodels easy and less costly. Moreover, to unlock an advanced interactiveexperience like GPT-4o, we further design a sentence-wise decoding solution forstreaming speech generation. Extensive experiments demonstrate that Olasurpasses existing open omni-modal LLMs across all modalities while achievinghighly competitive performance compared to state-of-the-art specialized modelsof similar sizes. We aim to make Ola a fully open omni-modal understandingsolution to advance future research in this emerging field. Model weights,code, and data are open-sourced at https://github.com/Ola-Omni/Ola.",Zuyan Liu,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.CL', 'cs.MM', 'cs.SD', 'eess.AS', 'eess.IV']"
2502.04327v1,Value-Based Deep RL Scales Predictably,http://arxiv.org/abs/2502.04327v1,"Scaling data and compute is critical to the success of machine learning.However, scaling demands predictability: we want methods to not only performwell with more compute or data, but also have their performance be predictablefrom small-scale runs, without running the large-scale experiment. In thispaper, we show that value-based off-policy RL methods are predictable despitecommunity lore regarding their pathological behavior. First, we show that dataand compute requirements to attain a given performance level lie on a Paretofrontier, controlled by the updates-to-data (UTD) ratio. By estimating thisfrontier, we can predict this data requirement when given more compute, andthis compute requirement when given more data. Second, we determine the optimalallocation of a total resource budget across data and compute for a givenperformance and use it to determine hyperparameters that maximize performancefor a given budget. Third, this scaling behavior is enabled by first estimatingpredictable relationships between hyperparameters, which is used to manageeffects of overfitting and plasticity loss unique to RL. We validate ourapproach using three algorithms: SAC, BRO, and PQL on DeepMind Control, OpenAIgym, and IsaacGym, when extrapolating to higher levels of data, compute,budget, or performance.",Oleh Rybkin,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04326v1,WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs,http://arxiv.org/abs/2502.04326v1,"In this paper, we introduce WorldSense, the first benchmark to assess themulti-modal video understanding, that simultaneously encompasses visual, audio,and text inputs. In contrast to existing benchmarks, our WorldSense has severalfeatures: (i) collaboration of omni-modality, we design the evaluation tasks tofeature a strong coupling of audio and video, requiring models to effectivelyutilize the synergistic perception of omni-modality; (ii) diversity of videosand tasks, WorldSense encompasses a diverse collection of 1,662 audio-visualsynchronised videos, systematically categorized into 8 primary domains and 67fine-grained subcategories to cover the broad scenarios, and 3,172 multi-choiceQA pairs across 26 distinct tasks to enable the comprehensive evaluation; (iii)high-quality annotations, all the QA pairs are manually labeled by 80 expertannotators with multiple rounds of correction to ensure quality. Based on ourWorldSense, we extensively evaluate various state-of-the-art models. Theexperimental results indicate that existing models face significant challengesin understanding real-world scenarios (48.0% best accuracy). We hope ourWorldSense can provide a platform for evaluating the ability in constructingand understanding coherent contexts from omni-modality.",Jack Hong,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04324v1,Can Grammarly and ChatGPT accelerate language change? AI-powered technologies and their impact on the English language: wordiness vs. conciseness,http://arxiv.org/abs/2502.04324v1,"The proliferation of NLP-powered language technologies, AI-based naturallanguage generation models, and English as a mainstream means of communicationamong both native and non-native speakers make the output of AI-powered toolsespecially intriguing to linguists. This paper investigates how Grammarly andChatGPT affect the English language regarding wordiness vs. conciseness. A casestudy focusing on the purpose subordinator in order to is presented toillustrate the way in which Grammarly and ChatGPT recommend shorter grammaticalstructures instead of longer and more elaborate ones. Although the analysedsentences were produced by native speakers, are perfectly correct, and wereextracted from a language corpus of contemporary English, both Grammarly andChatGPT suggest more conciseness and less verbosity, even for relatively shortsentences. The present article argues that technologies such as Grammarly notonly mirror language change but also have the potential to facilitate oraccelerate it.",Karolina Rudnicka,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.CY']"
2502.04323v1,The Uniformly Rotated Mondrian Kernel,http://arxiv.org/abs/2502.04323v1,"First proposed by Rahimi and Recht, random features are used to decrease thecomputational cost of kernel machines in large-scale problems. The Mondriankernel is one such example of a fast random feature approximation of theLaplace kernel, generated by a computationally efficient hierarchical randompartition of the input space known as the Mondrian process. In this work, westudy a variation of this random feature map by using uniformly randomlyrotated Mondrian processes to approximate a kernel that is invariant underrotations. We obtain a closed-form expression for this isotropic kernel, aswell as a uniform convergence rate of the uniformly rotated Mondrian kernel tothis limit. To this end, we utilize techniques from the theory of stationaryrandom tessellations in stochastic geometry and prove a new result on thegeometry of the typical cell of the superposition of uniformly random rotationsof Mondrian tessellations. Finally, we test the empirical performance of thisrandom feature map on both synthetic and real-world datasets, demonstrating itsimproved performance over the Mondrian kernel on a debiased dataset.",Calvin Osborne,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.PR']"
2502.04428v1,Confident or Seek Stronger: Exploring Uncertainty-Based On-device LLM Routing From Benchmarking to Generalization,http://arxiv.org/abs/2502.04428v1,"Large language models (LLMs) are increasingly deployed and democratized onedge devices. To improve the efficiency of on-device deployment, small languagemodels (SLMs) are often adopted due to their efficient decoding latency andreduced energy consumption. However, these SLMs often generate inaccurateresponses when handling complex queries. One promising solution isuncertainty-based SLM routing, offloading high-stakes queries to stronger LLMswhen resulting in low-confidence responses on SLM. This follows the principleof ""If you lack confidence, seek stronger support"" to enhance reliability.Relying on more powerful LLMs is yet effective but increases invocation costs.Therefore, striking a routing balance between efficiency and efficacy remains acritical challenge. Additionally, efficiently generalizing the routing strategyto new datasets remains under-explored. In this paper, we conduct acomprehensive investigation into benchmarking and generalization ofuncertainty-driven routing strategies from SLMs to LLMs over 1500+ settings.Our findings highlight: First, uncertainty-correctness alignment in differentuncertainty quantification (UQ) methods significantly impacts routingperformance. Second, uncertainty distributions depend more on both the specificSLM and the chosen UQ method, rather than downstream data. Building on theinsight, we propose a calibration data construction instruction pipeline andopen-source a constructed hold-out set to enhance routing generalization on newdownstream scenarios. The experimental results indicate calibration dataeffectively bootstraps routing performance without any new data.",Yu-Neng Chuang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04321v1,Variation of sentence length across time and genre,http://arxiv.org/abs/2502.04321v1,"The goal of this paper is threefold: i) to present some practical aspects ofusing full-text version of Corpus of Historical American English (COHA), thelargest diachronic multi-genre corpus of the English language, in theinvestigation of a linguistic trend of change; ii) to test a widely heldassumption that sentence length in written English has been steadily decreasingover the past few centuries; iii) to point to a possible link between thechanges in sentence length and changes in the English syntactic usage. Theempirical proof of concept for iii) is provided by the decline in the frequencyof the non-finite purpose subordinator in order to. Sentence length, genre andthe likelihood of occurrence of in order to are shown to be interrelated.",Karolina Rudnicka,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04322v1,Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions,http://arxiv.org/abs/2502.04322v1,"Despite extensive safety alignment efforts, large language models (LLMs)remain vulnerable to jailbreak attacks that elicit harmful behavior. Whileexisting studies predominantly focus on attack methods that require technicalexpertise, two critical questions remain underexplored: (1) Are jailbrokenresponses truly useful in enabling average users to carry out harmful actions?(2) Do safety vulnerabilities exist in more common, simple human-LLMinteractions? In this paper, we demonstrate that LLM responses most effectivelyfacilitate harmful actions when they are both actionable and informative--twoattributes easily elicited in multi-step, multilingual interactions. Using thisinsight, we propose HarmScore, a jailbreak metric that measures how effectivelyan LLM response enables harmful actions, and Speak Easy, a simple multi-step,multilingual attack framework. Notably, by incorporating Speak Easy into directrequest and jailbreak baselines, we see an average absolute increase of 0.319in Attack Success Rate and 0.426 in HarmScore in both open-source andproprietary LLMs across four safety benchmarks. Our work reveals a critical yetoften overlooked vulnerability: Malicious users can easily exploit commoninteraction patterns for harmful intentions.",Yik Siu Chan,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.CY']"
2502.04320v1,ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features,http://arxiv.org/abs/2502.04320v1,"Do the rich representations of multi-modal diffusion transformers (DiTs)exhibit unique properties that enhance their interpretability? We introduceConceptAttention, a novel method that leverages the expressive power of DiTattention layers to generate high-quality saliency maps that precisely locatetextual concepts within images. Without requiring additional training,ConceptAttention repurposes the parameters of DiT attention layers to producehighly contextualized concept embeddings, contributing the major discovery thatperforming linear projections in the output space of DiT attention layersyields significantly sharper saliency maps compared to commonly usedcross-attention mechanisms. Remarkably, ConceptAttention even achievesstate-of-the-art performance on zero-shot image segmentation benchmarks,outperforming 11 other zero-shot interpretability methods on theImageNet-Segmentation dataset and on a single-class subset of PascalVOC. Ourwork contributes the first evidence that the representations of multi-modal DiTmodels like Flux are highly transferable to vision tasks like segmentation,even outperforming multi-modal foundation models like CLIP.",Alec Helbling,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.04319v1,On the origin of the $Σ_1$-$M_\star$ quenching boundary,http://arxiv.org/abs/2502.04319v1,"We have considered a phenomenologically motivated model in which galaxies arequenched when the energy output of the central black hole exceeds a hundredtimes the gravitational binding energy of the baryons in the host halo. Themodel reproduces the mass functions of star-forming and quiescent galaxies at0<z<2.5 and the quenching boundary on a $\Sigma_1$-stellar mass diagram. Thequenching boundary arises because of the colour-morphology relation. Thestellar surface density $\Sigma_1$ in the central kiloparsec is a morphologicalindicator. Galaxies becomes redder as $\Sigma_1$ increases until they cross thequenching boundary and enter the passive population. Mergers drive the growthof supermassive black holes and the morphological evolution that accompany themigration to the red sequence. That is the origin of the population ofhigh-mass passive galaxies. At lower masses, passive galaxies are mainlysatellites that ceased to form stars because of environmental effects.",Andrea Cattaneo,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.04318v1,sshELF: Single-Shot Hierarchical Extrapolation of Latent Features for 3D Reconstruction from Sparse-Views,http://arxiv.org/abs/2502.04318v1,"Reconstructing unbounded outdoor scenes from sparse outward-facing viewsposes significant challenges due to minimal view overlap. Previous methodsoften lack cross-scene understanding and their primitive-centric formulationsoverload local features to compensate for missing global context, resulting inblurriness in unseen parts of the scene. We propose sshELF, a fast, single-shotpipeline for sparse-view 3D scene reconstruction via hierarchal extrapolationof latent features. Our key insights is that disentangling informationextrapolation from primitive decoding allows efficient transfer of structuralpatterns across training scenes. Our method: (1) learns cross-scene priors togenerate intermediate virtual views to extrapolate to unobserved regions, (2)offers a two-stage network design separating virtual view generation from 3Dprimitive decoding for efficient training and modular model design, and (3)integrates a pre-trained foundation model for joint inference of latentfeatures and texture, improving scene understanding and generalization. sshELFcan reconstruct 360 degree scenes from six sparse input views and achievescompetitive results on synthetic and real-world datasets. We find that sshELFfaithfully reconstructs occluded regions, supports real-time rendering, andprovides rich latent features for downstream applications. The code will bereleased.",Eyvaz Najafli,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04317v1,Factorized Implicit Global Convolution for Automotive Computational Fluid Dynamics Prediction,http://arxiv.org/abs/2502.04317v1,"Computational Fluid Dynamics (CFD) is crucial for automotive design,requiring the analysis of large 3D point clouds to study how vehicle geometryaffects pressure fields and drag forces. However, existing deep learningapproaches for CFD struggle with the computational complexity of processinghigh-resolution 3D data. We propose Factorized Implicit Global Convolution(FIGConv), a novel architecture that efficiently solves CFD problems for verylarge 3D meshes with arbitrary input and output geometries. FIGConv achievesquadratic complexity $O(N^2)$, a significant improvement over existing 3Dneural CFD models that require cubic complexity $O(N^3)$. Our approach combinesFactorized Implicit Grids to approximate high-resolution domains, efficientglobal convolutions through 2D reparameterization, and a U-shaped architecturefor effective information gathering and integration. We validate our approachon the industry-standard Ahmed body dataset and the large-scale DrivAerNetdataset. In DrivAerNet, our model achieves an $R^2$ value of 0.95 for dragprediction, outperforming the previous state-of-the-art by a significantmargin. This represents a 40% improvement in relative mean squared error and a70% improvement in absolute mean squared error over previous methods.",Chris Choy,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04316v1,Shape-asymmetry and flexibility in active cross-stream migration in nonuniform shear,http://arxiv.org/abs/2502.04316v1,"We show that the interplay of activity and broken fore-aft symmetry of shapeshelps microswimmers to migrate across streamlines in nonuniform shear,emphasizing a hitherto overlooked fundamental cause of active cross-streammigration in imposed flows. Using a framework on model flagellatedmicroswimmers in a microchannel flow, we find that besides the broken head-tailshape symmetry, extended hydrodynamic coupling is vital for cross-streammigration, whereas flagellar flexibility significantly affects the same.Furthermore, by simplifying the problem to a basic analytical model, we areable to identify the fundamental factors affecting the observed rich nonlineardynamics and predict the sorting and control of microswimmer populations insidea microchannel. Our predictions are general and apply to both living andartificial microswimmers, whereas the hydrodynamic framework developed here isnecessary to probe other scenarios, such as in dense suspensions, wherenon-uniform shear and near-field flows become important.",Derek C. Gomes,2025-02-06,2025-02-06,,N/A,"['cond-mat.soft', 'physics.bio-ph']"
2502.04315v1,ChamaleonLLM: Batch-Aware Dynamic Low-Rank Adaptation via Inference-Time Clusters,http://arxiv.org/abs/2502.04315v1,"Recent advances in large language models (LLMs) have shown remarkableperformance across diverse tasks. However, these models are typically deployedwith fixed weights, which limits their ability to adapt dynamically to thevariability inherent in real-world data during inference. This paper introducesChamaleonLLM, a novel framework that enables inference-time adaptation of LLMsby leveraging batch-aware clustering and on-the-fly generation of low-rankupdates. Unlike traditional fine-tuning approaches such as Low-Rank Adaptation(LoRA) or methods that rely on a fixed set of pre-learned uniforms (changeablemasks), our method dynamically generates adaptive modifications to the decoderweights based on the aggregated statistics of clustered batches. Byintelligently grouping similar inputs and computing context-aware low-rankupdates via a hyper-network, ChamaleonLLM achieves significant performancegains, outperforming conventional LoRA methods while eliminating the overheadof maintaining multiple expert models. Our experiments highlight the potentialof our approach to serve as a versatile and highly adaptive solution forlanguage model inference. ChamaleonLLM is open-sourced to ensure thereproducibility of our experiments:https://anonymous.4open.science/r/ChamaleonLLM/",Kamer Ali Yuksel,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04314v1,"BOUQuET: dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation",http://arxiv.org/abs/2502.04314v1,"This paper presents BOUQuET, a multicentric and multi-register/domain datasetand benchmark, and its broader collaborative extension initiative. This datasetis handcrafted in non-English languages first, each of these source languagesbeing represented among the 23 languages commonly used by half of the world'spopulation and therefore having the potential to serve as pivot languages thatwill enable more accurate translations. The dataset is specially designed toavoid contamination and be multicentric, so as to enforce representation ofmultilingual language features. In addition, the dataset goes beyond thesentence level, as it is organized in paragraphs of various lengths. Comparedwith related machine translation (MT) datasets, we show that BOUQuET has abroader representation of domains while simplifying the translation task fornon-experts. Therefore, BOUQuET is specially suitable for the open initiativeand call for translation participation that we are launching to extend it to amulti-way parallel corpus to any written language.",The Omnilingual MT Team,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'I.2.7']"
2502.04313v1,Great Models Think Alike and this Undermines AI Oversight,http://arxiv.org/abs/2502.04313v1,"As Language Model (LM) capabilities advance, evaluating and supervising themat scale is getting harder for humans. There is hope that other language modelscan automate both these tasks, which we refer to as ""AI Oversight"". We studyhow model similarity affects both aspects of AI oversight by proposing aprobabilistic metric for LM similarity based on overlap in model mistakes.Using this metric, we first show that LLM-as-a-judge scores favor modelssimilar to the judge, generalizing recent self-preference results. Then, westudy training on LM annotations, and find complementary knowledge between theweak supervisor and strong student model plays a crucial role in gains from""weak-to-strong generalization"". As model capabilities increase, it becomesharder to find their mistakes, and we might defer more to AI oversight.However, we observe a concerning trend -- model mistakes are becoming moresimilar with increasing capabilities, pointing to risks from correlatedfailures. Our work underscores the importance of reporting and correcting formodel similarity, especially in the emerging paradigm of AI oversight.",Shashwat Goel,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.04312v1,Consistency of augmentation graph and network approximability in contrastive learning,http://arxiv.org/abs/2502.04312v1,"Contrastive learning leverages data augmentation to develop featurerepresentation without relying on large labeled datasets. However, despite itsempirical success, the theoretical foundations of contrastive learning remainincomplete, with many essential guarantees left unaddressed, particularly therealizability assumption concerning neural approximability of an optimalspectral contrastive loss solution. In this work, we overcome these limitationsby analyzing the pointwise and spectral consistency of the augmentation graphLaplacian. We establish that, under specific conditions for data generation andgraph connectivity, as the augmented dataset size increases, the augmentationgraph Laplacian converges to a weighted Laplace-Beltrami operator on thenatural data manifold. These consistency results ensure that the graphLaplacian spectrum effectively captures the manifold geometry. Consequently,they give way to a robust framework for establishing neural approximability,directly resolving the realizability assumption in a current paradigm.",Chenghui Li,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.AP', 'math.SP']"
2502.04426v1,Decoding AI Judgment: How LLMs Assess News Credibility and Bias,http://arxiv.org/abs/2502.04426v1,"Large Language Models (LLMs) are increasingly used to assess newscredibility, yet little is known about how they make these judgments. Whileprior research has examined political bias in LLM outputs or their potentialfor automated fact-checking, their internal evaluation processes remain largelyunexamined. Understanding how LLMs assess credibility provides insights into AIbehavior and how credibility is structured and applied in large-scale languagemodels. This study benchmarks the reliability and political classifications ofstate-of-the-art LLMs - Gemini 1.5 Flash (Google), GPT-4o mini (OpenAI), andLLaMA 3.1 (Meta) - against structured, expert-driven rating systems such asNewsGuard and Media Bias Fact Check. Beyond assessing classificationperformance, we analyze the linguistic markers that shape LLM decisions,identifying which words and concepts drive their evaluations. We uncoverpatterns in how LLMs associate credibility with specific linguistic features byexamining keyword frequency, contextual determinants, and rank distributions.Beyond static classification, we introduce a framework in which LLMs refinetheir credibility assessments by retrieving external information, queryingother models, and adapting their responses. This allows us to investigatewhether their assessments reflect structured reasoning or rely primarily onprior learned associations.",Edoardo Loru,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.CY']"
2502.04309v1,Targeted Learning for Data Fairness,http://arxiv.org/abs/2502.04309v1,"Data and algorithms have the potential to produce and perpetuatediscrimination and disparate treatment. As such, significant effort has beeninvested in developing approaches to defining, detecting, and eliminatingunfair outcomes in algorithms. In this paper, we focus on performingstatistical inference for fairness. Prior work in fairness inference haslargely focused on inferring the fairness properties of a given predictivealgorithm. Here, we expand fairness inference by evaluating fairness in thedata generating process itself, referred to here as data fairness. We performinference on data fairness using targeted learning, a flexible framework fornonparametric inference. We derive estimators demographic parity, equalopportunity, and conditional mutual information. Additionally, we find that ourestimators for probabilistic metrics exploit double robustness. To validate ourapproach, we perform several simulations and apply our estimators to real data.",Alexander Asemota,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ML']"
2502.04308v1,HOG-Diff: Higher-Order Guided Diffusion for Graph Generation,http://arxiv.org/abs/2502.04308v1,"Graph generation is a critical yet challenging task as empirical analysesrequire a deep understanding of complex, non-Euclidean structures. Althoughdiffusion models have recently made significant achievements in graphgeneration, these models typically adapt from the frameworks designed for imagegeneration, making them ill-suited for capturing the topological properties ofgraphs. In this work, we propose a novel Higher-order Guided Diffusion(HOG-Diff) model that follows a coarse-to-fine generation curriculum and isguided by higher-order information, enabling the progressive generation ofplausible graphs with inherent topological structures. We further prove thatour model exhibits a stronger theoretical guarantee than classical diffusionframeworks. Extensive experiments on both molecular and generic graphgeneration tasks demonstrate that our method consistently outperforms orremains competitive with state-of-the-art baselines. Our code is available athttps://github.com/Yiminghh/HOG-Diff.",Yiming Huang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.SI', 'physics.soc-ph']"
2502.04307v1,DexterityGen: Foundation Controller for Unprecedented Dexterity,http://arxiv.org/abs/2502.04307v1,"Teaching robots dexterous manipulation skills, such as tool use, presents asignificant challenge. Current approaches can be broadly categorized into twostrategies: human teleoperation (for imitation learning) and sim-to-realreinforcement learning. The first approach is difficult as it is hard forhumans to produce safe and dexterous motions on a different embodiment withouttouch feedback. The second RL-based approach struggles with the domain gap andinvolves highly task-specific reward engineering on complex tasks. Our keyinsight is that RL is effective at learning low-level motion primitives, whilehumans excel at providing coarse motion commands for complex, long-horizontasks. Therefore, the optimal solution might be a combination of bothapproaches. In this paper, we introduce DexterityGen (DexGen), which uses RL topretrain large-scale dexterous motion primitives, such as in-hand rotation ortranslation. We then leverage this learned dataset to train a dexterousfoundational controller. In the real world, we use human teleoperation as aprompt to the controller to produce highly dexterous behavior. We evaluate theeffectiveness of DexGen in both simulation and real world, demonstrating thatit is a general-purpose controller that can realize input dexterousmanipulation commands and significantly improves stability by 10-100x measuredas duration of holding objects across diverse tasks. Notably, with DexGen wedemonstrate unprecedented dexterous skills including diverse objectreorientation and dexterous tool use such as pen, syringe, and screwdriver forthe first time.",Zhao-Heng Yin,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI', 'cs.LG', 'cs.SY', 'eess.SY']"
2502.04306v1,ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization,http://arxiv.org/abs/2502.04306v1,"Recent research has leveraged large language model multi-agent systems forcomplex problem-solving while trying to reduce the manual effort required tobuild them, driving the development of automated agent workflow optimizationmethods. However, existing methods remain inflexible due to representationallimitations, a lack of adaptability, and poor scalability when relying ondiscrete optimization techniques. We address these challenges with ScoreFlow, asimple yet high-performance framework that leverages efficient gradient-basedoptimization in a continuous space. ScoreFlow incorporates Score-DPO, a novelvariant of the direct preference optimization method that accounts forquantitative feedback. Across six benchmarks spanning question answering,coding, and mathematical reasoning, ScoreFlow achieves an 8.2% improvement overexisting baselines. Moreover, it empowers smaller models to outperform largerones with lower inference costs. Project:https://github.com/Gen-Verse/ScoreFlow",Yinjie Wang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04304v1,Almost toric fibrations on K3 surfaces,http://arxiv.org/abs/2502.04304v1,"For K\""ahler K3 surfaces we consider Kulikov models of type III tamed by asymplectic form. Our main result shows that the generic smooth fiber admits analmost toric fibration over the intersection complex, which inherits a naturalnodal integral affine structure from almost toric fibrations of the boundarydivisors. We prove that a smooth anti-canonical hypersurface in a smooth toricFano threefold, equipped with a toric K\""ahler form, admits a symplecticKulikov model. Moreover, we demonstrate that the induced integral affinestructure on the intersection complex is integral affine isomorphic (up tonodal slides) nodal integral affine structure considered by Gross and Sieberton the boundary of the moment polytope.",Pranav Chakravarthy,2025-02-06,2025-02-06,,N/A,"['math.SG', 'Primary 14H70, Secondary 14J28, 14J32, 14D06']"
2502.04302v1,Strong Equivalence in Answer Set Programming with Constraints,http://arxiv.org/abs/2502.04302v1,"We investigate the concept of strong equivalence within the extendedframework of Answer Set Programming with constraints. Two groups of rules areconsidered strongly equivalent if, informally speaking, they have the samemeaning in any context. We demonstrate that, under certain assumptions, strongequivalence between rule sets in this extended setting can be preciselycharacterized by their equivalence in the logic of Here-and-There withconstraints. Furthermore, we present a translation from the language of severalclingo-based answer set solvers that handle constraints into the language ofHere-and-There with constraints. This translation enables us to leverage thelogic of Here-and-There to reason about strong equivalence within the contextof these solvers. We also explore the computational complexity of determiningstrong equivalence in this context.",Pedro Cabalar,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.LO', 'I.2.4; I.2.8']"
2502.04301v1,Type II Degenerations of K3 Surfaces of Degree 4,http://arxiv.org/abs/2502.04301v1,We study Type II degenerations of K3 surfaces of degree 4 where the centralfiber consists of two rational components glued along an elliptic curve. Suchdegenerations are called Tyurin degenerations. We construct explicit Tyurindegenerations corresponding to each of the 1-dimensional boundary components ofthe Baily-Borel compactification of the moduli space of K3 surfaces of degree4. For every such boundary component we also construct an 18-dimensional familyof Tyurin degenerations of K3 surfaces of degree 4 and compute the stablemodels of these degenerations.,James Matthew Jones,2025-02-06,2025-02-06,,N/A,"['math.AG', '14D06, 14J10, 14J26, 14J28']"
2502.04300v1,CMB-S4: Foreground-Cleaning Pipeline Comparison for Measuring Primordial Gravitational Waves,http://arxiv.org/abs/2502.04300v1,"We compare multiple foreground-cleaning pipelines for estimating thetensor-to-scalar ratio, $r$, using simulated maps of the planned CMB-S4experiment within the context of the South Pole Deep Patch. To evaluaterobustness, we analyze bias and uncertainty on $r$ across various foregroundsuites using map-based simulations. The foreground-cleaning methods include: aparametric maximum likelihood approach applied to auto- and cross-power spectrabetween frequency maps; a map-based parametric maximum-likelihood method; and aharmonic-space internal linear combination using frequency maps. We summarizethe conceptual basis of each method to highlight their similarities anddifferences. To better probe the impact of foreground residuals, we implementan iterative internal delensing step, leveraging a map-based pipeline togenerate a lensing $B$-mode template from the Large Aperture Telescopefrequency maps. Our results show that the performance of the three approachesis comparable for simple and intermediate-complexity foregrounds, with$\sigma(r)$ ranging from 3 to 5 $\times 10^{-4}$. However, biases at the$1-2\sigma$ level appear when analyzing more complex forms of foregroundemission. By extending the baseline pipelines to marginalize over foregroundresiduals, we demonstrate that contamination can be reduced to withinstatistical uncertainties, albeit with a pipeline-dependent impact on$\sigma(r)$, which translates to a detection significance between 2 and4$\sigma$ for an input value of $r = 0.003$. These findings suggest varyinglevels of maturity among the tested pipelines, with the auto- andcross-spectra-based approach demonstrating the best stability and overallperformance. Moreover, given the extremely low noise levels, mutual validationof independent foreground-cleaning pipelines is essential to ensure therobustness of any potential detection.",Federico Bianchini,2025-02-06,2025-02-06,,N/A,['astro-ph.CO']
2502.04299v1,MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation,http://arxiv.org/abs/2502.04299v1,"This paper presents a method that allows users to design cinematic videoshots in the context of image-to-video generation. Shot design, a criticalaspect of filmmaking, involves meticulously planning both camera movements andobject motions in a scene. However, enabling intuitive shot design in modernimage-to-video generation systems presents two main challenges: first,effectively capturing user intentions on the motion design, where both cameramovements and scene-space object motions must be specified jointly; and second,representing motion information that can be effectively utilized by a videodiffusion model to synthesize the image animations. To address thesechallenges, we introduce MotionCanvas, a method that integrates user-drivencontrols into image-to-video (I2V) generation models, allowing users to controlboth object and camera motions in a scene-aware manner. By connecting insightsfrom classical computer graphics and contemporary video generation techniques,we demonstrate the ability to achieve 3D-aware motion control in I2V synthesiswithout requiring costly 3D-related training data. MotionCanvas enables usersto intuitively depict scene-space motion intentions, and translates them intospatiotemporal motion-conditioning signals for video diffusion models. Wedemonstrate the effectiveness of our method on a wide range of real-world imagecontent and shot-design scenarios, highlighting its potential to enhance thecreative workflows in digital content creation and adapt to various image andvideo editing applications.",Jinbo Xing,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04298v1,Mutual Multilinearity of Nonequilibrium Network Currents,http://arxiv.org/abs/2502.04298v1,"Continuous-time Markov chains have been successful in modelling systemsacross numerous fields, with currents being fundamental entities that describethe flows of energy, particles, individuals, chemical species, information, orother quantities. They apply to systems described by agents transitioningbetween vertices along the edges of a network (at some rate in each direction).It has recently been shown by the authors that, at stationarity, a hiddenlinearity exists between currents that flow along edges: if one controls thecurrent of a specific ""input"" edge (by tuning transition rates along it), anyother current is a linear-affine function of the input current [PRL 133, 047401(2024)]. In this paper, we extend this result to the situation where onecontrols the currents of several edges, and prove that other currents are inlinear-affine relation with the input ones. Two proofs with distinct insightsare provided: the first relies on Kirchhoff's current law and reduces the inputset inductively through graph analysis, while the second utilizes the resolventapproach via a Laplace transform in time. We obtain explicit expressions forthe current-to-current susceptibilities, which allow one to map currentdependencies through the network. We also verify from our expression thatKirchhoff's current law is recovered as a limiting case of our mutuallinearity. Last, we uncover that susceptibilities can be obtained fromfluctuations when the reference system is originally at equilibrium.",Sara Dal Cengio,2025-02-06,2025-02-06,,N/A,"['cond-mat.stat-mech', 'math-ph', 'math.MP']"
2502.04296v1,Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression,http://arxiv.org/abs/2502.04296v1,"We propose Heterogeneous Masked Autoregression (HMA) for modelingaction-video dynamics to generate high-quality data and evaluation in scalingrobot learning. Building interactive video world models and policies forrobotics is difficult due to the challenge of handling diverse settings whilemaintaining computational efficiency to run in real time. HMA usesheterogeneous pre-training from observations and action sequences acrossdifferent robotic embodiments, domains, and tasks. HMA uses maskedautoregression to generate quantized or soft tokens for video predictions.\ourshort achieves better visual fidelity and controllability than the previousrobotic video generation models with 15 times faster speed in the real world.After post-training, this model can be used as a video simulator from low-levelaction inputs for evaluating policies and generating synthetic data. See thislink https://liruiw.github.io/hma for more information.",Lirui Wang,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.CV', 'cs.LG']"
2502.04295v1,Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization,http://arxiv.org/abs/2502.04295v1,"Large Language Models (LLMs) have shown significant capability across varioustasks, with their real-world effectiveness often driven by prompt design. Whilerecent research has focused on optimizing prompt content, the role of promptformatting, a critical but often overlooked dimension, has received limitedsystematic investigation. In this paper, we introduce Content-Format IntegratedPrompt Optimization (CFPO), an innovative methodology that jointly optimizesboth prompt content and formatting through an iterative refinement process.CFPO leverages natural language mutations to explore content variations andemploys a dynamic format exploration strategy that systematically evaluatesdiverse format options. Our extensive evaluations across multiple tasks andopen-source LLMs demonstrate that CFPO demonstrates measurable performanceimprovements compared to content-only optimization methods. This highlights theimportance of integrated content-format optimization and offers a practical,model-agnostic approach to enhancing LLM performance. Code will be available athttps://github.com/HenryLau7/CFPO.",Yuanye Liu,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04294v1,Prediction-Powered E-Values,http://arxiv.org/abs/2502.04294v1,"Quality statistical inference requires a sufficient amount of data, which canbe missing or hard to obtain. To this end, prediction-powered inference hasrisen as a promising methodology, but existing approaches are largely limitedto Z-estimation problems such as inference of means and quantiles. In thispaper, we apply ideas of prediction-powered inference to e-values. By doing so,we inherit all the usual benefits of e-values -- such as anytime-validity,post-hoc validity and versatile sequential inference -- as well as greatlyexpand the set of inferences achievable in a prediction-powered manner. Inparticular, we show that every inference procedure that can be framed in termsof e-values has a prediction-powered counterpart, given by our method. Weshowcase the effectiveness of our framework across a wide range of inferencetasks, from simple hypothesis testing and confidence intervals to more involvedprocedures for change-point detection and causal discovery, which were out ofreach of previous techniques. Our approach is modular and easily integrableinto existing algorithms, making it a compelling choice for practicalapplications.",Daniel Csillag,2025-02-06,2025-02-06,,N/A,"['stat.ML', 'cs.LG', 'stat.ME']"
2502.04293v1,GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation,http://arxiv.org/abs/2502.04293v1,"A key challenge in model-free category-level pose estimation is theextraction of contextual object features that generalize across varyinginstances within a specific category. Recent approaches leverage foundationalfeatures to capture semantic and geometry cues from data. However, theseapproaches fail under partial visibility. We overcome this with afirst-complete-then-aggregate strategy for feature extraction utilizing classpriors. In this paper, we present GCE-Pose, a method that enhances poseestimation for novel instances by integrating category-level global contextprior. GCE-Pose performs semantic shape reconstruction with a proposed SemanticShape Reconstruction (SSR) module. Given an unseen partial RGB-D objectinstance, our SSR module reconstructs the instance's global geometry andsemantics by deforming category-specific 3D semantic prototypes through alearned deep Linear Shape Model. We further introduce a Global Context Enhanced(GCE) feature fusion module that effectively fuses features from partial RGB-Dobservations and the reconstructed global context. Extensive experimentsvalidate the impact of our global context prior and the effectiveness of theGCE fusion module, demonstrating that GCE-Pose significantly outperformsexisting methods on challenging real-world datasets HouseCat6D andNOCS-REAL275. Our project page is available athttps://colin-de.github.io/GCE-Pose/.",Weihang Li,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04288v1,Leveraging Geolocation in Clinical Records to Improve Alzheimer's Disease Diagnosis Using DMV Framework,http://arxiv.org/abs/2502.04288v1,"Alzheimer's Disease (AD) early detection is critical for enabling timelyintervention and improving patient outcomes. This paper presents a DMVframework using Llama3-70B and GPT-4o as embedding models to analyze clinicalnotes and predict a continuous risk score associated with early AD onset.Framing the task as a regression problem, we model the relationship betweenlinguistic features in clinical notes (inputs) and a target variable (datavalue) that answers specific questions related to AD risk within certain topiccategories. By leveraging a multi-faceted feature set that includes geolocationdata, we capture additional environmental context potentially linked to AD. Ourresults demonstrate that the integration of the geolocation informationsignificantly decreases the error of predicting early AD risk scores over priormodels by 28.57% (Llama3-70B) and 33.47% (GPT4-o). Our findings suggest thatthis combined approach can enhance the predictive accuracy of AD riskassessment, supporting early diagnosis and intervention in clinical settings.Additionally, the framework's ability to incorporate geolocation data providesa more comprehensive risk assessment model that could help healthcare providersbetter understand and address environmental factors contributing to ADdevelopment.",Peng Zhang,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04287v1,Breaking the Vault: A Case Study of the 2022 LastPass Data Breach,http://arxiv.org/abs/2502.04287v1,"Managing the security of employee work computers has become increasinglyimportant as today's work model shifts to remote and hybrid work plans. In thispaper, we explore the recent 2022 LastPass data breach, in which the attackerobtained sensitive customer data by exploiting a software vulnerability on aDevSecOps engineer's computer. We discuss the methodology of the attacker aswell as the impact this incident had on LastPass and its customers. Next, weexpand upon the impact the breach had on LastPass as well as its customers.From this, we propose solutions for preparing for and mitigating similarattacks in the future. The aim of this paper is to shed light on the LastPassincident and provide methods for companies to secure their employee base, bothnationally and internationally. With a strong security structure, companies canvastly reduce the chances of falling victim to a similar attack.",Jessica Gentles,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04286v1,"A Methodology for Studying Linguistic and Cultural Change in China, 1900-1950",http://arxiv.org/abs/2502.04286v1,"This paper presents a quantitative approach to studying linguistic andcultural change in China during the first half of the twentieth century, aperiod that remains understudied in computational humanities research. Thedramatic changes in Chinese language and culture during this time call forgreater reflection on the tools and methods used for text analysis. Thispreliminary study offers a framework for analyzing Chinese texts from the latenineteenth and twentieth centuries, demonstrating how established methods suchas word counts and word embeddings can provide new historical insights into thecomplex negotiations between Western modernity and Chinese cultural discourse.",Spencer Dean Stewart,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04283v1,The Young Ages of 70 μm-dark Clumps Inferred from Carbon Chain Chemistry,http://arxiv.org/abs/2502.04283v1,"The physical conditions of the earliest environment of high-mass starformation are currently poorly understood. To that end, we present observationsof the carbon chain molecules HC$_5$N , CCS, and HC$_7$N in the 22-25 GHz bandtowards 12 high-mass 70 micron-dark clumps (SMDC) with the Jansky Very LargeArray (VLA). We detect HC$_5$N and CCS towards 11 of these SMDC sources. Wecalculate column densities and abundances relative to H$_2$ for HC$_5$N andCCS. We do not find any clear HC$_7$N detections in the 11 sourcesindividually, but by stacking the HC$_7$N spectra, we do detect HC$_7$N onaverage in these sources. We also calculate the ratio of the column densitiesof HC$_5$N to HC$_7$N using the stacked spectra of both species. We compare ourmeasured abundances of HC$_5$N and our measured ratio of HC$_5$N to HC$_7$N tothe UMIST dark cloud chemistry models to constrain an age for the gas assuminga fixed volume density and temperature. The chemical models favor a chemicalevolutionary age less than 1 Myr at densities of n(H2) = 2 x 10$^4$ cm$^{-3}$.The consistent carbon-chain detections and young model-derived ages support theconclusion that these 11 70 micron-dark clumps lack high mass protostarsbecause they are young and not because they are inefficient and incapable ofhigh mass star formation.",Kadin Worthen,2025-02-06,2025-02-06,,N/A,"['astro-ph.GA', 'astro-ph.SR']"
2502.04282v1,Isolating the hard core of phaseless inference: the Phase selection formulation,http://arxiv.org/abs/2502.04282v1,"Real-valued Phase retrieval is a non-convex continuous inference problem,where a high-dimensional signal is to be reconstructed from a dataset ofsignless linear measurements. Focusing on the noiseless case, we aim todisentangle the two distinct sub-tasks entailed in the Phase retrieval problem:the hard combinatorial problem of retrieving the missing signs of themeasurements, and the nested convex problem of regressing the input-outputobservations to recover the hidden signal. To this end, we introduce andanalytically characterize a two-level formulation of the problem, called``Phase selection''. Within the Replica Theory framework, we perform a largedeviation analysis to characterize the minimum mean squared error achievablewith different guesses for the hidden signs. Moreover, we study the free-energylandscape of the problem when both levels are optimized simultaneously, as afunction of the dataset size. At low temperatures, in proximity to theBayes-optimal threshold -- previously derived in the context of Phase retrieval-- we detect the coexistence of two free-energy branches, one connected to therandom initialization condition and a second to the signal. We derive the phasediagram for a first-order transition after which the two branches merge.Interestingly, introducing an $L_2$ regularization in the regression sub-taskcan anticipate the transition to lower dataset sizes, at the cost of a bias inthe signal reconstructions which can be removed by annealing the regularizationintensity. Finally, we study the inference performance of three meta-heuristicsin the context of Phase selection: Simulated Annealing, Approximate MessagePassing, and Langevin Dynamics on the continuous relaxation of the signvariables. With simultaneous annealing of the temperature and the $L_2$regularization, they are shown to approach the Bayes-optimal sample efficiency.",Davide Straziota,2025-02-06,2025-02-06,,N/A,['cond-mat.dis-nn']
2502.04280v1,Mean-Field Analysis of Latent Variable Process Models on Dynamically Evolving Graphs with Feedback Effects,http://arxiv.org/abs/2502.04280v1,"In this paper, we study the asymptotic behavior of a class of dynamicco-evolving latent space networks. The model we study is subject tobi-directional feedback effects, meaning that at any given time, the latentprocess depends on its own value and the graph structure at the previous timestep, and the graph structure at the current time depends on the value of thelatent processes at the current time but also on the graph structure at theprevious time instance (sometimes called a persistence effect). We constructthe mean-field limit of this model, which we use to characterize the limitingbehavior of a random sample taken from the latent space network in the limit asthe number of nodes in the network diverges. From this limiting model, we canderive the limiting behavior of the empirical measure of the latent process andestablish the related graphon limit of the latent particle network process. Wealso provide a description of the rich conditional probabilistic structure ofthe limiting model. The inherent dependence structure complicates themathematical analysis significantly. In the process of proving our mainresults, we derive a general conditional propagation of chaos result, which isof independent interest. In addition, our novel approach of studying thelimiting behavior of random samples proves to be a very useful methodology forfully grasping the asymptotic behavior of co-evolving particle systems.Numerical results are included to illustrate the theoretical findings.",Ankan Ganguly,2025-02-06,2025-02-06,,N/A,"['math.PR', '60K35, 60J05, 91D30 (Primary) 60B10, 60G57, 62D05 (Secondary)']"
2502.04278v1,Probing Spin-Orbit Resonances with the Binary Black Hole Population,http://arxiv.org/abs/2502.04278v1,"Measurements of the binary black hole spin distribution from the growingcatalog of gravitational-wave observations can help elucidate the astrophysicalprocesses shaping the formation and evolution of these systems. Spin-orbitresonances are one process of interest, in which the component spin vectors andthe orbital angular momentum align into a common plane and jointly precessabout the total angular momentum of the system. These resonances, which occurpreferentially in systems formed via isolated binary evolution with strongtidal effects, lead to excesses in the distribution of the azimuthal anglebetween the projections of the component spin vectors onto the orbital plane at$\phi_{12}=0,\pm\pi$. Previous analyses have demonstrated that this parameteris particularly difficult to constrain for individual binaries. In this work,we conduct the first hierarchical analysis modeling the population-leveldistribution of $\phi_{12}$ simultaneously with the other mass and spinparameters for simulated binary black hole populations to determine whetherspin-orbit resonances can be reliably constrained. While we are unlikely tofind definitive evidence for spin-orbit resonances with a population of thesize expected by the end of the ongoing LIGO-Virgo-KAGRA fourth observing run,we correctly recover the various $\phi_{12}$ distributions we simulate withinuncertainties. We find that we can place meaningful constraints on the relativeexcesses at $\phi_{12}=0,\pm\pi$, which encodes information about mass transferin the formation of the binary. We can also distinguish between fully isotropicspin angle distributions and those with features in the spin azimuth and tiltdistributions. Thus, we show that population-level measurements of the$\phi_{12}$ distribution offer a reliable, novel way to probe binary formationchannels, dynamics, and mass transfer with gravitational-wave observations.",Sylvia Biscoveanu,2025-02-06,2025-02-06,,N/A,"['astro-ph.HE', 'gr-qc']"
2502.04276v1,Gaussian Process Regression for Inverse Problems in Linear PDEs,http://arxiv.org/abs/2502.04276v1,"This paper introduces a computationally efficient algorithm in system theoryfor solving inverse problems governed by linear partial differential equations(PDEs). We model solutions of linear PDEs using Gaussian processes with priorsdefined based on advanced commutative algebra and algebraic analysis. Theimplementation of these priors is algorithmic and achieved using the Macaulay2computer algebra software. An example application includes identifying the wavespeed from noisy data for classical wave equations, which are widely used inphysics. The method achieves high accuracy while enhancing computationalefficiency.",Xin Li,2025-02-06,2025-02-06,,N/A,"['stat.ML', 'cs.LG', 'math.AC']"
2502.04273v1,Electrical Impedance Tomography for Anisotropic Media: a Machine Learning Approach to Classify Inclusions,http://arxiv.org/abs/2502.04273v1,"We consider the problem in Electrical Impedance Tomography (EIT) ofidentifying one or multiple inclusions in a background-conducting body$\Omega\subset\mathbb{R}^2$, from the knowledge of a finite number ofelectrostatic measurements taken on its boundary $\partial\Omega$ and modelledby the Dirichlet-to-Neumann (D-N) matrix. Once the presence of one inclusion in$\Omega$ is established, our model, combined with the machine learningtechniques of Artificial Neural Networks (ANN) and Support Vector Machines(SVM), may be used to determine the size of the inclusion, the presence ofmultiple inclusions, and also that of anisotropy within the inclusion(s).Utilising both real and simulated datasets within a 16-electrode setup, weachieve a high rate of inclusion detection and show that two measurements aresufficient to achieve a good level of accuracy when predicting the size of aninclusion. This underscores the substantial potential of integrating machinelearning approaches with the more classical analysis of EIT and the inverseinclusion problem to extract critical insights, such as the presence ofanisotropy.",Romina Gaburro,2025-02-06,2025-02-06,,N/A,"['math.NA', 'cs.LG', 'cs.NA', '65N21, 35R30, 68T99']"
2502.04424v1,EmoBench-M: Benchmarking Emotional Intelligence for Multimodal Large Language Models,http://arxiv.org/abs/2502.04424v1,"With the integration of Multimodal large language models (MLLMs) into roboticsystems and various AI applications, embedding emotional intelligence (EI)capabilities into these models is essential for enabling robots to effectivelyaddress human emotional needs and interact seamlessly in real-world scenarios.Existing static, text-based, or text-image benchmarks overlook the multimodalcomplexities of real-world interactions and fail to capture the dynamic,multimodal nature of emotional expressions, making them inadequate forevaluating MLLMs' EI. Based on established psychological theories of EI, webuild EmoBench-M, a novel benchmark designed to evaluate the EI capability ofMLLMs across 13 valuation scenarios from three key dimensions: foundationalemotion recognition, conversational emotion understanding, and socially complexemotion analysis. Evaluations of both open-source and closed-source MLLMs onEmoBench-M reveal a significant performance gap between them and humans,highlighting the need to further advance their EI capabilities. All benchmarkresources, including code and datasets, are publicly available athttps://emo-gml.github.io/.",He Hu,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04270v1,PILAF: Optimal Human Preference Sampling for Reward Modeling,http://arxiv.org/abs/2502.04270v1,"As large language models increasingly drive real-world applications, aligningthem with human values becomes paramount. Reinforcement Learning from HumanFeedback (RLHF) has emerged as a key technique, translating preference datainto reward models when oracle human values remain inaccessible. In practice,RLHF mostly relies on approximate reward models, which may not consistentlyguide the policy toward maximizing the underlying human values. We proposePolicy-Interpolated Learning for Aligned Feedback (PILAF), a novel responsesampling strategy for preference labeling that explicitly aligns preferencelearning with maximizing the underlying oracle reward. PILAF is theoreticallygrounded, demonstrating optimality from both an optimization and a statisticalperspective. The method is straightforward to implement and demonstrates strongperformance in iterative and online RLHF settings where feedback curation iscritical.",Yunzhen Feng,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ML']"
2502.04269v1,How does a Multilingual LM Handle Multiple Languages?,http://arxiv.org/abs/2502.04269v1,"Multilingual language models have significantly advanced due to rapidprogress in natural language processing. Models like BLOOM 1.7B, trained ondiverse multilingual datasets, aim to bridge linguistic gaps. However, theireffectiveness in capturing linguistic knowledge, particularly for low-resourcelanguages, remains an open question. This study critically examines MLMscapabilities in multilingual understanding, semantic representation, andcross-lingual knowledge transfer. While these models perform well forhigh-resource languages, they struggle with less-represented ones.Additionally, traditional evaluation methods often overlook their internalsyntactic and semantic encoding.  This research addresses key limitations through three objectives. First, itassesses semantic similarity by analyzing multilingual word embeddings forconsistency using cosine similarity. Second, it examines BLOOM-1.7B and Qwen2through Named Entity Recognition and sentence similarity tasks to understandtheir linguistic structures. Third, it explores cross-lingual knowledgetransfer by evaluating generalization from high-resource to low-resourcelanguages in sentiment analysis and text classification.  By leveraging linguistic probing, performance metrics, and visualizations,this study provides insights into the strengths and limitations of MLMs. Thefindings aim to enhance multilingual NLP models, ensuring better support forboth high- and low-resource languages, thereby promoting inclusivity inlanguage technologies.",Santhosh Kakarla,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04265v1,Fermion Dark Matter Effect on Electroweak Phase Transition,http://arxiv.org/abs/2502.04265v1,"The addition of extra scalars to the Standard Model (SM) of particle physicsenriches the vacuum structure and consequently gives rise to strong first-orderphase transitions (EWPT) in the early universe. We raise the question that howthe EWPT is affected by the addition of fermions in models beyond the SM, andaddress this question by studying the EWPT in a dark matter model comprising asinglet scalar and two Dirac fermions. The singlet scalar develops a nonzerovacuum expectation value (VEV), and the lighter fermion plays the role of thedark matter. The model evades the stringent direct detection bounds due to thepresence of two fermions. We first show that applying the high-temperatureapproximation, no first-order phase transition is found. Then we demonstratethat when including the full finite temperature corrections to the effectivepotential, the first-order phase transition becomes possible, nevertheless, allthe phase transitions will be weak. We therefore deduce that the addition offermions reduces the strength of the EWPT.",Soudeh Mirzaie,2025-02-06,2025-02-06,,N/A,['hep-ph']
2502.04264v1,Fundamental Oscillation Modes in Neutron Stars with Hyperons and Delta Baryons,http://arxiv.org/abs/2502.04264v1,"For a new parameterization of the modified effective chiral model, developedprimarily to regulate the density content of the symmetry energy and its higherorder terms, equations of state (EoSs) for hyperon-rich matter ($H$) and deltabaryon matter ($\Delta$) were obtained. The models were used to investigate theemission of gravitational waves (GWs) through $f$-mode oscillations in thecorresponding neutron stars. We obtained the stellar structure, $f$-modefrequency and tidal deformability $\Lambda$ for our models. We report that the$\Delta$ EoS is stiffer compared to the $H$ EoS. We also analyzed the velocityof sound in these media. The corresponding mass--radius relationships wereobtained and compared with various observations. We studied the dependence of$f$-mode frequencies on the stellar mass, redshift and tidal deformability. Weemployed the well known Cowling approximation to obtain the $f$-modefrequencies for $l=2,\,3$ and $4$ modes of oscillation. We found that the$f$-mode frequencies of the $H$ and $\Delta$ EoSs were almost the same in thelower mass region, while we observed a substantial difference between them inthe high-mass region. We also obtained an empirical relation for the EoSsconsidered. The various attributes obtained for our models showed closeagreement with various observational constraints from pulsars and GW events.",O. P. Jyothilakshmi,2025-02-06,2025-02-06,,N/A,"['astro-ph.HE', 'nucl-th']"
2502.04263v1,Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion,http://arxiv.org/abs/2502.04263v1,"Pre-trained multi-modal Vision-Language Models like CLIP are widely usedoff-the-shelf for a variety of applications. In this paper, we show that thecommon practice of individually exploiting the text or image encoders of thesepowerful multi-modal models is highly suboptimal for intra-modal tasks likeimage-to-image retrieval. We argue that this is inherently due to theCLIP-style inter-modal contrastive loss that does not enforce any intra-modalconstraints, leading to what we call intra-modal misalignment. To demonstratethis, we leverage two optimization-based modality inversion techniques that maprepresentations from their input modality to the complementary one without anyneed for auxiliary data or additional trained adapters. We empirically showthat, in the intra-modal tasks of image-to-image and text-to-text retrieval,approaching these tasks inter-modally significantly improves performance withrespect to intra-modal baselines on more than fifteen datasets. Additionally,we demonstrate that approaching a native inter-modal task (e.g. zero-shot imageclassification) intra-modally decreases performance, further validating ourfindings. Finally, we show that incorporating an intra-modal term in thepre-training objective or narrowing the modality gap between the text and imagefeature embedding spaces helps reduce the intra-modal misalignment. The code ispublicly available at: https://github.com/miccunifi/Cross-the-Gap.",Marco Mistretta,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.04262v1,Efficient Randomized Experiments Using Foundation Models,http://arxiv.org/abs/2502.04262v1,"Randomized experiments are the preferred approach for evaluating the effectsof interventions, but they are costly and often yield estimates withsubstantial uncertainty. On the other hand, in silico experiments leveragingfoundation models offer a cost-effective alternative that can potentiallyattain higher statistical precision. However, the benefits of in silicoexperiments come with a significant risk: statistical inferences are not validif the models fail to accurately predict experimental responses tointerventions. In this paper, we propose a novel approach that integrates thepredictions from multiple foundation models with experimental data whilepreserving valid statistical inference. Our estimator is consistent andasymptotically normal, with asymptotic variance no larger than the standardestimator based on experimental data alone. Importantly, these statisticalproperties hold even when model predictions are arbitrarily biased. Empiricalresults across several randomized experiments show that our estimator offerssubstantial precision gains, equivalent to a reduction of up to 20% in thesample size needed to match the same precision as the standard estimator basedon experimental data alone.",Piersilvio De Bartolomeis,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ME', 'stat.ML']"
2502.04260v1,Realistic Image-to-Image Machine Unlearning via Decoupling and Knowledge Retention,http://arxiv.org/abs/2502.04260v1,"Machine Unlearning allows participants to remove their data from a trainedmachine learning model in order to preserve their privacy, and security.However, the machine unlearning literature for generative models is ratherlimited. The literature for image-to-image generative model (I2I model)considers minimizing the distance between Gaussian noise and the output of I2Imodel for forget samples as machine unlearning. However, we argue that themachine learning model performs fairly well on unseen data i.e., a retrainedmodel will be able to catch generic patterns in the data and hence will notgenerate an output which is equivalent to Gaussian noise. In this paper, weconsider that the model after unlearning should treat forget samples asout-of-distribution (OOD) data, i.e., the unlearned model should no longerrecognize or encode the specific patterns found in the forget samples. Toachieve this, we propose a framework which decouples the model parameters withgradient ascent, ensuring that forget samples are OOD for unlearned model withtheoretical guarantee. We also provide $(\epsilon, \delta)$-unlearningguarantee for model updates with gradient ascent. The unlearned model isfurther fine-tuned on the remaining samples to maintain its performance. Wealso propose an attack model to ensure that the unlearned model has effectivelyremoved the influence of forget samples. Extensive empirical evaluation on twolarge-scale datasets, ImageNet-1K and Places365 highlights the superiority ofour approach. To show comparable performance with retrained model, we also showthe comparison of a simple AutoEncoder on various baselines on CIFAR-10dataset.",Ayush K. Varshney,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04259v1,Cognitive AI framework: advances in the simulation of human thought,http://arxiv.org/abs/2502.04259v1,"The Human Cognitive Simulation Framework represents a significant advancementin integrating human cognitive capabilities into artificial intelligencesystems. By merging short-term memory (conversation context), long-term memory(interaction context), advanced cognitive processing, and efficient knowledgemanagement, it ensures contextual coherence and persistent data storage,enhancing personalization and continuity in human-AI interactions. Theframework employs a unified database that synchronizes these contexts whileincorporating logical, creative, and analog processing modules inspired byhuman brain hemispheric functions to perform structured tasks and complexinferences. Dynamic knowledge updates enable real-time integration, improvingadaptability and fostering applications in education, behavior analysis, andknowledge management. Despite its potential to process vast data volumes andenhance user experience, challenges remain in scalability, cognitive biasmitigation, and ethical compliance. This framework lays the foundation forfuture research in continuous learning algorithms, sustainability, andmultimodal adaptability, positioning Cognitive AI as a transformative model inemerging fields.",Rommel Salas-Guerra,2025-02-06,2025-02-06,,N/A,"['cs.HC', 'cs.CY']"
2502.04257v1,Probability Bracket Notation for Probability Modeling,http://arxiv.org/abs/2502.04257v1,"Following the Dirac Notation in Quantum Mechanics (QM), we propose theBracket Notation (PBN) by defining a probability-bra (P-bra), P-ket, P-bracket,P-identity, etc. Using the PBN, many formulae, such as normalizations andexpectations in systems of one or more random variables, can now be written inabstract basis-independent expressions, which are easy to expand by inserting aproper P-identity. The time evolution of homogeneous Markov processes can alsobe formatted in such a way. Our system P-kets are identified with probabilityvectors, and our system P-bra is comparable to the Doi state function or thePeliti standard bra. In the Heisenberg picture of the PBN, a random variablebecomes a stochastic process, and the Chapman-Kolmogorov equations are obtainedby inserting a time-dependent P-identity. Also, some QM expressions in theDirac notation are naturally transformed into probability expressions in PBN bya special Wick rotation. Potential applications show the usefulness of the PBNbeyond the constrained domain and range of Hermitian operators on HilbertSpaces in QM all the way to IT.",Xing M. Wang,2025-02-06,2025-02-06,,N/A,"['math.PR', 'math-ph', 'math.MP', 'quant-ph']"
2502.04251v1,Combining Language and App UI Analysis for the Automated Assessment of Bug Reproduction Steps,http://arxiv.org/abs/2502.04251v1,"Bug reports are essential for developers to confirm software problems,investigate their causes, and validate fixes. Unfortunately, reports often missimportant information or are written unclearly, which can cause delays,increased issue resolution effort, or even the inability to solve issues. Oneof the most common components of reports that are problematic is the steps toreproduce the bug(s) (S2Rs), which are essential to replicate the describedprogram failures and reason about fixes. Given the proclivity for deficienciesin reported S2Rs, prior work has proposed techniques that assist reporters inwriting or assessing the quality of S2Rs. However, automated understanding ofS2Rs is challenging, and requires linking nuanced natural language phrases withspecific, semantically related program information. Prior techniques oftenstruggle to form such language to program connections - due to issues inlanguage variability and limitations of information gleaned from programanalyses.  To more effectively tackle the problem of S2R quality annotation, we proposea new technique called AstroBR, which leverages the language understandingcapabilities of LLMs to identify and extract the S2Rs from bug reports and mapthem to GUI interactions in a program state model derived via dynamic analysis.We compared AstroBR to a related state-of-the-art approach and we found thatAstroBR annotates S2Rs 25.2% better (in terms of F1 score) than the baseline.Additionally, AstroBR suggests more accurate missing S2Rs than the baseline (by71.4% in terms of F1 score).",Junayed Mahmud,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.LG']"
2502.04249v1,Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study,http://arxiv.org/abs/2502.04249v1,"We investigate the Free Energy Principle as a foundation for measuring riskin agentic and multi-agent systems. From these principles we introduce aCumulative Risk Exposure metric that is flexible to differing contexts andneeds. We contrast this to other popular theories for safe AI that hinge onmassive amounts of data or describing arbitrarily complex world models. In ourframework, stakeholders need only specify their preferences over systemoutcomes, providing straightforward and transparent decision rules for riskgovernance and mitigation. This framework naturally accounts for uncertainty inboth world model and preference model, allowing for decision-making that isepistemically and axiologically humble, parsimonious, and future-proof. Wedemonstrate this novel approach in a simplified autonomous vehicle environmentwith multi-agent vehicles whose driving policies are mediated by gatekeepersthat evaluate, in an online fashion, the risk to the collective safety in theirneighborhood, and intervene through each vehicle's policy when appropriate. Weshow that the introduction of gatekeepers in an AV fleet, even at lowpenetration, can generate significant positive externalities in terms ofincreased system safety.",Michael Walters,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.LG', 'cs.MA', 'physics.data-an', 'stat.ML']"
2502.04248v1,Adapting to Evolving Adversaries with Regularized Continual Robust Training,http://arxiv.org/abs/2502.04248v1,"Robust training methods typically defend against specific attack types, suchas Lp attacks with fixed budgets, and rarely account for the fact thatdefenders may encounter new attacks over time. A natural solution is to adaptthe defended model to new adversaries as they arise via fine-tuning, a methodwhich we call continual robust training (CRT). However, when implementednaively, fine-tuning on new attacks degrades robustness on previous attacks.This raises the question: how can we improve the initial training andfine-tuning of the model to simultaneously achieve robustness against previousand new attacks? We present theoretical results which show that the gap in amodel's robustness against different attacks is bounded by how far each attackperturbs a sample in the model's logit space, suggesting that regularizing withrespect to this logit space distance can help maintain robustness againstprevious attacks. Extensive experiments on 3 datasets (CIFAR-10, CIFAR-100, andImageNette) and over 100 attack combinations demonstrate that the proposedregularization improves robust accuracy with little overhead in training time.Our findings and open-source code lay the groundwork for the deployment ofmodels robust to evolving attacks.",Sihui Dai,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04247v1,Student-t processes as infinite-width limits of posterior Bayesian neural networks,http://arxiv.org/abs/2502.04247v1,"The asymptotic properties of Bayesian Neural Networks (BNNs) have beenextensively studied, particularly regarding their approximations by Gaussianprocesses in the infinite-width limit. We extend these results by showing thatposterior BNNs can be approximated by Student-t processes, which offer greaterflexibility in modeling uncertainty. Specifically, we show that, if theparameters of a BNN follow a Gaussian prior distribution, and the variance ofboth the last hidden layer and the Gaussian likelihood function follows anInverse-Gamma prior distribution, then the resulting posterior BNN converges toa Student-t process in the infinite-width limit. Our proof leverages theWasserstein metric to establish control over the convergence rate of theStudent-t process approximation.",Francesco Caporali,2025-02-06,2025-02-06,,N/A,"['stat.ML', 'cs.LG', 'math.PR']"
2502.04246v1,Multi-fidelity emulator for large-scale 21 cm lightcone images: a few-shot transfer learning approach with generative adversarial network,http://arxiv.org/abs/2502.04246v1,"Emulators using machine learning techniques have emerged to efficientlygenerate mock data matching the large survey volume for upcoming experiments,as an alternative approach to large-scale numerical simulations. However,high-fidelity emulators have become computationally expensive as the simulationvolume grows to hundreds of megaparsecs. Here, we present a {\itmulti-fidelity} emulation of large-scale 21~cm lightcone images from the epochof reionization, which is realized by applying the {\it few-shot transferlearning} to training generative adversarial networks (GAN) from small-scale tolarge-scale simulations. Specifically, a GAN emulator is first trained with ahuge number of small-scale simulations, and then transfer-learned with only alimited number of large-scale simulations, to emulate large-scale 21~cmlightcone images. We test the precision of our transfer-learned GAN emulator interms of representative statistics including global 21~cm brightnesstemperature history, 2D power spectrum, and scattering transform coefficients.We demonstrate that the lightcone images generated by the transfer-learned GANemulator can reach the percentage level precision in most cases on smallscales, and the error on large scales only increases mildly to the level of afew tens of per cent. Nevertheless, our multi-fidelity emulation techniquesaves a significant portion of computational resources that are mostly consumedfor generating training samples for GAN. On estimate, the computationalresource by training GAN completely with large-scale simulations would be oneto two orders of magnitude larger than using our multi-fidelity technique. Thisimplies that our technique allows for emulating high-fidelity, traditionallycomputationally prohibitive, images in an economic manner.",Kangning Diao,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'astro-ph.CO']"
2502.04245v1,"TriNER: A Series of Named Entity Recognition Models For Hindi, Bengali & Marathi",http://arxiv.org/abs/2502.04245v1,"India's rich cultural and linguistic diversity poses various challenges inthe domain of Natural Language Processing (NLP), particularly in Named EntityRecognition (NER). NER is a NLP task that aims to identify and classify tokensinto different entity groups like Person, Location, Organization, Number, etc.This makes NER very useful for downstream tasks like context-awareanonymization. This paper details our work to build a multilingual NER modelfor the three most spoken languages in India - Hindi, Bengali & Marathi. Wetrain a custom transformer model and fine tune a few pretrained models,achieving an F1 Score of 92.11 for a total of 6 entity groups. Through thispaper, we aim to introduce a single model to perform NER and significantlyreduce the inconsistencies in entity groups and tag names, across the threelanguages.",Mohammed Amaan Dhamaskar,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04244v1,An object detection approach for lane change and overtake detection from motion profiles,http://arxiv.org/abs/2502.04244v1,"In the application domain of fleet management and driver monitoring, it isvery challenging to obtain relevant driving events and activities from dashcamfootage while minimizing the amount of information stored and analyzed. In thispaper, we address the identification of overtake and lane change maneuvers witha novel object detection approach applied to motion profiles, a compactrepresentation of driving video footage into a single image. To train and testour model we created an internal dataset of motion profile images obtained froma heterogeneous set of dashcam videos, manually labeled with overtake and lanechange maneuvers by the ego-vehicle. In addition to a standard object-detectionapproach, we show how the inclusion of CoordConvolution layers further improvesthe model performance, in terms of mAP and F1 score, yielding state-of-the artperformance when compared to other baselines from the literature. The extremelylow computational requirements of the proposed solution make it especiallysuitable to run in device.",Andrea Benericetti,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04243v1,FedOptimus: Optimizing Vertical Federated Learning for Scalability and Efficiency,http://arxiv.org/abs/2502.04243v1,"Federated learning (FL) is a collaborative machine learning paradigm whichensures data privacy by training models across distributed datasets withoutcentralizing sensitive information. Vertical Federated Learning (VFL), a kindof FL training method, facilitates collaboration among participants with eachclient having received a different feature space of a shared user set. VFLthus, proves invaluable in privacy-sensitive domains such as finance andhealthcare. Despite its inherent advantages, VFL faced challenges includingcommunication bottlenecks, computational inefficiency, and slow convergence dueto non-IID data distributions. This paper introduces FedOptimus, a robustMulti-VFL framework integrating advanced techniques for improved modelefficiency and scalability. FedOptimus leverages a Mutual Information(MI)-based client selection to prioritize high-contribution participants,reducing computational overhead. Further, it incorporates server-side momentumtechniques like FedAvgM and SLOWMO to stabilize updates and accelerateconvergence on heterogeneous data. Additionally, performing K-Step Averagingminimizes communication costs while maintaining model performance. FedOptimusproves to be superior in performance on benchmark datasets such as CIFAR-10,MNIST, and FMNIST, showcasing its scalability and effectiveness in real-worldmulti-server, multi-client settings. By unifying advanced optimization methods,FedOptimus sets a new standard for efficient and scalable Vertical FederatedLearning frameworks, paving the way for broader adoption in complex,privacy-sensitive domains.",Nikita Shrivastava,2025-02-06,2025-02-06,,N/A,['cs.DC']
2502.04242v1,A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cramér-Rao Bound,http://arxiv.org/abs/2502.04242v1,"Multi-source transfer learning provides an effective solution to datascarcity in real-world supervised learning scenarios by leveraging multiplesource tasks. In this field, existing works typically use all available samplesfrom sources in training, which constrains their training efficiency and maylead to suboptimal results. To address this, we propose a theoretical frameworkthat answers the question: what is the optimal quantity of source samplesneeded from each source task to jointly train the target model? Specifically,we introduce a generalization error measure that aligns with cross-entropyloss, and minimize it based on the Cram\'er-Rao Bound to determine the optimaltransfer quantity for each source task. Additionally, we develop anarchitecture-agnostic and data-efficient algorithm OTQMS to implement ourtheoretical results for training deep multi-source transfer learning models.Experimental studies on diverse architectures and two real-world benchmarkdatasets show that our proposed algorithm significantly outperformsstate-of-the-art approaches in both accuracy and data efficiency. The code andsupplementary materials are available inhttps://anonymous.4open.science/r/Materials.",Qingyue Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04241v1,Search for hadronic decays of feebly-interacting particles at NA62,http://arxiv.org/abs/2502.04241v1,"The NA62 experiment at CERN has the capability to collect data in a beam-dumpmode, where 400 GeV protons are dumped on an absorber. In this configuration,New Physics particles, including dark photons, dark scalars, and axion-likeparticles, may be produced in the absorber and decay in the instrumented volumebeginning approximately 80 m downstream of the dump. A search for theseparticles decaying in flight to hadronic final states is reported, based on ananalysis of a sample of $1.4 \times 10^{17}$ protons on dump collected in 2021.No evidence of a New Physics signal is observed, excluding new regions ofparameter spaces of multiple models.",NA62 Collaboration,2025-02-06,2025-02-06,,N/A,"['hep-ex', 'hep-ph']"
2502.04240v1,Memory-dependent abstractions of stochastic systems through the lens of transfer operators,http://arxiv.org/abs/2502.04240v1,"With the increasing ubiquity of safety-critical autonomous systems operatingin uncertain environments, there is a need for mathematical methods for formalverification of stochastic models. Towards formally verifying properties ofstochastic systems, methods based on discrete, finite Markov approximations --abstractions -- thereof have surged in recent years. These are found incontexts where: either a) one only has partial, discrete observations of theunderlying continuous stochastic process, or b) the original system is toocomplex to analyze, so one partitions the continuous state-space of theoriginal system to construct a handleable, finite-state model thereof. In bothcases, the abstraction is an approximation of the discrete stochastic processthat arises precisely from the discretization of the underlying continuousprocess. The fact that the abstraction is Markov and the discrete process isnot (even though the original one is) leads to approximation errors. Towardsaccounting for non-Markovianity, we introduce memory-dependent abstractions forstochastic systems, capturing dynamics with memory effects. Our contribution istwofold. First, we provide a formalism for memory-dependent abstractions basedon transfer operators. Second, we quantify the approximation error by upperbounding the total variation distance between the true continuous statedistribution and its discrete approximation.",Adrien Banse,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04238v1,Multitype Lévy trees as scaling limits of multitype Bienaymé-Galton-Watson trees,http://arxiv.org/abs/2502.04238v1,"We establish sufficient conditions for a sequence of metric spaces equippedwith vector-valued measures glued via an iterative operation to converge in theGromov-Hausdorff-Prohorov topology. We use this to show that under mildconditions multitype Bienaym\'e-Galton-Watson trees, conditioned in some senseto be large, converge to a limiting compact metric space which we call amultitype L\'{e}vy tree. More precisely we condition on the size of the maximalsubtree of vertices of the same type generated by the root to be large.Although under a different conditioning, our result can be seen as ageneralization to the multitype setting, of the Continuum Random Tree definedby Aldous in (Aldous 1991, 1993).",Osvaldo Angtuncio Hernández,2025-02-06,2025-02-06,,N/A,['math.PR']
2502.04235v1,MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion,http://arxiv.org/abs/2502.04235v1,"Despite the remarkable capabilities of large language models across varioustasks, their continued scaling faces a critical challenge: the scarcity ofhigh-quality pretraining data. While model architectures continue to evolve,the natural language data struggles to scale up. To tackle this bottleneck, wepropose \textbf{MA}ssive \textbf{G}enre-\textbf{A}udience~(MAGA) reformulationmethod, which systematic synthesizes diverse, contextually-rich pretrainingdata from existing corpus. This work makes three main contributions: (1) Wepropose MAGA reformulation method, a lightweight and scalable approach forpretraining corpus expansion, and build a 770B tokens MAGACorpus. (2) Weevaluate MAGACorpus with different data budget scaling strategies,demonstrating consistent improvements across various model sizes (134M-13B),establishing the necessity for next-generation large-scale syntheticpretraining language models. (3) Through comprehensive analysis, we investigateprompt engineering's impact on synthetic training collapse and reveallimitations in conventional collapse detection metrics using validation losses.Our work shows that MAGA can substantially expand training datasets whilemaintaining quality, offering a reliably pathway for scaling models beyond datalimitations.",Xintong Hao,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04234v1,A Classification System Approach in Predicting Chinese Censorship,http://arxiv.org/abs/2502.04234v1,"This paper is dedicated to using a classifier to predict whether a Weibo postwould be censored under the Chinese internet. Through randomized sampling from\citeauthor{Fu2021} and Chinese tokenizing strategies, we constructed a cleanedChinese phrase dataset with binary censorship markings. Utilizing variousprobability-based information retrieval methods on the data, we were able toderive 4 logistic regression models for classification. Furthermore, weexperimented with pre-trained transformers to perform similar classificationtasks. After evaluating both the macro-F1 and ROC-AUC metrics, we concludedthat the Fined-Tuned BERT model exceeds other strategies in performance.",Matt Prodani,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG', 'cs.SI']"
2502.04233v1,Graph machine learning for flight delay prediction due to holding manouver,http://arxiv.org/abs/2502.04233v1,"Flight delays due to holding maneuvers are a critical and costly phenomenonin aviation, driven by the need to manage air traffic congestion and ensuresafety. Holding maneuvers occur when aircraft are instructed to circle indesignated airspace, often due to factors such as airport congestion, adverseweather, or air traffic control restrictions. This study models the predictionof flight delays due to holding maneuvers as a graph problem, leveragingadvanced Graph Machine Learning (Graph ML) techniques to capture complexinterdependencies in air traffic networks. Holding maneuvers, while crucial forsafety, cause increased fuel usage, emissions, and passenger dissatisfaction,making accurate prediction essential for operational efficiency. Traditionalmachine learning models, typically using tabular data, often overlookspatial-temporal relations within air traffic data. To address this, we modelthe problem of predicting holding as edge feature prediction in a directed(multi)graph where we apply both CatBoost, enriched with graph featurescapturing network centrality and connectivity, and Graph Attention Networks(GATs), which excel in relational data contexts. Our results indicate thatCatBoost outperforms GAT in this imbalanced dataset, effectively predictingholding events and offering interpretability through graph-based featureimportance. Additionally, we discuss the model's potential operational impactthrough a web-based tool that allows users to simulate real-time delaypredictions. This research underscores the viability of graph-based approachesfor predictive analysis in aviation, with implications for enhancing fuelefficiency, reducing delays, and improving passenger experience.",Jorge L. Franco,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.SI']"
2502.04232v1,$D_1$ and $D_2$ resonances in coupled-channel scattering amplitudes from lattice QCD,http://arxiv.org/abs/2502.04232v1,"Isospin-1/2 charmed axial-vector $D^*\pi-D^*\eta-D^*_s\bar{K}$ scatteringamplitudes are computed, along with interactions in several other $I=1/2$ $J^P$channels. Using lattice QCD, we work at a light-quark mass corresponding to$m_\pi\approx 391$ MeV, where the lowest three-hadron threshold ($D\pi\pi$)lies high enough to enable a rigorous treatment of this system considering onlytwo-hadron scattering channels. At this light-quark mass, an axial-vector $D_1$bound state is observed just below $D^*\pi$ threshold, that is strongly coupledto $D^*\pi$ in a relative $S$-wave and influences a wide energy region up tothe $D^*\eta$ threshold. An axial-vector $D_1^\prime$ resonance is observed inthe elastic $D^*\pi$ energy-region, which is coupled more strongly to $D$-wave$D^*\pi$. A single narrow tensor state is seen in $J^P=2^+$ coupled to both$D\pi$ and $D^*\pi$. In the region where $D^*\eta$ and $D^*_s\bar{K}$ arekinematically open, the available energy levels indicate significant $S$-waveinteractions. Upon searching this region for poles, several possibilities existwith large uncertainties. One additional state consistently arises,predominantly coupled to the $S$-wave $D^*\pi-D^*\eta-D^*_s\bar{K}$ amplitudesaround the upper energy limit of this analysis.",Nicolas Lang,2025-02-06,2025-02-06,,N/A,"['hep-lat', 'hep-ph']"
2502.04423v1,Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions,http://arxiv.org/abs/2502.04423v1,"Referral workflow inefficiencies, including misaligned referrals and delays,contribute to suboptimal patient outcomes and higher healthcare costs. In thisstudy, we investigated the possibility of predicting procedural needs based onprimary care diagnostic entries, thereby improving referral accuracy,streamlining workflows, and providing better care to patients. A de-identifieddataset of 2,086 orthopedic referrals from the University of Texas Health atTyler was analyzed using machine learning models built on Base GeneralEmbeddings (BGE) for semantic extraction. To ensure real-world applicability,noise tolerance experiments were conducted, and oversampling techniques wereemployed to mitigate class imbalance. The selected optimum and parsimoniousembedding model demonstrated high predictive accuracy (ROC-AUC: 0.874, MatthewsCorrelation Coefficient (MCC): 0.540), effectively distinguishing patientsrequiring surgical intervention. Dimensionality reduction techniques confirmedthe model's ability to capture meaningful clinical relationships. A thresholdsensitivity analysis identified an optimal decision threshold (0.30) to balanceprecision and recall, maximizing referral efficiency. In the predictivemodeling analysis, the procedure rate increased from 11.27% to an optimal60.1%, representing a 433% improvement with significant implications foroperational efficiency and healthcare revenue.  The results of our study demonstrate that referral optimization can enhanceprimary and surgical care integration. Through this approach, precise andtimely predictions of procedural requirements can be made, thereby minimizingdelays, improving surgical planning, and reducing administrative burdens. Inaddition, the findings highlight the potential of clinical decision support asa scalable solution for improving patient outcomes and the efficiency of thehealthcare system.",Khushboo Verma,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7; J.3; H.2.8']"
2502.04229v1,Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data,http://arxiv.org/abs/2502.04229v1,"Dataset distillation (DD) enhances training efficiency and reduces bandwidthby condensing large datasets into smaller synthetic ones. It enables models toachieve performance comparable to those trained on the raw full dataset and hasbecome a widely adopted method for data sharing. However, security concerns inDD remain underexplored. Existing studies typically assume that maliciousbehavior originates from dataset owners during the initial distillationprocess, where backdoors are injected into raw datasets. In contrast, this workis the first to address a more realistic and concerning threat: attackers mayintercept the dataset distribution process, inject backdoors into the distilleddatasets, and redistribute them to users. While distilled datasets werepreviously considered resistant to backdoor attacks, we demonstrate that theyremain vulnerable to such attacks. Furthermore, we show that attackers do noteven require access to any raw data to inject the backdoors successfully.Specifically, our approach reconstructs conceptual archetypes for each classfrom the model trained on the distilled dataset. Backdoors are then injectedinto these archetypes to update the distilled dataset. Moreover, we ensure theupdated dataset not only retains the backdoor but also preserves the originaloptimization trajectory, thus maintaining the knowledge of the raw dataset. Toachieve this, a hybrid loss is designed to integrate backdoor information alongthe benign optimization trajectory, ensuring that previously learnedinformation is not forgotten. Extensive experiments demonstrate that distilleddatasets are highly vulnerable to backdoor attacks, with risks pervasive acrossvarious raw datasets, distillation methods, and downstream training strategies.Moreover, our attack method is efficient, capable of synthesizing a maliciousdistilled dataset in under one minute in certain cases.",Ziyuan Yang,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.AI']"
2502.04227v1,Can LLMs Hack Enterprise Networks? Autonomous Assumed Breach Penetration-Testing Active Directory Networks,http://arxiv.org/abs/2502.04227v1,"We explore the feasibility and effectiveness of using LLM-driven autonomoussystems for Assumed Breach penetration testing in enterprise networks. Weintroduce a novel prototype that, driven by Large Language Models (LLMs), cancompromise accounts within a real-life Active Directory testbed. Our researchprovides a comprehensive evaluation of the prototype's capabilities, andhighlights both strengths and limitations while executing attack. Theevaluation uses a realistic simulation environment (Game of Active Directory,GOAD) to capture intricate interactions, stochastic outcomes, and timingdependencies that characterize live network scenarios. The study concludes thatautonomous LLMs are able to conduct Assumed Breach simulations, potentiallydemocratizing access to penetration testing for organizations facing budgetaryconstraints.  The prototype's source code, traces, and analyzed logs are released asopen-source to enhance collective cybersecurity and facilitate future researchin LLM-driven cybersecurity automation.",Andreas Happe,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04226v1,Keep It Light! Simplifying Image Clustering Via Text-Free Adapters,http://arxiv.org/abs/2502.04226v1,"Many competitive clustering pipelines have a multi-modal design, leveraginglarge language models (LLMs) or other text encoders, and text-image pairs,which are often unavailable in real-world downstream applications.Additionally, such frameworks are generally complicated to train and requiresubstantial computational resources, making widespread adoption challenging. Inthis work, we show that in deep clustering, competitive performance with morecomplex state-of-the-art methods can be achieved using a text-free and highlysimplified training pipeline. In particular, our approach, Simple Clusteringvia Pre-trained models (SCP), trains only a small cluster head while leveragingpre-trained vision model feature representations and positive data pairs.Experiments on benchmark datasets including CIFAR-10, CIFAR-20, CIFAR-100,STL-10, ImageNet-10, and ImageNet-Dogs, demonstrate that SCP achieves highlycompetitive performance. Furthermore, we provide a theoretical resultexplaining why, at least under ideal conditions, additional text-basedembeddings may not be necessary to achieve strong clustering performance invision.",Yicen Li,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG', 'cs.NE', 'stat.CO', 'stat.ML']"
2502.04225v1,Stochastic SIR model with individual heterogeneity and infection-age dependent infectivity on large non-homogeneous random graphs,http://arxiv.org/abs/2502.04225v1,"We study an individual-based stochastic SIR epidemic model with infection-agedependent infectivity on a large random graph, capturing individualheterogeneity and non-homogeneous connectivity. Each individual is associatedwith particular characteristics (for example, spatial location and agestructure), which may not be i.i.d., and represented by a particular node. Theconnectivities among the individuals are given by a non-homogeneous randomgraph, whose connecting probabilities may depend on the individualcharacteristics of the edge. Each individual is associated with a randomvarying infectivity function, which is also associated with the individualcharacteristics. We use measure-valued processes to describe the epidemicevolution dynamics, tracking the infection age of all individuals, and theirassociated characteristics. We consider the epidemic dynamics as the populationsize grows to infinity under a specific scaling of the connectivity graphrelated to the convergence to a graphon. In the limit, we obtain a system ofmeasure-valued equations, which can be also represented as a PDE model ongraphon, which reflects the heterogeneities in individual characteristics andsocial connectivity.",Guodong Pang,2025-02-06,2025-02-06,,N/A,"['math.PR', '60F17, 05C80, 92D30 (Primary), 60J76, 60G57, 35Q70 (Secondary)']"
2502.04224v1,Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks,http://arxiv.org/abs/2502.04224v1,"Explaining Graph Neural Network (XGNN) has gained growing attention tofacilitate the trust of using GNNs, which is the mainstream method to learngraph data. Despite their growing attention, Existing XGNNs focus on improvingthe explanation performance, and its robustness under attacks is largelyunexplored. We noticed that an adversary can slightly perturb the graphstructure such that the explanation result of XGNNs is largely changed. Suchvulnerability of XGNNs could cause serious issues particularly insafety/security-critical applications. In this paper, we take the first step tostudy the robustness of XGNN against graph perturbation attacks, and proposeXGNNCert, the first provably robust XGNN. Particularly, our XGNNCert canprovably ensure the explanation result for a graph under the worst-case graphperturbation attack is close to that without the attack, while not affectingthe GNN prediction, when the number of perturbed edges is bounded. Evaluationresults on multiple graph datasets and GNN explainers show the effectiveness ofXGNNCert.",Jiate Li,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04223v1,Éclair -- Extracting Content and Layout with Integrated Reading Order for Documents,http://arxiv.org/abs/2502.04223v1,"Optical Character Recognition (OCR) technology is widely used to extract textfrom images of documents, facilitating efficient digitization and dataretrieval. However, merely extracting text is insufficient when dealing withcomplex documents. Fully comprehending such documents requires an understandingof their structure -- including formatting, formulas, tables, and the readingorder of multiple blocks and columns across multiple pages -- as well assemantic information for detecting elements like footnotes and image captions.This comprehensive understanding is crucial for downstream tasks such asretrieval, document question answering, and data curation for training LargeLanguage Models (LLMs) and Vision Language Models (VLMs). To address this, weintroduce \'Eclair, a general-purpose text-extraction tool specificallydesigned to process a wide range of document types. Given an image, \'Eclair isable to extract formatted text in reading order, along with bounding boxes andtheir corresponding semantic classes. To thoroughly evaluate these novelcapabilities, we introduce our diverse human-annotated benchmark fordocument-level OCR and semantic classification. \'Eclair achievesstate-of-the-art accuracy on this benchmark, outperforming other methods acrosskey metrics. Additionally, we evaluate \'Eclair on established benchmarks,demonstrating its versatility and strength across several evaluation standards.",Ilia Karmanov,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04222v1,Separation Property for the Nonlocal Cahn Hilliard Brinkman System with Singular Potential and Degenerate Mobility,http://arxiv.org/abs/2502.04222v1,"This work studies the nonlocal Cahn Hilliard Brinkman system, which modelsthe phase separation of a binary fluid in a bounded domain and porous media. Wefocus on a system with a singular potential namely logarithmic form and adegenerate mobility function. The singular potential introduces challenges dueto the blow up of its derivatives near pure phases, while the degeneratemobility complicates the analysis. Our main result is the separation property,which ensures that the solution eventually stays away from the pure phases. Weadopt a new method, inspired by the De Giorgi iteration, introduced for the twodimensional Cahn Hilliard equation with constant mobility. This work extendsprevious results and provides a general approach for proving the separationproperty for similar systems.",Sheetal Dharmatti,2025-02-06,2025-02-06,,N/A,"['math.AP', '35B40, 35B45, 35K55, 76S05, 76D99, 76T99']"
2502.04220v1,Dimension estimation in PCA model using high-dimensional data augmentation,http://arxiv.org/abs/2502.04220v1,"We propose a modified, high-dimensional version of a recent dimensionestimation procedure that determines the dimension via the introduction ofaugmented noise variables into the data. Our asymptotic results show that theproposal is consistent in wide high-dimensional scenarios, and further shedlight on why the original method breaks down when the dimension of either thedata or the augmentation becomes too large. Simulations are used to demonstratethe superiority of the proposal to competitors both under and outside of thetheoretical model.",Una Radojicic,2025-02-06,2025-02-06,,N/A,"['math.ST', 'stat.ME', 'stat.TH']"
2502.04219v1,NLP-Based .NET CLR Event Logs Analyzer,http://arxiv.org/abs/2502.04219v1,"In this paper, we present a tool for analyzing .NET CLR event logs based on anovel method inspired by Natural Language Processing (NLP) approach. Ourresearch addresses the growing need for effective monitoring and optimizationof software systems through detailed event log analysis. We utilize aBERT-based architecture with an enhanced tokenization process customized toevent logs. The tool, developed using Python, its libraries, and an SQLitedatabase, allows both conducting experiments for academic purposes andefficiently solving industry-emerging tasks. Our experiments demonstrate theefficacy of our approach in compressing event sequences, detecting recurringpatterns, and identifying anomalies. The trained model shows promising results,with a high accuracy rate in anomaly detection, which demonstrates thepotential of NLP methods to improve the reliability and stability of softwaresystems.",Maxim Stavtsev,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.AI']"
2502.04218v1,Sports and Women's Sports: Gender Bias in Text Generation with Olympic Data,http://arxiv.org/abs/2502.04218v1,"Large Language Models (LLMs) have been shown to be biased in prior work, asthey generate text that is in line with stereotypical views of the world orthat is not representative of the viewpoints and values of historicallymarginalized demographic groups. In this work, we propose using data fromparallel men's and women's events at the Olympic Games to investigate differentforms of gender bias in language models. We define three metrics to measurebias, and find that models are consistently biased against women when thegender is ambiguous in the prompt. In this case, the model frequently retrievesonly the results of the men's event with or without acknowledging them as such,revealing pervasive gender bias in LLMs in the context of athletics.",Laura Biester,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04217v1,Recovering sparse DFT from missing signals via interior point method on GPU,http://arxiv.org/abs/2502.04217v1,"We propose a method to recover the sparse discrete Fourier transform (DFT) ofa signal that is both noisy and potentially incomplete, with missing values.The problem is formulated as a penalized least-squares minimization based onthe inverse discrete Fourier transform (IDFT) with an $\ell_1$-penalty term,reformulated to be solvable using a primal-dual interior point method (IPM).Although Krylov methods are not typically used to solve Karush-Kuhn-Tucker(KKT) systems arising in IPMs due to their ill-conditioning, we employ atailored preconditioner and establish new asymptotic bounds on the conditionnumber of preconditioned KKT matrices. Thanks to this dedicated preconditioner-- and the fact that FFT and IFFT operate as linear operators without requiringexplicit matrix materialization -- KKT systems can be solved efficiently atlarge scales in a matrix-free manner. Numerical results from a Juliaimplementation leveraging GPU-accelerated interior point methods, Krylovmethods, and FFT toolkits demonstrate the scalability of our approach onproblems with hundreds of millions of variables, inclusive of real dataobtained from the diffuse scattering from a slightly disordered MolybdenumVanadium Dioxide crystal.",Wei Kuang,2025-02-06,2025-02-06,,N/A,['math.OC']
2502.04216v1,Resolving shortwave and longwave irradiation distributions across the human body in outdoor built environments,http://arxiv.org/abs/2502.04216v1,"Outdoor built environments can be designed to enhance thermal comfort, yetthe relationship between the two is often assessed in whole-body terms,overlooking the asymmetric nature of thermal interactions between the humanbody and its surroundings. Moreover, the radiative component of heatexchange-dominant in hot and dry climates-is typically lumped into a singleartificial metric, the mean radiant temperature, rather than being resolvedinto its shortwave and longwave spectral components. The shortwave irradiationdistribution on the human body is often highly anisotropic, causing localizedthermal discomfort in outdoor environments. However, no existing methodseffectively quantify shortwave and longwave irradiation distributions on thehuman body. To address this gap, we developed two methods to quantify theseprocesses. The first approach uses an outdoor thermal manikin with awhite-coated side, enabling the separation of spectral components bysubtracting measurements from symmetrically corresponding surface zones of tancolor. The second hybrid approach converts radiometer measurements in sixdirections into boundary conditions for computational thermal manikinsimulations. We evaluated irradiation distributions for various body partsusing both methods during outdoor measurements across sunny, partially shaded,and fully shaded sites under warm to extremely hot conditions. In most cases,the two methods produced closely aligned results, with divergences highlightingtheir respective strengths and limitations. Additionally, we used the manikinto quantify irradiation attenuation provided by five long-sleeve shirts withcolors ranging from white to black. These advanced methods can be integratedwith airflow and thermoregulatory modeling to optimize outdoor builtenvironments for enhanced human thermal comfort.",Kambiz Sadeghi,2025-02-06,2025-02-06,,N/A,['physics.bio-ph']
2502.04212v1,The DESI 2024 hint for dynamical dark energy is biased by low-redshift supernovae,http://arxiv.org/abs/2502.04212v1,"Recently, a $\sim3.9\sigma$ preference for dynamical dark energy from theDark Energy Spectroscopic Instrument (DESI) collaboration inspired hot debateson new physics or systematics. In this letter, we reveal this significantpreference is dominated by an external low-redshift supernova (low-$z$ SN)sample that combines with the Dark Energy Survey SN program (DES-SN) in theirYear 5 data release (DESY5). Further implementing the $a_B$ (the intercept ofthe SN magnitude-redshift relation) diagnosis between low-$z$ and DES-SNsamples, we find large dispersions in the low-$z$ SN sample with a $\sim0.043$magnitude discrepancy in $-5a_B$ from the high-$z$ DES-SN sample, suggestingpotential systematics in DESY5. Correcting for this low-$z$ systematics ordirectly ignoring the low-$z$ sample can largely reduce the preference fordynamical DE to be $<2\sigma$. Therefore, the DESI preference for dynamical DEmight be a mirage of low-$z$ SN systematics with a mismatch intercept. Ouradditional test demonstrates the currently available data cannot providedecisive evidence for dynamical DE.",Lu Huang,2025-02-06,2025-02-06,,N/A,['astro-ph.CO']
2502.04211v1,Exploring the limits of nucleonic metamodelling using different relativistic density functionals,http://arxiv.org/abs/2502.04211v1,"In this work, we explore two classes of density dependent relativisticmean-field models, their predictions of proton fractions at high densities andneutron star structure. We have used a metamodelling approach to theserelativistic density functionals. We have generated a large ensemble of modelswith these classes and then applied constraints from theoretical andexperimental nuclear physics and astrophysical observations. We find that bothmodels produce similar equations of state and neutron star mass-radiussequences. But, their underlying compositions, denoted by the proton fractionin this case, are vastly different. This reinstates previous findings thatinformation on composition gets masqueraded in $\beta$-equilibrium. Additionalobservations of non-equilibrium phenomena are necessary to pin it down.",Prasanta Char,2025-02-06,2025-02-06,,N/A,"['nucl-th', 'astro-ph.HE']"
2502.04210v1,Algorithmic causal structure emerging through compression,http://arxiv.org/abs/2502.04210v1,"We explore the relationship between causality, symmetry, and compression. Webuild on and generalize the known connection between learning and compressionto a setting where causal models are not identifiable. We propose a frameworkwhere causality emerges as a consequence of compressing data across multipleenvironments. We define algorithmic causality as an alternative definition ofcausality when traditional assumptions for causal identifiability do not hold.We demonstrate how algorithmic causal and symmetric structures can emerge fromminimizing upper bounds on Kolmogorov complexity, without knowledge ofintervention targets. We hypothesize that these insights may also provide anovel perspective on the emergence of causality in machine learning models,such as large language models, where causal relationships may not be explicitlyidentifiable.",Liang Wendong,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CC', 'cs.IT', 'math.IT']"
2502.04209v1,Radon Removal in XENONnT down to the Solar Neutrino Level,http://arxiv.org/abs/2502.04209v1,"The XENONnT experiment has achieved an unprecedented reduction of the$^\text{222}$Rn activity concentration within its liquid xenon dual-phase timeprojection chamber to a level of (0.90$\,\pm\,$0.01$\,$stat.$\,\pm\,$0.07sys.)$\,\mu$Bq/kg, equivalent to about 1200 $^\text{222}$Rn atoms per cubicmeter of liquid xenon. This represents a 15-fold improvement over the$^\text{222}$Rn levels encountered during XENON1T's main science runs and is afactor five lower compared to other currently operational multi-tonne liquidxenon detectors engaged in dark matter searches. This breakthrough enables thepursuit of various rare event searches that lie beyond the confines of thestandard model of particle physics, with world-leading sensitivity. Theultra-low $^\text{222}$Rn levels have diminished the radon-induced backgroundrate in the detector to a point where it is for the first time lower than thesolar neutrino-induced background, which is poised to become the primaryirreducible background in liquid xenon-based detectors.",E. Aprile,2025-02-06,2025-02-06,,N/A,"['physics.ins-det', 'hep-ex']"
2502.04206v1,Ensuring Reliability via Hyperparameter Selection: Review and Advances,http://arxiv.org/abs/2502.04206v1,"Hyperparameter selection is a critical step in the deployment of artificialintelligence (AI) models, particularly in the current era of foundational,pre-trained, models. By framing hyperparameter selection as a multiplehypothesis testing problem, recent research has shown that it is possible toprovide statistical guarantees on population risk measures attained by theselected hyperparameter. This paper reviews the Learn-Then-Test (LTT)framework, which formalizes this approach, and explores several extensionstailored to engineering-relevant scenarios. These extensions encompassdifferent risk measures and statistical guarantees, multi-objectiveoptimization, the incorporation of prior knowledge and dependency structuresinto the hyperparameter selection process, as well as adaptivity. The paperalso includes illustrative applications for communication systems.",Amirmohammad Farzaneh,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.IT', 'math.IT']"
2502.04205v1,Beyond 2050: From deployment to renewal of the global solar PV system,http://arxiv.org/abs/2502.04205v1,"The global energy transition relies heavily on the large-scale deployment ofPV capacity with deployment targets typically defined for 2050. However,sustaining the PV system beyond 2050 will require continuous renewal. Thisresearch explores the overlooked industrial transition from the initialimplementation phase to the long-term renewal phase, emphasizing theconsequences of this dynamic shift. Using streamlined modelling we estimate theannual production needed to both expand and maintain the global PV system. Ourresults indicate that PV panel production dynamics during this transition arevery sensitive to two key factors: deployment speed and panel lifespan. Ifdeployment occurs over a shorter period than the average panel lifespan,production initially overshoots and exhibits an endogenous damped oscillatorybehavior due to a succession of installation and replacement cycles.Conversely, if deployment is more gradual, production increases smoothly beforestabilizing at the renewal rate. Given the current deployment scenarios andlifespan estimates, the PV industry is likely to face significant productiondamped oscillations, up to 60%. These oscillations, corresponding toover/underproduction, are further amplified by the increasingly ambitiousenergy transition targets, which accelerate deployment rates. Panel lifespanconversly remains a less flexible parameter. This study discusses oscillationsfrom a systemic perspective and how they could exacerbate challenges for thelong-term sustainability of PV, including industrial, workforce, economic andgeopolitical dimensions. Beyond the case of PV, this study underscores abroader issue in the energy transition: the shift from infrastructure expansionto long-term maintenance through renewal. Addressing this often-overlookedphase is essential for ensuring the sustainability of renewable energy systemsbeyond 2050.",Joseph Le Bihan,2025-02-06,2025-02-06,,N/A,"['physics.soc-ph', '93-10, 91B74']"
2502.04204v1,"""Short-length"" Adversarial Training Helps LLMs Defend ""Long-length"" Jailbreak Attacks: Theoretical and Empirical Evidence",http://arxiv.org/abs/2502.04204v1,"Jailbreak attacks against large language models (LLMs) aim to induce harmfulbehaviors in LLMs through carefully crafted adversarial prompts. To mitigateattacks, one way is to perform adversarial training (AT)-based alignment, i.e.,training LLMs on some of the most adversarial prompts to help them learn how tobehave safely under attacks. During AT, the length of adversarial prompts playsa critical role in the robustness of aligned LLMs. This paper focuses onadversarial suffix jailbreak attacks and unveils that to defend against ajailbreak attack with an adversarial suffix of length $\Theta(M)$, it is enoughto align LLMs on prompts with adversarial suffixes of length$\Theta(\sqrt{M})$. Theoretically, we analyze the adversarial in-contextlearning of linear transformers on linear regression tasks and prove a robustgeneralization bound for trained transformers. The bound depends on the term$\Theta(\sqrt{M_{\text{test}}}/M_{\text{train}})$, where $M_{\text{train}}$ and$M_{\text{test}}$ are the number of adversarially perturbed in-context samplesduring training and testing. Empirically, we conduct AT on popular open-sourceLLMs and evaluate their robustness against jailbreak attacks of differentadversarial suffix lengths. Results confirm a positive correlation between theattack success rate and the ratio of the square root of the adversarial suffixduring jailbreaking to the length during AT. Our findings show that it ispractical to defend ""long-length"" jailbreak attacks via efficient""short-length"" AT. The code is available at https://github.com/fshp971/adv-icl.",Shaopeng Fu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CR', 'stat.ML']"
2502.04203v1,Large Negative Magnetoresistance in off-Stochiometric Topological Material PrSbTe,http://arxiv.org/abs/2502.04203v1,"Magnetic topological materials LnSbTe (Ln = lanthanide) have attractedintensive attention because of the presence of interplay between magnetism,topological, and electron correlations depending on the choices of magnetic Lnelements. Varying Sb and Te composition is an efficient approach to controlstructural, magnetic, and electronic properties. Here we report thecomposition-dependent properties in PrSbxTe2-x. We identified thetetragonal-to-orthorhombic structure transitions in this material system, andvery large negative magnetoresistance in the x = 0.3 composition, which mightbe ascribed to the coupling between magnetism and transport. Such unusualmagnetotransport enables PrSbxTe2-x topological materials as a promisingplatform for device applications.",Gokul Acharya,2025-02-06,2025-02-06,,N/A,['cond-mat.mtrl-sci']
2502.04200v2,Characterizing Bugs in Login Processes of Android Applications: An Empirical Study,http://arxiv.org/abs/2502.04200v2,"The login functionality, being the gateway to app usage, plays a criticalrole in both user experience and application security. As Android appsincreasingly incorporate login functionalities, they support a variety ofauthentication methods with complicated login processes, catering topersonalized user experiences. However, the complexities in managing differentoperations in login processes make it difficult for developers to handle themcorrectly. In this paper, we present the first empirical study of login issuesin Android apps. We analyze 361 issues from 44 popular open-source Androidrepositories, examining the root causes, symptoms, and trigger conditions ofthese issues. Our findings indicate that the vast majority of the login issuesare induced by the improper handling of complex state transitions during thelogin process, which can prevent users from logging in or misdirect them toincorrect subsequent actions. Additionally, we observed that issues related tothis cause typically require the convergence of multiple trigger conditions tomanifest. These findings can help developers to model the login processes whichcan help them to identify the causes of issues and design targeted test casesand precise test oracles. Our dataset has been made openly available tofacilitate future research in this area.",Zixu Zhou,2025-02-06,2025-02-07,,N/A,['cs.SE']
2502.04199v1,Expanding Training Data for Endoscopic Phenotyping of Eosinophilic Esophagitis,http://arxiv.org/abs/2502.04199v1,"Eosinophilic esophagitis (EoE) is a chronic esophageal disorder marked byeosinophil-dominated inflammation. Diagnosing EoE usually involves endoscopicinspection of the esophageal mucosa and obtaining esophageal biopsies forhistologic confirmation. Recent advances have seen AI-assisted endoscopicimaging, guided by the EREFS system, emerge as a potential alternative toreduce reliance on invasive histological assessments. Despite theseadvancements, significant challenges persist due to the limited availability ofdata for training AI models - a common issue even in the development of AI formore prevalent diseases. This study seeks to improve the performance of deeplearning-based EoE phenotype classification by augmenting our training datawith a diverse set of images from online platforms, public datasets, andelectronic textbooks increasing our dataset from 435 to 7050 images. Weutilized the Data-efficient Image Transformer for image classification andincorporated attention map visualizations to boost interpretability. Thefindings show that our expanded dataset and model enhancements improveddiagnostic accuracy, robustness, and comprehensive analysis, enhancing patientoutcomes.",Juming Xiong,2025-02-06,2025-02-06,,N/A,"['eess.IV', 'cs.CV']"
2502.04195v1,Integration of Prior Knowledge into Direct Learning for Safe Control of Linear Systems,http://arxiv.org/abs/2502.04195v1,"This paper integrates prior knowledge into direct learning of safecontrollers for linear uncertain systems under disturbances. To this end, wecharacterize the set of all closed-loop systems that can be explained byavailable prior knowledge of the system model and the disturbances. We leveragematrix zonotopes for data-based characterization of closed-loop systems andshow that the explainability of closed-loop systems by prior knowledge can beformalized by adding an equality conformity constraint to the matrix zonotope.We then leverage the resulting constraint matrix zonotope and design safecontrollers that conform with both data and prior knowledge. This is achievedby ensuring the inclusion of a constrained zonotope of all possible next statesin a {\lambda}-scaled level set of the safe set. We consider both polytope andzonotope safe sets and provide set inclusion conditions using linearprogramming.",Amir Modares,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04194v2,The Best Instruction-Tuning Data are Those That Fit,http://arxiv.org/abs/2502.04194v2,"High-quality supervised fine-tuning (SFT) data are crucial for elicitingstrong capabilities from pretrained large language models (LLMs). Typically,instructions are paired with multiple responses sampled from other LLMs, whichare often out of the distribution of the target model to be fine-tuned. This,at scale, can lead to diminishing returns and even hurt the models' performanceand robustness. We propose **GRAPE**, a novel SFT framework that accounts forthe unique characteristics of the target model. For each instruction, itgathers responses from various LLMs and selects the one with the highestprobability measured by the target model, indicating that it aligns mostclosely with the target model's pretrained distribution; it then proceeds withstandard SFT training.  We first evaluate GRAPE with a controlled experiment, where we sample varioussolutions for each question in UltraInteract from multiple models and fine-tunecommonly used LMs like LLaMA3.1-8B, Mistral-7B, and Qwen2.5-7B onGRAPE-selected data. GRAPE significantly outperforms strong baselines,including distilling from the strongest model with an absolute gain of up to13.8%, averaged across benchmarks, and training on 3x more data with a maximumperformance improvement of 17.3%. GRAPE's strong performance generalizes torealistic settings. We experiment with the post-training data used for Tulu3and Olmo-2. GRAPE outperforms strong baselines trained on 4.5 times more databy 6.1% and a state-of-the-art data selection approach by 3% on averageperformance. Remarkably, using 1/3 of the data and half the number of epochs,GRAPE enables LLaMA3.1-8B to surpass the performance of Tulu3-SFT by 3.5%.",Dylan Zhang,2025-02-06,2025-02-07,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.04192v1,PixFoundation: Are We Heading in the Right Direction with Pixel-level Vision Foundation Models?,http://arxiv.org/abs/2502.04192v1,"Multiple works have emerged to push the boundaries on multi-modal largelanguage models (MLLMs) towards pixel-level understanding. Such approaches haveshown strong performance on benchmarks for referring expression segmentationand grounded conversation generation. The current trend in pixel-level MLLMs isto train with pixel-level grounding supervision on large-scale labelled data.However, we show that such MLLMs when evaluated on recent challenging visioncentric benchmarks, exhibit a weak ability in visual question answering.Surprisingly, some of these methods even downgrade the grounding ability ofMLLMs that were never trained with such supervision. In this work, we proposetwo novel challenging benchmarks and show that MLLMs without pixel-levelgrounding supervision can outperform the state of the art in such tasks whenevaluating both the pixel-level grounding and visual question answering. Wepropose simple baselines to extract the grounding information that can beplugged into any MLLM, which we call as PixFoundation. More importantly, westudy the research question of ``When does grounding emerge in MLLMs that arenot trained with pixel-level grounding supervision?'' We show that groundingcan coincide with object parts or location/appearance information. Coderepository is at https://github.com/MSiam/PixFoundation/.",Mennatullah Siam,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04191v1,Systematic Analysis of $B_s \to SP$ Decays in Perturbative QCD Approach,http://arxiv.org/abs/2502.04191v1,"Within the perturbative QCD (PQCD) framework, we present a systematicinvestigation of charmless $B_s \to SP$ decays, where $S$ and $P$ denote scalarand pseudoscalar mesons, respectively. By employing two distinct structuralscenarios for scalar mesons, we calculate the branching fractions and direct$CP$ asymmetries for these processes. Our results reveal branching fractionsranging from $10^{-7}$ to $10^{-5}$, values that are well within the measurablerange of current experiments. A striking contrast emerges between penguin- andtree-dominated decays: while penguin-dominated processes yield larger branchingfractions, tree-dominated decays exhibit significantly enhanced direct $CP$asymmetries. In particular, the decays $B_s \to f_0(1370) \eta$ and $B_s \toa_0(1450) K$ demonstrate marked sensitivity to the choice of scalar mesonscenario, offering critical constraints for identifying the optimal model onceexperimental data are available. Furthermore, we calculate the branchingfractions of $B_s \to f_0(980)(\sigma)P$ decays in two distinct ranges of themixing angle of $f_0(980)-\sigma$. The dependencies of both branching fractionsand $CP$ asymmetries on this mixing angle are rigorously analyzed, establishinga framework essential for determining its value with future experimentalresults. These findings provide a robust theoretical foundation for advancingthe understanding of nonleptonic $B_s$decays in QCD-based formalisms, as wellas the nature of scalar mesons.",Zhi-Tian Zou,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'hep-ex']"
2502.04188v1,Automated Microservice Pattern Instance Detection Using Infrastructure-as-Code Artifacts and Large Language Models,http://arxiv.org/abs/2502.04188v1,"Documenting software architecture is essential to preserve architectureknowledge, even though it is frequently costly. Architecture pattern instances,including microservice pattern instances, provide important structural softwareinformation. Practitioners should document this information to preventknowledge vaporization. However, architecture patterns may not be detectable byanalyzing source code artifacts, requiring the analysis of other types ofartifacts. Moreover, many existing pattern detection instance approaches arecomplex to extend. This article presents our ongoing PhD research, earlyexperiments, and a prototype for a tool we call MicroPAD for automating thedetection of microservice pattern instances. The prototype uses Large LanguageModels (LLMs) to analyze Infrastructure-as-Code (IaC) artifacts to aiddetection, aiming to keep costs low and maximize the scope of detectablepatterns. Early experiments ran the prototype thrice in 22 GitHub projects. Weverified that 83\% of the patterns that the prototype identified were in theproject. The costs of detecting the pattern instances were minimal. Theseresults indicate that the approach is likely viable and, by lowering the entrybarrier to automating pattern instance detection, could help democratizedeveloper access to this category of architecture knowledge. Finally, wepresent our overall research methodology, planned future work, and an overviewof MicroPAD's potential industrial impact.",Carlos Eduardo Duarte,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'D.2.11']"
2502.04186v1,Model-based reconstruction of real-world fractal complex networks,http://arxiv.org/abs/2502.04186v1,"This paper presents a versatile model for generating fractal complex networksthat closely mirror the properties of real-world systems. By combining featuresof reverse renormalization and evolving network models, the proposed approachintroduces several tunable parameters, offering exceptional flexibility incapturing the diverse topologies and scaling behaviors found in both naturaland man-made networks. The model effectively replicates their keycharacteristics such as fractal dimensions, power-law degree distributions, anddensities. Unlike traditional deterministic models, it incorporatesstochasticity into the network growth process, overcoming limitations likediscontinuities in degree distributions and rigid size constraints. The model'sapplicability is demonstrated through its ability to reproduce the structuralfeatures of real-world fractal networks, including the Internet, the World WideWeb, and co-authorship networks.",Kordian Makulski,2025-02-06,2025-02-06,,N/A,"['physics.soc-ph', 'cond-mat.dis-nn']"
2502.04182v1,Fast In-Spectrum Graph Watermarks,http://arxiv.org/abs/2502.04182v1,"We address the problem of watermarking graph objects, which consists inhiding information within them, to prove their origin. The two existing methodsto watermark graphs use subgraph matching or graph isomorphism techniques,which are known to be intractable for large graphs. To reduce the operationalcomplexity, we propose FFG, a new graph watermarking scheme adapted from animage watermarking scheme, since graphs and images can be represented asmatrices. We analyze and compare FFG, whose novelty lies in embedding thewatermark in the Fourier transform of the adjacency matrix of a graph. Ourtechnique enjoys a much lower complexity than that of related works (i.e. in$\mathcal{O}\left(N^2 \log N\right)$), while performing better or at least aswell as the two state-of-the-art methods.",Jade Garcia Bourrée,2025-02-06,2025-02-06,,N/A,['cs.DS']
2502.04180v1,Multi-agent Architecture Search via Agentic Supernet,http://arxiv.org/abs/2502.04180v1,"Large Language Model (LLM)-empowered multi-agent systems extend the cognitiveboundaries of individual agents through disciplined collaboration andinteraction, while constructing these systems often requires labor-intensivemanual designs. Despite the availability of methods to automate the design ofagentic workflows, they typically seek to identify a static, complex,one-size-fits-all system, which, however, fails to dynamically allocateinference resources based on the difficulty and domain of each query. Toaddress this challenge, we shift away from the pursuit of a monolithic agenticsystem, instead optimizing the \textbf{agentic supernet}, a probabilistic andcontinuous distribution of agentic architectures. We introduce MaAS, anautomated framework that samples query-dependent agentic systems from thesupernet, delivering high-quality solutions and tailored resource allocation(\textit{e.g.}, LLM calls, tool calls, token cost). Comprehensive evaluationacross six benchmarks demonstrates that MaAS \textbf{(I)} requires only$6\sim45\%$ of the inference costs of existing handcrafted or automatedmulti-agent systems, \textbf{(II)} surpasses them by $0.54\%\sim11.82\%$, and\textbf{(III)} enjoys superior cross-dataset and cross-LLM-backbonetransferability.",Guibin Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL', 'cs.MA']"
2502.04179v1,The Maximum Likelihood Degree of Gumbel's Type-I Bivariate Exponential Distribution,http://arxiv.org/abs/2502.04179v1,"In algebraic statistics, the maximum likelihood degree of a statistical modelrefers to the number of solutions (counted with multiplicity) of the scoreequations over the complex field. In this paper, the maximum likelihood degreeof the association parameter of Gumbels Type-I bivariate exponentialdistribution is investigated using algebraic techniques.",Pooja Yadav,2025-02-06,2025-02-06,,N/A,"['math.ST', 'math.AC', 'stat.TH']"
2502.04422v1,The Maximum Likelihood Degree of Farlie Gumbel Morgenstern Bivariate Exponential Distribution,http://arxiv.org/abs/2502.04422v1,"The maximum likelihood degree of a statistical model refers to the number ofsolutions, where the derivative of the log-likelihood function is zero, overthe complex field. This paper examines the maximum likelihood degree of theparameter in Farlie-Gumbel-Morgenstern bivariate exponential distribution.",Pooja Yadav,2025-02-06,2025-02-06,,N/A,"['math.ST', 'math.AC', 'stat.TH']"
2502.04176v1,MRAMG-Bench: A BeyondText Benchmark for Multimodal Retrieval-Augmented Multimodal Generation,http://arxiv.org/abs/2502.04176v1,"Recent advancements in Retrieval-Augmented Generation (RAG) have shownremarkable performance in enhancing response accuracy and relevance byintegrating external knowledge into generative models. However, existing RAGmethods primarily focus on providing text-only answers, even in multimodalretrieval-augmented generation scenarios. In this work, we introduce theMultimodal Retrieval-Augmented Multimodal Generation (MRAMG) task, which aimsto generate answers that combine both text and images, fully leveraging themultimodal data within a corpus. Despite the importance of this task, there isa notable absence of a comprehensive benchmark to effectively evaluate MRAMGperformance. To bridge this gap, we introduce the MRAMG-Bench, a carefullycurated, human-annotated dataset comprising 4,346 documents, 14,190 images, and4,800 QA pairs, sourced from three categories: Web Data, Academic Papers, andLifestyle. The dataset incorporates diverse difficulty levels and complexmulti-image scenarios, providing a robust foundation for evaluating multimodalgeneration tasks. To facilitate rigorous evaluation, our MRAMG-Benchincorporates a comprehensive suite of both statistical and LLM-based metrics,enabling a thorough analysis of the performance of popular generative models inthe MRAMG task. Besides, we propose an efficient multimodal answer generationframework that leverages both LLMs and MLLMs to generate multimodal responses.Our datasets are available at: https://huggingface.co/MRAMG.",Qinhan Yu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.IR']"
2502.04174v1,Dense Fixed-Wing Swarming using Receding-Horizon NMPC,http://arxiv.org/abs/2502.04174v1,"In this paper, we present an approach for controlling a team of agilefixed-wing aerial vehicles in close proximity to one another. Our approachrelies on receding-horizon nonlinear model predictive control (NMPC) to planmaneuvers across an expanded flight envelope to enable inter-agent collisionavoidance. To facilitate robust collision avoidance and characterize thelikelihood of inter-agent collisions, we compute a statistical bound on theprobability of the system leaving a tube around the planned nominal trajectory.Finally, we propose a metric for evaluating highly dynamic swarms and use thismetric to evaluate our approach. We successfully demonstrated our approachthrough both simulation and hardware experiments, and to our knowledge, thisthe first time close-quarters swarming has been achieved with physicalaerobatic fixed-wing vehicles.",Varun Madabushi,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.SY', 'eess.SY']"
2502.04173v1,Lexical Substitution is not Synonym Substitution: On the Importance of Producing Contextually Relevant Word Substitutes,http://arxiv.org/abs/2502.04173v1,"Lexical Substitution is the task of replacing a single word in a sentencewith a similar one. This should ideally be one that is not necessarily onlysynonymous, but also fits well into the surrounding context of the target word,while preserving the sentence's grammatical structure. Recent advances inLexical Substitution have leveraged the masked token prediction task ofPre-trained Language Models to generate replacements for a given word in asentence. With this technique, we introduce ConCat, a simple augmented approachwhich utilizes the original sentence to bolster contextual information sent tothe model. Compared to existing approaches, it proves to be very effective inguiding the model to make contextually relevant predictions for the targetword. Our study includes a quantitative evaluation, measured via sentencesimilarity and task performance. In addition, we conduct a qualitative humananalysis to validate that users prefer the substitutions proposed by ourmethod, as opposed to previous methods. Finally, we test our approach on theprevailing benchmark for Lexical Substitution, CoInCo, revealing potentialpitfalls of the benchmark. These insights serve as the foundation for acritical discussion on the way in which Lexical Substitution is evaluated.",Juraj Vladika,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04171v2,Cyclic functional causal models beyond unique solvability with a graph separation theorem,http://arxiv.org/abs/2502.04171v2,"Functional causal models (fCMs) specify functional dependencies betweenrandom variables associated to the vertices of a graph. In directed acyclicgraphs (DAGs), fCMs are well-understood: a unique probability distribution onthe random variables can be easily specified, and a crucial graph-separationresult called the d-separation theorem allows one to characterize conditionalindependences between the variables. However, fCMs on cyclic graphs posechallenges due to the absence of a systematic way to assign a uniqueprobability distribution to the fCM's variables, the failure of thed-separation theorem, and lack of a generalization of this theorem that isapplicable to all consistent cyclic fCMs. In this work, we develop a causalmodeling framework applicable to all cyclic fCMs involving finite-cardinalityvariables, except inconsistent ones admitting no solutions. Our probabilityrule assigns a unique distribution even to non-uniquely solvable cyclic fCMsand reduces to the known rule for uniquely solvable fCMs. We identify a classof fCMs, called averagely uniquely solvable, that we show to be the largestclass where the probabilities admit a Markov factorization. Furthermore, weintroduce a new graph-separation property, p-separation, and prove this to besound and complete for all consistent finite-cardinality cyclic fCMs whilerecovering the d-separation theorem for DAGs. These results are obtained byconsidering classical post-selected teleportation protocols inspired byanalogous protocols in quantum information theory. We discuss further avenuesfor exploration, linking in particular problems in cyclic fCMs and in quantumcausality.",Carla Ferradini,2025-02-06,2025-02-07,,N/A,"['math.ST', 'quant-ph', 'stat.ML', 'stat.TH']"
2502.04421v1,Assessing and Prioritizing Ransomware Risk Based on Historical Victim Data,http://arxiv.org/abs/2502.04421v1,"We present an approach to identifying which ransomware adversaries are mostlikely to target specific entities, thereby assisting these entities informulating better protection strategies. Ransomware poses a formidablecybersecurity threat characterized by profit-driven motives, a complexunderlying economy supporting criminal syndicates, and the overt nature of itsattacks. This type of malware has consistently ranked among the most prevalent,with a rapid escalation in activity observed. Recent estimates indicate thatapproximately two-thirds of organizations experienced ransomware attacks in2023 \cite{Sophos2023Ransomware}. A central tactic in ransomware campaigns ispublicizing attacks to coerce victims into paying ransoms. Our study utilizespublic disclosures from ransomware victims to predict the likelihood of anentity being targeted by a specific ransomware variant. We employ a LargeLanguage Model (LLM) architecture that uses a unique chain-of-thought,multi-shot prompt methodology to define adversary SKRAM (Skills, Knowledge,Resources, Authorities, and Motivation) profiles from ransomware bulletins,threat reports, and news items. This analysis is enriched with publiclyavailable victim data and is further enhanced by a heuristic for generatingsynthetic data that reflects victim profiles. Our work culminates in thedevelopment of a machine learning model that assists organizations inprioritizing ransomware threats and formulating defenses based on the tactics,techniques, and procedures (TTP) of the most likely attackers.",Spencer Massengale,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.AI', 'cs.LG']"
2502.04169v1,The Effects of Kinematic MHD on the Atmospheric Circulation of Eccentric Hot Jupiters,http://arxiv.org/abs/2502.04169v1,"Hot Jupiters are typically considered to be tidally locked due to their shortorbital periods. The extreme irradiation can result in atmospheric speciesbecoming thermally ionized on the dayside, which then interact with theplanet's magnetic field by resisting flow across magnetic field lines, shapingthe atmospheric structure. However, an eccentric orbit results in temporallydependent irradiation and a non-permanent dayside, as the planet-star distancecan change drastically during its orbit. In this paper, we present 3Datmospheric models of TOI-150b, an eccentric (e=0.26), Jupiter-mass 1.75 M_Jupplanet whose equilibrium temperature varies from 1300K to 1700K. We conductsimulations for magnetic field strengths ranging from 0-30 Gauss using thekinematic magnetohydrodynamics (MHD) approach. When compared to simulations ofthe planet assuming a circular orbit, we find that the eccentric orbit resultsin a strengthened and narrowed equatorial jet, westward winds at mid-latitudes,and a phase-dependent thermal inversion. The strength and magnitude of theseeffects scale with the chosen global magnetic field strength. We also generatehigh-resolution (R=100,000) emission spectra to study net Doppler shifts andfind inter-orbit spectroscopic variability at moderate magnetic fieldstrengths, as well as decreased Doppler broadening as magnetic field strengthsincrease. This work represents the first time that the kinematic MHD approachhas been applied to an eccentric hot Jupiter and highlights the importance of alocally calculated, temperature dependent magnetic drag prescription forpredicting atmospheric structure and resulting spectra.",Hayley Beltz,2025-02-06,2025-02-06,,N/A,['astro-ph.EP']
2502.04168v2,Cyclic quantum causal modelling with a graph separation theorem,http://arxiv.org/abs/2502.04168v2,"Causal modelling frameworks link observable correlations to causalexplanations, which is a crucial aspect of science. These models representcausal relationships through directed graphs, with vertices and edges denotingsystems and transformations within a theory. Most studies focus on acycliccausal graphs, where well-defined probability rules and powerfulgraph-theoretic properties like the d-separation theorem apply. However,understanding complex feedback processes and exotic fundamental scenarios withcausal loops requires cyclic causal models, where such results do not generallyhold. While progress has been made in classical cyclic causal models,challenges remain in uniquely fixing probability distributions and identifyinggraph-separation properties applicable in general cyclic models. In cyclicquantum scenarios, existing frameworks have focussed on a subset of possiblecyclic causal scenarios, with graph-separation properties yet unexplored. Thiswork proposes a framework applicable to all consistent quantum and classicalcyclic causal models on finite-dimensional systems. We address these challengesby introducing a robust probability rule and a novel graph-separation property,p-separation, which we prove to be sound and complete for all such models. Ourapproach maps cyclic causal models to acyclic ones with post-selection,leveraging the post-selected quantum teleportation protocol. We characterizethese protocols and their success probabilities along the way. We alsoestablish connections between this formalism and other classical and quantumframeworks to inform a more unified perspective on causality. This provides afoundation for more general cyclic causal discovery algorithms and tosystematically extend open problems and techniques from acyclic informationalnetworks (e.g., certification of non-classicality) to cyclic causal structuresand networks.",Carla Ferradini,2025-02-06,2025-02-07,,N/A,"['quant-ph', 'math.ST', 'stat.ML', 'stat.TH']"
2502.04165v1,Continuously varying critical exponents in an exactly solvable long-range cluster XY mode,http://arxiv.org/abs/2502.04165v1,"We investigate a generalized antiferromagnetic cluster XY model in atransverse magnetic field, where long-range interactions decay algebraicallywith distance. This model can be exactly solvable within a free fermionframework. By analyzing the gap, we explicitly derive the critical exponents$\nu$ and $z$, finding that the relationship $\nu z = 1$ still holds. However,the values of $\nu$ and $z$ depend on the decaying exponent $\alpha$, incontrast to those for the quantum long-range antiferromagnetic Ising chain. Tooptimize scaling behavior, we verify these critical exponents using correlationfunctions and fidelity susceptibility, achieving excellent data collapse acrossvarious system sizes by adjusting fitting parameters. Finally, we compute theentanglement entropy at the critical point to determine the central charge $c$,and find it also varies with $\alpha$. This study provides insights into theunique effect of long-range cluster interactions on the critical properties ofquantum spin systems.",Tian-Cheng Yi,2025-02-06,2025-02-06,,N/A,"['cond-mat.str-el', 'cond-mat.stat-mech']"
2502.04164v1,Efficient Distributed Optimization under Heavy-Tailed Noise,http://arxiv.org/abs/2502.04164v1,"Distributed optimization has become the default training paradigm in modernmachine learning due to the growing scale of models and datasets. To mitigatecommunication overhead, local updates are often applied before globalaggregation, resulting in a nested optimization approach with inner and outersteps. However, heavy-tailed stochastic gradient noise remains a significantchallenge, particularly in attention-based models, hindering effectivetraining. In this work, we propose TailOPT, an efficient framework designed toaddress heavy-tailed noise by leveraging adaptive optimization or clippingtechniques. We establish convergence guarantees for the TailOPT framework underheavy-tailed noise with potentially unbounded gradient variance and localupdates. Among its variants, we highlight a memory and communication efficientinstantiation which we call $Bi^2Clip$, which performs coordinate-wise clippingat both the inner and outer optimizers, achieving adaptive-like performance(e.g., Adam) without the cost of maintaining or transmitting additionalgradient statistics. Empirically, TailOPT, including $Bi^2Clip$, demonstratessuperior performance on several language tasks and models, outperformingstate-of-the-art methods.",Su Hyeong Lee,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04162v1,A Pseudo Markov-Chain Model and Time-Elapsed Measures of Mobility from Collective Data,http://arxiv.org/abs/2502.04162v1,"In this paper we develop a pseudo Markov-chain model to understandtime-elapsed flows, over multiple intervals, from time and space aggregatedcollective inter-location trip data, given as a time-series. Building on themodel, we develop measures of mobility that parallel those known for individualmobility data, such as the radius of gyration. We apply these measures to theNetMob 2024 Data Challenge data, and obtain interesting results that areconsistent with published statistics and commuting patterns in cities. Besidesbuilding a new framework, we foresee applications of this approach to animproved understanding of human mobility in the context of environmentalchanges and sustainable development.",Alisha Foster,2025-02-06,2025-02-06,,N/A,"['stat.AP', 'cs.LG', 'cs.SI', 'stat.ML', '60J20, 91D10']"
2502.04160v1,Lotka-Volterra-type kinetic equations for competing species,http://arxiv.org/abs/2502.04160v1,"In this work, we examine a kinetic framework for modeling the time evolutionof size distribution densities of two populations governed by predator-preyinteractions. The model builds upon the classical Boltzmann-type equations,where the dynamics arise from elementary binary interactions between thepopulations. The model uniquely incorporates a linear redistribution operatorto quantify the birth rates in both populations, inspired by wealthredistribution operators. We prove that, under a suitable scaling regime, theBoltzmann formulation transitions to a system of coupled Fokker-Planck-typeequations. These equations describe the evolution of the distribution densitiesand link the macroscopic dynamics of their mean values to a Lotka-Volterrasystem of ordinary differential equations, with parameters explicitly derivedfrom the microscopic interaction rules. We then determine the local equilibriaof the Fokker-Planck system, which are Gamma-type densities, and investigatethe problem of relaxation of its solutions toward these kinetic equilibria, interms of their moments' dynamics. The results establish a bridge betweenkinetic modeling and classical population dynamics, offering a multiscaleperspective on predator-prey systems.",Andrea Bondesan,2025-02-06,2025-02-06,,N/A,"['math.AP', 'nlin.AO', 'q-bio.PE', '35Q20, 35Q84, 92D25']"
2502.04158v1,Diffusion-based mass map reconstruction from weak lensing data,http://arxiv.org/abs/2502.04158v1,"Diffusion models have been used in cosmological applications as a generativemodel for fast simulations and to reconstruct underlying cosmological fields orastrophysical images from noisy data. These two tasks are often treated asseparate: diffusion models trained for one purpose do not generalize to performthe other task. In this paper, we develop a single diffusion model that can beused for both tasks. By using the Diffusion Posterior Sampling (DPS) approach,we use a diffusion model trained to simulate weak lensing maps for the inverseproblem of reconstructing mass maps from noisy weak lensing data. We find thatthe standard DPS method leads to biased inference but we correct this bias bydown weighting the likelihood term at early sampling time steps of thediffusion. Our method give us a way to reconstruct accurate high-resolution(sub-arcminute) mass maps that have the correct power spectrum and a range ofnon-Gaussian summary statistics. We discuss several applications enabled by thecomputational efficiency and accuracy of our model. These include generation ofsimulation quality mass maps, aiding covariance estimation for higher orderstatistics, and for finding filaments, voids and clusters from noisy lensingshear data.",Supranta S. Boruah,2025-02-06,2025-02-06,,N/A,"['astro-ph.CO', 'astro-ph.IM']"
2502.04157v1,Sensor Resistant Instruction Independent Obfuscation for Multiple Programs,http://arxiv.org/abs/2502.04157v1,"This work builds upon and optimizes our prior research on obfuscation asinstruction decorrelation which achieves multiple program obfuscation.Leveraging this infrastructure, we further achieve the property ofsensor-resistant computation.",Ali Ajorian,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.PL']"
2502.04156v1,Estimation of backgrounds from jets misidentified as $τ$-leptons using the Universal Fake Factor method with the ATLAS detector,http://arxiv.org/abs/2502.04156v1,"Processes with $\tau$-leptons in the final state are important for StandardModel measurements and searches for physics beyond the Standard Model. TheATLAS experiment at the Large Hadron Collider observes $\tau$-leptons producedin proton-proton collisions only through their decay products. Data analysesinvolving hadronically decaying $\tau$-leptons face challenges due tobackgrounds from jets misidentified as $\tau$-leptons. These fake$\tau$-leptons are not modelled reliably by Monte Carlo simulations.Data-driven methods such as the fake-factor method allow such 'fake'backgrounds to be predicted by measuring transfer factors, known as fakefactors, in data from control regions. This paper describes a new technique fordetermining the fake factors, the Universal Fake Factor method. It evaluatesthe fake factors for any signal region by using fake factors from samplesenriched in different sources of fake $\tau$-leptons (light-quark, gluon,$b$-quark, and pile-up jets). Each fake factor is calculated as a linearcombination of fake factors measured in these different enriched samples. Forthe full Run 2 data set, the systematic uncertainty of the calculated fakefactors ranges from 15% to 35% depending on the $\tau$-lepton's transversemomentum and charged-particle decay multiplicity.",ATLAS Collaboration,2025-02-06,2025-02-06,,N/A,['hep-ex']
2502.04155v1,User-Friendly Game-Theoretic Modeling and Analysis of Multi-Modal Transportation Systems,http://arxiv.org/abs/2502.04155v1,"The evolution of existing transportation systems, mainly driven byurbanization and increased availability of mobility options, such as private,profit-maximizing ride-hailing companies, calls for tools to reason about theirdesign and regulation. To study this complex socio-technical problem, one needsto account for the strategic interactions of the stakeholders involved in themobility ecosystem. In this paper, we present a game-theoretic framework tomodel multi-modal mobility systems, focusing on municipalities, serviceproviders, and travelers. Through a user-friendly, Graphical User Interface,one can visualize system dynamics and compute equilibria for various scenarios.The framework enables stakeholders to assess the impact of local decisions(e.g., fleet size for services or taxes for private companies) on the fullmobility system. Furthermore, this project aims to foster STEM interest amonghigh school students (e.g., in the context of prior activities in Switzerland,and planned activities with the MIT museum). This initiative combinestheoretical advancements, practical applications, and educational outreach toimprove mobility system design.",Margarita Zambrano,2025-02-06,2025-02-06,,N/A,"['cs.CY', 'math.OC']"
2502.04154v1,Searching for Internal Absorption Signatures in High-Redshift Blazars,http://arxiv.org/abs/2502.04154v1,"The gamma-ray emission from Flat Spectrum Radio Quasars (FSRQs), a sub-classof blazars, is believed to be generated through interactions of high-energyleptons and/or hadrons in the jet with the ambient photon fields, includingthose from the accretion disk, the broad line region (BLR), and the dustytorus. However, these same photon fields can also attenuate gamma-rays throughinternal photon-photon (gamma-gamma) absorption, imprinting characteristicspectral features. Investigating the internal absorption is crucial forunraveling the complex structure of FSRQs and constraining the poorly knownlocation of the gamma-ray emission region. In this study, we select a sample ofgamma-ray detected FSRQs with high redshift (z >= 3), to search for absorptionfeatures appearing at lower photon energies due to a substantial redshift. Weextract the Fermi-LAT gamma-ray spectra of these sources and perform physicalmodeling using a detailed gamma-gamma opacity model, assuming that the BLRphoton field dominates the absorption and focusing on the energy range ~25GeV/(1+z), where the absorption feature due to Ly{\alpha} photons is expected.Our analysis reveals a hint of internal absorption for one source (the lowestredshift object in our sample, z~3) and provides constraints on the location ofits gamma-ray emitting region along the jet. For the remaining, higher-redshiftsources, the limited photon statistics prevent a reliable detection of internalopacity features.",Anton Dmytriiev,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.04153v1,UltraIF: Advancing Instruction Following from the Wild,http://arxiv.org/abs/2502.04153v1,"Instruction-following made modern large language models (LLMs) helpfulassistants. However, the key to taming LLMs on complex instructions remainsmysterious, for that there are huge gaps between models trained by open-sourcecommunity and those trained by leading companies. To bridge the gap, we proposea simple and scalable approach UltraIF for building LLMs that can followcomplex instructions with open-source data. UltraIF first decomposes real-worlduser prompts into simpler queries, constraints, and corresponding evaluationquestions for the constraints. Then, we train an UltraComposer to composeconstraint-associated prompts with evaluation questions. This prompt composerallows us to synthesize complicated instructions as well as filter responseswith evaluation questions. In our experiment, for the first time, wesuccessfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5instruction-following benchmarks without any benchmark information, using only8B model as response generator and evaluator. The aligned model also achievedcompetitive scores on other benchmarks. Moreover, we also show that UltraIFcould further improve LLaMA-3.1-8B-Instruct through self-alignment, motivatingbroader use cases for the method. Our code will be available athttps://github.com/kkk-an/UltraIF.",Kaikai An,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04150v1,How large are the gaps in phase space?,http://arxiv.org/abs/2502.04150v1,"Given a sampling measure for the wavelet transform (resp. the short-timeFourier transform) with the wavelet (resp. window) being chosen from the familyof Laguerre (resp. Hermite) functions, we provide quantitative upper bounds onthe radius of any ball that does not intersect the support of the measure. Theestimates depend on the condition number, i.e., the ratio of the samplingconstants, but are independent of the structure of the measure. Our proofs arecompletely elementary and rely on explicit formulas for the respectivetransforms.",Michael Speckbacher,2025-02-06,2025-02-06,,N/A,['math.FA']
2502.04147v2,SPRINT: An Assistant for Issue Report Management,http://arxiv.org/abs/2502.04147v2,"Managing issue reports is essential for the evolution and maintenance ofsoftware systems. However, manual issue management tasks such as triaging,prioritizing, localizing, and resolving issues are highly resource-intensivefor projects with large codebases and users. To address this challenge, wepresent SPRINT, a GitHub application that utilizes state-of-the-art deeplearning techniques to streamline issue management tasks. SPRINT assistsdevelopers by: (i) identifying existing issues similar to newly reported ones,(ii) predicting issue severity, and (iii) suggesting code files that likelyrequire modification to solve the issues. We evaluated SPRINT using existingdatasets and methodologies, measuring its predictive performance, and conducteda user study with five professional developers to assess its usability andusefulness. The results show that SPRINT is accurate, usable, and useful,providing evidence of its effectiveness in assisting developers in managingissue reports. SPRINT is an open-source tool available athttps://github.com/sea-lab-wm/sprint_issue_report_assistant_tool.",Ahmed Adnan,2025-02-06,2025-02-07,,N/A,['cs.SE']
2502.04420v1,KVTuner: Sensitivity-Aware Layer-wise Mixed Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference,http://arxiv.org/abs/2502.04420v1,"KV cache quantization can improve Large Language Models (LLMs) inferencethroughput and latency in long contexts and large batch-size scenarios whilepreserving LLMs effectiveness. However, current methods have three unsolvedissues: overlooking layer-wise sensitivity to KV cache quantization, highoverhead of online fine-grained decision-making, and low flexibility todifferent LLMs and constraints. Therefore, we thoroughly analyze the inherentcorrelation of layer-wise transformer attention patterns to KV cachequantization errors and study why key cache is more important than value cachefor quantization error reduction. We further propose a simple yet effectiveframework KVTuner to adaptively search for the optimal hardware-friendlylayer-wise KV quantization precision pairs for coarse-grained KV cache withmulti-objective optimization and directly utilize the offline searchedconfigurations during online inference. To reduce the computational cost ofoffline calibration, we utilize the intra-layer KV precision pair pruning andinter-layer clustering to reduce the search space. Experimental results showthat we can achieve nearly lossless 3.25-bit mixed precision KV cachequantization for LLMs like Llama-3.1-8B-Instruct and 4.0-bit for sensitivemodels like Qwen2.5-7B-Instruct on mathematical reasoning tasks. The maximuminference throughput can be improved by 38.3% compared with KV8 quantizationover various context lengths.",Xing Li,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.04143v1,A data-driven two-microphone method for in-situ sound absorption measurements,http://arxiv.org/abs/2502.04143v1,"This work presents a data-driven approach to estimating the sound absorptioncoefficient of an infinite porous slab using a neural network and atwo-microphone measurement on a finite porous sample. A 1D-convolutionalnetwork predicts the sound absorption coefficient from the complex-valuedtransfer function between the sound pressure measured at the two microphonepositions. The network is trained and validated with numerical data generatedby a boundary element model using the Delany-Bazley-Miki model, demonstratingaccurate predictions for various numerical samples. The method isexperimentally validated with baffled rectangular samples of a fibrousmaterial, where sample size and source height are varied. The results show thatthe neural network offers the possibility to reliably predict the in-situ soundabsorption of a porous material using the traditional two-microphone method asif the sample were infinite. The normal-incidence sound absorption coefficientobtained by the network compares well with that obtained theoretically and inan impedance tube. The proposed method has promising perspectives forestimating the sound absorption coefficient of acoustic materials afterinstallation and in realistic operational conditions.",Leon Emmerich,2025-02-06,2025-02-06,,N/A,"['cs.SD', 'cs.LG', 'eess.AS']"
2502.04419v1,Understanding and Mitigating the Bias Inheritance in LLM-based Data Augmentation on Downstream Tasks,http://arxiv.org/abs/2502.04419v1,"Generating synthetic datasets via large language models (LLMs) themselves hasemerged as a promising approach to improve LLM performance. However, LLMsinherently reflect biases present in their training data, leading to a criticalchallenge: when these models generate synthetic data for training, they maypropagate and amplify their inherent biases that can significantly impact modelfairness and robustness on downstream tasks--a phenomenon we term biasinheritance. This work presents the first systematic investigation inunderstanding, analyzing, and mitigating bias inheritance. We study thisproblem by fine-tuning LLMs with a combined dataset consisting of original andLLM-augmented data, where bias ratio represents the proportion of augmenteddata. Through systematic experiments across 10 classification and generationtasks, we analyze how 6 different types of biases manifest at varying biasratios. Our results reveal that bias inheritance has nuanced effects ondownstream tasks, influencing both classification tasks and generation tasksdifferently. Then, our analysis identifies three key misalignment factors:misalignment of values, group data, and data distributions. Based on theseinsights, we propose three mitigation strategies: token-based, mask-based, andloss-based approaches. Experiments demonstrate that these strategies also workdifferently on various tasks and bias, indicating the substantial challenges tofully mitigate bias inheritance. We hope this work can provide valuableinsights to the research of LLM data augmentation.",Miaomiao Li,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.04140v1,Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs,http://arxiv.org/abs/2502.04140v1,"Many physical processes can be expressed through partial differentialequations (PDEs). Real-world measurements of such processes are often collectedat irregularly distributed points in space, which can be effectivelyrepresented as graphs; however, there are currently only a few existingdatasets. Our work aims to make advancements in the field of PDE-modelingaccessible to the temporal graph machine learning community, while addressingthe data scarcity problem, by creating and utilizing datasets based on PDEs. Inthis work, we create and use synthetic datasets based on PDEs to supportspatio-temporal graph modeling in machine learning for different applications.More precisely, we showcase three equations to model different types ofdisasters and hazards in the fields of epidemiology, atmospheric particles, andtsunami waves. Further, we show how such created datasets can be used bybenchmarking several machine learning models on the epidemiological dataset.Additionally, we show how pre-training on this dataset can improve modelperformance on real-world epidemiological data. The presented methods enableothers to create datasets and benchmarks customized to individual requirements.The source code for our methodology and the three created datasets can be foundon https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs.",Jost Arndt,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04134v1,The Order Effect: Investigating Prompt Sensitivity in Closed-Source LLMs,http://arxiv.org/abs/2502.04134v1,"As large language models (LLMs) become integral to diverse applications,ensuring their reliability under varying input conditions is crucial. One keyissue affecting this reliability is order sensitivity, wherein slightvariations in input arrangement can lead to inconsistent or biased outputs.Although recent advances have reduced this sensitivity, the problem remainsunresolved. This paper investigates the extent of order sensitivity inclosed-source LLMs by conducting experiments across multiple tasks, includingparaphrasing, relevance judgment, and multiple-choice questions. Our resultsshow that input order significantly affects performance across tasks, withshuffled inputs leading to measurable declines in output accuracy. Few-shotprompting demonstrates mixed effectiveness and offers partial mitigation,however, fails to fully resolve the problem. These findings highlightpersistent risks, particularly in high-stakes applications, and point to theneed for more robust LLMs or improved input-handling techniques in futuredevelopment.",Bryan Guan,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04132v1,Transfer Learning for Covert Speech Classification Using EEG Hilbert Envelope and Temporal Fine Structure,http://arxiv.org/abs/2502.04132v1,"Brain-Computer Interfaces (BCIs) can decode imagined speech from neuralactivity. However, these systems typically require extensive training sessionswhere participants imaginedly repeat words, leading to mental fatigue anddifficulties identifying the onset of words, especially when imaginingsequences of words. This paper addresses these challenges by transferring aclassifier trained in overt speech data to covert speech classification. Weused electroencephalogram (EEG) features derived from the Hilbert envelope andtemporal fine structure, and used them to train a bidirectional long-short-termmemory (BiLSTM) model for classification. Our method reduces the burden ofextensive training and achieves state-of-the-art classification accuracy:86.44% for overt speech and 79.82% for covert speech using the overt speechclassifier.",Saravanakumar Duraisamy,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04131v1,On the importance of structural identifiability for machine learning with partially observed dynamical systems,http://arxiv.org/abs/2502.04131v1,"The successful application of modern machine learning for time seriesclassification is often hampered by limitations in quality and quantity ofavailable training data. To overcome these limitations, available domain expertknowledge in the form of parametrised mechanistic dynamical models can be usedwhenever it is available and time series observations may be represented as anelement from a given class of parametrised dynamical models. This makes thelearning process interpretable and allows the modeller to deal with sparselyand irregularly sampled data in a natural way. However, the internal processesof a dynamical model are often only partially observed. This can lead toambiguity regarding which particular model realization best explains a giventime series observation. This problem is well-known in the literature, and adynamical model with this issue is referred to as structurally unidentifiable.Training a classifier that incorporates knowledge about a structurallyunidentifiable dynamical model can negatively influence classificationperformance. To address this issue, we employ structural identifiabilityanalysis to explicitly relate parameter configurations that are associated withidentical system outputs. Using the derived relations in classifier training,we demonstrate that this method significantly improves the classifier's abilityto generalize to unseen data on a number of example models from the biomedicaldomain. This effect is especially pronounced when the number of traininginstances is limited. Our results demonstrate the importance of accounting forstructural identifiability, a topic that has received relatively littleattention from the machine learning community.",Janis Norden,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04129v1,Discontinuous transition in 2D Potts: I. Order-Disorder Interface convergence,http://arxiv.org/abs/2502.04129v1,"It is known that the planar q-state Potts model undergoes a discontinuousphase transition when q > 4 and there are exactly q + 1 extremal Gibbs measuresat the transition point: q ordered (monochromatic) measures and one disordered(free). We focus on the Potts model under the Dobrushin order-disorder boundaryconditions on a finite $N\times N$ part of the square grid. Our main result isthat this interface is a well defined object, has $\sqrt{N}$ fluctuations, andconverges to a Brownian bridge under diffusive scaling. The same holds also forthe corresponding FK-percolation model for all q > 4. Our proofs rely on acoupling between FK-percolation, the six-vertex model, and the random-clusterrepresentation of an Ashkin-Teller model (ATRC), and on a detailed study of thelatter. The coupling relates the interface in FK-percolation to a longsubcritical cluster in the ATRC model. For this cluster, we develop a ``renewalpicture'' \`a la Ornstein-Zernike. This is based on fine mixing properties ofthe ATRC model that we establish using the link to the six-vertex model and itsheight function. Along the way, we derive various properties of theAshkin-Teller model, such as Ornstein-Zernike asymptotics for its two-pointfunction. In a companion work, we provide a detailed study of the Potts modelunder order-order Dobrushin conditions. We show emergence of a free layer ofwidth $\sqrt{N}$ between the two ordered phases (wetting) and establishconvergence of its boundaries to two Brownian bridges conditioned not tointersect.",Moritz Dober,2025-02-06,2025-02-06,,N/A,"['math.PR', 'math-ph', 'math.MP']"
2502.04128v1,Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis,http://arxiv.org/abs/2502.04128v1,"Recent advances in text-based large language models (LLMs), particularly inthe GPT series and the o1 model, have demonstrated the effectiveness of scalingboth training-time and inference-time compute. However, currentstate-of-the-art TTS systems leveraging LLMs are often multi-stage, requiringseparate models (e.g., diffusion models after LLM), complicating the decisionof whether to scale a particular model during training or testing. This workmakes the following contributions: First, we explore the scaling of train-timeand inference-time compute for speech synthesis. Second, we propose a simpleframework Llasa for speech synthesis that employs a single-layer vectorquantizer (VQ) codec and a single Transformer architecture to fully align withstandard LLMs such as Llama. Our experiments reveal that scaling train-timecompute for Llasa consistently improves the naturalness of synthesized speechand enables the generation of more complex and accurate prosody patterns.Furthermore, from the perspective of scaling inference-time compute, we employspeech understanding models as verifiers during the search, finding thatscaling inference-time compute shifts the sampling modes toward the preferencesof specific verifiers, thereby improving emotional expressiveness, timbreconsistency, and content accuracy. In addition, we released the checkpoint andtraining code for our TTS model (1B, 3B, 8B) and codec model publiclyavailable.",Zhen Ye,2025-02-06,2025-02-06,,N/A,"['eess.AS', 'cs.AI', 'cs.CL', 'cs.MM', 'cs.SD']"
2502.04121v1,Optimizing Perturbations for Improved Training of Machine Learning Models,http://arxiv.org/abs/2502.04121v1,"Machine learning models have become indispensable tools in applicationsacross the physical sciences. Their training is often time-consuming, vastlyexceeding the inference timescales. Several protocols have been developed toperturb the learning process and improve the training, such as shrink andperturb, warm restarts, and stochastic resetting. For classifiers, theseperturbations have been shown to result in enhanced speedups or improvedgeneralization. However, the design of such perturbations is usually done\textit{ad hoc} by intuition and trial and error. To rationally optimizetraining protocols, we frame them as first-passage processes and consider theirresponse to perturbations. We show that if the unperturbed learning processreaches a quasi-steady state, the response at a single perturbation frequencycan predict the behavior at a wide range of frequencies. We demonstrate thatthis is the case when training a CIFAR-10 classifier using the ResNet-18 modeland use this approach to identify an optimal perturbation and frequency. Ourwork allows optimization of training protocols of machine learning models usinga statistical mechanical approach.",Sagi Meir,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'physics.chem-ph']"
2502.04117v1,A new perspective on the equivalence between Weak and Strong Spatial Mixing in two dimensions,http://arxiv.org/abs/2502.04117v1,"Weak mixing in lattice models is informally the property that ``informationdoes not propagate inside a system''. Strong mixing is the property that``information does not propagate inside and on the boundary of a system''. Indimension two, the boundary of reasonable systems is one dimensional, soinformation should not be able to propagate there. This led to the conjecturethat in 2D, weak mixing implies strong mixing. The question was investigated inseveral previous works, and proof of this conjecture is available in the caseof finite range Gibbsian specifications, and in the case of nearest-neighbourFK percolation (under some restrictions). The present work gives a new proof ofthese results, extends the family of models for which the implication holds,and, most interestingly, provides a ``percolative picture'' of the informationpropagation.",Sébastien Ott,2025-02-06,2025-02-06,,N/A,"['math.PR', 'math-ph', 'math.MP']"
2502.04116v1,Generative Adversarial Networks Bridging Art and Machine Intelligence,http://arxiv.org/abs/2502.04116v1,"This book begins with a detailed introduction to the fundamental principlesand historical development of GANs, contrasting them with traditionalgenerative models and elucidating the core adversarial mechanisms throughillustrative Python examples. The text systematically addresses themathematical and theoretical underpinnings including probability theory,statistics, and game theory providing a solid framework for understanding theobjectives, loss functions, and optimisation challenges inherent to GANtraining. Subsequent chapters review classic variants such as Conditional GANs,DCGANs, InfoGAN, and LAPGAN before progressing to advanced trainingmethodologies like Wasserstein GANs, GANs with gradient penalty, least squaresGANs, and spectral normalisation techniques. The book further examinesarchitectural enhancements and task-specific adaptations in generators anddiscriminators, showcasing practical implementations in high resolution imagegeneration, artistic style transfer, video synthesis, text to image generationand other multimedia applications. The concluding sections offer insights intoemerging research trends, including self-attention mechanisms,transformer-based generative models, and a comparative analysis with diffusionmodels, thus charting promising directions for future developments in bothacademic and applied settings.",Junhao Song,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CV']"
2502.04115v1,A Neural Network-based Multi-timestep Command Governor for Nonlinear Systems with Constraints,http://arxiv.org/abs/2502.04115v1,"The multi-timestep command governor (MCG) is an add-on algorithm thatenforces constraints by modifying, at each timestep, the reference command to apre-stabilized control system. The MCG can be interpreted as a Model-PredictiveControl scheme operating on the reference command. The implementation of MCG onnonlinear systems carries a heavy computational burden as it requires solving anonlinear program with multiple decision variables at each timestep. This paperproposes a less computationally demanding alternative, based on approximatingthe MCG control law using a neural network (NN) trained on offline data.However, since the NN output may not always be constraint-admissible due totraining errors, its output is adjusted using a sensitivity-based method. Wethus refer to the resulting control strategy as the neural network-based MCG(NN-MCG). As validation, the proposed controller is applied as a load governorfor constraint management in an automotive fuel cell system. It is shown thatthe proposed strategy is significantly more computationally efficient than thetraditional MCG, while achieving nearly identical performance if the NN iswell-trained.",Mostafaali Ayubirad,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04112v1,Quasi maximum likelihood estimation of high-dimensional approximate dynamic matrix factor models via the EM algorithm,http://arxiv.org/abs/2502.04112v1,"This paper considers an approximate dynamic matrix factor model that accountsfor the time series nature of the data by explicitly modelling the timeevolution of the factors. We study Quasi Maximum Likelihood estimation of themodel parameters based on the Expectation Maximization (EM) algorithm,implemented jointly with the Kalman smoother which gives estimates of thefactors. This approach allows to easily handle arbitrary patterns of missingdata. We establish the consistency of the estimated loadings and factormatrices as the sample size $T$ and the matrix dimensions $p_1$ and $p_2$diverge to infinity. The finite sample properties of the estimators areassessed through a large simulation study and an application to a financialdataset of volatility proxies.",Matteo Barigozzi,2025-02-06,2025-02-06,,N/A,"['stat.ME', 'econ.EM']"
2502.04111v1,Adaptive Margin Contrastive Learning for Ambiguity-aware 3D Semantic Segmentation,http://arxiv.org/abs/2502.04111v1,"In this paper, we propose an adaptive margin contrastive learning method for3D point cloud semantic segmentation, namely AMContrast3D. Most existingmethods use equally penalized objectives, which ignore per-point ambiguitiesand less discriminated features stemming from transition regions. However, ashighly ambiguous points may be indistinguishable even for humans, theirmanually annotated labels are less reliable, and hard constraints over thesepoints would lead to sub-optimal models. To address this, we design adaptiveobjectives for individual points based on their ambiguity levels, aiming toensure the correctness of low-ambiguity points while allowing mistakes forhigh-ambiguity points. Specifically, we first estimate ambiguities based onposition embeddings. Then, we develop a margin generator to shift decisionboundaries for contrastive feature embeddings, so margins are narrowed due toincreasing ambiguities with even negative margins for extremely high-ambiguitypoints. Experimental results on large-scale datasets, S3DIS and ScanNet,demonstrate that our method outperforms state-of-the-art methods.",Yang Chen,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04108v1,Can a secluded self-interacting dark sector generate detectable gravitational waves?,http://arxiv.org/abs/2502.04108v1,"In this work we study the possibility to detect the gravitational wavesgenerated by a secluded self-interacting dark sector. ``Secluded'' means thatthe dark sector has almost no portal to the visible sector and thus its entropyis conserved by itself, and ``self-interacting'' means that dark matter in thismodel has a significant interaction to itself, making it consistent with thesmall-scale structure observations. A spontaneously broken $U(1)'$ isintroduced for the interactions in the dark sector, and nearly massless darkradiation is also introduced to avoid the over-closure problem. Through aparameter space scan, we find that this model is highly constrained by thecurrent observed effective number of neutrinos ($N_{\text{eff}}$) and thelarge-scale structure observable Lyman-$\alpha$. Combined together, these twoconstraints make such a secluded self-interacting dark sector almost impossibleto generate gravitational waves accessible at future projects like SKA or LISA.",Song Li,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'astro-ph.HE']"
2502.04106v1,The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning,http://arxiv.org/abs/2502.04106v1,"In Federated Learning (FL), clients share gradients with a central serverwhile keeping their data local. However, malicious servers could deliberatelymanipulate the models to reconstruct clients' data from shared gradients,posing significant privacy risks. Although such active gradient leakage attacks(AGLAs) have been widely studied, they suffer from several limitationsincluding incomplete attack coverage and poor stealthiness. In this paper, weaddress these limitations with two core contributions. First, we introduce anew theoretical analysis approach, which uniformly models AGLAs as backdoorpoisoning. This analysis approach reveals that the core principle of AGLAs isto bias the gradient space to prioritize the reconstruction of a small subsetof samples while sacrificing the majority, which theoretically explains theabove limitations of existing AGLAs. Second, we propose Enhanced GradientGlobal Vulnerability (EGGV), the first AGLA that achieves complete attackcoverage while evading client-side detection. In particular, EGGV employs agradient projector and a jointly optimized discriminator to assess gradientvulnerability, steering the gradient space toward the point most prone to dataleakage. Extensive experiments show that EGGV achieves complete attack coverageand surpasses SOTA with at least a 43% increase in reconstruction quality(PSNR) and a 45% improvement in stealthiness (D-SNR).",Kunlan Xiang,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04105v1,Sensitivity of three-dimensional boundary-layer stability to intrinsic uncertainties of fluid properties: a study on supercritical CO2,http://arxiv.org/abs/2502.04105v1,"The intrinsic uncertainty of fluid properties, including the equation ofstate, viscosity, and thermal conductivity, on boundary layer stability hasscarcely been addressed. When a fluid is operating in the vicinity of the Widomline (defined as the maximum of isobaric specific heat) in supercritical state,its properties exhibit highly non-ideal behavior, which is an ongoing researchfield leading to refined and more accurate fluid property databases. Uponcrossing the Widom line, new mechanisms of flow instability emerge, feasiblyleading to changes in dominating modes that yield turbulence. The present workinvestigates the sensitivity of three-dimensional boundary-layer modalinstability to these intrinsic uncertainties in fluid properties. Theuncertainty, regardless of its source and the fluid regimes, gives rise todistortions of all profiles that constitute the inputs of the stabilityoperator. The effect of these distortions on flow stability is measured bysensitivity coefficients, which are formulated with the adjoint operator andvalidated against linear modal stability analysis. The results are presentedfor carbon dioxide at a representative supercritical pressure of about 80 bar.The sensitivity to different inputs of the stability operator across variousthermodynamic regimes show an immense range of sensitivity amplitude. Abalancing relationship between the density gradient and its perturbation leadsto a quadratic effect across the Widom line, provoking significant sensitivityto distortions of the second derivative of the pressure with respect to thedensity, $\partial^2 p/\partial \rho^2$. From an application-oriented point ofview, one important question is whether the correct baseflow profiles can bemeaningfully analyzed by the simplified ideal-fluid model...",Jie Ren,2025-02-06,2025-02-06,,N/A,['physics.flu-dyn']
2502.04104v1,Exploring Group Convolutional Networks for Sign Problem Mitigation via Contour Deformation,http://arxiv.org/abs/2502.04104v1,"The sign problem that arises in Hybrid Monte Carlo calculations can bemitigated by deforming the integration manifold. While simple transformationsare highly efficient for simulation, their efficacy systematically decreaseswith decreasing temperature and increasing interaction. Machine learning modelshave demonstrated the ability to push further, but require additionalcomputational effort and upfront training. While neural networks possess thecapacity to learn physical symmetries through proper training, there areanticipated advantages associated with encoding them into the network'sstructure. These include enhanced accuracy, accelerated training, and improvedstability. The objective of the present study is twofold. First, we investigatethe benefits of group convolutional models in comparison to fully connectednetworks, with a specific focus on the effects on the sign problem and oncomputational aspects. Second, we examine their capabilities for transferlearning, demonstrating the ability to further reduce training cost. We performour investigations on the Hubbard model on select low-dimensional systems.",Christoph Gäntgen,2025-02-06,2025-02-06,,N/A,"['cond-mat.dis-nn', 'cond-mat.str-el', 'hep-lat']"
2502.04103v1,VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output,http://arxiv.org/abs/2502.04103v1,"The rapid evolution of large language models (LLMs) has transformedhuman-computer interaction (HCI), but the interaction with LLMs is currentlymainly focused on text-based interactions, while other multi-model approachesremain under-explored. This paper introduces VTutor, an open-source SoftwareDevelopment Kit (SDK) that combines generative AI with advanced animationtechnologies to create engaging, adaptable, and realistic APAs for human-AImulti-media interactions. VTutor leverages LLMs for real-time personalizedfeedback, advanced lip synchronization for natural speech alignment, and WebGLrendering for seamless web integration. Supporting various 2D and 3D charactermodels, VTutor enables researchers and developers to design emotionallyresonant, contextually adaptive learning agents. This toolkit enhances learnerengagement, feedback receptivity, and human-AI interaction while promotingtrustworthy AI principles in education. VTutor sets a new standard fornext-generation APAs, offering an accessible, scalable solution for fosteringmeaningful and immersive human-AI interaction experiences. The VTutor projectis open-sourced and welcomes community-driven contributions and showcases.",Eason Chen,2025-02-06,2025-02-06,,N/A,"['cs.HC', 'cs.AI', 'cs.SE']"
2502.04417v1,NeuralMOVES: A lightweight and microscopic vehicle emission estimation model based on reverse engineering and surrogate learning,http://arxiv.org/abs/2502.04417v1,"The transportation sector significantly contributes to greenhouse gasemissions, necessitating accurate emission models to guide mitigationstrategies. Despite its field validation and certification, theindustry-standard Motor Vehicle Emission Simulator (MOVES) faces challengesrelated to complexity in usage, high computational demands, and itsunsuitability for microscopic real-time applications. To address theselimitations, we present NeuralMOVES, a comprehensive suite of high-performance,lightweight surrogate models for vehicle CO2 emissions. Developed based onreverse engineering and Neural Networks, NeuralMOVES achieves a remarkable6.013% Mean Average Percentage Error relative to MOVES across extensive testsspanning over two million scenarios with diverse trajectories and the factorsregarding environments and vehicles. NeuralMOVES is only 2.4 MB, largelycondensing the original MOVES and the reverse engineered MOVES into a compactrepresentation, while maintaining high accuracy. Therefore, NeuralMOVESsignificantly enhances accessibility while maintaining the accuracy of MOVES,simplifying CO2 evaluation for transportation analyses and enabling real-time,microscopic applications across diverse scenarios without reliance on complexsoftware or extensive computational resources. Moreover, this paper provides,for the first time, a framework for reverse engineering industrial-gradesoftware tailored specifically to transportation scenarios, going beyond MOVES.The surrogate models are available at https://github.com/edgar-rs/neuralMOVES.",Edgar Ramirez-Sanchez,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04102v1,Qualitative differences in the robust controllability of model two-qubit systems,http://arxiv.org/abs/2502.04102v1,"The precise implementation and manipulation of quantum gates is key toextracting advantages from future quantum technologies. Achieving this requiresvery accurate control over the quantum system. If one has complete knowledgeabout a Hamiltonian, accurate manipulation of the system is possible. However,in real scenarios, there will often be some uncertainty in the parameters ofthe Hamiltonian, which makes full control of the system either difficult orimpossible. In this paper we consider two model Hamiltonians with a continuousparameter that is partly unknown. We assess robust controllability against thisparameter uncertainty using existing theoretical frameworks and take anumerical route by discretizing the unknown parameter in the cases where wecannot predict controllability. Furthermore, we introduce a penalty term intothe fidelity function to optimize control pulses, enhancing robustness againstthe influence of parameter fluctuations. Within our framework, we analyze thequalitative differences in the robust controllability of the two systems.",Anirban Dey,2025-02-06,2025-02-06,,N/A,['quant-ph']
2502.04099v1,The Cabibbo-favored hadronic weak decays of the $Ξ_c$ in the quark model,http://arxiv.org/abs/2502.04099v1,"The Cabibbo-favored hadronic weak decay of the $\Xi_c^+\to \Xi^0\pi^+$,$\Xi_c^0\to \Xi^-\pi^+$, $\Xi_c^0\to \Xi^0\pi^0$, $\Xi_c^0\to \Xi^0\eta^{(')}$and $\Xi_c^0\to \Xi^+K^-$ are studied in the non-relativistic constituent quarkmodel. By analyzing their decay mechanisms at the quark level we show that thepole terms are essential for understanding the transition dynamics in additionto the usually considered direct meson emission process and color suppressedprocess in the charmed baryon hadronic weak decays. The experimentallymeasurable asymmetry parameters are also predicted in order to further pin downthe decay mechanism.",Peng-Yu Niu,2025-02-06,2025-02-06,,N/A,['hep-ph']
2502.04098v2,Efficient Few-Shot Continual Learning in Vision-Language Models,http://arxiv.org/abs/2502.04098v2,"Vision-language models (VLMs) excel in tasks such as visual questionanswering and image captioning. However, VLMs are often limited by their use ofpretrained image encoders, like CLIP, leading to image understanding errorsthat hinder overall performance. On top of that, real-world applications oftenrequire the model to be continuously adapted as new and often limited datacontinuously arrive. To address this, we propose LoRSU (Low-Rank Adaptationwith Structured Updates), a robust and computationally efficient method forselectively updating image encoders within VLMs. LoRSU introduces structuredand localized parameter updates, effectively correcting performance onpreviously error-prone data while preserving the model's general robustness.Our approach leverages theoretical insights to identify and update only themost critical parameters, achieving significant resource efficiency.Specifically, we demonstrate that LoRSU reduces computational overhead by over25x compared to full VLM updates, without sacrificing performance. Experimentalresults on VQA tasks in the few-shot continual learning setting, validateLoRSU's scalability, efficiency, and effectiveness, making it a compellingsolution for image encoder adaptation in resource-constrained environments.",Aristeidis Panos,2025-02-06,2025-02-07,,N/A,"['cs.CV', 'cs.AI']"
2502.04095v1,LLMs to Support a Domain Specific Knowledge Assistant,http://arxiv.org/abs/2502.04095v1,"This work presents a custom approach to developing a domain specificknowledge assistant for sustainability reporting using the InternationalFinancial Reporting Standards (IFRS). In this domain, there is no publiclyavailable question-answer dataset, which has impeded the development of ahigh-quality chatbot to support companies with IFRS reporting. The two keycontributions of this project therefore are:  (1) A high-quality synthetic question-answer (QA) dataset based on IFRSsustainability standards, created using a novel generation and evaluationpipeline leveraging Large Language Models (LLMs). This comprises 1,063 diverseQA pairs that address a wide spectrum of potential user queries insustainability reporting. Various LLM-based techniques are employed to createthe dataset, including chain-of-thought reasoning and few-shot prompting. Acustom evaluation framework is developed to assess question and answer qualityacross multiple dimensions, including faithfulness, relevance, and domainspecificity. The dataset averages a score range of 8.16 out of 10 on thesemetrics.  (2) Two architectures for question-answering in the sustainability reportingdomain - a RAG pipeline and a fully LLM-based pipeline. The architectures aredeveloped by experimenting, fine-tuning, and training on the QA dataset. Thefinal pipelines feature an LLM fine-tuned on domain specific data and anindustry classification component to improve the handling of complex queries.The RAG architecture achieves an accuracy of 85.32% on single-industry and72.15% on cross-industry multiple-choice questions, outperforming the baselineapproach by 4.67 and 19.21 percentage points, respectively. The LLM-basedpipeline achieves an accuracy of 93.45% on single-industry and 80.30% oncross-industry multiple-choice questions, an improvement of 12.80 and 27.36percentage points over the baseline, respectively.",Maria-Flavia Lovin,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04094v1,Soft and Highly-Integrated Optical Fiber Bending Sensors for Proprioception in Multi-Material 3D Printed Fingers,http://arxiv.org/abs/2502.04094v1,"Accurate shape sensing, only achievable through distributed proprioception,is a key requirement for closed-loop control of soft robots. Low-cost powerefficient optoelectronic sensors manufactured from flexible materials representa natural choice as they can cope with the large deformations of soft robotswithout loss of performance. However, existing integration approaches arecumbersome and require manual steps and complex assembly. We propose asemi-automated printing process where plastic optical fibers are embedded withreadout electronics in 3D printed flexures. The fibers become locked in placeand the readout electronics remain optically coupled to them while the flexuresundergo large bending deformations, creating a repeatable, monolithicallymanufactured bending transducer with only 10 minutes required in total for themanual embedding steps. We demonstrate the process by manufacturingmulti-material 3D printed fingers and extensively evaluating the performance ofeach proprioceptive joint. The sensors achieve 70% linearity and 4.81{\deg} RMSerror on average. Furthermore, the distributed architecture allows formaintaining an average fingertip position estimation accuracy of 12 mm in thepresence of external static forces. To demonstrate the potential of thedistributed sensor architecture in robotics applications, we build adata-driven model independent of actuation feedback to detect contact withobjects in the environment.",Ellis Capp,2025-02-06,2025-02-06,,N/A,['cs.RO']
2502.04416v1,CMoE: Fast Carving of Mixture-of-Experts for Efficient LLM Inference,http://arxiv.org/abs/2502.04416v1,"Large language models (LLMs) achieve impressive performance by scaling modelparameters, but this comes with significant inference overhead. Feed-forwardnetworks (FFNs), which dominate LLM parameters, exhibit high activationsparsity in hidden neurons. To exploit this, researchers have proposed using amixture-of-experts (MoE) architecture, where only a subset of parameters isactivated. However, existing approaches often require extensive training dataand resources, limiting their practicality. We propose CMoE (Carved MoE), anovel framework to efficiently carve MoE models from dense models. CMoEachieves remarkable performance through efficient expert grouping andlightweight adaptation. First, neurons are grouped into shared and routedexperts based on activation rates. Next, we construct a routing mechanismwithout training from scratch, incorporating a differentiable routing processand load balancing. Using modest data, CMoE produces a well-designed, usableMoE from a 7B dense model within five minutes. With lightweight fine-tuning, itachieves high-performance recovery in under an hour. We make our code publiclyavailable at https://github.com/JarvisPei/CMoE.",Zehua Pei,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04084v1,Modular Units on $X_{1}( p)$ and Quotients of the Cuspidal Group,http://arxiv.org/abs/2502.04084v1,"Modular units are functions on modular curves whose divisors are supported onthe cusps. They form a free abelian group of rank at most one less than thenumber of cusps. In this paper we study the group of modular units on $X_{1}( p)$, with prime level $p \ge 5$. We give an explicit basis for this group andstudy certain rational subgroups of it. We use the basis to numericallyinvestigate the structure of the cuspidal group of $X_{1}( p)$ and its rationalsubgroup. In the later stages of this paper we use our basis to determine aspecific large quotient of the cuspidal group.",Elvira Lupoian,2025-02-06,2025-02-06,,N/A,"['math.NT', '11G16, 11G18']"
2502.04083v1,Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation,http://arxiv.org/abs/2502.04083v1,"Neoadjuvant chemotherapy (NAC) has become a standard clinical practice fortumor downsizing in breast cancer with 18F-FDG Positron Emission Tomography(PET). Our work aims to leverage PET imaging for the segmentation of breastlesions. The focus is on developing an automated system that accuratelysegments primary tumor regions and extracts key biomarkers from these areas toprovide insights into the evolution of breast cancer following the first courseof NAC. 243 baseline 18F-FDG PET scans (PET_Bl) and 180 follow-up 18F-FDG PETscans (PET_Fu) were acquired before and after the first course of NAC,respectively. Firstly, a deep learning-based breast tumor segmentation methodwas developed. The optimal baseline model (model trained on baseline exams) wasfine-tuned on 15 follow-up exams and adapted using active learning to segmenttumor areas in PET_Fu. The pipeline computes biomarkers such as maximumstandardized uptake value (SUVmax), metabolic tumor volume (MTV), and totallesion glycolysis (TLG) to evaluate tumor evolution between PET_Fu and PET_Bl.Quality control measures were employed to exclude aberrant outliers. The nnUNetdeep learning model outperformed in tumor segmentation on PET_Bl, achieved aDice similarity coefficient (DSC) of 0.89 and a Hausdorff distance (HD) of 3.52mm. After fine-tuning, the model demonstrated a DSC of 0.78 and a HD of 4.95 mmon PET_Fu exams. Biomarkers analysis revealed very strong correlations whateverthe biomarker between manually segmented and automatically predicted regions.The significant average decrease of SUVmax, MTV and TLG were 5.22, 11.79 cm3and 19.23 cm3, respectively. The presented approach demonstrates an automatedsystem for breast tumor segmentation from 18F-FDG PET. Thanks to the extractedbiomarkers, our method enables the automatic assessment of cancer progression.",Tewele W. Tareke,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04082v1,Market-based insurance ratemaking: application to pet insurance,http://arxiv.org/abs/2502.04082v1,"This paper introduces a method for pricing insurance policies using marketdata. The approach is designed for scenarios in which the insurance companyseeks to enter a new market, in our case: pet insurance, lacking historicaldata. The methodology involves an iterative two-step process. First, a suitableparameter is proposed to characterize the underlying risk. Second, theresulting pure premium is linked to the observed commercial premium using anisotonic regression model. To validate the method, comprehensive testing isconducted on synthetic data, followed by its application to a dataset of actualpet insurance rates. To facilitate practical implementation, we have developedan R package called IsoPriceR. By addressing the challenge of pricing insurancepolicies in the absence of historical data, this method helps enhance pricingstrategies in emerging markets.",Pierre-Olivier Goffard,2025-02-06,2025-02-06,,N/A,"['stat.AP', '62P05, 91G70, 62F15']"
2502.04415v1,TerraQ: Spatiotemporal Question-Answering on Satellite Image Archives,http://arxiv.org/abs/2502.04415v1,"TerraQ is a spatiotemporal question-answering engine for satellite imagearchives. It is a natural language processing system that is built to processrequests for satellite images satisfying certain criteria. The requests canrefer to image metadata and entities from a specialized knowledge base (e.g.,the Emilia-Romagna region). With it, users can make requests like ""Give me ahundred images of rivers near ports in France, with less than 20% snow coverageand more than 10% cloud coverage"", thus making Earth Observation data moreeasily accessible, in-line with the current landscape of digital assistants.",Sergios-Anestis Kefalidis,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04077v1,AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference,http://arxiv.org/abs/2502.04077v1,"With the development of large language models (LLMs), efficient inferencethrough Key-Value (KV) cache compression has attracted considerable attention,especially for long-context generation. To compress the KV cache, recentmethods identify critical KV tokens through heuristic ranking with attentionscores. However, these methods often struggle to accurately determine criticaltokens as they neglect the \textit{temporal patterns} in attention scores,resulting in a noticeable degradation in LLM performance. To address thischallenge, we propose AttentionPredictor, which is the first learning-basedcritical token identification approach. Specifically, AttentionPredictor learnsa lightweight convolution model to capture spatiotemporal patterns and predictthe next-token attention score. An appealing feature of AttentionPredictor isthat it accurately predicts the attention score while consuming negligiblememory. Moreover, we propose a cross-token critical cache prefetching frameworkthat hides the token estimation time overhead to accelerate the decoding stage.By retaining most of the attention information, AttentionPredictor achieves16$\times$ KV cache compression with comparable LLM performance, significantlyoutperforming the state-of-the-art.",Qingyue Yang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG']"
2502.04076v1,Content-Rich AIGC Video Quality Assessment via Intricate Text Alignment and Motion-Aware Consistency,http://arxiv.org/abs/2502.04076v1,"The advent of next-generation video generation models like \textit{Sora}poses challenges for AI-generated content (AIGC) video quality assessment(VQA). These models substantially mitigate flickering artifacts prevalent inprior models, enable longer and complex text prompts and generate longer videoswith intricate, diverse motion patterns. Conventional VQA methods designed forsimple text and basic motion patterns struggle to evaluate these content-richvideos. To this end, we propose \textbf{CRAVE}(\underline{C}ontent-\underline{R}ich \underline{A}IGC \underline{V}ideo\underline{E}valuator), specifically for the evaluation of Sora-era AIGCvideos. CRAVE proposes the multi-granularity text-temporal fusion that alignslong-form complex textual semantics with video dynamics. Additionally, CRAVEleverages the hybrid motion-fidelity modeling to assess temporal artifacts.Furthermore, given the straightforward prompts and content in current AIGC VQAdatasets, we introduce \textbf{CRAVE-DB}, a benchmark featuring content-richvideos from next-generation models paired with elaborate prompts. Extensiveexperiments have shown that the proposed CRAVE achieves excellent results onmultiple AIGC VQA benchmarks, demonstrating a high degree of alignment withhuman perception. All data and code will be publicly available athttps://github.com/littlespray/CRAVE.",Shangkun Sun,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04075v1,Controllable Emotion Generation with Emotion Vectors,http://arxiv.org/abs/2502.04075v1,"In recent years, technologies based on large-scale language models (LLMs)have made remarkable progress in many fields, especially in customer service,content creation, and embodied intelligence, showing broad applicationpotential. However, The LLM's ability to express emotions with proper tone,timing, and in both direct and indirect forms is still insufficient butsignificant. Few works have studied on how to build the controlable emotionalexpression capability of LLMs. In this work, we propose a method for emotionexpression output by LLMs, which is universal, highly flexible, and wellcontrollable proved with the extensive experiments and verifications. Thismethod has broad application prospects in fields involving emotions output byLLMs, such as intelligent customer service, literary creation, and homecompanion robots. The extensive experiments on various LLMs with differentmodel-scales and architectures prove the versatility and the effectiveness ofthe proposed method.",Yurui Dong,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04074v1,3D Prior is All You Need: Cross-Task Few-shot 2D Gaze Estimation,http://arxiv.org/abs/2502.04074v1,"3D and 2D gaze estimation share the fundamental objective of capturing eyemovements but are traditionally treated as two distinct research domains. Inthis paper, we introduce a novel cross-task few-shot 2D gaze estimationapproach, aiming to adapt a pre-trained 3D gaze estimation network for 2D gazeprediction on unseen devices using only a few training images. This task ishighly challenging due to the domain gap between 3D and 2D gaze, unknown screenposes, and limited training data. To address these challenges, we propose anovel framework that bridges the gap between 3D and 2D gaze. Our frameworkcontains a physics-based differentiable projection module with learnableparameters to model screen poses and project 3D gaze into 2D gaze. Theframework is fully differentiable and can integrate into existing 3D gazenetworks without modifying their original architecture. Additionally, weintroduce a dynamic pseudo-labelling strategy for flipped images, which isparticularly challenging for 2D labels due to unknown screen poses. To overcomethis, we reverse the projection process by converting 2D labels to 3D space,where flipping is performed. Notably, this 3D space is not aligned with thecamera coordinate system, so we learn a dynamic transformation matrix tocompensate for this misalignment. We evaluate our method on MPIIGaze, EVE, andGazeCapture datasets, collected respectively on laptops, desktop computers, andmobile devices. The superior performance highlights the effectiveness of ourapproach, and demonstrates its strong potential for real-world applications.",Yihua Cheng,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04073v1,An Empirical Study on the Impact of Code Duplication-aware Refactoring Practices on Quality Metrics,http://arxiv.org/abs/2502.04073v1,"Context: Code refactoring is widely recognized as an essential softwareengineering practice that improves the understandability and maintainability ofsource code. Several studies attempted to detect refactoring activities throughmining software repositories, allowing one to collect, analyze, and getactionable data-driven insights about refactoring practices within softwareprojects. Objective: Our goal is to identify, among the various quality modelspresented in the literature, the ones that align with the developer's vision ofeliminating duplicates of code, when they explicitly mention that they refactorthe code to improve them. Method: We extract a corpus of 332 refactoringcommits applied and documented by developers during their daily changes from128 open-source Java projects. In particular, we extract 32 structural metricsfrom which we identify code duplicate removal commits with their correspondingrefactoring operations, as perceived by software engineers. Thereafter, weempirically analyze the impact of these refactoring operations on a set ofcommon state-of-the-art design quality metrics. Results: The statisticalanalysis of the results obtained shows that (i) some state-of-the-art metricsare capable of capturing the developer's intention of removing codeduplication; and (ii) some metrics are being more emphasized than others. Weconfirm that various structural metrics can effectively represent codeduplication, leading to different impacts on software quality. Some metricscontribute to improvements, while others may lead to degradation. Conclusion:Most of the mapped metrics associated with the main quality attributessuccessfully capture developers' intentions for removing code duplicates, as isevident from the commit messages. However, certain metrics do not fully capturethese intentions",Eman Abdullah AlOmar,2025-02-06,2025-02-06,,N/A,['cs.SE']
2502.04070v2,Performance studies of the CE-65v2 MAPS prototype structure,http://arxiv.org/abs/2502.04070v2,"With the next upgrade of the ALICE inner tracking system (ITS3) as itsprimary focus, a set of small MAPS test structures have been developed in the65 nm TPSCo CMOS process. The CE-65 focuses on the characterisation of theanalogue charge collection properties of this technology. The latest iteration,the CE-65v2, was produced in different processes (Standard, with a low-dosen-type blanket, and blanket with gap between pixels), pixel pitches (15, 18,22.5 $\mu$m) and pixel arrangements (square or staggered). The comparativelylarge pixel array size of $48\times24$ pixels in CE-65v2 allows, among otherbenefits, to study the uniformity of the pixel response.  The CE-65v2 chip was characterised in a test beam at the CERN SPS. A firstanalysis showed that hit efficiencies of $\geq 99\%$ and spatial resolutionbetter than 5 $\mu$m can be achieved for all pitches and process variants. Forthe Standard process, thanks to larger charge sharing, even spatial resolutionsbelow 3 $\mu$m are reached, in line with vertex detector requirements for theFCC-ee.  This contribution further investigates the data collected at the SPS testbeam. Thanks to the large sensor size and efficient data collection, a largeamount of statistics was collected, which allows for detailed in-pixel studiesto see the efficiency and spatial resolution as a function of the hit positionwithin the pixels. Again, different pitches and process variants are compared.",A. Ilg,2025-02-06,2025-02-07,,N/A,"['physics.ins-det', 'hep-ex']"
2502.04066v1,Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training,http://arxiv.org/abs/2502.04066v1,"The GPT-4 technical report from OpenAI suggests that model performance onspecific tasks can be predicted prior to training, though methodologies remainunspecified. This approach is crucial for optimizing resource allocation andensuring data alignment with target tasks. To achieve this vision, we focus onpredicting performance on Closed-book Question Answering (CBQA) tasks, whichare closely tied to pre-training data and knowledge retention. We address threemajor challenges: 1) mastering the entire pre-training process, especially dataconstruction; 2) evaluating a model's knowledge retention; and 3) predictingtask-specific knowledge retention using only information available prior totraining. To tackle these challenges, we pre-train three large language models(i.e., 1.6B, 7B, and 13B) using 560k dollars and 520k GPU hours. We analyze thepre-training data with knowledge triples and assess knowledge retention usingestablished methods. Additionally, we introduce the SMI metric, aninformation-theoretic measure that quantifies the relationship betweenpre-training data, model size, and task-specific knowledge retention. Ourexperiments reveal a strong linear correlation ($\text{R}^2 > 0.84$) betweenthe SMI metric and the model's accuracy on CBQA tasks across models of varyingsizes (i.e., 1.1B, 1.6B, 7B, and 13B). The dataset, model, and code areavailable at https://github.com/yuhui1038/SMI.",Changhao Jiang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04065v1,Revisiting convolutive blind source separation for identifying spiking motor neuron activity: From theory to practice,http://arxiv.org/abs/2502.04065v1,"Objective: Identifying the activity of motor neurons (MNs) non-invasively ispossible by decomposing signals from muscles, e.g., surface electromyography(EMG) or ultrasound. The theoretical background of MN identification isconvolutive blind source separation (cBSS), and different algorithms have beendeveloped and validated. Yet, the existence and identifiability of inversesolutions and the corresponding estimation errors are not fully understood.Further, the guidelines for selecting appropriate parameters are often built onempirical observations, limiting the translation to clinical applications andother modalities. Approach: We revisited the cBSS model for MN identification,augmented it with new theoretical insights and derived a framework that canpredict the existence of inverse solutions. This framework allows thequantification of estimation errors due to the imperfect inversion of the motorunit action potentials (MUAP), noise sources, and the ill-conditioning of theinverse problem. To bridge the gap between theory and practice, we usedcomputer simulations. Main results: (1) Increasing the similarity of MUAPs orcorrelation between spike trains increases the bias for detecting highamplitude MUs. (2) The optimal objective function depends on the expected spikeamplitude, spike amplitude statistics and the amplitude of background spikes.(3) There is some wiggle room for MN detection given non-stationary MUAPs. (4)There is no connection between MUAP duration and extension factor, in contrastto previous guidelines. (5) Source quality metrics like the silhouette score(SIL) or the pulse-to-noise ratio (PNR) are highly correlated with a source'sobjective function output. (6) SIL is superior to PNR. Significance: Thesefindings will guide cBSS algorithm developments tailored to MN identificationand clinical application translation.",Thomas Klotz,2025-02-06,2025-02-06,,N/A,"['q-bio.QM', 'q-bio.CB', 'q-bio.NC', 'q-bio.TO']"
2502.04064v1,Inteligencia artificial para la multi-clasificación de fauna en fotografías automáticas utilizadas en investigación científica,http://arxiv.org/abs/2502.04064v1,"The management of natural environments, whether for conservation orproduction, requires a deep understanding of wildlife. The number, location,and behavior of wild animals are among the main subjects of study in ecologyand wildlife research. The use of camera traps offers the opportunity toquickly collect large quantities of photographs that capture wildlife in itsnatural habitat, avoiding factors that could alter their behavior. In Tierradel Fuego, Argentina, research is being conducted on forest use by differentherbivores (guanacos, cows, sheep) to optimize management and protect thesenatural ecosystems. Although camera traps allow for the collection of millionsof images, interpreting such photographs presents a scalability challenge formanual processing. As a result, much of the valuable knowledge stored in thesevast data repositories remains untapped. Neural Networks and Deep Learning areareas of study within Artificial Intelligence. Over the past decade, these twodisciplines have made significant contributions to image recognition on aglobal scale. Ecological and wildlife conservation studies can be combined withthese new technologies to extract important information from the photographsobtained by camera traps, contributing to the understanding of various naturalprocesses and improving the management of the involved wild areas. Our projectaims to develop neural network models to classify animal species in photographstaken with camera traps, addressing large-scale challenges in scientificresearch.",Federico Gonzalez,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04063v1,A Multi-level Compiler Backend for Accelerated Micro-kernels Targeting RISC-V ISA Extensions,http://arxiv.org/abs/2502.04063v1,"High-performance micro-kernels must fully exploit today's diverse andspecialized hardware to deliver peak performance to DNNs. While higher-leveloptimizations for DNNs are offered by numerous compilers (e.g., MLIR, TVM,OpenXLA), performance-critical micro-kernels are left to specialized codegenerators or handwritten assembly. Even though widely-adopted compilers (e.g.,LLVM, GCC) offer tuned backends, their CPU-focused input abstraction,unstructured IR, and general-purpose best-effort design inhibit tailored codegeneration for innovative hardware. We think it is time to widen the classicalhourglass backend and embrace progressive lowering across a diverse set ofstructured abstractions to bring domain-specific code generation to compilerbackends. We demonstrate this concept by implementing a custom backend for aRISC-V-based accelerator with hardware loops and streaming registers,leveraging knowledge about the hardware at levels of abstraction that match itscustom ISA. We use incremental register allocation over structured IRs, whiledropping classical spilling heuristics, and show up to 90% FPU utilizationacross key DNN kernels. By breaking the backend hourglass model, we reopen thepath from domain-specific abstractions to specialized hardware.",Alexandre Lopoukhine,2025-02-06,2025-02-06,,N/A,"['cs.PL', 'D.3.4']"
2502.04059v1,Fundamental Oscillations of Massive Boson Stars and Distinguishability,http://arxiv.org/abs/2502.04059v1,"Massive Boson Stars are self-gravitating configurations of self-interactingscalar fields. The equation of state of massive boson stars and their masses,radii, modeled by a self-interacting scalar field with potential of the form$V(\phi) = \frac{1}{2}m^2|\phi|^2 + \frac{1}{4}\lambda |\phi|^4$ are known tofollow scaling relations. The non-radial fundamental oscillations of suchmassive BSs have been studied only for a few select model parameters so far. Inthis work, we demonstrate for the first time that the $f$-mode characteristicsalso follow a scaling in the strong interaction limit ($\lambda \ggm^2/M_{Pl}^2$). This opens up the outstanding prospect of studying the$f$-modes of massive BSs throughout the scalar DM parameter space. We study theimplications of this finding by carrying out a detailed study of massive BS$f$-modes in a separate work. Here, having introduced this scaling, we use itto compare boson star oscillations with the neutron star and black holequasinormal modes, thus providing a smoking gun for the distinguishability ofBSs using gravitational waves.",Swarnim Shirke,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.HE', 'hep-ph']"
2502.04058v1,Strategic Learning with Local Explanations as Feedback,http://arxiv.org/abs/2502.04058v1,"We investigate algorithmic decision problems where agents can respondstrategically to the decision maker's (DM) models. The demand for clear andactionable explanations from DMs to (potentially strategic) agents continues torise. While prior work often treats explanations as full model disclosures,explanations in practice might convey only partial information, which can leadto misinterpretations and harmful responses. When full disclosure of thepredictive model is neither feasible nor desirable, a key open question is howDMs can use explanations to maximise their utility without compromising agentwelfare. In this work, we explore well-known local and global explanationmethods, and establish a necessary condition to prevent explanations frommisleading agents into self-harming actions. Moreover, with conditionalhomogeneity, we establish that action recommendation (AR)-based explanationsare sufficient for non-harmful responses, akin to the revelation principle ininformation design. To operationalise AR-based explanations, we propose asimple algorithm to jointly optimise the predictive model and AR policy tobalance DM outcomes with agent welfare. Our empirical results demonstrate thebenefits of this approach as a more refined strategy for safe and effectivepartial model disclosure in algorithmic decision-making.",Kiet Q. H. Vo,2025-02-06,2025-02-06,,N/A,['cs.AI']
2502.04057v1,Smart IoT Security: Lightweight Machine Learning Techniques for Multi-Class Attack Detection in IoT Networks,http://arxiv.org/abs/2502.04057v1,"In the growing terrain of the Internet of Things (IoT), it is vital thatnetworks are secure to protect against a range of cyber threats. Based on thestrong machine learning framework, this study proposes novel lightweightensemble approaches for improving multi-class attack detection of IoT devices.Using the large CICIoT 2023 dataset with 34 attack types distributed amongst 10attack categories, we systematically evaluated the performance of a widevariety of modern machine learning methods with the aim of establishing thebest-performing algorithmic choice to secure IoT applications. In particular,we explore approaches based on ML classifiers to tackle the biochargescharacterized by the challenging and heterogeneous nature of attack vectors inIoT environments. The method that performed best was the Decision Tree, with anaccuracy of 99.56% and an F1 score of 99.62%, showing that this model iscapable of accurately and reliably detecting threats.The Random Forest modelwas the next best-performing model with 98.22% and an F1 score of 98.24%,suggesting that ML methods are quite effective in a situation ofhigh-dimensional data. Our results highlight the potential for using MLclassifiers in bolstering security for IoT devices and also serve asmotivations for future investigations targeting scalable, keystroke-basedattack detection systems. We believe that our method provides a new path todevelop complex machine learning algorithms for low-resource IoT devices,balancing both accuracy and time efficiency needs. In summary, thesecontributions enrich the state of the art of the IoT security literature,laying down solid ground and guidelines for the deployment of smart, adaptivesecurity in IoT settings.",Shahran Rahman Alve,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04056v1,TQ-DiT: Efficient Time-Aware Quantization for Diffusion Transformers,http://arxiv.org/abs/2502.04056v1,"Diffusion transformers (DiTs) combine transformer architectures withdiffusion models. However, their computational complexity imposes significantlimitations on real-time applications and sustainability of AI systems. In thisstudy, we aim to enhance the computational efficiency through modelquantization, which represents the weights and activation values with lowerprecision. Multi-region quantization (MRQ) is introduced to address theasymmetric distribution of network values in DiT blocks by allocating twoscaling parameters to sub-regions. Additionally, time-grouping quantization(TGQ) is proposed to reduce quantization error caused by temporal variation inactivations. The experimental results show that the proposed algorithm achievesperformance comparable to the original full-precision model with only a 0.29increase in FID at W8A8. Furthermore, it outperforms other baselines at W6A6,thereby confirming its suitability for low-bit quantization. These resultshighlight the potential of our method to enable efficient real-time generativemodels.",Younghye Hwang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'eess.SP']"
2502.04055v1,Evaluating Inter-Column Logical Relationships in Synthetic Tabular Data Generation,http://arxiv.org/abs/2502.04055v1,"Current evaluations of synthetic tabular data mainly focus on how well jointdistributions are modeled, often overlooking the assessment of theireffectiveness in preserving realistic event sequences and coherent entityrelationships across columns.This paper proposes three evaluation metricsdesigned to assess the preservation of logical relationships among columns insynthetic tabular data. We validate these metrics by assessing the performanceof both classical and state-of-the-art generation methods on a real-worldindustrial dataset.Experimental results reveal that existing methods often failto rigorously maintain logical consistency (e.g., hierarchical relationships ingeography or organization) and dependencies (e.g., temporal sequences ormathematical relationships), which are crucial for preserving the fine-grainedrealism of real-world tabular data. Building on these insights, this study alsodiscusses possible pathways to better capture logical relationships whilemodeling the distribution of synthetic tabular data.",Yunbo Long,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04054v1,Precision Agriculture Revolution: Integrating Digital Twins and Advanced Crop Recommendation for Optimal Yield,http://arxiv.org/abs/2502.04054v1,"With the help of a digital twin structure, Agriculture 4.0 technologies likeweather APIs (Application programming interface), GPS (Global PositioningSystem) modules, and NPK (Nitrogen, Phosphorus and Potassium) soil sensors andmachine learning recommendation models, we seek to revolutionize agriculturalproduction through this concept. In addition to providing precise crop growthforecasts, the combination of real-time data on soil composition,meteorological dynamics, and geographic coordinates aims to support croprecommendation models and simulate predictive scenarios for improved water andpesticide management.",Sayan Banerjee,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04052v1,Decision Trees That Remember: Gradient-Based Learning of Recurrent Decision Trees with Memory,http://arxiv.org/abs/2502.04052v1,"Neural architectures such as Recurrent Neural Networks (RNNs), Transformers,and State-Space Models have shown great success in handling sequential data bylearning temporal dependencies. Decision Trees (DTs), on the other hand, remaina widely used class of models for structured tabular data but are typically notdesigned to capture sequential patterns directly. Instead, DT-based approachesfor time-series data often rely on feature engineering, such as manuallyincorporating lag features, which can be suboptimal for capturing complextemporal dependencies. To address this limitation, we introduce ReMeDe Trees, anovel recurrent DT architecture that integrates an internal memory mechanism,similar to RNNs, to learn long-term dependencies in sequential data. Our modellearns hard, axis-aligned decision rules for both output generation and stateupdates, optimizing them efficiently via gradient descent. We provide aproof-of-concept study on synthetic benchmarks to demonstrate the effectivenessof our approach.",Sascha Marton,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04053v2,Proof of principle for a light dark matter search with low-energy positron beams at NA64,http://arxiv.org/abs/2502.04053v2,"Thermal light dark matter (LDM) with particle masses in the 1 MeV - 1 GeVrange could successfully explain the observed dark matter abundance as a relicfrom the primordial Universe. In this picture, a new feeble interaction acts asa ""portal"" between the Standard Model and LDM particles, allowing for theexploration of this paradigm at accelerator experiments. In the last years, the""missing energy"" experiment NA64e at CERN SPS (Super Proton Synchrotron) hasset world-leading constraints in the vector-mediated LDM parameter space, byexploiting a 100 GeV electron beam impinging on an electromagnetic calorimeter,acting as an active target. In this paper, we report a detailed description ofthe analysis of a preliminary measurement with a 70 GeV positron beam at NA64e,performed during summer 2023 with an accumulated statistic of 1.6 x 10^10positrons on target. This data set was analyzed with the primary aim ofevaluating the performance of the NA64e detector with a lower energy positronbeam, towards the realization of the post-LS3 program. The analysis results,other than additionally probing unexplored regions in the LDM parameter space,provide valuable information towards the future NA64e positron campaign.",Yu. M. Andreev,2025-02-06,2025-02-07,,N/A,"['hep-ex', 'physics.ins-det']"
2502.04050v1,PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models,http://arxiv.org/abs/2502.04050v1,"We present the first text-based image editing approach for object parts basedon pre-trained diffusion models. Diffusion-based image editing approachescapitalized on the deep understanding of diffusion models of image semantics toperform a variety of edits. However, existing diffusion models lack sufficientunderstanding of many object parts, hindering fine-grained edits requested byusers. To address this, we propose to expand the knowledge of pre-traineddiffusion models to allow them to understand various object parts, enablingthem to perform fine-grained edits. We achieve this by learning special textualtokens that correspond to different object parts through an efficient tokenoptimization process. These tokens are optimized to produce reliablelocalization masks at each inference step to localize the editing region.Leveraging these masks, we design feature-blending and adaptive thresholdingstrategies to execute the edits seamlessly. To evaluate our approach, weestablish a benchmark and an evaluation protocol for part editing. Experimentsshow that our approach outperforms existing editing methods on all metrics andis preferred by users 77-90% of the time in conducted user studies.",Aleksandar Cvejic,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04049v2,Towards Explainable Spoofed Speech Attribution and Detection:a Probabilistic Approach for Characterizing Speech Synthesizer Components,http://arxiv.org/abs/2502.04049v2,"We propose an explainable probabilistic framework for characterizing spoofedspeech by decomposing it into probabilistic attribute embeddings. Unlike rawhigh-dimensional countermeasure embeddings, which lack interpretability, theproposed probabilistic attribute embeddings aim to detect specific speechsynthesizer components, represented through high-level attributes and theircorresponding values. We use these probabilistic embeddings with fourclassifier back-ends to address two downstream tasks: spoofing detection andspoofing attack attribution. The former is the well-known bonafide-spoofdetection task, whereas the latter seeks to identify the source method(generator) of a spoofed utterance. We additionally use Shapley values, awidely used technique in machine learning, to quantify the relativecontribution of each attribute value to the decision-making process in eachtask. Results on the ASVspoof2019 dataset demonstrate the substantial role ofduration and conversion modeling in spoofing detection; and waveform generationand speaker modeling in spoofing attack attribution. In the detection task, theprobabilistic attribute embeddings achieve $99.7\%$ balanced accuracy and$0.22\%$ equal error rate (EER), closely matching the performance of rawembeddings ($99.9\%$ balanced accuracy and $0.22\%$ EER). Similarly, in theattribution task, our embeddings achieve $90.23\%$ balanced accuracy and$2.07\%$ EER, compared to $90.16\%$ and $2.11\%$ with raw embeddings. Theseresults demonstrate that the proposed framework is both inherently explainableby design and capable of achieving performance comparable to raw CM embeddings.",Jagabandhu Mishra,2025-02-06,2025-02-07,,N/A,['eess.AS']
2502.04048v1,Adaptive Output Feedback MPC with Guaranteed Stability and Robustness,http://arxiv.org/abs/2502.04048v1,"This work proposes an adaptive output feedback model predictive control (MPC)framework for uncertain systems subject to external disturbances. In theabsence of exact knowledge about the plant parameters and complete statemeasurements, the MPC optimization problem is reformulated in terms of theirestimates derived from a suitably designed robust adaptive observer. The MPCroutine returns a homothetic tube for the state estimate trajectory. Sets thatcharacterize the state estimation errors are then added to the homothetic tubesections, resulting in a larger tube containing the true state trajectory. Thetwo-tier tube architecture provides robustness to uncertainties due toimperfect parameter knowledge, external disturbances, and incomplete stateinformation. Additionally, recursive feasibility and robust exponentialstability are guaranteed and validated using a numerical example.",Anchita Dey,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY', 'math.OC']"
2502.04047v1,Non-renormalization of the fractional quantum Hall conductivity by interactions,http://arxiv.org/abs/2502.04047v1,"We investigate the theory of the fractional quantum Hall effect (QHE)proposed a long time ago by Lopez and Fradkin \cite{Fradkin1991chern}. Themagnetic fluxes of the statistical gauge field attached to electrons remain atrest in the reference frame moving together with the electron liquid. In thelaboratory reference frame the electric field of the statistical gauge fieldforms and screens the external electric field. The fractional QHE conductivityappears as a consequence of this screening already on the mean field theorylevel. We consider a relativistic extension of the model, and propose analternative description of the fractional QHE based on macroscopic motion ofthe electron liquid within the Zubarev statistical operator approach. It isthis macroscopic motion of electrons which in this pattern gives rise to thefractional QHE. Within this approach we propose the proof to all orders ofperturbation theory that the interaction corrections cannot change the abovementioned mean field theory result for the QHE conductivity.",M. Selch,2025-02-06,2025-02-06,,N/A,['cond-mat.mes-hall']
2502.04414v1,Establishing the vector-meson-exchange dominance for the short range interactions of light quarks,http://arxiv.org/abs/2502.04414v1,"I give a brief comment on a recent study revealing the vector meson exchange(VME) dominant for the short range interactions between u/d quarks in the $NN$,$D_{03}$, and $D_{30}$ systems. The finding echoes nicely with an earlier studyof hadron spectroscopy using a quark model with hidden local symmetry whichalso favors the VME dominant for the short range interactions of light quarks.The VME dominance for the short range interactions of light quarks gives anatural explanation of the empiric VME dominance for the interactions betweenhadrons containing light quarks.",Bing-Song Zou,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'nucl-th']"
2502.04043v1,Probe-Free Low-Rank Activation Intervention,http://arxiv.org/abs/2502.04043v1,"Language models (LMs) can produce texts that appear accurate and coherent butcontain untruthful or toxic content. Inference-time interventions that edit thehidden activations have shown promising results in steering the LMs towardsdesirable generations. Existing activation intervention methods often comprisean activation probe to detect undesirable generation, triggering the activationmodification to steer subsequent generation. This paper proposes a probe-freeintervention method FLORAIN for all attention heads in a specific activationlayer. It eliminates the need to train classifiers for probing purposes. Theintervention function is parametrized by a sample-wise nonlinear low-rankmapping, which is trained by minimizing the distance between the modifiedactivations and their projection onto the manifold of desirable content. Underspecific constructions of the manifold and projection distance, we show thatthe intervention strategy can be computed efficiently by solving a smoothoptimization problem. The empirical results, benchmarked on multiple basemodels, demonstrate that FLORAIN consistently outperforms several baselinemethods in enhancing model truthfulness and quality across generation andmultiple-choice tasks.",Chonghe Jiang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04042v1,Spontaneous helix formation in polar smectic phase,http://arxiv.org/abs/2502.04042v1,"In soft ferroelectric crystals, the depolarization field can be reduced byperiodic distortion of the polarization direction. In the polar nematic andtilted smectic phases, this process is energetically favorured , as it onlyrequires changes in the director orientation. We demonstrate the spontaneousformation of a helical structure in the proper ferroelectric tilted smectic(SmCTBF) phase, the phase is formed below the heliconical polar nematic (NTBF)phase. The helical pitch in the smectic phase is approximately 600 nm andremains nearly constant across the entire temperature range of the phase. Underweak electric fields, the helix reorients while its structure remains largelyintact; however, in stronger fields, the helix is destroyed as the electricpolarization aligns along the electric field.",Ewa Gorecka,2025-02-06,2025-02-06,,N/A,['cond-mat.soft']
2502.04041v1,$\tt GrayHawk$: A public code for calculating the Gray Body Factors of massless fields around spherically symmetric Black Holes,http://arxiv.org/abs/2502.04041v1,"We introduce and describe $\tt GrayHawk$, a publicly availableMathematica-based tool designed for the efficient computation of gray-bodyfactors for spherically symmetric and asymptotically flat black holes. Thisprogram provides users with a rapid and reliable means to compute gray-bodyfactors for massless fields with spin \(s = 0, 1/2, 1, 2\) in modes specifiedby the angular quantum number \(l\), given a black hole metric and theassociated parameter values. $\tt GrayHawk$ is preloaded with seven differentblack hole metrics, offering immediate applicability to a variety oftheoretical models. Additionally, its modular structure allows users to extendits functionality easily by incorporating alternative metrics orconfigurations. This versatility makes $\tt GrayHawk$ a powerful and adaptableresource for researchers studying black hole physics and Hawking radiation. Thecodes described in this work are publicly available athttps://github.com/marcocalza89/GrayHawk.",Marco Calzá,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.CO', 'astro-ph.IM', 'hep-th']"
2502.04040v1,Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment,http://arxiv.org/abs/2502.04040v1,"Training safe LLMs is one of the most critical research challenge. However,the commonly used method, Refusal Training (RT), struggles to generalizeagainst various OOD jailbreaking attacks. Many safety training methods havebeen proposed to address this issue. While they offer valuable insights, we aimto complement this line of research by investigating whether OOD attacks trulyexceed the capability of RT model. Conducting evaluation with BoN, we observesignificant improvements on generalization as N increases. This underscoresthat the model possesses sufficient safety-related latent knowledge, but RTfails to consistently elicit this knowledge when addressing OOD attacks.Further analysis based on domain adaptation reveals that training with directrefusal causes model to rely on superficial shortcuts, resulting in learning ofnon-robust representation mappings. Based on our findings, we propose trainingmodel to perform safety reasoning for each query. Reasoning supervisionencourages model to perform more computations, explicitly eliciting and usinglatent knowledge through reasoning. To achieve this, we synthesize reasoningsupervision based on pre-guidelines, training the model to reason in alignmentwith them, thereby effectively eliciting and utilizing latent knowledge fromdiverse perspectives. Extensive experiments show that our method significantlyimproves generalization performance against OOD attacks.",Haoyu Wang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.04039v1,A Cloud-native Agile approach to cyber platform prototyping and integration for astronomy: the ENGAGE SKA case,http://arxiv.org/abs/2502.04039v1,"The Square Kilometre Array (SKA) Observatory is gearing up the formalconstruction of its two radio interferometers in Australia and South Africaafter the end of design and pre-construction phases. Agile methodologies, theCloud native Computing technologies and the DevOps software ideas areinfluencing the design of compute infrastructures that will be key to reducethe operational costs of SKA while improving the control and monitoring of theSKA antennas and ancillary systems, Correlators, HPC facilities or related datacentre tiered systems. These tools will likely include advanced power meteringtechnologies and efficient distribution automation and Network OperationCentres (NOC). SKA will become the world's largest radio telescope and isexpected to achieve its first science by 2026. To cope with this dimension andcomplexity, a key part of this distributed Observatory is the overall softwarecontrol and monitoring system embodied in the Observatory Management andControl (OMC) and the Services Teams that requires specialized Agile Teams toassist in software and cyber infrastructure building using an Agile developmentenvironment that includes test automation, Continuous Integration, andContinuous Deployment. To manage such a large and distributed machine, theAgile approach was adopted for the core software package of the SKA Telescopeaimed at scheduling observations, controlling their execution, monitoring thetelescope status and ensuring scalability and reliability. Here, we report onthe ENGAGE SKA ciberinfrastructure prototyping support to the SKA AgileSoftware Development Life Cycle (SDLC).",Domingos Barbosa,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'cs.SY', 'eess.SY', 'physics.med-ph']"
2502.04038v1,Simulating the Emergence of Differential Case Marking with Communicating Neural-Network Agents,http://arxiv.org/abs/2502.04038v1,"Differential Case Marking (DCM) refers to the phenomenon where grammaticalcase marking is applied selectively based on semantic, pragmatic, or otherfactors. The emergence of DCM has been studied in artificial language learningexperiments with human participants, which were specifically aimed atdisentangling the effects of learning from those of communication (Smith &Culbertson, 2020). Multi-agent reinforcement learning frameworks based onneural networks have gained significant interest to simulate the emergence ofhuman-like linguistic phenomena. In this study, we employ such a framework inwhich agents first acquire an artificial language before engaging incommunicative interactions, enabling direct comparisons to human result. Usinga very generic communication optimization algorithm and neural-network learnersthat have no prior experience with language or semantic preferences, ourresults demonstrate that learning alone does not lead to DCM, but when agentscommunicate, differential use of markers arises. This supports Smith andCulbertson (2020)'s findings that highlight the critical role of communicationin shaping DCM and showcases the potential of neural-agent models to complementexperimental research on language evolution.",Yuchen Lian,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04037v1,Exploring Imbalanced Annotations for Effective In-Context Learning,http://arxiv.org/abs/2502.04037v1,"Large language models (LLMs) have shown impressive performance on downstreamtasks through in-context learning (ICL), which heavily relies on thedemonstrations selected from annotated datasets. Existing selection methods mayhinge on the distribution of annotated datasets, which can often be long-tailedin real-world scenarios. In this work, we show that imbalanced classdistributions in annotated datasets significantly degrade the performance ofICL across various tasks and selection methods. Moreover, traditional rebalancemethods fail to ameliorate the issue of class imbalance in ICL. Our method ismotivated by decomposing the distributional differences between annotated andtest datasets into two-component weights: class-wise weights and conditionalbias. The key idea behind our method is to estimate the conditional bias byminimizing the empirical error on a balanced validation dataset and to employthe two-component weights to modify the original scoring functions duringselection. Our approach can prevent selecting too many demonstrations from asingle class while preserving the effectiveness of the original selectionmethods. Extensive experiments demonstrate the effectiveness of our method,improving the average accuracy by up to 5.46 on common benchmarks withimbalanced datasets.",Hongfu Gao,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG']"
2502.04035v1,Complete FSM Testing Using Strong Separability,http://arxiv.org/abs/2502.04035v1,"Apartness is a concept developed in constructive mathematics, which hasresurfaced as a powerful notion for separating states in the area of modellearning and model-based testing. We identify some fundamental shortcomings ofapartness in quantitative models, such as in hybrid and stochastic systems. Wepropose a closely-related alternative, called strong separability and show thatusing it to replace apartness addresses the identified shortcomings. We adapt awell-known complete model-based testing method, called the Harmonized StateIdentifiers (HSI) method, to adopt the proposed notion of strong separability.We prove that the adapted HSI method is complete. As far as we are aware, thisis the first work to show how complete test suites can be generated forquantitative models such as those found in the development of cyber-physicalsystems.",Robert M. Hierons,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.FL']"
2502.04034v1,Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization,http://arxiv.org/abs/2502.04034v1,"The accurate prediction of drug responses remains a formidable challenge,particularly at the single-cell level and in clinical treatment contexts. Somestudies employ transfer learning techniques to predict drug responses inindividual cells and patients, but they require access to target-domain dataduring training, which is often unavailable or only obtainable in future. Inthis study, we propose a novel domain generalization framework, termedpanCancerDR, to address this challenge. We conceptualize each cancer type as adistinct source domain, with its cell lines serving as domain-specific samples.Our primary objective is to extract domain-invariant features from theexpression profiles of cell lines across diverse cancer types, therebygeneralize the predictive capacity to out-of-distribution samples. To enhancerobustness, we introduce a latent independence projection (LIP) module thatencourages the encoder to extract informative yet non-redundant features. Also,we propose an asymmetric adaptive clustering constraint, which clustersdrug-sensitive samples into a compact group while drives resistant samplesdispersed across separate clusters in the latent space. Our empiricalexperiments demonstrate that panCancerDR effectively learns task-relevantfeatures from diverse source domains, and achieves accurate predictions of drugresponse for unseen cancer type during training. Furthermore, when evaluated onsingle-cell and patient-level prediction tasks, our model-trained solely on invitro cell line data without access to target-domain information-consistentlyoutperforms and matched current state-of-the-art methods. These findingshighlights the potential of our method for real-world clinical applications.",Ran Song,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.04031v1,Modeling the laser-pulse induced helium trimer dynamics,http://arxiv.org/abs/2502.04031v1,"Motivated by ongoing pump-probe spectroscopy experiments, this work developsa theoretical framework for describing the rovibrational wave packet dynamicsthat ensues when a single weakly-bound van der Waals trimer is exposed to ashort, sub-picosecond linearly polarized pump laser pulse. The intensity I ofthe pump laser is chosen such that excitation and ionization of the electronicdegrees of freedom are negligible while excitation of the wavepacket in thenuclear degrees of freedom is non-negligible. The numerical treatment, whichtakes advantage of the fact that the laser pulse is very short compared totypical molecular time scales, is based on a wave packet decomposition thatutilizes hyperspherical coordinates. The framework is applied to the extremelyfloppy bosonic helium trimer. A convergence analysis of the partial wavedecomposition is conducted. The kinetic energy release and orientation dynamicsare presented. While the dynamics of more strongly-bound van der Waals trimerssuch as, e.g., the argon trimer display negligible coupling between vibrationaland rotational degrees of freedom, rendering a description within a rigid-bodypicture appropriate, those of weakly-bound trimers display non-negligiblecoupling between vibrational and rotational degrees of freedom, rendering adescription within a rigid-body picture inappropriate. It is shown that a modelthat constructs the helium trimer dynamics from the dynamics of the heliumdimer captures a number of key characteristics of the alignment signal,including the interference between different angular momentum wave packetcomponents.",Q. Guan,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'cond-mat.quant-gas']"
2502.04030v1,"Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging",http://arxiv.org/abs/2502.04030v1,"Reasoning capabilities represent a critical frontier for large languagemodels (LLMs), but developing them requires extensive proprietary datasets andcomputational resources. One way to efficiently supplement capabilities with isby model merging, which offers a promising alternative by combining multiplemodels without retraining. However, current merging approaches rely onmanually-designed strategies for merging hyperparameters, limiting theexploration of potential model combinations and requiring significant humaneffort. We propose an Automated Model Merging Framework that enablesfine-grained exploration of merging strategies while reducing costs throughmulti-fidelity approximations. We support both single and multi-objectiveoptimization and introduce two novel search spaces: layerwise fusion (LFS) anddepth-wise integration (DIS). Evaluating across a number of benchmarks, we findthat the search autonomously finds 1) Merges that further boostsingle-objective performance, even on tasks the model has already beenfinetuned on, and 2) Merges that optimize multi-objective frontiers acrosstasks. Effective merges are found with limited compute, e.g. within less than500 search steps.",Guinan Su,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.LG']"
2502.04029v1,Echo-Teddy: Preliminary Design and Development of Large Language Model-based Social Robot for Autistic Students,http://arxiv.org/abs/2502.04029v1,"Autistic students often face challenges in social interaction, which canhinder their educational and personal development. This study introducesEcho-Teddy, a Large Language Model (LLM)-based social robot designed to supportautistic students in developing social and communication skills. Unlikeprevious chatbot-based solutions, Echo-Teddy leverages advanced LLMcapabilities to provide more natural and adaptive interactions. The researchaddresses two key questions: (1) What are the design principles and initialprototype characteristics of an effective LLM-based social robot for autisticstudents? (2) What improvements can be made based on developerreflection-on-action and expert interviews? The study employed a mixed-methodsapproach, combining prototype development with qualitative analysis ofdeveloper reflections and expert interviews. Key design principles identifiedinclude customizability, ethical considerations, and age-appropriateinteractions. The initial prototype, built on a Raspberry Pi platform, featurescustom speech components and basic motor functions. Evaluation of the prototyperevealed potential improvements in areas such as user interface, educationalvalue, and practical implementation in educational settings. This researchcontributes to the growing field of AI-assisted special education bydemonstrating the potential of LLM-based social robots in supporting autisticstudents. The findings provide valuable insights for future developments inaccessible and effective social support tools for special education.",Unggi Lee,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.04028v1,Deep Meta Coordination Graphs for Multi-agent Reinforcement Learning,http://arxiv.org/abs/2502.04028v1,"This paper presents deep meta coordination graphs (DMCG) for learningcooperative policies in multi-agent reinforcement learning (MARL). Coordinationgraph formulations encode local interactions and accordingly factorize thejoint value function of all agents to improve efficiency in MARL. However,existing approaches rely solely on pairwise relations between agents, whichpotentially oversimplifies complex multi-agent interactions. DMCG goes beyondthese simple direct interactions by also capturing useful higher-order andindirect relationships among agents. It generates novel graph structuresaccommodating multiple types of interactions and arbitrary lengths of multi-hopconnections in coordination graphs to model such interactions. It then employsa graph convolutional network module to learn powerful representations in anend-to-end manner. We demonstrate its effectiveness in multiple coordinationproblems in MARL where other state-of-the-art methods can suffer from sampleinefficiency or fail entirely. All codes can be found here:https://github.com/Nikunj-Gupta/dmcg-marl.",Nikunj Gupta,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04027v1,High-Frequency Market Manipulation Detection with a Markov-modulated Hawkes process,http://arxiv.org/abs/2502.04027v1,"This work focuses on a self-exciting point process defined by a Hawkes-likeintensity and a switching mechanism based on a hidden Markov chain. Previousworks in such a setting assume constant intensities between consecutive events.We extend the model to general Hawkes excitation kernels that are piecewiseconstant between events. We develop an expectation-maximization algorithm forthe statistical inference of the Hawkes intensities parameters as well as thestate transition probabilities. The numerical convergence of the estimators isextensively tested on simulated data. Using high-frequency cryptocurrency dataon a top centralized exchange, we apply the model to the detection of anomalousbursts of trades. We benchmark the goodness-of-fit of the model with theMarkov-modulated Poisson process and demonstrate the relevance of the model indetecting suspicious activities.",Timothée Fabre,2025-02-06,2025-02-06,,N/A,"['stat.ME', 'q-fin.ST', 'q-fin.TR']"
2502.04025v1,Renormalization group invariant mean-field model for QCD at finite isospin density,http://arxiv.org/abs/2502.04025v1,"QCD at nonzero isospin chemical potentials has phenomenological relevance fora series of physical systems and provides an ideal testground for the modelingof dense strongly interacting matter. The two-flavor quark-meson model is knownto effectively describe the condensation of charged pions in QCD that occurs inthis setting. In this paper, we work out a renormalization-group invariantmean-field formulation of the model and demonstrate that the resulting phasediagram and equation of state is in quantitative agreement with data fromlattice QCD simulations.",Bastian B. Brandt,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'hep-lat', 'nucl-th']"
2502.04024v1,A Robust Optimization Model for Cost-Efficient and Fast Electric Vehicle Charging with L2-norm Uncertainty,http://arxiv.org/abs/2502.04024v1,"In this paper, we propose a robust optimization model that addresses both thecost-efficiency and fast charging requirements for electric vehicles (EVs) atcharging stations. By combining elements from traditional cost-minimizationmodels and a fast charging objective, we construct an optimization model thatbalances user costs with rapid power allocation. Additionally, we incorporateL2-norm uncertainty into the charging cost, ensuring that the model remainsresilient under cost fluctuations. The proposed model is tested underreal-world scenarios and demonstrates its potential for efficient and flexibleEV charging solutions.",Trung Duc Tran,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.04413v1,MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot,http://arxiv.org/abs/2502.04413v1,"Retrieval-augmented generation (RAG) is a well-suited technique forretrieving privacy-sensitive Electronic Health Records (EHR). It can serve as akey module of the healthcare copilot, helping reduce misdiagnosis forhealthcare practitioners and patients. However, the diagnostic accuracy andspecificity of existing heuristic-based RAG models used in the medical domainare inadequate, particularly for diseases with similar manifestations. Thispaper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicitedreasoning for the medical domain that retrieves diagnosis and treatmentrecommendations based on manifestations. MedRAG systematically constructs acomprehensive four-tier hierarchical diagnostic KG encompassing criticaldiagnostic differences of various diseases. These differences are dynamicallyintegrated with similar EHRs retrieved from an EHR database, and reasonedwithin a large language model. This process enables more accurate and specificdecision support, while also proactively providing follow-up questions toenhance personalized medical decision-making. MedRAG is evaluated on both apublic dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)collected from Tan Tock Seng Hospital, and its performance is compared againstvarious existing RAG methods. Experimental results show that, leveraging theinformation integration and relational abilities of the KG, our MedRAG providesmore specific diagnostic insights and outperforms state-of-the-art models inreducing misdiagnosis rates. Our code will be available athttps://github.com/SNOWTEAM2023/MedRAG",Xuejiao Zhao,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.IR']"
2502.04022v1,Quantification of Biodiversity from Historical Survey Text with LLM-based Best-Worst Scaling,http://arxiv.org/abs/2502.04022v1,"In this study, we evaluate methods to determine the frequency of species viaquantity estimation from historical survey text. To that end, we formulateclassification tasks and finally show that this problem can be adequatelyframed as a regression task using Best-Worst Scaling (BWS) with Large LanguageModels (LLMs). We test Ministral-8B, DeepSeek-V3, and GPT-4, finding that thelatter two have reasonable agreement with humans and each other. We concludethat this approach is more cost-effective and similarly robust compared to afine-grained multi-class approach, allowing automated quantity estimationacross species.",Thomas Haider,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04018v1,PINT: Physics-Informed Neural Time Series Models with Applications to Long-term Inference on WeatherBench 2m-Temperature Data,http://arxiv.org/abs/2502.04018v1,"This paper introduces PINT (Physics-Informed Neural Time Series Models), aframework that integrates physical constraints into neural time series modelsto improve their ability to capture complex dynamics. We apply PINT to the ERA5WeatherBench dataset, focusing on long-term forecasting of 2m-temperature data.PINT incorporates the Simple Harmonic Oscillator Equation as a physics-informedprior, embedding its periodic dynamics into RNN, LSTM, and GRU architectures.This equation's analytical solutions (sine and cosine functions) facilitaterigorous evaluation of the benefits of incorporating physics-informedconstraints. By benchmarking against a linear regression baseline derived fromits exact solutions, we quantify the impact of embedding physical principles indata-driven models. Unlike traditional time series models that rely on futureobservations, PINT is designed for practical forecasting. Using only the first90 days of observed data, it iteratively predicts the next two years,addressing challenges posed by limited real-time updates. Experiments on theWeatherBench dataset demonstrate PINT's ability to generalize, capture periodictrends, and align with physical principles. This study highlights the potentialof physics-informed neural models in bridging machine learning andinterpretable climate applications.  Our models and datasets are publicly available on GitHub:https://github.com/KV-Park.",Keon Vin Park,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04015v1,Search for Stable States in Two-Body Excitations of the Hubbard Model on the Honeycomb Lattice,http://arxiv.org/abs/2502.04015v1,"We present one- and two-body measurements for the Hubbard model on thehoneycomb (graphene) lattice from ab-initio quantum monte carlo simulations. Ofparticular interest is excitons, which are particle/hole excitations inlow-dimensional systems. They are analogous to the pion in QCD, but withoutconfinement, the question of whether they are bound and stable is of greatinterest in the condensed matter arena. By measuring one- and two-bodycorrelators across various spin and isospin channels we can compute two-bodyenergies relative to their thresholds, ultimately allowing us to check forstable states.",Petar Sinilkov,2025-02-06,2025-02-06,,N/A,['cond-mat.str-el']
2502.04412v1,Decoder-Only LLMs are Better Controllers for Diffusion Models,http://arxiv.org/abs/2502.04412v1,"Groundbreaking advancements in text-to-image generation have recently beenachieved with the emergence of diffusion models. These models exhibit aremarkable ability to generate highly artistic and intricately detailed imagesbased on textual prompts. However, obtaining desired generation outcomes oftennecessitates repetitive trials of manipulating text prompts just like castingspells on a magic mirror, and the reason behind that is the limited capabilityof semantic understanding inherent in current image generation models.Specifically, existing diffusion models encode the text prompt input with apre-trained encoder structure, which is usually trained on a limited number ofimage-caption pairs. The state-of-the-art large language models (LLMs) based onthe decoder-only structure have shown a powerful semantic understandingcapability as their architectures are more suitable for training on verylarge-scale unlabeled data. In this work, we propose to enhance text-to-imagediffusion models by borrowing the strength of semantic understanding from largelanguage models, and devise a simple yet effective adapter to allow thediffusion models to be compatible with the decoder-only structure. Meanwhile,we also provide a supporting theoretical analysis with various architectures(e.g., encoder-only, encoder-decoder, and decoder-only), and conduct extensiveempirical evaluations to verify its effectiveness. The experimental resultsshow that the enhanced models with our adapter module are superior to thestat-of-the-art models in terms of text-to-image generation quality andreliability.",Ziyi Dong,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.CL']"
2502.04013v1,Search for resonance-enhanced $CP$ and angular asymmetries in the $Λ^+_{c}\to pμ^+μ^-$ decay at LHCb,http://arxiv.org/abs/2502.04013v1,"The first measurement of the $CP$ asymmetry of the decay rate ($A_{CP}$) andthe $CP$ average ($\Sigma A_{\text{FB}}$) and $CP$ asymmetry ($\DeltaA_{\text{FB}}$) of the forward-backward asymmetry in the muon system of$\mathit{\Lambda}^+_c\to p\mu^+\mu^-$ decays is reported. The measurement isperformed using a data sample of proton-proton collisions, recorded by the LHCbexperiment from 2016 to 2018 at a center-of-mass energy of 13$\text{ TeV}$,which corresponds to an integrated luminosity of 5.4$\text{ fb}^{-1}$. Theasymmetries are measured in two regions of dimuon mass near the $\phi$-mesonmass peak. The dimuon-mass integrated results are \begin{align*} A_{CP} &=(-1.1 \pm 4.0 \pm 0.5)\%,\\ \Sigma A_{\text{FB}} &= (\phantom{-}3.9 \pm 4.0 \pm0.6)\%,\\ \Delta A_{\text{FB}} &= (\phantom{-}3.1 \pm 4.0 \pm 0.4)\%,\end{align*} where the first uncertainty is statistical and the secondsystematic. The results are consistent with the conservation of $CP$ symmetryand the Standard Model expectations.",LHCb collaboration,2025-02-06,2025-02-06,,N/A,['hep-ex']
2502.04008v1,Automating a Complete Software Test Process Using LLMs: An Automotive Case Study,http://arxiv.org/abs/2502.04008v1,"Vehicle API testing verifies whether the interactions between a vehicle'sinternal systems and external applications meet expectations, ensuring thatusers can access and control various vehicle functions and data. However, thistask is inherently complex, requiring the alignment and coordination of APIsystems, communication protocols, and even vehicle simulation systems todevelop valid test cases. In practical industrial scenarios, inconsistencies,ambiguities, and interdependencies across various documents and systemspecifications pose significant challenges. This paper presents a systemdesigned for the automated testing of in-vehicle APIs. By clearly defining andsegmenting the testing process, we enable Large Language Models (LLMs) to focuson specific tasks, ensuring a stable and controlled testing workflow.Experiments conducted on over 100 APIs demonstrate that our system effectivelyautomates vehicle API testing. The results also confirm that LLMs canefficiently handle mundane tasks requiring human judgment, making them suitablefor complete automation in similar industrial contexts.",Shuai Wang,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.AI']"
2502.04005v2,Quantifying Ionic Liquid Affinity and Its Effect on Phospholipid Membrane Structure and Dynamics,http://arxiv.org/abs/2502.04005v2,"In this study, we examine the impact of imidazolium based ILs on theviscoelasticity, dynamics, and phase behavior of two model membrane systems,(i) lipid monolayers and (ii) unilamellar vesicles composed ofdipalmitoylphosphatidylcholine (DPPC). Our findings demonstrate that both ILsinduce significant disorder in lipid membranes by altering the area per lipidmolecule, thereby modulating their viscoelastic properties. ILs with longeralkyl chains show stronger interactions with membranes, causing more pronounceddisorder. Fourier transform infrared spectroscopy indicates that ILincorporation shifts the membrane main phase transition to lower temperaturesand introduces gauche defects, signifying increased structural disorder. Thiseffect is amplified with longer alkyl chains and higher IL concentrations.Quasielastic neutron scattering studies highlight that ILs markedly enhance thelateral diffusion of lipids within the membrane leaflet, with the extent ofenhancement determined by the membrane physical state, IL concentration, andalkyl chain length. The most pronounced acceleration in lateral diffusionoccurs in ordered membrane phase with higher concentrations of the longer chainIL. Molecular dynamics simulations corroborate these experimental findings,showing that longer chain ILs extensively disrupt lipid organization, introducemore gauche defects, increase the area per lipid, and consequently enhancelateral diffusion. This increase in lipid fluidity and permeability provides amechanistic basis for the observed higher toxicity associated with longer chainILs.",V. K. Sharma,2025-02-06,2025-02-07,,N/A,['cond-mat.soft']
2502.04003v1,Performance Analysis of BEM-based Channel Estimation for OTFS with Hardware Impairments,http://arxiv.org/abs/2502.04003v1,"This letter studies the low-complexity channel estimation for orthogonal timefrequency space (OTFS) in the presence of hardware impairments. Firstly, totackle the computational complexity of channel estimation, the basis expansionmodel (BEM) is utilized. Then, the mean square error (MSE) of the estimatedchannel is theoretically derived, revealing the effects of hardware impairmentson channel estimation. Based on the estimated channel, the minimum mean squareerror (MMSE) detector is adopted to analyze the impacts of imperfect hardwareon the bit error rate (BER). Finally, the numerical results validate thecorrectness of our theoretical analysis of the MSE for channel estimation andlower bound of the BER, and also demonstrate that even minor hardwareimpairments can significantly degrade the performance of the OTFS system.",Haowei Wu,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.04002v1,Nonextensive entropic behavior observed in Quasar 3C 273,http://arxiv.org/abs/2502.04002v1,"We investigate the flux intensities spanning from radio waves to X-raysacross 39 light curves of Quasar 3C 273, utilizing publicly available datacollected by the Integral Science Data Centre (ISDC) database. Our resultssuggest that Quasar 3C 273 exhibits nonextensive behavior. Furthermore, wecalculate the $q$ entropic indices for these light curves using the$q$-Gaussian distribution with a predominant observation of cases where $q>1$.Based on this index, we estimate the non-extensive entropy ($S_{q}$) andexplore its correlation with the energy (in eV). In this context, we identifytwo jump-like increases in entropy, particularly evident in the infrared (IR)and X-ray wavebands. The peak in the far-IR band, around 0.34 eV, results fromsynchrotron flares evolving from higher to lower energies and thermal radiationemitted by hot dust near the sublimation radius. However, the second entropicpeak in the hard X-ray range lacks statistical robustness due to limited dataor large measurement uncertainties.",C. V. da Silva,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03998v1,Online Learning of Counter Categories and Ratings in PvP Games,http://arxiv.org/abs/2502.03998v1,"In competitive games, strength ratings like Elo are widely used to quantifyplayer skill and support matchmaking by accounting for skill disparities betterthan simple win rate statistics. However, scalar ratings cannot handle complexintransitive relationships, such as counter strategies seen inRock-Paper-Scissors. To address this, recent work introduced Neural RatingTable and Neural Counter Table, which combine scalar ratings with discretecounter categories to model intransitivity. While effective, these methods relyon neural network training and cannot perform real-time updates. In this paper,we propose an online update algorithm that extends Elo principles toincorporate real-time learning of counter categories. Our method dynamicallyadjusts both ratings and counter relationships after each match, preserving theexplainability of scalar ratings while addressing intransitivity. Experimentson zero-sum competitive games demonstrate its practicality, particularly inscenarios without complex team compositions.",Chiu-Chou Lin,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.GT', 'cs.MA']"
2502.03997v1,CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing,http://arxiv.org/abs/2502.03997v1,"Computer Aided Design (CAD) is indispensable across various industries.\emph{Text-based CAD editing}, which automates the modification of CAD modelsbased on textual instructions, holds great potential but remains underexplored.Existing methods primarily focus on design variation generation or text-basedCAD generation, either lacking support for text-based control or neglectingexisting CAD models as constraints. We introduce \emph{CAD-Editor}, the firstframework for text-based CAD editing. To address the challenge of demandingtriplet data with accurate correspondence for training, we propose an automateddata synthesis pipeline. This pipeline utilizes design variation models togenerate pairs of original and edited CAD models and employs LargeVision-Language Models (LVLMs) to summarize their differences into editinginstructions. To tackle the composite nature of text-based CAD editing, wepropose a locate-then-infill framework that decomposes the task into twofocused sub-tasks: locating regions requiring modification and infilling theseregions with appropriate edits. Large Language Models (LLMs) serve as thebackbone for both sub-tasks, leveraging their capabilities in natural languageunderstanding and CAD knowledge. Experiments show that CAD-Editor achievessuperior performance both quantitatively and qualitatively.",Yu Yuan,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03995v1,Modeling fast X-ray variability around an accreting black hole,http://arxiv.org/abs/2502.03995v1,"X-ray inter-band time lags are observed during the outbursts of black holeX-ray binaries (BHXRBs). Timing analysis of fast variability in low Fourierfrequency bands shows that high-energy photons lag behind low-energy photons, aphenomenon referred to as hard lag. Conversely, in high Fourier frequencybands, low-energy photons lag behind high-energy photons, known as soft lag.This frequency-dependent lag spectrum suggests that the lags arise fromdifferent physical processes. Notably, a trend has been observed wherein thelags shift towards shorter timescales during the rising hard state, indicatingan evolution in the inner accretion flow. In this study, we simulate theseinter-band lags by conducting Monte Carlo simulations of the rapid variabilitywithin the geometry of a jet base corona. We consider both inward propagatingaccretion rate fluctuations and reverberation (light crossing) delays in oursimulations. We successfully reproduce both low-frequency hard lags andhigh-frequency soft lags in a self-consistent manner. We replicate the observedevolution of the frequency-dependent lag spectra by varying the geometricalscale of the corona and the viscous frequency of the disc. Finally, we discussthe potential of a spherical corona and emphasize that polarizationobservations from the Imaging X-ray Polarimetry Explorer (IXPE) and theenhanced X-ray Timing and Polarimetry mission (eXTP) will be crucial fordistinguishing the corona's geometry in future studies.",Yejing Zhan,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03992v1,"Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering",http://arxiv.org/abs/2502.03992v1,"Most existing Knowledge Graph Question Answering (KGQA) approaches aredesigned for a specific KG, such as Wikidata, DBpedia or Freebase. Due to theheterogeneity of the underlying graph schema, topology and assertions, mostKGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) withoutresource-intensive training data. We present OntoSCPrompt, a novel LargeLanguage Model (LLM)-based KGQA approach with a two-stage architecture thatseparates semantic parsing from KG-dependent interactions. OntoSCPrompt firstgenerates a SPARQL query structure (including SPARQL keywords such as SELECT,ASK, WHERE and placeholders for missing tokens) and then fills them withKG-specific information. To enhance the understanding of the underlying KG, wepresent an ontology-guided, hybrid prompt learning strategy that integrates KGontology into the learning process of hybrid prompts (e.g., discrete andcontinuous vectors). We also present several task-specific decoding strategiesto ensure the correctness and executability of generated SPARQL queries in bothstages. Experimental results demonstrate that OntoSCPrompt performs as well asSOTA approaches without retraining on a number of KGQA datasets such as CWQ,WebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize wellto unseen domain-specific KGs like DBLP-QuAD and CoyPu KG Code:\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}",Longquan Jiang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03991v1,Simulation of the thermocapillary assembly of a colloidal cluster during the evaporation of a liquid film in an unevenly heated cell,http://arxiv.org/abs/2502.03991v1,"The control of the thermocapillary assembly of colloidal particle clusters isimportant for a variety of applications, including the creation of photoniccrystals for microelectronics and optoelectronics, membrane formation forbiotechnology, and surface cleaning for laboratory-on-chip devices. It isimportant to understand the main mechanisms that influence the formation ofsuch clusters. This article considers a two-dimensional mathematical modeldescribing the transfer of particles by a thermocapillary flow in an unevenlyheated cell during the evaporation of a liquid. This gave us the opportunity tostudy one of the main processes that triggers the formation of a particlecluster. Whether the particle will move with the flow or stop at the heater,becoming the basis for the cluster, is determined by the ratio between gravityand the drag force. The results of numerical calculations show that, for smallparticle concentrations, their fraction entering the cluster decreases as thevolumetric heat flux density $Q$ increases. The reason for this is an increasein the thermocapillary flow with an increase in the volumetric heat flux $Q$.It reduces the probability of particles entering the cluster.",Kristina N. Kondrashova,2025-02-06,2025-02-06,,N/A,"['cond-mat.soft', 'physics.flu-dyn']"
2502.03989v1,Radii of light nuclei from the Jacobi No-Core Shell Model,http://arxiv.org/abs/2502.03989v1,"Accurately determining the size of the atomic nucleus with realistic nuclearforces is a long outstanding issue of nuclear physics. The no-core shell model(NCSM), one of the powerful ab initio methods for nuclear structure, canachieve accurate energies of light nuclei. The extraction of converged radii ismore difficult. In this work, we present a novel method to effectively extractthe radius of light nuclei by restoring the long-range behavior of densitiesfrom NCSM calculations. The correct large distance asymptotic of two-bodyrelative densities are deduced based on the NCSM densities in limited basissize. The resulting radii using the corrected densities show a niceconvergence. The root-mean-square matter and charge radii of $^{4,6,8}$He and$^{6,7,8}$Li can be accurately obtained based on Jacobi-NCSM calculations withthe high-precision chiral two-nucleon and three-nucleon forces combined withthis new method. Our method can be straightforwardly extended to other abinitio calculations, potentially providing a better description of nuclearsizes with realistic nuclear forces.",Xiang-Xiang Sun,2025-02-06,2025-02-06,,N/A,['nucl-th']
2502.03988v1,Tight Bounds on Jensen's Gap: Novel Approach with Applications in Generative Modeling,http://arxiv.org/abs/2502.03988v1,"Among various mathematical tools of particular interest are those thatprovide a common basis for researchers in different scientific fields. One ofthem is Jensen's inequality, which states that the expectation of a convexfunction is greater than or equal to the function evaluated at the expectation.The resulting difference, known as Jensen's gap, became the subject ofinvestigation by both the statistical and machine learning communities. Amongmany related topics, finding lower and upper bounds on Jensen's gap (underdifferent assumptions on the underlying function and distribution) has recentlybecome a problem of particular interest. In our paper, we take another step inthis direction by providing a novel general and mathematically rigoroustechnique, motivated by the recent results of Struski et al. (2023). Inaddition, by studying in detail the case of the logarithmic function and thelog-normal distribution, we explore a method for tightly estimating thelog-likelihood of generative models trained on real-world datasets.Furthermore, we present both analytical and experimental arguments in supportof the superiority of our approach in comparison to existing state-of-the-artsolutions, contingent upon fulfillment of the criteria set forth by theoreticalstudies and corresponding experiments on synthetic data.",Marcin Mazur,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03987v1,"Deep Learning-Optimized, Fabrication Error-Tolerant Photonic Crystal Nanobeam Cavities for Scalable On-Chip Diamond Quantum Systems",http://arxiv.org/abs/2502.03987v1,"Cavity-enhanced diamond color center qubits can be initialized, manipulated,entangled, and read individually with high fidelity, which makes them ideal forlarge-scale, modular quantum computers, quantum networks, and distributedquantum sensing systems. However, diamond's unique material properties posesignificant challenges in manufacturing nanophotonic devices, leading tofabrication-induced structural imperfections and inaccuracies in defectimplantation, which hinder reproducibility, degrade optical properties andcompromise the spatial coupling of color centers to small mode-volume cavities.A cavity design tolerant to fabrication imperfections, such as surfaceroughness, sidewall slant, and non-optimal emitter positioning, can improvecoupling efficiency while simplifying fabrication. To address this challenge, adeep learning-based optimization methodology is developed to enhance thefabrication error tolerance of nanophotonic devices. Convolutional neuralnetworks (CNNs) are applied to promising designs, such as L2 and fishbonenanobeam cavities, predicting Q-factors up to one million times faster thantraditional finite-difference time-domain (FDTD) simulations, enablingefficient optimization of complex, high-dimensional parameter spaces. The CNNsachieve prediction errors below 3.99% and correlation coefficients up to 0.988.Optimized structures demonstrate a 52% reduction in Q-factor degradation,achieving quality factors of 5e4 under real-world conditions and a two-foldexpansion in field distribution, enabling efficient coupling of non-optimallypositioned emitters. This methodology enables scalable, high-yieldmanufacturing of robust nanophotonic devices, including the cavity-enhanceddiamond quantum systems developed in this study.",Sander van Haagen,2025-02-06,2025-02-06,,N/A,"['physics.optics', 'physics.app-ph', 'quant-ph']"
2502.03984v1,PGB: One-Shot Pruning for BERT via Weight Grouping and Permutation,http://arxiv.org/abs/2502.03984v1,"Large pretrained language models such as BERT suffer from slow inference andhigh memory usage, due to their huge size. Recent approaches to compressingBERT rely on iterative pruning and knowledge distillation, which, however, areoften too complicated and computationally intensive. This paper proposes anovel semi-structured one-shot pruning method for BERT, called$\textit{Permutation and Grouping for BERT}$ (PGB), which achieves highcompression efficiency and sparsity while preserving accuracy. To this end, PGBidentifies important groups of individual weights by permutation and prunes allother weights as a structure in both multi-head attention and feed-forwardlayers. Furthermore, if no important group is formed in a particular layer, PGBdrops the entire layer to produce an even more compact model. Our experimentalresults on BERT$_{\text{BASE}}$ demonstrate that PGB outperforms thestate-of-the-art structured pruning methods in terms of computational cost andaccuracy preservation.",Hyemin Lim,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04411v1,Mediator: Memory-efficient LLM Merging with Less Parameter Conflicts and Uncertainty Based Routing,http://arxiv.org/abs/2502.04411v1,"Model merging aggregates Large Language Models (LLMs) finetuned on differenttasks into a stronger one. However, parameter conflicts between models leads toperformance degradation in averaging. While model routing addresses this issueby selecting individual models during inference, it imposes excessive storageand compute costs, and fails to leverage the common knowledge from differentmodels. In this work, we observe that different layers exhibit varying levelsof parameter conflicts. Building on this insight, we average layers withminimal parameter conflicts and use a novel task-level expert routing forlayers with significant conflicts. To further reduce storage costs, inspired bytask arithmetic sparsity, we decouple multiple fine-tuned experts into a denseexpert and several sparse experts. Considering the out-of-distribution samples,we select and merge appropriate experts based on the task uncertainty of theinput data. We conduct extensive experiments on both LLaMA and Qwen withvarying parameter scales, and evaluate on real-world reasoning tasks. Resultsdemonstrate that our method consistently achieves significant performanceimprovements while requiring less system cost compared to existing methods.",Kunfeng Lai,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL', '68T50']"
2502.03982v1,Temporal Distribution Shift in Real-World Pharmaceutical Data: Implications for Uncertainty Quantification in QSAR Models,http://arxiv.org/abs/2502.03982v1,"The estimation of uncertainties associated with predictions from quantitativestructure-activity relationship (QSAR) models can accelerate the drug discoveryprocess by identifying promising experiments and allowing an efficientallocation of resources. Several computational tools exist that estimate thepredictive uncertainty in machine learning models. However, deviations from thei.i.d. setting have been shown to impair the performance of these uncertaintyquantification methods. We use a real-world pharmaceutical dataset to addressthe pressing need for a comprehensive, large-scale evaluation of uncertaintyestimation methods in the context of realistic distribution shifts over time.We investigate the performance of several uncertainty estimation methods,including ensemble-based and Bayesian approaches. Furthermore, we use thisreal-world setting to systematically assess the distribution shifts in labeland descriptor space and their impact on the capability of the uncertaintyestimation methods. Our study reveals significant shifts over time in bothlabel and descriptor space and a clear connection between the magnitude of theshift and the nature of the assay. Moreover, we show that pronounceddistribution shifts impair the performance of popular uncertainty estimationmethods used in QSAR models. This work highlights the challenges of identifyinguncertainty quantification methods that remain reliable under distributionshifts introduced by real-world data.",Hannah Rosa Friesacher,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.04410v1,Magnetic levitation at low rotation frequencies using an on-axis magnetic field,http://arxiv.org/abs/2502.04410v1,"Magnetic levitation by rotation is a simply yet astonishing phenomenon wherea permanent magnet can be levitated by placing it in the vicinity of anotherpermanent magnet that rotates sufficiently fast. The few previous works on thisnovel type of magnetic levitation all required magnets rotating on the order of200 Hz. Here we investigate the influence of applying an on-axis, staticmagnetic field and show that this can lower the needed rotation frequency tobelow 50 Hz. We explain this by a detailed analysis of the force producinglevitation, which is a superposition of a repelling force caused by theoff-axis (rotating) magnetic field and an attractive force due to the on-axisfield. We study this force and resulting levitation experimentally,analytically and numerically for three different rotor magnet configurations,showing that the levitation distance and frequency range can be accuratelypredicted from both the numerical and analytical models.",Joachim Marco Hermansen,2025-02-06,2025-02-06,,N/A,['physics.class-ph']
2502.03979v1,Towards Unified Music Emotion Recognition across Dimensional and Categorical Models,http://arxiv.org/abs/2502.03979v1,"One of the most significant challenges in Music Emotion Recognition (MER)comes from the fact that emotion labels can be heterogeneous across datasetswith regard to the emotion representation, including categorical (e.g., happy,sad) versus dimensional labels (e.g., valence-arousal). In this paper, wepresent a unified multitask learning framework that combines these two types oflabels and is thus able to be trained on multiple datasets. This framework usesan effective input representation that combines musical features (i.e., key andchords) and MERT embeddings. Moreover, knowledge distillation is employed totransfer the knowledge of teacher models trained on individual datasets to astudent model, enhancing its ability to generalize across multiple tasks. Tovalidate our proposed framework, we conducted extensive experiments on avariety of datasets, including MTG-Jamendo, DEAM, PMEmo, and EmoMusic.According to our experimental results, the inclusion of musical features,multitask learning, and knowledge distillation significantly enhancesperformance. In particular, our model outperforms the state-of-the-art models,including the best-performing model from the MediaEval 2021 competition on theMTG-Jamendo dataset. Our work makes a significant contribution to MER byallowing the combination of categorical and dimensional emotion labels in oneunified framework, thus enabling training across datasets.",Jaeyong Kang,2025-02-06,2025-02-06,,N/A,"['cs.SD', 'cs.AI', 'eess.AS']"
2502.03977v1,Performance Analysis of Digital Flux-locked Loop Circuit with Different SQUID $V$-$φ$ Transfer Curves for TES Readout System,http://arxiv.org/abs/2502.03977v1,"A superconducting quantum interference device (SQUID), functioning as anonlinear response device, typically requires the incorporation of aflux-locked loop (FLL) circuit to facilitate linear amplification of thecurrent signal transmitted through a superconducting transition-edge sensor(TES) across a large dynamic range. This work presents a reasonable model ofthe SQUID-FLL readout system, based on a digitalproportional-integral-differential (PID) flux negative feedback algorithm. Thiswork investigates the effect of $V$-$\phi$ shape on the performance of digitalFLL circuits. Such as the impact factors of bandwidth, design limits of slewrate of the system and the influence of the shapes of SQUID $V$-$\phi$ curve.Furthermore, the dynamic response of the system to X-ray pulse signals withrise time ranging from $4.4{\sim}281$ $\mathrm{{\mu}s}$ and amplitudes rangingfrom $6{\sim}8$ $\mathrm{\phi_0}$ was simulated. All the simulation resultswere found to be consistent with the existing mature theories, therebyvalidating the accuracy of the model. The results also provide a reliablemodelling reference for the design of digital PID flux negative feedback andmultiplexing SQUID readout electronic systems.",Nan Li,2025-02-06,2025-02-06,,N/A,['astro-ph.IM']
2502.03976v1,Small Signal Stability Analysis of Kurdistan Regional Power System,http://arxiv.org/abs/2502.03976v1,"This paper presents for the first time a mathematical model for evaluatingthe Planned Kurdistan Regional Power System (KRPS) for its ability to maintainstability under small disturbances and fluctuations during normal operatingconditions. To achieve this objective, practical field data, manufacture'sdatasheets, related IEEE task force reports have been used to build a completemathematical model in MATLAB/SIMULINK/SimPowerSystem environment. New moduleshave been established and added to the platform wherever it does not supportspecial type of elements. The model represents accurately all the power systemcomponents involved in physical phenomena of system dynamic oscillations. Themodel consists of 53 transmission lines, 35 nodes and 6 generating stations.The system is simulated under different configurations and settings; thedynamic behaviors associated with each configuration are recorded and analyzedaccordingly.",Ibrahim Ismael Hamarash,2025-02-06,2025-02-06,,N/A,"['eess.SY', 'cs.SY']"
2502.03971v1,RWKV-UI: UI Understanding with Enhanced Perception and Reasoning,http://arxiv.org/abs/2502.03971v1,"Existing Visual Language Modelsoften struggle with information loss andlimited reasoning abilities when handling high-resolution web interfaces thatcombine complex visual, textual, and interactive elements. These challenges areparticularly evident in tasks requiring webpage layout comprehension andmulti-step interactive reasoning. To address these challenges, we proposeRWKV-UI, a Visual Language Model based on the RWKV architecture, specificallydesigned to handle high-resolution UI images. During model training, weintroduce layout detection as a visual prompt to help the model betterunderstand the webpage layout structures. Additionally, we design a visualprompt based on the Chain-of-Thought(CoT) mechanism, which enhances the model'sability to understand and reason about webpage content through reasoningchains. Experimental results show that RWKV-UI demonstrates significantperformance improvements in high-resolution UI understanding and interactivereasoning tasks.",Jiaxi Yang,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.HC']"
2502.03966v1,MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation,http://arxiv.org/abs/2502.03966v1,"In this paper, we present synthetic data generation framework for floodhazard detection system. For high fidelity and quality, we characterize severalreal-world properties into virtual world and simulate the flood situation bycontrolling them. For the sake of efficiency, recent generative models inimage-to-3D and urban city synthesis are leveraged to easily composite floodenvironments so that we avoid data bias due to the hand-crafted manner. Basedon our framework, we build the flood synthetic dataset with 5 levels, dubbedMultiFloodSynth which contains rich annotation types like normal map,segmentation, 3D bounding box for a variety of downstream task. In experiments,our dataset demonstrate the enhanced performance of flood hazard detection withon-par realism compared with real dataset.",YoonJe Kang,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.03965v1,Innovative Framework for Early Estimation of Mental Disorder Scores to Enable Timely Interventions,http://arxiv.org/abs/2502.03965v1,"Individual's general well-being is greatly impacted by mental healthconditions including depression and Post-Traumatic Stress Disorder (PTSD),underscoring the importance of early detection and precise diagnosis in orderto facilitate prompt clinical intervention. An advanced multimodal deeplearning system for the automated classification of PTSD and depression ispresented in this paper. Utilizing textual and audio data from clinicalinterview datasets, the method combines features taken from both modalities bycombining the architectures of LSTM (Long Short Term Memory) and BiLSTM(Bidirectional Long Short-Term Memory).Although text features focus on speech'ssemantic and grammatical components; audio features capture vocal traitsincluding rhythm, tone, and pitch. This combination of modalities enhances themodel's capacity to identify minute patterns connected to mental healthconditions. Using test datasets, the proposed method achieves classificationaccuracies of 92% for depression and 93% for PTSD, outperforming traditionalunimodal approaches and demonstrating its accuracy and robustness.",Himanshi Singh,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03964v1,"""It Warned Me Just at the Right Moment"": Exploring LLM-based Real-time Detection of Phone Scams",http://arxiv.org/abs/2502.03964v1,"Despite living in the era of the internet, phone-based scams remain one ofthe most prevalent forms of scams. These scams aim to exploit victims forfinancial gain, causing both monetary losses and psychological distress. Whilegovernments, industries, and academia have actively introduced variouscountermeasures, scammers also continue to evolve their tactics, making phonescams a persistent threat. To combat these increasingly sophisticated scams,detection technologies must also advance. In this work, we propose a frameworkfor modeling scam calls and introduce an LLM-based real-time detectionapproach, which assesses fraudulent intent in conversations, further providingimmediate warnings to users to mitigate harm. Through experiments, we evaluatethe method's performance and analyze key factors influencing its effectiveness.This analysis enables us to refine the method to improve precision whileexploring the trade-off between recall and timeliness, paving the way forfuture directions in this critical area of research.",Zitong Shen,2025-02-06,2025-02-06,,N/A,"['cs.HC', 'cs.CR', 'H.5']"
2502.03963v1,AL-PINN: Active Learning-Driven Physics-Informed Neural Networks for Efficient Sample Selection in Solving Partial Differential Equations,http://arxiv.org/abs/2502.03963v1,"Physics-Informed Neural Networks (PINNs) have emerged as a promising approachfor solving Partial Differential Equations (PDEs) by incorporating physicalconstraints into deep learning models. However, standard PINNs often require alarge number of training samples to achieve high accuracy, leading to increasedcomputational costs. To address this issue, we propose Active Learning-DrivenPINNs (AL-PINN), which integrates Uncertainty Quantification (UQ) and ActiveLearning (AL) strategies to optimize sample selection dynamically.  AL-PINN utilizes Monte Carlo Dropout to estimate epistemic uncertainty in themodel predictions, enabling the adaptive selection of high-uncertainty regionsfor additional training. This approach significantly enhances learningefficiency by focusing computational resources on the most informative datapoints. We evaluate AL-PINN on benchmark PDE problems with known analyticalsolutions and real-world WeatherBench climate data. Our results demonstratethat AL-PINN achieves comparable or superior accuracy compared to traditionalPINNs while reducing the number of required training samples.  The proposed framework is particularly beneficial for scientific andengineering applications where data collection is expensive or limited, such asclimate modeling, medical simulations, and material science. Our findingshighlight the potential of active learning in accelerating PINN-based PDEsolvers while maintaining high accuracy and computational efficiency.",Keon Vin Park,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03960v1,Bilevel Multi-Armed Bandit-Based Hierarchical Reinforcement Learning for Interaction-Aware Self-Driving at Unsignalized Intersections,http://arxiv.org/abs/2502.03960v1,"In this work, we present BiM-ACPPO, a bilevel multi-armed bandit-basedhierarchical reinforcement learning framework for interaction-awaredecision-making and planning at unsignalized intersections. Essentially, itproactively takes the uncertainties associated with surrounding vehicles (SVs)into consideration, which encompass those stemming from the driver's intention,interactive behaviors, and the varying number of SVs. Intermediate decisionvariables are introduced to enable the high-level RL policy to provide aninteraction-aware reference, for guiding low-level model predictive control(MPC) and further enhancing the generalization ability of the proposedframework. By leveraging the structured nature of self-driving at unsignalizedintersections, the training problem of the RL policy is modeled as a bilevelcurriculum learning task, which is addressed by the proposed Exp3.S-based BiMABalgorithm. It is noteworthy that the training curricula are dynamicallyadjusted, thereby facilitating the sample efficiency of the RL trainingprocess. Comparative experiments are conducted in the high-fidelity CARLAsimulator, and the results indicate that our approach achieves superiorperformance compared to all baseline methods. Furthermore, experimental resultsin two new urban driving scenarios clearly demonstrate the commendablegeneralization performance of the proposed method.",Zengqi Peng,2025-02-06,2025-02-06,,N/A,['cs.RO']
2502.03959v1,Phase diagram of the hard-sphere potential model in three and four dimensions using a pseudo-hard-sphere potential,http://arxiv.org/abs/2502.03959v1,"The hard-sphere potential has become a cornerstone in the study of bothmolecular and complex fluids. Despite its mathematical simplicity, itsimplementation in fixed time-step molecular simulations remains a formidablechallenge due to the discontinuity at contact. To circumvent the issuesassociated with the ill-defined force at contact, a continuouspotential--referred to here as the pseudo-hard-sphere (pHS) potential--hasrecently been proposed [J. Chem, Phys. 149, 164907 (2018)]. This potential isconstructed to match the second virial coefficient of the hard-sphere potentialand is expected to mimic its thermodynamic properties. However, this hypothesishas only been partially validated within the fluid region of the phase diagramfor hard-sphere dispersions in two and three dimensions. In this contribution,we examine the ability of the continuous pHS potential to reproduce theequation of state of a hard-sphere fluid, not only in the fluid phase but alsoacross the fluid-solid coexistence region. Our focus is primarily onhard-sphere systems in three and four dimensions. We compare the resultsobtained from Brownian dynamics simulations of the pHS potential with thosederived from refined event-driven simulations of the corresponding hard-spherepotential. Furthermore, we provide a comparative analysis with theoreticalequations of state based on both mean-field and integral equationapproximations.",Edwin A. Bedolla-Montiel,2025-02-06,2025-02-06,,N/A,['cond-mat.soft']
2502.03957v1,Improving the Perturbation-Based Explanation of Deepfake Detectors Through the Use of Adversarially-Generated Samples,http://arxiv.org/abs/2502.03957v1,"In this paper, we introduce the idea of using adversarially-generated samplesof the input images that were classified as deepfakes by a detector, to formperturbation masks for inferring the importance of different input features andproduce visual explanations. We generate these samples based on NaturalEvolution Strategies, aiming to flip the original deepfake detector's decisionand classify these samples as real. We apply this idea to fourperturbation-based explanation methods (LIME, SHAP, SOBOL and RISE) andevaluate the performance of the resulting modified methods using a SOTAdeepfake detection model, a benchmarking dataset (FaceForensics++) and acorresponding explanation evaluation framework. Our quantitative assessmentsdocument the mostly positive contribution of the proposed perturbation approachin the performance of explanation methods. Our qualitative analysis shows thecapacity of the modified explanation methods to demarcate the manipulated imageregions more accurately, and thus to provide more useful explanations.",Konstantinos Tsigos,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.CR']"
2502.03956v1,POPACheck: a Model Checker for probabilistic Pushdown Automata,http://arxiv.org/abs/2502.03956v1,"We present POPACheck, the first full-fledged model checking tool for pPDA.POPACheck provides a user-friendly probabilistic modeling language withrecursion that automatically translates into pOPA. pOPA are a class of pPDAthat can express all the behaviors of probabilistic programs. On pOPA,POPACheck can solve reachability queries as well as qualitative andquantitative model checking queries for specifications in LTL and a fragment ofPOTL, a logic for context-free properties such as pre/post-conditioning.",Francesco Pontiggia,2025-02-06,2025-02-06,,N/A,['cs.LO']
2502.03955v1,On the extension of analytic solutions of first-order difference equations,http://arxiv.org/abs/2502.03955v1,"We will consider first-order difference equations of the form \[ y(z+1) =\frac{\lambda y(z)+a_2(z)y(z)^2+\cdots+a_p(z)y(z)^p}{1 +b_1(z)y(z)+\cdots+b_q(z)y(z)^q}, \]  where $\lambda\in\mathbb{C}\setminus\{0\}$ and the coefficients $a_j(z)$ and$b_k(z)$ are meromorphic.  When existence of an analytic solution can be proved for large negativevalues of $\Re(z)$, the equation determines a unique extension to a globalmeromorphic solution. In this paper we prove the existence of non-constantmeromorphic solutions when the coefficients satisfy $|a_{j}(z)|\leq \nu^{|z|}$and $|b_{k}(z)|\leq \nu^{|z|}$ for some $\nu<|\lambda|$ in a half-plane.Furthermore, when a solution exists that is analytic for large positive valuesof $\Re(z)$, the equation determines a unique extension to a global solutionthat will generically have algebraic branch points. We analyse a particularconstant coefficient equation, $y(z+1)=\lambda y(z)+y(z)^2$, $0<\lambda<1$, anddescribe in detail the infinitely-sheeted Riemann surface for such a solution.We also describe solutions with natural boundaries found by Mahler.",Rod Halburd,2025-02-06,2025-02-06,,N/A,"['math.CV', '30D05']"
2502.03954v1,MAQInstruct: Instruction-based Unified Event Relation Extraction,http://arxiv.org/abs/2502.03954v1,"Extracting event relations that deviate from known schemas has provenchallenging for previous methods based on multi-class classification, MASKprediction, or prototype matching. Recent advancements in large language modelshave shown impressive performance through instruction tuning. Nevertheless, inthe task of event relation extraction, instruction-based methods face severalchallenges: there are a vast number of inference samples, and the relationsbetween events are non-sequential. To tackle these challenges, we present animproved instruction-based event relation extraction framework namedMAQInstruct. Firstly, we transform the task from extracting event relationsusing given event-event instructions to selecting events using givenevent-relation instructions, which reduces the number of samples required forinference. Then, by incorporating a bipartite matching loss, we reduce thedependency of the instruction-based method on the generation sequence. Ourexperimental results demonstrate that MAQInstruct significantly improves theperformance of event relation extraction across multiple LLMs.",Jun Xu,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03952v1,Bridging the inference gap in Mutimodal Variational Autoencoders,http://arxiv.org/abs/2502.03952v1,"From medical diagnosis to autonomous vehicles, critical applications rely onthe integration of multiple heterogeneous data modalities. MultimodalVariational Autoencoders offer versatile and scalable methods for generatingunobserved modalities from observed ones. Recent models usingmixturesof-experts aggregation suffer from theoretically grounded limitationsthat restrict their generation quality on complex datasets. In this article, wepropose a novel interpretable model able to learn both joint and conditionaldistributions without introducing mixture aggregation. Our model follows amultistage training process: first modeling the joint distribution withvariational inference and then modeling the conditional distributions withNormalizing Flows to better approximate true posteriors. Importantly, we alsopropose to extract and leverage the information shared between modalities toimprove the conditional coherence of generated samples. Our method achievesstate-of-the-art results on several benchmark datasets.",Agathe Senellart,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'stat.ML']"
2502.03950v2,LR0.FM: Low-Resolution Zero-shot Classification Benchmark For Foundation Models,http://arxiv.org/abs/2502.03950v2,"Visual-language foundation Models (FMs) exhibit remarkable zero-shotgeneralization across diverse tasks, largely attributed to extensivepre-training on largescale datasets. However, their robustness onlow-resolution/pixelated (LR) images, a common challenge in real-worldscenarios, remains underexplored. We introduce LR0.FM, a comprehensivebenchmark evaluating the impact of low resolution on the zero-shotclassification performance of 10 FM(s) across 66 backbones and 15 datasets. Wepropose a novel metric, Weighted Aggregated Robustness, to address thelimitations of existing metrics and better evaluate model performance acrossresolutions and datasets. Our key findings show that: (i) model size positivelycorrelates with robustness to resolution degradation, (ii) pre-training datasetquality is more important than its size, and (iii) fine-tuned and higherresolution models are less robust against LR. Our analysis further reveals thatthe model makes semantically reasonable predictions at LR, and the lack offine-grained details in input adversely impacts the model's initial layers morethan the deeper layers. We use these insights and introduce a simple strategy,LR-TK0, to enhance the robustness of models without compromising theirpre-trained weights. We demonstrate the effectiveness of LR-TK0 for robustnessagainst low-resolution across several datasets and its generalizationcapability across backbones and other approaches. Code is available athttps://github.com/shyammarjit/LR0.FM",Priyank Pathak,2025-02-06,2025-02-07,,N/A,['cs.CV']
2502.03948v1,Enhancing Online Learning Efficiency Through Heterogeneous Resource Integration with a Multi-Agent RAG System,http://arxiv.org/abs/2502.03948v1,"Efficient online learning requires seamless access to diverse resources suchas videos, code repositories, documentation, and general web content. Thisposter paper introduces early-stage work on a Multi-Agent Retrieval-AugmentedGeneration (RAG) System designed to enhance learning efficiency by integratingthese heterogeneous resources. Using specialized agents tailored for specificresource types (e.g., YouTube tutorials, GitHub repositories, documentationwebsites, and search engines), the system automates the retrieval and synthesisof relevant information. By streamlining the process of finding and combiningknowledge, this approach reduces manual effort and enhances the learningexperience. A preliminary user study confirmed the system's strong usabilityand moderate-high utility, demonstrating its potential to improve theefficiency of knowledge acquisition.",Devansh Srivastav,2025-02-06,2025-02-06,,N/A,"['cs.AI', 'cs.CL', 'cs.MA']"
2502.03946v1,CleanSurvival: Automated data preprocessing for time-to-event models using reinforcement learning,http://arxiv.org/abs/2502.03946v1,"Data preprocessing is a critical yet frequently neglected aspect of machinelearning, often paid little attention despite its potentially significantimpact on model performance. While automated machine learning pipelines arestarting to recognize and integrate data preprocessing into their solutions forclassification and regression tasks, this integration is lacking for morespecialized tasks like survival or time-to-event models. As a result, survivalanalysis not only faces the general challenges of data preprocessing but alsosuffers from the lack of tailored, automated solutions in this area.  To address this gap, this paper presents 'CleanSurvival', areinforcement-learning-based solution for optimizing preprocessing pipelines,extended specifically for survival analysis. The framework can handlecontinuous and categorical variables, using Q-learning to select whichcombination of data imputation, outlier detection and feature extractiontechniques achieves optimal performance for a Cox, random forest, neuralnetwork or user-supplied time-to-event model. The package is available onGitHub: https://github.com/datasciapps/CleanSurvival  Experimental benchmarks on real-world datasets show that the Q-learning-baseddata preprocessing results in superior predictive performance to standardapproaches, finding such a model up to 10 times faster than undirected randomgrid search. Furthermore, a simulation study demonstrates the effectiveness indifferent types and levels of missingness and noise in the data.",Yousef Koka,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03945v1,Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond,http://arxiv.org/abs/2502.03945v1,"Speech technologies are transforming interactions across various sectors,from healthcare to call centers and robots, yet their performance onAfrican-accented conversations remains underexplored. We introduceAfrispeech-Dialog, a benchmark dataset of 50 simulated medical and non-medicalAfrican-accented English conversations, designed to evaluate automatic speechrecognition (ASR) and related technologies. We assess state-of-the-art (SOTA)speaker diarization and ASR systems on long-form, accented speech, comparingtheir performance with native accents and discover a 10%+ performancedegradation. Additionally, we explore medical conversation summarizationcapabilities of large language models (LLMs) to demonstrate the impact of ASRerrors on downstream medical summaries, providing insights into the challengesand opportunities for speech technologies in the Global South. Our workhighlights the need for more inclusive datasets to advance conversational AI inlow-resource settings.",Mardhiyah Sanni,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03942v2,A retake on the analysis of scores truncated by terminal events,http://arxiv.org/abs/2502.03942v2,"Analysis of data from randomized controlled trials in vulnerable populationsrequires special attention when assessing treatment effect by a scoremeasuring, e.g., disease stage or activity together with onset of prevalentterminal events. In reality, it is impossible to disentangle a disease scorefrom the terminal event, since the score is not clinically meaningful afterthis event. In this work, we propose to assess treatment interventionssimultaneously on disease score and the terminal event. Our proposal is basedon a natural data-generating mechanism respecting that a disease score does notexist beyond the terminal event. We use modern semi-parametric statisticalmethods to provide robust and efficient estimation of the risk of terminalevent and expected disease score conditional on no terminal event at apre-specified landmark time. We also use the simultaneous asymptotic behaviorof our estimators to develop a powerful closed testing procedure forconfirmatory assessment of treatment effect on both onset of terminal event andlevel of disease score. A simulation study mimicking a large-scale outcometrial in chronic kidney patients as well as an analysis of that trial isprovided to assess performance.",Klaus Kähler Holst,2025-02-06,2025-02-07,,N/A,['stat.ME']
2502.03938v1,Unravelling Causal Genetic Biomarkers of Alzheimer's Disease via Neuron to Gene-token Backtracking in Neural Architecture: A Groundbreaking Reverse-Gene-Finder Approach,http://arxiv.org/abs/2502.03938v1,"Alzheimer's Disease (AD) affects over 55 million people globally, yet the keygenetic contributors remain poorly understood. Leveraging recent advancementsin genomic foundation models, we present the innovative Reverse-Gene-Findertechnology, a ground-breaking neuron-to-gene-token backtracking approach in aneural network architecture to elucidate the novel causal genetic biomarkersdriving AD onset. Reverse-Gene-Finder comprises three key innovations. Firstly,we exploit the observation that genes with the highest probability of causingAD, defined as the most causal genes (MCGs), must have the highest probabilityof activating those neurons with the highest probability of causing AD, definedas the most causal neurons (MCNs). Secondly, we utilize a gene tokenrepresentation at the input layer to allow each gene (known or novel to AD) tobe represented as a discrete and unique entity in the input space. Lastly, incontrast to the existing neural network architectures, which track neuronactivations from the input layer to the output layer in a feed-forward manner,we develop an innovative backtracking method to track backwards from the MCNsto the input layer, identifying the Most Causal Tokens (MCTs) and thecorresponding MCGs. Reverse-Gene-Finder is highly interpretable, generalizable,and adaptable, providing a promising avenue for application in other diseasescenarios.",Victor OK Li,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03937v1,Quantifying Correlations of Machine Learning Models,http://arxiv.org/abs/2502.03937v1,"Machine Learning models are being extensively used in safety criticalapplications where errors from these models could cause harm to the user. Suchrisks are amplified when multiple machine learning models, which are deployedconcurrently, interact and make errors simultaneously. This paper exploresthree scenarios where error correlations between multiple models arise,resulting in such aggregated risks. Using real-world data, we simulate thesescenarios and quantify the correlations in errors of different models. Ourfindings indicate that aggregated risks are substantial, particularly whenmodels share similar algorithms, training datasets, or foundational models.Overall, we observe that correlations across models are pervasive and likely tointensify with increased reliance on foundational models and widely used publicdatasets, highlighting the need for effective mitigation strategies to addressthese challenges.",Yuanyuan Li,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.NA', 'math.NA']"
2502.03936v1,ICGNN: Graph Neural Network Enabled Scalable Beamforming for MISO Interference Channels,http://arxiv.org/abs/2502.03936v1,"This paper investigates the graph neural network (GNN)-enabled beamformingdesign for interference channels. We propose a model termed interferencechannel GNN (ICGNN) to solve a quality-of-service constrained energy efficiencymaximization problem. The ICGNN is two-stage, where the direction and powerparts of beamforming vectors are learned separately but trained jointly viaunsupervised learning. By formulating the dimensionality of featuresindependent of the transceiver pairs, the ICGNN is scalable with the number oftransceiver pairs. Besides, to improve the performance of the ICGNN, the hybridmaximum ratio transmission and zero-forcing scheme reduces the output ports,the feature enhancement module unifies the two types of links into one type,the subgraph representation enhances the message passing efficiency, and themulti-head attention and residual connection facilitate the feature extracting.Furthermore, we present the over-the-air distributed implementation of theICGNN. Ablation studies validate the effectiveness of key components in theICGNN. Numerical results also demonstrate the capability of ICGNN in achievingnear-optimal performance with an average inference time less than 0.1 ms. Thescalability of ICGNN for unseen problem sizes is evaluated and enhanced bytransfer learning with limited fine-tuning cost. The results of the centralizedand distributed implementations of ICGNN are illustrated.",Changpeng He,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.03935v1,Thermal Model Calibration of a Squirrel-Cage Induction Machine,http://arxiv.org/abs/2502.03935v1,"Accurate and efficient thermal simulations of induction machines areindispensable for detecting thermal hot spots and hence avoiding potentialmaterial failure in an early design stage. A goal is the better utilization ofthe machines with reduced safety margins due to a better knowledge of thecritical conditions. In this work, the parameters of a two-dimensionalinduction machine model are calibrated according to evidence from measurements,by solving an inverse field problem. The set of parameters comprise materialparameters as well as parameters that model three-dimensional effects. Thisallows a consideration of physical effects without explicit knowledge of itsquantities. First, the accuracy of the approach is studied using an academicexample in combination with synthetic data. Afterwards, it is successfullyapplied to a realistic induction machine model.",Leon Blumrich,2025-02-06,2025-02-06,,N/A,['cs.CE']
2502.04409v1,Learning low-dimensional representations of ensemble forecast fields using autoencoder-based methods,http://arxiv.org/abs/2502.04409v1,"Large-scale numerical simulations often produce high-dimensional gridded datathat is challenging to process for downstream applications. A prime example isnumerical weather prediction, where atmospheric processes are modeled usingdiscrete gridded representations of the physical variables and dynamics.Uncertainties are assessed by running the simulations multiple times, yieldingensembles of simulated fields as a high-dimensional stochastic representationof the forecast distribution. The high-dimensionality and large volume ofensemble datasets poses major computing challenges for subsequent forecastingstages. Data-driven dimensionality reduction techniques could help to reducethe data volume before further processing by learning meaningful and compactrepresentations. However, existing dimensionality reduction methods aretypically designed for deterministic and single-valued inputs, and thus cannothandle ensemble data from multiple randomized simulations. In this study, wepropose novel dimensionality reduction approaches specifically tailored to theformat of ensemble forecast fields. We present two alternative frameworks,which yield low-dimensional representations of ensemble forecasts whilerespecting their probabilistic character. The first approach derives adistribution-based representation of an input ensemble by applying standarddimensionality reduction techniques in a member-by-member fashion and mergingthe member representations into a joint parametric distribution model. Thesecond approach achieves a similar representation by encoding all membersjointly using a tailored variational autoencoder. We evaluate and compare bothapproaches in a case study using 10 years of temperature and wind speedforecasts over Europe. The approaches preserve key spatial and statisticalcharacteristics of the ensemble and enable probabilistic reconstructions of theforecast fields.",Jieyu Chen,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'physics.ao-ph']"
2502.03933v1,HEP-JEPA: A foundation model for collider physics using joint embedding predictive architecture,http://arxiv.org/abs/2502.03933v1,We present a transformer architecture-based foundation model for tasks athigh-energy particle colliders such as the Large Hadron Collider. We train themodel to classify jets using a self-supervised strategy inspired by the JointEmbedding Predictive Architecture. We use the JetClass dataset containing 100Mjets of various known particles to pre-train the model with a data-centricapproach -- the model uses a fraction of the jet constituents as the context topredict the embeddings of the unseen target constituents. Our pre-trained modelfares well with other datasets for standard classification benchmark tasks. Wetest our model on two additional downstream tasks: top tagging anddifferentiating light-quark jets from gluon jets. We also evaluate our modelwith task-specific metrics and baselines and compare it with state-of-the-artmodels in high-energy physics. Project site: https://hep-jepa.github.io/,Jai Bardhan,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'hep-ex', 'hep-ph']"
2502.03932v1,Memory-induced current reversal of Brownian motors,http://arxiv.org/abs/2502.03932v1,"Kinetics of biological motors such as kinesin or dynein is notably influencedby viscoelastic intracellular environment. The characteristic relaxation timeof the cytosol is not separable from the colloidal timescale and thereforetheir dynamics is inherently non-Markovian. In this paper we consider a variantof a Brownian motor model, namely a Brownian ratchet immersed in a correlatedthermal bath and analyze how memory influences its dynamics. In particular, wedemonstrate the memory-induced current reversal effect and explain thisphenomenon by applying the effective mass approximation as well as uncoveringthe memory-induced dynamical localization of the motor trajectories in thephase space. Our results reveal new aspects of the role of memory inmicroscopic systems out of thermal equilibrium.",Mateusz Wiśniewski,2025-02-06,2025-02-06,,N/A,"['cond-mat.stat-mech', 'cond-mat.mes-hall', 'cond-mat.soft']"
2502.03930v1,DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation,http://arxiv.org/abs/2502.03930v1,"Several recent studies have attempted to autoregressively generate continuousspeech representations without discrete speech tokens by combining diffusionand autoregressive models, yet they often face challenges with excessivecomputational loads or suboptimal outcomes. In this work, we propose DiffusionTransformer Autoregressive Modeling (DiTAR), a patch-based autoregressiveframework combining a language model with a diffusion transformer. Thisapproach significantly enhances the efficacy of autoregressive models forcontinuous tokens and reduces computational demands. DiTAR utilizes adivide-and-conquer strategy for patch generation, where the language modelprocesses aggregated patch embeddings and the diffusion transformersubsequently generates the next patch based on the output of the languagemodel. For inference, we propose defining temperature as the time point ofintroducing noise during the reverse diffusion ODE to balance diversity anddeterminism. We also show in the extensive scaling analysis that DiTAR hassuperb scalability. In zero-shot speech generation, DiTAR achievesstate-of-the-art performance in robustness, speaker similarity, andnaturalness.",Dongya Jia,2025-02-06,2025-02-06,,N/A,"['eess.AS', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.SD']"
2502.03929v1,pyEFPE: An improved post-Newtonian waveform model for inspiralling precessing-eccentric compact binaries,http://arxiv.org/abs/2502.03929v1,"The measurement of spin-precession and orbital eccentricity ingravitational-wave (GW) signals is a key priority in GW astronomy, as theseeffects not only provide insights into the astrophysical formation andevolution of compact binaries but also, if neglected, could introducesignificant biases in parameter estimation, searches, and tests of GeneralRelativity. Despite the growing potential of upcoming LIGO-Virgo-KAGRAobserving runs and future detectors to measure eccentric-precessing signals,accurately and efficiently modeling them remains a challenge. In this work, wepresent pyEFPE, a frequency-domain post-Newtonian (PN) waveform model for theinspiral of precessing-eccentric compact binaries. pyEFPE improves uponprevious models by introducing analytical expressions for the Fourier modeamplitudes, enhancing the numerical stability of the multiple scale analysisframework, and adding recently derived PN corrections, critical to accuratelydescribe signals in GW detectors. Additionally, we simplify the numericalimplementation and introduce a scheme to interpolate the amplitudes, achievinga speedup of up to ~O(20) in the waveform computations, making the modelpractical for data analysis applications. We thoroughly validate pyEFPE bycomparing it to other waveform models in the quasi-circular andeccentric-spin-aligned limits, finding good agreement. Additionally, wedemonstrate pyEFPE's capability to analyze simulated GW events, accuratelyrecovering the parameters of signals described by both pyEFPE and IMRPhenomXP.While pyEFPE still lacks important physical effects, such as higher-order PNcorrections, higher-order modes, mode asymmetries, tidal interactions or themerger-ringdown phase, it represents a significant step towards more completewaveform models, offering a flexible and efficient framework that can beextended in future work to incorporate these effects.",Gonzalo Morras,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.HE', 'astro-ph.IM']"
2502.03928v1,SWIPTNet: A Unified Deep Learning Framework for SWIPT based on GNN and Transfer Learning,http://arxiv.org/abs/2502.03928v1,"This paper investigates the deep learning based approaches for simultaneouswireless information and power transfer (SWIPT). The quality-of-service (QoS)constrained sum-rate maximization problems are, respectively, formulated forpower-splitting (PS) receivers and time-switching (TS) receivers and solved bya unified graph neural network (GNN) based model termed SWIPT net (SWIPTNet).To improve the performance of SWIPTNet, we first propose a single-type outputmethod to reduce the learning complexity and facilitate the satisfaction of QoSconstraints, and then, utilize the Laplace transform to enhance input featureswith the structural information. Besides, we adopt the multi-head attention andlayer connection to enhance feature extracting. Furthermore, we present theimplementation of transfer learning to the SWIPTNet between PS and TSreceivers. Ablation studies show the effectiveness of key components in theSWIPTNet. Numerical results also demonstrate the capability of SWIPTNet inachieving near-optimal performance with millisecond-level inference speed whichis much faster than the traditional optimization algorithms. We also show theeffectiveness of transfer learning via fast convergence and expressivecapability improvement.",Hong Han,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.03927v1,Free Growth under Tension,http://arxiv.org/abs/2502.03927v1,"Ever since the ground breaking work of Trepat et al. in 2009, we know thatcell colonies growing on a substrate can be under tensile mechanical stress.The origin of tension has so far been attributed to cellular motility forcesbeing oriented outward of the colony. Works in the field mainly revolve aroundhow this orientation of the forces can be explained, ranging from velocityalignment, self-sorting due to self-propulsion, to kenotaxis. In this work, wedemonstrate that tension in growing colonies can also be explained withoutcellular motility forces! Using a combination of well established tissue growthsimulation technique and analytical modelling, we show how tension can arise asa consequence of simple mechanics of growing tissues. Combining these modelswith a minimalistic motility model shows how colonies can expand while undereven larger tension. Furthermore, our results and analytical models providenovel analysis procedures to identify the underlying mechanics.",Chenyun Yao,2025-02-06,2025-02-06,,N/A,"['physics.bio-ph', 'cond-mat.soft', 'q-bio.CB']"
2502.04408v1,Transforming Multimodal Models into Action Models for Radiotherapy,http://arxiv.org/abs/2502.04408v1,"Radiotherapy is a crucial cancer treatment that demands precise planning tobalance tumor eradication and preservation of healthy tissue. Traditionaltreatment planning (TP) is iterative, time-consuming, and reliant on humanexpertise, which can potentially introduce variability and inefficiency. Wepropose a novel framework to transform a large multimodal foundation model(MLM) into an action model for TP using a few-shot reinforcement learning (RL)approach. Our method leverages the MLM's extensive pre-existing knowledge ofphysics, radiation, and anatomy, enhancing it through a few-shot learningprocess. This allows the model to iteratively improve treatment plans using aMonte Carlo simulator. Our results demonstrate that this method outperformsconventional RL-based approaches in both quality and efficiency, achievinghigher reward scores and more optimal dose distributions in simulations onprostate cancer data. This proof-of-concept suggests a promising direction forintegrating advanced AI models into clinical workflows, potentially enhancingthe speed, quality, and standardization of radiotherapy treatment planning.",Matteo Ferrante,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.03918v1,Adaptation of Task Goal States from Prior Knowledge,http://arxiv.org/abs/2502.03918v1,"This paper presents a framework to define a task with freedom and variabilityin its goal state. A robot could use this to observe the execution of a taskand target a different goal from the observed one; a goal that is stillcompatible with the task description but would be easier for the robot toexecute. We define the model of an environment state and an environmentvariation, and present experiments on how to interactively create the variationfrom a single task demonstration and how to use this variation to create anexecution plan for bringing any environment into the goal state.",Andrei Costinescu,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.03916v1,Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software,http://arxiv.org/abs/2502.03916v1,"Large Language Models (LLMs) are increasingly helpful in text generation,even writing code in programming languages based on user prompts written innatural language. They are even applied to generate simulation models formultibody systems from natural language. Research results suggest that LLMssurpass the mere replication of existing code examples, where some LLMs havebeen trained on an open-source multibody simulation code. However, forclosed-source simulation software, such results are not to be expected as theirideas and concepts might differ from other publicly available ones. LLMs canhallucinate for knowledge-intensive tasks, such as model creation, which canlead to wrong responses. This is especially the case for the LLM unknownclosed-source simulation software. The same applies to other internal knowledgekept private to protect intellectual property or data privacy. TheRetrieval-Augmented Generation (RAG) approach might yield a solution for theseknowledge-intensive tasks. This paper explores the application of RAG toclosed-source simulation software and presents first experiments. After a briefintroduction to LLMs, the RAG approach, and the simulation method applied bythe close-source simulation software, several examples are provided to testLLMs' knowledge of the simulation software and the creation of simulationmodels using two RAG systems. The examples show promising results indicatingthe benefits of applying RAG systems to closed-source simulation software,helping to access their knowledge. Nevertheless, they also reveal gaps in theapplied information and open questions for further research.",Andreas Baumann,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03908v1,Improving and benchmarking NISQ qubit routers,http://arxiv.org/abs/2502.03908v1,"Quantum computers with a limited qubit connectivity require inserting SWAPgates for qubit routing, which increases gate execution errors and the impactof environmental noise due to an overhead in circuit depth. In this work, webenchmark various routing techniques considering random quantum circuits onone-dimensional and square lattice connectivities, employing both analyticaland numerical methods. We introduce circuit fidelity as a comprehensive metricthat captures the effects of SWAP and circuit depth overheads. Leveraging anovel approach based on the SABRE algorithm, we achieve up to $84\%$ higheraverage circuit fidelity for large devices within the NISQ range, compared topreviously existing methods. Additionally, our results highlight that theoptimal routing choice critically depends on the qubit count and the hardwarecharacteristics, including gate fidelities and coherence times.",Vicente Pina-Canelles,2025-02-06,2025-02-06,,N/A,['quant-ph']
2502.03907v1,No Free Lunch in Annotation either: An objective evaluation of foundation models for streamlining annotation in animal tracking,http://arxiv.org/abs/2502.03907v1,"We analyze the capabilities of foundation models addressing the tedious taskof generating annotations for animal tracking. Annotating a large amount ofdata is vital and can be a make-or-break factor for the robustness of atracking model. Robustness is particularly crucial in animal tracking, asaccurate tracking over long time horizons is essential for capturing thebehavior of animals. However, generating additional annotations usingfoundation models can be counterproductive, as the quality of the annotationsis just as important. Poorly annotated data can introduce noise andinaccuracies, ultimately compromising the performance and accuracy of thetrained model. Over-reliance on automated annotations without ensuringprecision can lead to diminished results, making careful oversight and qualitycontrol essential in the annotation process. Ultimately, we demonstrate that athoughtful combination of automated annotations and manually annotated data isa valuable strategy, yielding an IDF1 score of 80.8 against blind usage of SAM2video with an IDF1 score of 65.6.",Emil Mededovic,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03904v1,A Gaussian-Sinc Pulse Shaping Filter for Zak-OTFS,http://arxiv.org/abs/2502.03904v1,"The choice of delay-Doppler domain (DD) pulse shaping filter plays animportant role in determining the performance of Zak-OTFS. Sinc filter has goodmain lobe characteristics (with nulls at information grid points) which is goodfor equalization/detection, but has high side lobes which are detrimental forinput-output (I/O) relation estimation. Whereas, Gaussian filter is highlylocalized with very low side lobes which is good for I/O relation estimation,but has poor main lobe characteristics which is not good forequalization/detection. In this paper, we propose a new filter, termed as {\emGaussian-sinc (GS) filter}, which inherits the complementary strengths of bothGaussian and sinc filters. The proposed filter does not incur time or bandwidthexpansion. We derive closed-form expressions for the I/O relation and noisecovariance of Zak-OTFS with the proposed GS filter. We evaluate the Zak-OTFSperformance for different pulse shaping filters with I/O relation estimatedusing exclusive and embedded pilots. Our results show that the proposed GSfilter achieves better bit error rate (BER) performance compared to otherfilters reported in the literature. For example, with model-free I/O relationestimation using embedded pilot and 8-QAM, the proposed GS filter achieves anSNR gain of about 4 dB at $10^{-2}$ uncoded BER compared to Gaussian and sincfilters, and the SNR gain becomes more than 6 dB at a coded BER of $10^{-4}$with rate-1/2 coding.",Arpan Das,2025-02-06,2025-02-06,,N/A,"['cs.IT', 'eess.SP', 'math.IT']"
2502.03901v1,LeAP: Consistent multi-domain 3D labeling using Foundation Models,http://arxiv.org/abs/2502.03901v1,"Availability of datasets is a strong driver for research on 3D semanticunderstanding, and whilst obtaining unlabeled 3D point cloud data isstraightforward, manually annotating this data with semantic labels istime-consuming and costly. Recently, Vision Foundation Models (VFMs) enableopen-set semantic segmentation on camera images, potentially aiding automaticlabeling. However,VFMs for 3D data have been limited to adaptations of 2Dmodels, which can introduce inconsistencies to 3D labels. This work introducesLabel Any Pointcloud (LeAP), leveraging 2D VFMs to automatically label 3D datawith any set of classes in any kind of application whilst ensuring labelconsistency. Using a Bayesian update, point labels are combined into voxels toimprove spatio-temporal consistency. A novel 3D Consistency Network (3D-CN)exploits 3D information to further improve label quality. Through variousexperiments, we show that our method can generate high-quality 3D semanticlabels across diverse fields without any manual labeling. Further, modelsadapted to new domains using our labels show up to a 34.2 mIoU increase insemantic segmentation tasks.",Simon Gebraad,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.RO']"
2502.03900v1,How to introduce an initial crack in phase field simulations to accurately predict the linear elastic fracture propagation threshold?,http://arxiv.org/abs/2502.03900v1,"Variational phase field fracture models are now widely used to simulate crackpropagation in structures. A critical aspect of these simulations is thecorrect determination of the propagation threshold of pre-existing cracks, asit highly relies on how the initial cracks are implemented. While prior studiesbriefly discuss initial crack implementation techniques, we present here asystematic investigation. Various techniques to introduce initial cracks inphase field fracture simulations are tested, from the crack explicit meshing tothe replacement by a fully damaged phase field, including different variantsfor the boundary conditions. Our focus here is on phase field models aiming toapproximate, in the $\Gamma$-convergence limit, Griffith quasi-staticpropagation in the framework of Linear Elastic Fracture Mechanics. Therefore, asharp crack model from classic linear elastic fracture mechanics based onGriffith criterion is the reference in this work. To assess the differenttechniques to introduce initial cracks, we rely on path-following methods tocompute the sharp crack and the phase field smeared crack solutions. Theunderlying idea is that path-following ensures staying at equilibrium at eachinstant so that any difference between phase field and sharp crack models canbe attributed to numerical artifacts. Thus, by comparing the results from bothmodels, we can provide practical recommendations for reliably incorporatinginitial cracks in phase field fracture simulations. The comparison shows thatan improper initial crack implementation often requires the smeared crack totransition to a one-element-wide phase band to adequately represent adisplacement jump along a crack. This transition increases the energy requiredto propagate the crack, leading to a significant overshoot in theforce-displacement response. The take-home message is that to predict thepropagation threshold accurately and avoid artificial toughening; the crackmust be initialized either setting the phase field to its damage state over aone-element-wide band or meshing the crack explicitly as a one-element-wideslit and imposing the fully cracked state on the crack surface.",Flavien Loiseau,2025-02-06,2025-02-06,,N/A,['cs.CE']
2502.04406v1,Calibrated Physics-Informed Uncertainty Quantification,http://arxiv.org/abs/2502.04406v1,"Neural PDEs offer efficient alternatives to computationally expensivenumerical PDE solvers for simulating complex physical systems. However, theirlack of robust uncertainty quantification (UQ) limits deployment in criticalapplications. We introduce a model-agnostic, physics-informed conformalprediction (CP) framework that provides guaranteed uncertainty estimateswithout requiring labelled data. By utilising a physics-based approach, we areable to quantify and calibrate the model's inconsistencies with the PDE ratherthan the uncertainty arising from the data. Our approach uses convolutionallayers as finite-difference stencils and leverages physics residual errors asnonconformity scores, enabling data-free UQ with marginal and joint coverageguarantees across prediction domains for a range of complex PDEs. We furthervalidate the efficacy of our method on neural PDE models for plasma modellingand shot design in fusion reactors.",Vignesh Gopakumar,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'physics.comp-ph']"
2502.03899v1,A Slicing Model for Transport Networks with Traffic Burst Control and QoS Compliance for Traffic Flows,http://arxiv.org/abs/2502.03899v1,"Network slicing has emerged as a key network technology, providing networkoperators with the means to offer virtual networks to vertical users over asingle physical network infrastructure. Recent research has resulted mainly intechniques for managing and deploying network slices, but the implementation ofnetwork slices on a real physical transport network infrastructure has receivedmuch less attention. Standardization bodies, such as the Internet EngineeringTask Force (IETF), have provided some implementation recommendations. Still,there is a lack of mechanisms to implement network slices capable of handlingtraffic bursts while simultaneously meeting the Quality of Service (QoS)requirements of the traffic flows associated with the slices. In this paper, wepropose a novel fine-grained resource control mechanism to implement transportnetwork slices that meet traffic QoS requirements while both accepting limitedtraffic bursts, and enabling efficient bandwidth sharing within and acrossslices. The mechanism is executed at the edge of the transport network. Theproposed model aligns with current standards on network slicing and has beentested on an experimental platform. Using this platform, we have conducted anextensive experimental campaign that demonstrates that our proposal caneffectively control traffic bursts generated within the network slices whilemaximizing bandwidth utilization across the network.",Aitor Encinas-Alonso,2025-02-06,2025-02-06,,N/A,['cs.NI']
2502.03895v1,Rule-Based Modeling of Low-Dimensional Data with PCA and Binary Particle Swarm Optimization (BPSO) in ANFIS,http://arxiv.org/abs/2502.03895v1,"Fuzzy rule-based systems interpret data in low-dimensional domains, providingtransparency and interpretability. In contrast, deep learning excels in complextasks like image and speech recognition but is prone to overfitting in sparse,unstructured, or low-dimensional data. This interpretability is crucial infields like healthcare and finance. Traditional rule-based systems, especiallyANFIS with grid partitioning, suffer from exponential rule growth asdimensionality increases. We propose a strategic rule-reduction model thatapplies Principal Component Analysis (PCA) on normalized firing strengths toobtain linearly uncorrelated components. Binary Particle Swarm Optimization(BPSO) selectively refines these components, significantly reducing the numberof rules while preserving precision in decision-making. A custom parameterupdate mechanism fine-tunes specific ANFIS layers by dynamically adjusting BPSOparameters, avoiding local minima. We validated our approach on standard UCIrespiratory, keel classification, regression datasets, and a real-worldischemic stroke dataset, demonstrating adaptability and practicality. Resultsindicate fewer rules, shorter training, and high accuracy, underscoring themethods effectiveness for low-dimensional interpretability and complex datascenarios. This synergy of fuzzy logic and optimization fosters robustsolutions. Our method contributes a powerful framework for interpretable AI inmultiple domains. It addresses dimensionality, ensuring a rule base.",Afnan Al-Ali,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.04405v1,FAS: Fast ANN-SNN Conversion for Spiking Large Language Models,http://arxiv.org/abs/2502.04405v1,"Spiking Large Language Models have been shown as a good alternative to LLMsin various scenarios. Existing methods for creating Spiking LLMs, i.e., directtraining and ANN-SNN conversion, often suffer from performance degradation andrelatively high computational costs. To address these issues, we propose anovel Fast ANN-SNN conversion strategy (FAS) that transforms LLMs into spikingLLMs in two stages. The first stage employs a full-parameter fine-tuning ofpre-trained models, so it does not need any direct training from scratch. Thesecond stage introduces a coarse-to-fine calibration method to reduceconversion errors and improve accuracy. Our experiments on both language andvision-language tasks across four different scales of LLMs demonstrate that FAScan achieve state-of-the-art performance yet with significantly reducedinference latency and computational costs. For example, FAS only takes 8timesteps to achieve an accuracy of 3% higher than that of the OPT-7B model,while reducing energy consumption by 96.63%.",Long Chen,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.03892v1,"A class of positive-preserving,energy stable and high order numerical schemes for the Poission-Nernst-Planck system",http://arxiv.org/abs/2502.03892v1,"In this paper, we introduce and analyze a class of numerical schemes thatdemonstrate remarkable superiority in terms of efficiency, the preservation ofpositivity, energy stability, and high-order precision to solve thetime-dependent Poisson-Nernst-Planck (PNP) system, which is  as a highly versatile and sophisticated model and accommodates a plenitude ofapplications in the emulation of the translocation of charged particles acrossa multifarious expanse of physical and biological systems. The numericalschemes presented here are based on the energy variational formulation. Itallows the PNP system to be reformulated as a non-constant mobility $H^{-1}$gradient flow, incorporating singular logarithmic energy potentials. To achievea fully discrete numerical scheme, we employ a combination offirst/second-order semi-implicit time discretization methods, coupled witheither the $k$-th order direct discontinuous Galerkin (DDG) method or thefinite element (FE) method for spatial discretization. The schemes are verifiedto possess positivity preservation and energy stability. Optimal errorestimates and particular superconvergence results for the fully-discretenumerical solution are established. Numerical experiments are provided toshowcase the accuracy, efficiency, and robustness of the proposed schemes.",Waixiang Cao,2025-02-06,2025-02-06,,N/A,"['math.NA', 'cs.NA']"
2502.03885v2,InfinitePOD: Building Datacenter-Scale High-Bandwidth Domain for LLM with Optical Circuit Switching Transceivers,http://arxiv.org/abs/2502.03885v2,"Scaling Large Language Model (LLM) training relies on multi-dimensionalparallelism, where High-Bandwidth Domains (HBDs) are critical forcommunication-intensive parallelism like Tensor Parallelism (TP) and ExpertParallelism (EP). However, existing HBD architectures face fundamentallimitations in scalability, cost, and fault resiliency: switch-centric HBDs(e.g., NVL-72) incur prohibitive scaling costs, while GPU-centric HBDs (e.g.,TPUv3/Dojo) suffer from severe fault propagation. Switch-GPU hybrid HBDs suchas TPUv4 takes a middle-ground approach by leveraging Optical Circuit Switches,but the fault explosion radius remains large at the cube level (e.g., 64 TPUs).  We propose InfinitePOD, a novel transceiver-centric HBD architecture thatunifies connectivity and dynamic switching at the transceiver level usingOptical Circuit Switching (OCS). By embedding OCS within each transceiver,InfinitePOD achieves reconfigurable point-to-multipoint connectivity, allowingthe topology to adapt into variable-size rings. This design provides: i)datacenter-wide scalability without cost explosion; ii) fault resilience byisolating failures to a single node, and iii) full bandwidth utilization forfault-free GPUs. Key innovations include a Silicon Photonic (SiPh) basedlow-cost OCS transceiver (OCSTrx), a reconfigurable k-hop ring topologyco-designed with intra-/inter-node communication, and an HBD-DCN orchestrationalgorithm maximizing GPU utilization while minimizing cross-ToR datacenternetwork traffic. The evaluation demonstrates that InfinitePOD achieves 31% ofthe cost of NVL-72, near-zero GPU waste ratio (over one order of magnitudelower than NVL-72 and TPUv4), near-zero cross-ToR traffic when node faultratios under 7%, and improves Model FLOPs Utilization by 3.37x compared toNVIDIA DGX (8 GPUs per Node).",Chenchen Shou,2025-02-06,2025-02-07,,N/A,"['cs.NI', 'cs.DC', 'cs.LG']"
2502.03884v1,Rank Also Matters: Hierarchical Configuration for Mixture of Adapter Experts in LLM Fine-Tuning,http://arxiv.org/abs/2502.03884v1,"Large language models (LLMs) have demonstrated remarkable success acrossvarious tasks, accompanied by a continuous increase in their parameter size.Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation(LoRA), address the challenges of fine-tuning LLMs by significantly reducingthe number of trainable parameters. Recent studies have integrated LoRA withMixture of Experts (MoE) architectures, leveraging multiple adapter experts andgating mechanisms to further improve fine-tuning performance. However, existingapproaches primarily focus on adjusting the allocations of adapter experts perlayer to optimize the introduced trainable parameter size, while neglecting acritical factor of adapters' rank. To this end, we propose a hierarchicalscheme for expert allocation and rank configuration, HILO, which dynamicallyadjusts the number and rank of adapter experts across layers, matching thevarying representational complexity of model layers in adapter-granularity.Extensive experiments on multiple benchmark tasks demonstrate that HILOoutperforms existing methods in accuracy while introducing fewer trainableparameters, providing an efficient and practical solution for fine-tuning LLMs.",Peizhuang Cong,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.03882v1,Hierarchical Entropic Diffusion for Ransomware Detection: A Probabilistic Approach to Behavioral Anomaly Isolation,http://arxiv.org/abs/2502.03882v1,"The increasing complexity of cryptographic extortion techniques hasnecessitated the development of adaptive detection frameworks capable ofidentifying adversarial encryption behaviors without reliance on predefinedsignatures. Hierarchical Entropic Diffusion (HED) introduces a structuredentropy-based anomaly classification mechanism that systematically tracksfluctuations in entropy evolution to differentiate between benign cryptographicprocesses and unauthorized encryption attempts. The integration of hierarchicalclustering, entropy profiling, and probabilistic diffusion modeling refinesdetection granularity, ensuring that encryption anomalies are identifieddespite obfuscation strategies or incremental execution methodologies.Experimental evaluations demonstrated that HED maintained high classificationaccuracy across diverse ransomware families, outperforming traditionalheuristic-based and signature-driven approaches while reducing false positiveoccurrences. Comparative analysis highlighted that entropy-driven anomalysegmentation improved detection efficiency under variable system workloadconditions, ensuring real-time classification feasibility. The computationaloverhead associated with entropy anomaly detection remained within operationalconstraints, reinforcing the suitability of entropy-driven classification forlarge-scale deployment. The ability to identify adversarial entropymanipulations before encryption completion contributes to broader cybersecuritydefenses, offering a structured methodology for isolating unauthorizedcryptographic activities within heterogeneous computing environments. Theresults further emphasized that entropy evolution modeling facilitatespredictive anomaly detection, enhancing resilience against encryption evasiontechniques designed to circumvent traditional detection mechanisms.",Vasili Iskorohodov,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.04404v1,Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models,http://arxiv.org/abs/2502.04404v1,"The integration of slow-thinking mechanisms into large language models (LLMs)offers a promising way toward achieving Level 2 AGI Reasoners, as exemplifiedby systems like OpenAI's o1. However, several significant challenges remain,including inefficient overthinking and an overreliance on auxiliary rewardmodels. We point out that these limitations stem from LLMs' inability tointernalize the search process, a key component of effective reasoning. Acritical step toward addressing this issue is enabling LLMs to autonomouslydetermine when and where to backtrack, a fundamental operation in traditionalsearch algorithms. To this end, we propose a self-backtracking mechanism thatequips LLMs with the ability to backtrack during both training and inference.This mechanism not only enhances reasoning ability but also efficiency bytransforming slow-thinking processes into fast-thinking throughself-improvement. Empirical evaluations demonstrate that our proposalsignificantly enhances the reasoning capabilities of LLMs, achieving aperformance gain of over 40 percent compared to the optimal-path supervisedfine-tuning method. We believe this study introduces a novel and promisingpathway for developing more advanced and robust Reasoners.",Xiao-Wen Yang,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03879v1,First-order CP phase transition in two-flavor QCD at $θ= π$ under electromagnetic scale anomaly via a Nambu-Jona-Lasinio description,http://arxiv.org/abs/2502.03879v1,"We discuss the thermal CP phase transition in QCD at $\theta=\pi$ under aweak magnetic field background, where the electromagnetic scale anomaly getssignificant. To explicitize, we work on a two-flavor Polyakov-loopNambu-Jona-Lasinio model at $\theta=\pi$ in the mean field approximation,including the electromagnetic-scale anomaly term. We find that the thermal CPphase transition becomes first order and the strength of the first order getsmore prominent as the magnetic field increases. The associated potentialbarrier is thermally created by the electromagnetic scale anomaly and givesrise to criticality due to the induced potential of a non-perturbative form$\sim \frac{|eB|^3}{f_\pi} \frac{|P|}{P^2 + m_0^2}$, where $eB$ denotes themagnetic field strength; $P$ the CP order parameter, and $m_0$ theisospin-symmetric current-quark mass. The CP-broken deconfinement(-like)domain, $T^{\rm (CP)}_c > T^{\rm (dec)}_{\rm pc}$, gets wider as $eB$increases.",Yuanyuan Wang. Shinya Matsuzaki,2025-02-06,2025-02-06,,N/A,"['hep-ph', 'hep-lat', 'hep-th', 'nucl-th']"
2502.03878v1,Sensitivity to Triple Higgs Couplings via Di-Higgs Production in the RxSM at the (HL-)LHC and future $e^+e^-$ Colliders,http://arxiv.org/abs/2502.03878v1,"The real Higgs singlet extension of the Standard Model (SM) without $Z_2$symmetry, the RxSM, is the simplest extension of the SM that features a FirstOrder Electroweak Phase Transition (FOEWPT) in the early universe. The FOEWPTis one of the requirements needed for electroweak baryogenesis to explain thebaryon asymmetry of the universe (BAU). Thus, the RxSM is a perfect example tostudy features related to the FOEWPT at current and future colliderexperiments. The RxSM has two CP-even Higgs bosons, $h$ and $H$, with masses$m_h < m_H$, where we assume that $h$ corresponds to the Higgs boson discoveredat the LHC. Our analysis is based on a benchmark plane that ensures theoccurence of a strong FOEWPT, where $m_H > 2 m_h$ is found. In a first step weanalyze the di-Higgs production at the (HL-)LHC, $gg \to hh$, with a focus onthe impact of the trilinear Higgs couplings (THCs), $\lambda_{hhh}$ and$\lambda_{hhH}$. The interferences of the resonant $H$-exchange diagraminvolving $\lambda_{hhH}$ and the non-resonant diagrams result in acharacteristic peak-dip (or dip-peak) structure in the $m_{hh}$ distribution.We analyze how $\lambda_{hhH}$ can be accessed, taking into account theexperimental smearing and binning. We also demonstrate that the approximationused by ATLAS and CMS for the resonant di-Higgs searches may fail to capturethe relevant effects and lead to erroneous results. In a second step we analyzethe benchmark plane at a future high-energy $e^+e^-$ collider with $\sqrt{s} =1000$ GeV (ILC1000). We demonstrate the potential sensitivity to$\lambda_{hhH}$ via an experimental determination at the ILC1000.",F. Arco,2025-02-06,2025-02-06,,N/A,['hep-ph']
2502.03877v1,Advanced Object Detection and Pose Estimation with Hybrid Task Cascade and High-Resolution Networks,http://arxiv.org/abs/2502.03877v1,"In the field of computer vision, 6D object detection and pose estimation arecritical for applications such as robotics, augmented reality, and autonomousdriving. Traditional methods often struggle with achieving high accuracy inboth object detection and precise pose estimation simultaneously. This studyproposes an improved 6D object detection and pose estimation pipeline based onthe existing 6D-VNet framework, enhanced by integrating a Hybrid Task Cascade(HTC) and a High-Resolution Network (HRNet) backbone. By leveraging thestrengths of HTC's multi-stage refinement process and HRNet's ability tomaintain high-resolution representations, our approach significantly improvesdetection accuracy and pose estimation precision. Furthermore, we introduceadvanced post-processing techniques and a novel model integration strategy thatcollectively contribute to superior performance on public and privatebenchmarks. Our method demonstrates substantial improvements overstate-of-the-art models, making it a valuable contribution to the domain of 6Dobject detection and pose estimation.",Yuhui Jin,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03876v1,Position: Untrained Machine Learning for Anomaly Detection,http://arxiv.org/abs/2502.03876v1,"Anomaly detection based on 3D point cloud data is an important researchproblem and receives more and more attention recently. Untrained anomalydetection based on only one sample is an emerging research problem motivated byreal manufacturing industries such as personalized manufacturing that only onesample can be collected without any additional labels. How to accuratelyidentify anomalies based on one 3D point cloud sample is a critical challengein both industrial applications and the field of machine learning. This paperaims to provide a formal definition of untrained anomaly detection problembased on 3D point cloud data, discuss the differences between untrained anomalydetection and current unsupervised anomaly detection methods. Unlikeunsupervised learning, untrained methods do not rely on any data, includingunlabeled data. Instead, they leverage prior knowledge about the manufacturingsurfaces and anomalies. Examples are used to illustrate these prior knowledgeand untrained machine learning model. Afterwards, literature review onuntrained anomaly detection based on 3D point cloud data is also provided, andthe potential of untrained deep neural networks for anomaly detection is alsodiscussed as outlooks.",Juan Du,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03874v1,Any theory that admits a Wigner's Friend type multi-agent paradox is logically contextual,http://arxiv.org/abs/2502.03874v1,"Wigner's Friend scenarios push the boundaries of quantum theory by modelingagents, along with their memories storing measurement outcomes, as physicalquantum systems. Extending these ideas beyond quantum theory, we ask: in whichphysical theories, and under what assumptions, can agents who are reasoninglogically about each other's measurement outcomes encounter apparent paradoxes?To address this, we prove a link between Wigner's Friend type multi-agentparadoxes and contextuality in general theories: if agents who are modeledwithin a physical theory come to a contradiction when reasoning using thattheory (under certain assumptions on how they reason and describemeasurements), then the theory must admit contextual correlations of a logicalform. This also yields a link between the distinct fundamental concepts ofHeisenberg cuts and measurement contexts in general theories, and inparticular, implies that the quantum Frauchiger-Renner paradox is a proof oflogical contextuality. Moreover, we identify structural properties of suchparadoxes in general theories and specific to quantum theory. For instance, wedemonstrate that theories admitting behaviors corresponding to extremalvertices of n-cycle contextuality scenarios admit Wigner's Friend typeparadoxes without post-selection, and that any quantum Wigner's Friend paradoxbased on the n-cycle scenario must necessarily involve post-selection. Further,we construct a multi-agent paradox based on a genuine contextuality scenarioinvolving sequential measurements on a single system, showing that Bellnon-local correlations between distinct subsystems are not necessary forWigner's Friend paradoxes. Our work offers an approach to investigate thestructure of physical theories and their information-theoretic resources bymeans of deconstructing the assumptions underlying multi-agent physicalparadoxes.",Nuriya Nurgalieva,2025-02-06,2025-02-06,,N/A,['quant-ph']
2502.03873v1,Oxygen sublattice disorder and valence state modulation in infinite-layer nickelate superlattices,http://arxiv.org/abs/2502.03873v1,"The family of infinite-layer nickelates promises important insights into themechanism of unconventional superconductivity. Since superconductivity has sofar only been observed in epitaxial thin films, heteroepitaxy with thesubstrate or a capping layer possibly plays an important role. Here, we usesoft x-ray spectroscopy to investigate superlattices as a potential approachfor a targeted material design of high-temperature superconductors. We observemodulations in valence state and oxygen coordination in topotactically reducedartificial superlattices with repeating interfaces between nickelate layers andlayers of materials commonly used as substrates and capping layers. Our resultsshow that depending on the interlayer material metallic conductivity akin tothe parent infinite-layer compounds is achieved. Depth-resolved electronicstructure measured by resonant x-ray reflectivity reveals a reconstructedligand field and valence state at the interface, which is confined to one ortwo unit cells. The central layers show characteristics of monovalent nickel,but linear dichroism analysis reveals considerable disorder in the oxygenremoval sites. We observe a quantitative correlation of this disorder with theinterlayer material that is important for future modeling and designstrategies.",R. A. Ortiz,2025-02-06,2025-02-06,,N/A,"['cond-mat.supr-con', 'cond-mat.mtrl-sci', 'cond-mat.str-el']"
2502.03871v1,"Blind Capon Beamformer Based on Independent Component Extraction: Single-Parameter Algorithm,",http://arxiv.org/abs/2502.03871v1,"We consider a phase-shift mixing model for linear sensor arrays in thecontext of blind source extraction. We derive a blind Capon beamformer thatseeks the direction where the output is independent of the other signals in themixture. The algorithm is based on Independent Component Extraction and imposesan orthogonal constraint, thanks to which it optimizes only one real-valuedparameter related to the angle of arrival. The Cram\'er-Rao lower bound for themean interference-to-signal ratio is derived. The algorithm and the bound arecompared with conventional blind and direction-of-arrivalestimation+beamforming methods, showing improvements in terms of extractionaccuracy. An application is demonstrated in frequency-domain speaker extractionin a low-reverberation room.",Zbyněk Koldovský,2025-02-06,2025-02-06,,N/A,"['eess.SP', 'eess.AS']"
2502.03869v1,A microscopic model of de Sitter spacetime with an observer,http://arxiv.org/abs/2502.03869v1,"We introduce a simple microscopic quantum mechanical model of low-dimensionalde Sitter holography with an observer. Using semiclassical gravity andelementary thermodynamic considerations, we derive a formula for the totalentropy of a 3D Schwarzschild-de Sitter universe with an observer. We thenmatch this entropy formula with the exactly known spectral density of thedouble scaled SYK model. Our result gives a de Sitter interpretation of theappearance of two notions of temperature in DSSYK.",Damiano Tietto,2025-02-06,2025-02-06,,N/A,['hep-th']
2502.03868v1,Time-based GNSS attack detection,http://arxiv.org/abs/2502.03868v1,"To safeguard Civilian Global Navigation Satellite Systems (GNSS) externalinformation available to the platform encompassing the GNSS receiver can beused to detect attacks. Cross-checking the GNSS-provided time againstalternative multiple trusted time sources can lead to attack detection aimingat controlling the GNSS receiver time. Leveraging external, network-connectedsecure time providers and onboard clock references, we achieve detection evenunder fine-grained time attacks. We provide an extensive evaluation of ourmulti-layered defense against adversaries mounting attacks against the GNSSreceiver along with controlling the network link. We implement adversariesspanning from simplistic spoofers to advanced ones synchronized with the GNSSconstellation. We demonstrate attack detection is possible in all tested cases(sharp discontinuity, smooth take-over, and coordinated network manipulation)without changes to the structure of the GNSS receiver. Leveraging the diversityof the reference time sources, detection of take-over time push as low as 150usis possible. Smooth take-overs forcing variations as low as 30ns are alsodetected based on on-board precision oscillators. The method (and thus theevaluation) is largely agnostic to the satellite constellation and the attackertype, making time-based data validation of GNSS information compatible withexisting receivers and readily deployable.",Marco Spanghero,2025-02-06,2025-02-06,,N/A,['cs.CR']
2502.03863v1,Compact Nested Hexagonal Metamaterial Sensor for High-Sensitivity Permittivity Characterization Across S and X-Band Frequencies,http://arxiv.org/abs/2502.03863v1,"This article presents a Compact Nested Hexagonal Metamaterial Sensor designedfor microwave sensing to characterize material permittivity in S and X-bandapplications. The proposed sensor attained compact dimensions of merely 30 mm x30 mm x 0.79 mm. This innovative design technique employs a distinctive andcompact architecture with elevated electromagnetic (EM) field strength,enhancing the precision of the sensing mechanism in the microwave frequencyspectrum. The design geometry and dimensions attained resonance frequencies of3.98 GHz and 11.57 GHz, with notch depths of -13.16129 dB and -10.23024 dB,respectively. The design evolution, metamaterial properties, equivalent circuitmodel, and electric (E) is delineated to elucidate the stopband features at theresonant frequency. The suggested sensor attains a very high sensitivity of9.55% in transmission mode (S21) for a permittivity range of 1 to 6. Thereflection and transmission properties of the proposed CRR-based sensor arevalidated by simulations using the mathematical equations of the design.Furthermore, the sensor's performance is corroborated by utilizing severaldielectric materials (Roger R04350B, Roger RT5880 and FR-4). The computedoutcomes demonstrate alignment with the simulated results. The compact,low-profile sensor design and its excellent sensitivity for characterizingmaterial permittivity render the suggested sensor appropriate for permittivitysensing applications.",Md Mujahid Hossain,2025-02-06,2025-02-06,,N/A,['eess.SP']
2502.03862v2,Enhancing Deliberativeness: Evaluating the Impact of Multimodal Reflection Nudges,http://arxiv.org/abs/2502.03862v2,"Nudging participants with text-based reflective nudges enhances deliberationquality on online deliberation platforms. The effectiveness of multimodalreflective nudges, however, remains largely unexplored. Given the multi-sensorynature of human perception, incorporating diverse modalities intoself-reflection mechanisms has the potential to better support variousreflective styles. This paper explores how presenting reflective nudges ofdifferent types (direct: persona and indirect: storytelling) in differentmodalities (text, image, video and audio) affects deliberation quality. Weconducted two user studies with 20 and 200 participants respectively. The firststudy identifies the preferred modality for each type of reflective nudges,revealing that text is most preferred for persona and video is most preferredfor storytelling. The second study assesses the impact of these modalities ondeliberation quality. Our findings reveal distinct effects associated with eachmodality, providing valuable insights for developing more inclusive andeffective online deliberation platforms.",ShunYi Yeo,2025-02-06,2025-02-07,,N/A,['cs.HC']
2502.03861v1,Analysis of Newly Catalogued Open Star Cluster UPK~220 with Gaia DR3 and TESS: Discovering Member Variable Stars,http://arxiv.org/abs/2502.03861v1,"Studies on star clusters with the same age and initial chemical compositionhave gained momentum in recent years with the use of \textit{Gaia}. Inaddition, the discovery of new clusters with Gaia has increased the number ofopen clusters to be examined. Many of these discovered sources areintermediate-age open clusters and have not been analyzed in detail yet. Inthis study, we focused on newly cataloged open cluster UPK~220. The fundamentalparameters (distance, age, metallicity and reddening) of UPK~220 weredetermined by analysing the variable stars within the cluster, whilesimultaneously constraining the parameters of the variable stars using thesecluster parameters. To achieve this, we combined GaiaDR3 and TESS photometricobservations. Using GaiaDR3, we derive fundamental parameters of UPK~220through membership analyses, and with TESS, we discovered eight member variablestars. We also extracted the atmospheric parameters ($logg$, $[Fe/H]$ and$T_{\rm eff}$) for the variable stars using SED, GSP-Phot and GSP-Spec, andMESA models.",İnci Akkaya Oralhan,2025-02-06,2025-02-06,,N/A,"['astro-ph.SR', 'astro-ph.GA']"
2502.03860v1,BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation,http://arxiv.org/abs/2502.03860v1,"Large language models (LLMs), such as o1 from OpenAI, have demonstratedremarkable reasoning capabilities. o1 generates a long chain-of-thought(LongCoT) before answering a question. LongCoT allows LLMs to analyze problems,devise plans, reflect, and backtrack effectively. These actions empower LLM tosolve complex problems. After the release of o1, many teams have attempted toreplicate its LongCoT and reasoning capabilities. In terms of methods, theyprimarily rely on knowledge distillation with data from existing models withLongCoT capacities (e.g., OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), leavingsignificant uncertainties on systematically developing such reasoningabilities. In terms of data domains, these works focus narrowly on math while afew others include coding, limiting their generalizability. This paperintroduces a novel approach to enable LLM's LongCoT capacity withoutdistillation from o1-like models or expensive human annotations, where webootstrap LongCoT (BOLT) from a standard instruct model. BOLT involves threestages: 1) LongCoT data bootstrapping with in-context learning on a standardinstruct model; 2) LongCoT supervised finetuning; 3) online training to furtherrefine LongCoT capacities. In BOLT, only a few in-context examples need to beconstructed during the bootstrapping stage; in our experiments, we created 10examples, demonstrating the feasibility of this approach. We useLlama-3.1-70B-Instruct to bootstrap LongCoT and apply our method to variousmodel scales (7B, 8B, 70B). We achieve impressive performance on a variety ofbenchmarks, Arena-Hard, MT-Bench, WildBench, ZebraLogic, MATH500, whichevaluate diverse task-solving and reasoning capabilities.",Bo Pang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03856v1,Taking A Closer Look at Interacting Objects: Interaction-Aware Open Vocabulary Scene Graph Generation,http://arxiv.org/abs/2502.03856v1,"Today's open vocabulary scene graph generation (OVSGG) extends traditionalSGG by recognizing novel objects and relationships beyond predefinedcategories, leveraging the knowledge from pre-trained large-scale models. Mostexisting methods adopt a two-stage pipeline: weakly supervised pre-trainingwith image captions and supervised fine-tuning (SFT) on fully annotated scenegraphs. Nonetheless, they omit explicit modeling of interacting objects andtreat all objects equally, resulting in mismatched relation pairs. To this end,we propose an interaction-aware OVSGG framework INOVA. During pre-training,INOVA employs an interaction-aware target generation strategy to distinguishinteracting objects from non-interacting ones. In SFT, INOVA devises aninteraction-guided query selection tactic to prioritize interacting objectsduring bipartite graph matching. Besides, INOVA is equipped with aninteraction-consistent knowledge distillation to enhance the robustness bypushing interacting object pairs away from the background. Extensiveexperiments on two benchmarks (VG and GQA) show that INOVA achievesstate-of-the-art performance, demonstrating the potential of interaction-awaremechanisms for real-world applications.",Lin Li,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03855v1,Semi-rPPG: Semi-Supervised Remote Physiological Measurement with Curriculum Pseudo-Labeling,http://arxiv.org/abs/2502.03855v1,"Remote Photoplethysmography (rPPG) is a promising technique to monitorphysiological signals such as heart rate from facial videos. However, thelabeled facial videos in this research are challenging to collect. Current rPPGresearch is mainly based on several small public datasets collected in simpleenvironments, which limits the generalization and scale of the AI models.Semi-supervised methods that leverage a small amount of labeled data andabundant unlabeled data can fill this gap for rPPG learning. In this study, anovel semi-supervised learning method named Semi-rPPG that combines curriculumpseudo-labeling and consistency regularization is proposed to extract intrinsicphysiological features from unlabelled data without impairing the model fromnoises. Specifically, a curriculum pseudo-labeling strategy withsignal-to-noise ratio (SNR) criteria is proposed to annotate the unlabelleddata while adaptively filtering out the low-quality unlabelled data. Besides, anovel consistency regularization term for quasi-periodic signals is proposedthrough weak and strong augmented clips. To benefit the research onsemi-supervised rPPG measurement, we establish a novel semi-supervisedbenchmark for rPPG learning through intra-dataset and cross-dataset evaluationon four public datasets. The proposed Semi-rPPG method achieves the bestresults compared with three classical semi-supervised methods under differentprotocols. Ablation studies are conducted to prove the effectiveness of theproposed methods.",Bingjie Wu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03853v1,VERITAS and multiwavelength observations of the Blazar B3 2247+381 in response to an IceCube neutrino alert,http://arxiv.org/abs/2502.03853v1,"While the sources of the diffuse astrophysical neutrino flux detected by theIceCube Neutrino Observatory are still largely unknown, one of the promisingmethods used towards understanding this is investigating the potential temporaland spatial correlations between neutrino alerts and the electromagneticradiation from blazars. We report on the multiwavelength target-of-opportunityobservations of the blazar B3 2247+381, taken in response to an IceCubemultiplet alert for a cluster of muon neutrino events compatible with thesource location between May 20, 2022 and November 10, 2022. B3 2247+381 was notdetected with VERITAS during this time period. The source was found to be in alow-flux state in the optical, ultraviolet and gamma-ray bands for the timeinterval corresponding to the neutrino event, but was detected in the hardX-ray band with NuSTAR during this period. We find the multiwavelength spectralenergy distribution is well described using a simple one-zone leptonicsynchrotron self-Compton radiation model. Moreover, assuming the neutrinosoriginate from hadronic processes within the jet, the neutrino flux would beaccompanied by a photon flux from the cascade emission, and the integratedphoton flux required in such a case would significantly exceed the totalmultiwavelength fluxes and the VERITAS upper limits presented here. The lack offlaring activity observed with VERITAS, combined with the low multiwavelengthflux levels, and given the significance of the neutrino excess is at 3$\sigma$level (uncorrected for trials), makes B3 2247+381 an unlikely source of theIceCube multiplet. We conclude that the neutrino excess is likely a backgroundfluctuation.",Atreya Acharyya,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03852v1,Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount,http://arxiv.org/abs/2502.03852v1,"In object detection, the instance count is typically used to define whether adataset exhibits a long-tail distribution, implicitly assuming that models willunderperform on categories with fewer instances. This assumption has led toextensive research on category bias in datasets with imbalanced instancecounts. However, models still exhibit category bias even in datasets whereinstance counts are relatively balanced, clearly indicating that instance countalone cannot explain this phenomenon. In this work, we first introduce theconcept and measurement of category information amount. We observe asignificant negative correlation between category information amount andaccuracy, suggesting that category information amount more accurately reflectsthe learning difficulty of a category. Based on this observation, we proposeInformation Amount-Guided Angular Margin (IGAM) Loss. The core idea of IGAM isto dynamically adjust the decision space of each category based on itsinformation amount, thereby reducing category bias in long-tail datasets. IGAMLoss not only performs well on long-tailed benchmark datasets such as LVIS v1.0and COCO-LT but also shows significant improvement for underrepresentedcategories in the non-long-tailed dataset Pascal VOC. Comprehensive experimentsdemonstrate the potential of category information amount as a tool and thegenerality of our proposed method.",Yanbiao Ma,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.04402v1,Beyond Interpolation: Extrapolative Reasoning with Reinforcement Learning and Graph Neural Networks,http://arxiv.org/abs/2502.04402v1,"Despite incredible progress, many neural architectures fail to properlygeneralize beyond their training distribution. As such, learning to reason in acorrect and generalizable way is one of the current fundamental challenges inmachine learning. In this respect, logic puzzles provide a great testbed, as wecan fully understand and control the learning environment. Thus, they allow toevaluate performance on previously unseen, larger and more difficult puzzlesthat follow the same underlying rules. Since traditional approaches oftenstruggle to represent such scalable logical structures, we propose to modelthese puzzles using a graph-based approach. Then, we investigate the keyfactors enabling the proposed models to learn generalizable solutions in areinforcement learning setting. Our study focuses on the impact of theinductive bias of the architecture, different reward systems and the role ofrecurrent modeling in enabling sequential reasoning. Through extensiveexperiments, we demonstrate how these elements contribute to successfulextrapolation on increasingly complex puzzles.These insights and frameworksoffer a systematic way to design learning-based systems capable ofgeneralizable reasoning beyond interpolation.",Niccolò Grillo,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.03851v1,Frustration In Physiology And Molecular Medicine,http://arxiv.org/abs/2502.03851v1,"Molecules provide the ultimate language in terms of which physiology andpathology must be understood. Myriads of proteins participate in elaboratenetworks of interactions and perform chemical activities coordinating the lifeof cells. To perform these often amazing tasks, proteins must move and we mustthink of them as dynamic ensembles of three dimensional structures formed firstby folding the polypeptide chains so as to minimize the conflicts between theinteractions of their constituent amino acids. It is apparent however that,even when completely folded, not all conflicting interactions have beenresolved so the structure remains ""locally frustrated"". Over the last decadesit has become clearer that this local frustration is not just a random accidentbut plays an essential part of the inner workings of protein molecules. We willreview here the physical origins of the frustration concept and review evidencethat local frustration is important for protein physiology, protein-proteinrecognition, catalysis and allostery. Also, we highlight examples showing howalterations in the local frustration patterns can be linked to distinctpathologies. Finally we explore the extensions of the impact of frustration inhigher order levels of organization of systems including gene regulatorynetworks and the neural networks of the brain.",R. Gonzalo Parra,2025-02-06,2025-02-06,,N/A,"['q-bio.BM', 'cond-mat.soft', 'physics.bio-ph', 'q-bio.QM']"
2502.03850v1,Electromagnetic Channel Modeling and Capacity Analysis for HMIMO Communications,http://arxiv.org/abs/2502.03850v1,"Advancements in emerging technologies, e.g., reconfigurable intelligentsurfaces and holographic MIMO (HMIMO), facilitate unprecedented manipulation ofelectromagnetic (EM) waves, significantly enhancing the performance of wirelesscommunication systems. To accurately characterize the achievable performancelimits of these systems, it is crucial to develop a universal EM-compliantchannel model. This paper addresses this necessity by proposing a comprehensiveEM channel model tailored for realistic multi-path environments, accounting forthe combined effects of antenna array configurations and propagation conditionsin HMIMO communications. Both polarization phenomena and spatial correlationare incorporated into this probabilistic channel model. Additionally, physicalconstraints of antenna configurations, such as mutual coupling effects andenergy consumption, are integrated into the channel modeling framework.Simulation results validate the effectiveness of the proposed probabilisticchannel model, indicating that traditional Rician and Rayleigh fading modelscannot accurately depict the channel characteristics and underestimate thechannel capacity. More importantly, the proposed channel model outperformsfree-space Green's functions in accurately depicting both near-field gain andmulti-path effects in radiative near-field regions. These gains are much moreevident in tri-polarized systems, highlighting the necessity of polarizationinterference elimination techniques. Moreover, the theoretical analysisaccurately verifies that capacity decreases with expanding communicationregions of two-user communications.",Li Wei,2025-02-06,2025-02-06,,N/A,"['cs.IT', 'eess.SP', 'math.IT']"
2502.03848v1,Consistent model selection in a collection of stochastic block models,http://arxiv.org/abs/2502.03848v1,"We introduce the penalized Krichevsky-Trofimov (KT) estimator as a convergentmethod for estimating the number of nodes clusters when observing multiplenetworks within both multi-layer and dynamic Stochastic Block Models. Weestablish the consistency of the KT estimator, showing that it converges to thecorrect number of clusters in both types of models when the number of nodes inthe networks increases. Our estimator does not require a known upper bound onthis number to be consistent. Furthermore, we show that these consistencyresults hold in both dense and sparse regimes, making the penalized KTestimator robust across various network configurations. We illustrate itsperformance on synthetic datasets.",Lucie Arts,2025-02-06,2025-02-06,,N/A,"['math.ST', 'stat.TH']"
2502.03846v1,On the limits of some Bayesian model evaluation statistics,http://arxiv.org/abs/2502.03846v1,"Model selection and order selection problems frequently arise in statisticalpractice. A popular approach to addressing these problems in the frequentistsetting involves information criteria based on penalized maxima oflog-likelihoods for competing models. In the Bayesian context, similar criteriaare employed, replacing the maxima of log-likelihoods with their posteriorexpectations. Despite their popularity in applications, the large-samplebehavior of these criteria -- such as the deviance information criterion (DIC),Bayesian predictive information criterion (BPIC), and widely-applicableBayesian information criterion (WBIC) -- has received relatively littleattention. In this work, we investigate the almost sure limits of thesecriteria and establish novel results on posterior and generalized posteriorconsistency, which are of independent interest. The utility of our theoreticalfindings is demonstrated via illustrative technical and numerical examples.",Hien Duy Nguyen,2025-02-06,2025-02-06,,N/A,"['math.ST', 'stat.TH']"
2502.03845v1,PAGNet: Pluggable Adaptive Generative Networks for Information Completion in Multi-Agent Communication,http://arxiv.org/abs/2502.03845v1,"For partially observable cooperative tasks, multi-agent systems must developeffective communication and understand the interplay among agents in order toachieve cooperative goals. However, existing multi-agent reinforcement learning(MARL) with communication methods lack evaluation metrics for informationweights and information-level communication modeling. This causes agents toneglect the aggregation of multiple messages, thereby significantly reducingpolicy learning efficiency. In this paper, we propose pluggable adaptivegenerative networks (PAGNet), a novel framework that integrates generativemodels into MARL to enhance communication and decision-making. PAGNet enablesagents to synthesize global states representations from weighted localobservations and use these representations alongside learned communicationweights for coordinated decision-making. This pluggable approach reduces thecomputational demands typically associated with the joint training ofcommunication and policy networks. Extensive experimental evaluations acrossdiverse benchmarks and communication scenarios demonstrate the significantperformance improvements achieved by PAGNet. Furthermore, we analyze theemergent communication patterns and the quality of generated global states,providing insights into operational mechanisms.",Zhuohui Zhang,2025-02-06,2025-02-06,,N/A,['cs.MA']
2502.03843v1,Improving Natural Language Understanding for LLMs via Large-Scale Instruction Synthesis,http://arxiv.org/abs/2502.03843v1,"High-quality, large-scale instructions are crucial for aligning largelanguage models (LLMs), however, there is a severe shortage of instruction inthe field of natural language understanding (NLU). Previous works onconstructing NLU instructions mainly focus on information extraction (IE),neglecting tasks such as machine reading comprehension, question answering, andtext classification. Furthermore, the lack of diversity in the data has led toa decreased generalization ability of trained LLMs in other NLU tasks and anoticeable decline in the fundamental model's general capabilities. To addressthis issue, we propose Hum, a large-scale, high-quality synthetic instructioncorpus for NLU tasks, designed to enhance the NLU capabilities of LLMs.Specifically, Hum includes IE (either close IE or open IE), machine readingcomprehension, text classification, and instruction generalist tasks, therebyenriching task diversity. Additionally, we introduce a human-LLMs collaborativemechanism to synthesize instructions, which enriches instruction diversity byincorporating guidelines, preference rules, and format variants. We conductextensive experiments on 5 NLU tasks and 28 general capability evaluationdatasets for LLMs. Experimental results show that Hum enhances the NLUcapabilities of six LLMs by an average of 3.1\%, with no significant declineobserved in other general capabilities.",Lin Yuan,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04401v1,Exploring generalized Starobinsky Model of Inflation: Observational Constraints,http://arxiv.org/abs/2502.04401v1,"We examine the power-law Starobinsky model, a generalized version of theStarobinsky inflation model, characterized by a power-law correction toEinstein gravity. Employing the $f(R)$ formalism, the scalar and tensor powerspectra were numerically computed as functions of the dimensionless parameters$M$ and $\beta$. A Markov Chain Monte Carlo (MCMC) analysis was conducted usingPlanck-2018, BICEP3 and BAO observational data, yielding precise constraints on$\beta = 1.987^{+0.013}_{-0.016},\, 95\%\, C.\, L.$. and $ \log_{10}M =-4.72^{+0.21}_{-0.20}$. The derived scalar spectral index$n_s=0.9676^{+0.0069}_{-0.0068}$ and tensor-to-scalar ratio$r=0.0074^{+0.0061}_{-0.0044}$ lie within the bounds set by Planckobservations. We analyse a general reheating scenario while keeping the numberof e-folds during inflation, $N_{pivot}$, fixed. The analysis confirms thatdeviations from the Starobinsky $R^2$ model are observationaly viable, withimplications for high-energy physics and supergravity-based inflationarymodels.",Saisandri Saini,2025-02-06,2025-02-06,,N/A,"['astro-ph.CO', 'gr-qc', 'hep-th']"
2502.03836v1,Adapting Human Mesh Recovery with Vision-Language Feedback,http://arxiv.org/abs/2502.03836v1,"Human mesh recovery can be approached using either regression-based oroptimization-based methods. Regression models achieve high pose accuracy butstruggle with model-to-image alignment due to the lack of explicit 2D-3Dcorrespondences. In contrast, optimization-based methods align 3D models to 2Dobservations but are prone to local minima and depth ambiguity. In this work,we leverage large vision-language models (VLMs) to generate interactive bodypart descriptions, which serve as implicit constraints to enhance 3D perceptionand limit the optimization space. Specifically, we formulate monocular humanmesh recovery as a distribution adaptation task by integrating both 2Dobservations and language descriptions. To bridge the gap between text and 3Dpose signals, we first train a text encoder and a pose VQ-VAE, aligning textsto body poses in a shared latent space using contrastive learning.Subsequently, we employ a diffusion-based framework to refine the initialparameters guided by gradients derived from both 2D observations and textdescriptions. Finally, the model can produce poses with accurate 3D perceptionand image consistency. Experimental results on multiple benchmarks validate itseffectiveness. The code will be made publicly available.",Chongyang Xu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03835v1,Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance,http://arxiv.org/abs/2502.03835v1,"Single-domain generalization for object detection (S-DGOD) aims to transferknowledge from a single source domain to unseen target domains. In recentyears, many models have focused primarily on achieving feature invariance toenhance robustness. However, due to the inherent diversity across domains, anexcessive emphasis on invariance can cause the model to overlook the actualdifferences between images. This overemphasis may complicate the trainingprocess and lead to a loss of valuable information. To address this issue, wepropose the Diversity Invariance Detection Model (DIDM), which focuses on thebalance between the diversity of domain-specific and invariance cross domains.Recognizing that domain diversity introduces variations in domain-specificfeatures, we introduce a Diversity Learning Module (DLM). The DLM is designedto preserve the diversity of domain-specific information with proposed featurediversity loss while limiting the category semantics in the features. Inaddition, to maintain domain invariance, we incorporate a Weighted AligningModule (WAM), which aligns features without compromising feature diversity. Weconducted our model on five distinct datasets, which have illustrated thesuperior performance and effectiveness of the proposed model.",Zhenwei He,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03833v1,Properties of the emission region in pulsars with opposite subpulse drift directions in different profile components,http://arxiv.org/abs/2502.03833v1,"We investigate properties of the emission region as revealed by driftingsubpulses of opposite drift directions at different parts of a pulse profile byusing the rotating carousel model in an obliquely rotating pulsar magnetosphereof multiple emission states. Subpulse emission is assumed coming from mdiscrete emission areas that are distributed around the magnetic axis on arotating carousel. The flow rate of the emission areas is determined by the E xB drift in an emission state, designated by the parameter y, in which E and theassociated flow rate are dependent on y. In this model, subpulses appear todrift in an emission state if a relative speed exists between the plasma flowand corotation, and the diversity in the drift rates and directions correspondsto the relative speed being different in different parts of a profile. We applythe model to three pulsars that exhibit drifting subpulses of opposite driftdirections to identify the emission states and the values of m. Our resultsshow that different drifting subpulses correspond to particular values of m andy, and the latter implies that different emission states can coexist andoperate concurrently in an emission region. We find that m does not show cleardependency on either the obliquity angle or emission state. We demonstrate thatsubpulse arrangement may vary across an emission region meaning that it is notalways uniform on a carousel. We discuss drifting subpulses of opposite driftdirections and subpulse drift-rate switching in terms of different emissionstates in our model, and speculate that they may be two manifestations of thesame underlying mechanism.",H. M. Tedila,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03832v1,Correlated helimagnetic configuration in a nonsymmorphic magnetic nodal semimetal,http://arxiv.org/abs/2502.03832v1,"Nonsymmorphic magnetic Weyl semimetal materials such as ReAlX (Re=rare earth,X=Si/Ge) provide a unique opportunity to explore the correlated phenomenabetween Weyl fermions and nontrivial magnetic configurations. To be specific,we study a lattice model in which the magnetic configuration is determined bythe competition among ferromagnetic (FM) interaction, the Dzyaloshinsky-Moriyainteraction, and the Kondo coupling $K_0$ to the Weyl fermion. Both quantum andfinite-temperature phase transitions between FM and correlated nesting helicalconfigurations are found. Different from the uncorrelated helimagnet thatdecouples to the Weyl fermions, this correlated helimagnet induces a magneticBrillouin zone with a $K_0$-dependent nesting in the band structure of theconducting fermions instead of the magnetic monopole-like Weyl cone. Bymeasuring the current induced by the chiral magnetic effect on the conductingfermion with nesting Weyl nodes, one can distinguish the correlated nestinghelical order and the ferromagnetism because the chiral magnetic effect isconsiderably suppressed in the former case. These properties we study here mayexplain the experimental observations in ReAlX.",Xi Luo,2025-02-06,2025-02-06,,N/A,['cond-mat.mes-hall']
2502.03831v1,Optimizing Bayesian model selection for equation of state of cold neutron stars,http://arxiv.org/abs/2502.03831v1,"We introduce a computational framework, Bayesian Evidence calculation fOrModel Selection (BEOMS) to evaluate multiple Bayesian model selection methodsin the context of determining the equation of state (EOS) for cold neutron star(NS), focusing on their performance with current and next-generationgravitational wave (GW) observatories. We conduct a systematic comparison ofvarious EOS models by using posterior distributions obtained from EOS-agnosticBayesian inference of binary parameters applied to GWs from a population ofbinary neutron star (BNS) mergers. The cumulative evidence for each model iscalculated in a multi-dimensional parameter space characterized by neutron starmasses and tidal deformabilities. Our findings indicate that Bayesian modelselection is most effective when performed in the two-dimensional subspace ofcomponent mass and tidal deformability, requiring fewer events to distinguishbetween EOS models with high confidence. Furthermore, we establish arelationship between the precision of tidal deformability measurements and theaccuracy of model selection, taking into account the evolving sensitivities ofcurrent and planned GW observatories. BEOMS offers computational efficiency andcan be adapted to execute model selection for gravitational wave data fromother sources.",Rahul Kashyap,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'astro-ph.HE', 'astro-ph.IM']"
2502.04400v1,Adaptive Prototype Knowledge Transfer for Federated Learning with Mixed Modalities and Heterogeneous Tasks,http://arxiv.org/abs/2502.04400v1,"Multimodal Federated Learning (MFL) enables multiple clients tocollaboratively train models on multimodal data while ensuring clients'privacy. However, modality and task heterogeneity hinder clients from learninga unified representation, weakening local model generalization, especially inMFL with mixed modalities where only some clients have multimodal data. In thiswork, we propose an Adaptive prototype-based Multimodal Federated Learning(AproMFL) framework for mixed modalities and heterogeneous tasks to address theaforementioned issues. Our AproMFL transfers knowledge throughadaptively-constructed prototypes without a prior public dataset. Clientsadaptively select prototype construction methods in line with tasks; serverconverts client prototypes into unified multimodal prototypes and aggregatesthem to form global prototypes, avoid clients keeping unified labels. We dividethe model into various modules and only aggregate mapping modules to reducecommunication and computation overhead. To address aggregation issues inheterogeneity, we develop a client relationship graph-based scheme todynamically adjust aggregation weights. Extensive experiments on representativedatasets evidence effectiveness of AproMFL.",Keke Gai,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CR', 'cs.MM']"
2502.03829v1,FE-UNet: Frequency Domain Enhanced U-Net with Segment Anything Capability for Versatile Image Segmentation,http://arxiv.org/abs/2502.03829v1,"Image segmentation is a critical task in visual understanding. ConvolutionalNeural Networks (CNNs) are predisposed to capture high-frequency features inimages, while Transformers exhibit a contrasting focus on low-frequencyfeatures. In this paper, we experimentally quantify the contrast sensitivityfunction of CNNs and compare it with that of the human visual system, informedby the seminal experiments of Mannos and Sakrison. Leveraging these insights,we propose the Wavelet-Guided Spectral Pooling Module (WSPM) to enhance andbalance image features across the frequency domain. To further emulate thehuman visual system, we introduce the Frequency Domain Enhanced Receptive FieldBlock (FE-RFB), which integrates WSPM to extract enriched features from thefrequency domain. Building on these innovations, we develop FE-UNet, a modelthat utilizes SAM2 as its backbone and incorporates Hiera-Large as apre-trained block, designed to enhance generalization capabilities whileensuring high segmentation accuracy. Experimental results demonstrate thatFE-UNet achieves state-of-the-art performance in diverse tasks, includingmarine animal and polyp segmentation, underscoring its versatility andeffectiveness.",Guohao Huo,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03827v1,"A comprehensive survey of contemporary Arabic sentiment analysis: Methods, Challenges, and Future Directions",http://arxiv.org/abs/2502.03827v1,"Sentiment Analysis, a popular subtask of Natural Language Processing, employscomputational methods to extract sentiment, opinions, and other subjectiveaspects from linguistic data. Given its crucial role in understanding humansentiment, research in sentiment analysis has witnessed significant growth inthe recent years. However, the majority of approaches are aimed at the Englishlanguage, and research towards Arabic sentiment analysis remains relativelyunexplored. This paper presents a comprehensive and contemporary survey ofArabic Sentiment Analysis, identifies the challenges and limitations ofexisting literature in this field and presents avenues for future research. Wepresent a systematic review of Arabic sentiment analysis methods, focusingspecifically on research utilizing deep learning. We then situate ArabicSentiment Analysis within the broader context, highlighting research gaps inArabic sentiment analysis as compared to general sentiment analysis. Finally,we outline the main challenges and promising future directions for research inArabic sentiment analysis.",Zhiqiang Shi,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04399v1,Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning,http://arxiv.org/abs/2502.04399v1,"Advances in artificial intelligence (AI) including foundation models (FMs),are increasingly transforming human society, with smart city driving theevolution of urban living.Meanwhile, vehicle crowdsensing (VCS) has emerged asa key enabler, leveraging vehicles' mobility and sensor-equipped capabilities.In particular, ride-hailing vehicles can effectively facilitate flexible datacollection and contribute towards urban intelligence, despite resourcelimitations. Therefore, this work explores a promising scenario, whereedge-assisted vehicles perform joint tasks of order serving and the emergingfoundation model fine-tuning using various urban data. However, integrating theVCS AI task with the conventional order serving task is challenging, due totheir inconsistent spatio-temporal characteristics: (i) The distributions ofride orders and data point-of-interests (PoIs) may not coincide in geography,both following a priori unknown patterns; (ii) they have distinct forms oftemporal effects, i.e., prolonged waiting makes orders become instantly invalidwhile data with increased staleness gradually reduces its utility for modelfine-tuning.To overcome these obstacles, we propose an online framework basedon multi-agent reinforcement learning (MARL) with careful augmentation. A newquality-of-service (QoS) metric is designed to characterize and balance theutility of the two joint tasks, under the effects of varying data volumes andstaleness. We also integrate graph neural networks (GNNs) with MARL to enhancestate representations, capturing graph-structured, time-varying dependenciesamong vehicles and across locations. Extensive experiments on our testbedsimulator, utilizing various real-world foundation model fine-tuning tasks andthe New York City Taxi ride order dataset, demonstrate the advantage of ourproposed method.",Bokeng Zheng,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY']"
2502.03826v1,FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing,http://arxiv.org/abs/2502.03826v1,"The proliferation of Text-to-Image (T2I) models has revolutionized contentcreation, providing powerful tools for diverse applications ranging fromartistic expression to educational material development and marketing. Despitethese technological advancements, significant ethical concerns arise from thesemodels' reliance on large-scale datasets that often contain inherent societalbiases. These biases are further amplified when AI-generated content isincluded in training data, potentially reinforcing and perpetuating stereotypesin the generated outputs. In this paper, we introduce FairT2I, a novelframework that harnesses large language models to detect and mitigate socialbiases in T2I generation. Our framework comprises two key components: (1) anLLM-based bias detection module that identifies potential social biases ingenerated images based on text prompts, and (2) an attribute rebalancing modulethat fine-tunes sensitive attributes within the T2I model to mitigateidentified biases. Our extensive experiments across various T2I models anddatasets show that FairT2I can significantly reduce bias while maintaininghigh-quality image generation. We conducted both qualitative user studies andquantitative non-parametric analyses in the generated image feature space,building upon the occupational dataset introduced in the Stable Bias study. Ourresults show that FairT2I successfully mitigates social biases and enhances thediversity of sensitive attributes in generated images. We further demonstrate,using the P2 dataset, that our framework can detect subtle biases that arechallenging for human observers to perceive, extending beyondoccupation-related prompts. On the basis of these findings, we introduce a newbenchmark dataset for evaluating bias in T2I models.",Jinya Sakurai,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03825v1,Synthetic Poisoning Attacks: The Impact of Poisoned MRI Image on U-Net Brain Tumor Segmentation,http://arxiv.org/abs/2502.03825v1,"Deep learning-based medical image segmentation models, such as U-Net, rely onhigh-quality annotated datasets to achieve accurate predictions. However, theincreasing use of generative models for synthetic data augmentation introducespotential risks, particularly in the absence of rigorous quality control. Inthis paper, we investigate the impact of synthetic MRI data on the robustnessand segmentation accuracy of U-Net models for brain tumor segmentation.Specifically, we generate synthetic T1-contrast-enhanced (T1-Ce) MRI scansusing a GAN-based model with a shared encoding-decoding framework andshortest-path regularization. To quantify the effect of synthetic datacontamination, we train U-Net models on progressively ""poisoned"" datasets,where synthetic data proportions range from 16.67% to 83.33%. Experimentalresults on a real MRI validation set reveal a significant performancedegradation as synthetic data increases, with Dice coefficients dropping from0.8937 (33.33% synthetic) to 0.7474 (83.33% synthetic). Accuracy andsensitivity exhibit similar downward trends, demonstrating the detrimentaleffect of synthetic data on segmentation robustness. These findings underscorethe importance of quality control in synthetic data integration and highlightthe risks of unregulated synthetic augmentation in medical image analysis. Ourstudy provides critical insights for the development of more reliable andtrustworthy AI-driven medical imaging systems.",Tianhao Li,2025-02-06,2025-02-06,,N/A,"['eess.IV', 'cs.CR', 'cs.CV']"
2502.03824v1,Syntriever: How to Train Your Retriever with Synthetic Data from LLMs,http://arxiv.org/abs/2502.03824v1,"LLMs have boosted progress in many AI applications. Recently, there wereattempts to distill the vast knowledge of LLMs into information retrievalsystems. Those distillation methods mostly use output probabilities of LLMswhich are unavailable in the latest black-box LLMs. We propose Syntriever, atraining framework for retrievers using synthetic data from black-box LLMs.Syntriever consists of two stages. Firstly in the distillation stage, wesynthesize relevant and plausibly irrelevant passages and augmented queriesusing chain-of-thoughts for the given queries. LLM is asked to self-verify thesynthetic data for possible hallucinations, after which retrievers are trainedwith a loss designed to cluster the embeddings of relevant passages. Secondlyin the alignment stage, we align the retriever with the preferences of LLMs. Wepropose a preference modeling called partial Plackett-Luce ranking to learn LLMpreferences with regularization which prevents the model from deviatingexcessively from that trained in the distillation stage. Experiments show thatSyntriever achieves state-of-the-art performances on benchmark datasets fromvarious domains in nDCG@$K$. The code is available at\href{https://github.com/kmswin1/Syntriever}{https://github.com/kmswin1/Syntriever}.",Minsang Kim,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03822v2,Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible Training,http://arxiv.org/abs/2502.03822v2,"Diffusion policies trained via offline behavioral cloning have recentlygained traction in robotic motion generation. While effective, these policiestypically require a large number of trainable parameters. This model sizeaffords powerful representations but also incurs high computational cost duringtraining. Ideally, it would be beneficial to dynamically adjust the trainableportion as needed, balancing representational power with computationalefficiency. For example, while overparameterization enables diffusion policiesto capture complex robotic behaviors via offline behavioral cloning, theincreased computational demand makes online interactive imitation learningimpractical due to longer training time. To address this challenge, we presenta framework, called DRIFT, that uses the Singular Value Decomposition to enabledynamic rank adjustment during diffusion policy training. We implement anddemonstrate the benefits of this framework in DRIFT-DAgger, an imitationlearning algorithm that can seamlessly slide between an offline bootstrappingphase and an online interactive phase. We perform extensive experiments tobetter understand the proposed framework, and demonstrate that DRIFT-DAggerachieves improved sample efficiency and faster training with minimal impact onmodel performance.",Xiatao Sun,2025-02-06,2025-02-07,,N/A,['cs.RO']
2502.03821v1,PsyPlay: Personality-Infused Role-Playing Conversational Agents,http://arxiv.org/abs/2502.03821v1,"The current research on Role-Playing Conversational Agents (RPCAs) with LargeLanguage Models (LLMs) primarily focuses on imitating specific speaking stylesand utilizing character backgrounds, neglecting the depiction of deeperpersonality traits.~In this study, we introduce personality-infusedrole-playing for LLM agents, which encourages agents to accurately portraytheir designated personality traits during dialogues. We then propose PsyPlay,a dialogue generation framework that facilitates the expression of richpersonalities among multiple LLM agents. Specifically, PsyPlay enables agentsto assume roles with distinct personality traits and engage in discussionscentered around specific topics, consistently exhibiting their designatedpersonality traits throughout the interactions. Validation on generateddialogue data demonstrates that PsyPlay can accurately portray the intendedpersonality traits, achieving an overall success rate of 80.31% on GPT-3.5.Notably, we observe that LLMs aligned with positive values are more successfulin portraying positive personality roles compared to negative ones. Moreover,we construct a dialogue corpus for personality-infused role-playing, calledPsyPlay-Bench. The corpus, which consists of 4745 instances of correctlyportrayed dialogues using PsyPlay, aims to further facilitate research inpersonalized role-playing and dialogue personality detection.",Tao Yang,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03817v1,Knowing When to Stop Matters: A Unified Algorithm for Online Conversion under Horizon Uncertainty,http://arxiv.org/abs/2502.03817v1,"This paper investigates the online conversion problem, which involvessequentially trading a divisible resource (e.g., energy) under dynamicallychanging prices to maximize profit. A key challenge in online conversion ismanaging decisions under horizon uncertainty, where the duration of trading iseither known, revealed partway, or entirely unknown. We propose a unifiedalgorithm that achieves optimal competitive guarantees across these horizonmodels, accounting for practical constraints such as box constraints, whichlimit the maximum allowable trade per step. Additionally, we extend thealgorithm to a learning-augmented version, leveraging horizon predictions toadaptively balance performance: achieving near-optimal results when predictionsare accurate while maintaining strong guarantees when predictions areunreliable. These results advance the understanding of online conversion undervarious degrees of horizon uncertainty and provide more practical strategies toaddress real world constraints.",Yanzhao Wang,2025-02-06,2025-02-06,,N/A,"['cs.DS', 'cs.LG']"
2502.04397v1,Multimodal Medical Code Tokenizer,http://arxiv.org/abs/2502.04397v1,"Foundation models trained on patient electronic health records (EHRs) requiretokenizing medical data into sequences of discrete vocabulary items. Existingtokenizers treat medical codes from EHRs as isolated textual tokens. However,each medical code is defined by its textual description, its position inontological hierarchies, and its relationships to other codes, such as diseaseco-occurrences and drug-treatment associations. Medical vocabularies containmore than 600,000 codes with critical information for clinical reasoning. Weintroduce MedTok, a multimodal medical code tokenizer that uses the textdescriptions and relational context of codes. MedTok processes text using alanguage model encoder and encodes the relational structure with a graphencoder. It then quantizes both modalities into a unified token space,preserving modality-specific and cross-modality information. We integrateMedTok into five EHR models and evaluate it on operational and clinical tasksacross in-patient and out-patient datasets, including outcome prediction,diagnosis classification, drug recommendation, and risk stratification.Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHRmodels, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, withthe largest gains in drug recommendation. Beyond EHR modeling, we demonstrateusing MedTok tokenizer with medical QA systems. Our results demonstrate thepotential of MedTok as a unified tokenizer for medical codes, improvingtokenization for medical foundation models.",Xiaorui Su,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.03814v1,Large Language Models for Multi-Robot Systems: A Survey,http://arxiv.org/abs/2502.03814v1,"The rapid advancement of Large Language Models (LLMs) has opened newpossibilities in Multi-Robot Systems (MRS), enabling enhanced communication,task planning, and human-robot interaction. Unlike traditional single-robot andmulti-agent systems, MRS poses unique challenges, including coordination,scalability, and real-world adaptability. This survey provides the firstcomprehensive exploration of LLM integration into MRS. It systematicallycategorizes their applications across high-level task allocation, mid-levelmotion planning, low-level action generation, and human intervention. Wehighlight key applications in diverse domains, such as household robotics,construction, formation control, target tracking, and robot games, showcasingthe versatility and transformative potential of LLMs in MRS. Furthermore, weexamine the challenges that limit adapting LLMs in MRS, including mathematicalreasoning limitations, hallucination, latency issues, and the need for robustbenchmarking systems. Finally, we outline opportunities for future research,emphasizing advancements in fine-tuning, reasoning techniques, andtask-specific models. This survey aims to guide researchers in the intelligenceand real-world deployment of MRS powered by LLMs. Based on the fast-evolvingnature of research in the field, we keep updating the papers in the open-sourceGithub repository.",Peihan Li,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.03813v1,Optimized Unet with Attention Mechanism for Multi-Scale Semantic Segmentation,http://arxiv.org/abs/2502.03813v1,"Semantic segmentation is one of the core tasks in the field of computervision, and its goal is to accurately classify each pixel in an image. Thetraditional Unet model achieves efficient feature extraction and fusion throughan encoder-decoder structure, but it still has certain limitations when dealingwith complex backgrounds, long-distance dependencies, and multi-scale targets.To this end, this paper proposes an improved Unet model combined with anattention mechanism, introduces channel attention and spatial attentionmodules, enhances the model's ability to focus on important features, andoptimizes skip connections through a multi-scale feature fusion strategy,thereby improving the combination of global semantic information andfine-grained features. The experiment is based on the Cityscapes dataset andcompared with classic models such as FCN, SegNet, DeepLabv3+, and PSPNet. Theimproved model performs well in terms of mIoU and pixel accuracy (PA), reaching76.5% and 95.3% respectively. The experimental results verify the superiorityof this method in dealing with complex scenes and blurred target boundaries. Inaddition, this paper discusses the potential of the improved model in practicalapplications and future expansion directions, indicating that it has broadapplication value in fields such as autonomous driving, remote sensing imageanalysis, and medical image processing.",Xuan Li,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03812v1,Numerical study on wave attenuation via 2D fully kinetic electromagnetic particle-in-cell simulations,http://arxiv.org/abs/2502.03812v1,"The propagation and absorption of electromagnetic waves in plasma is one ofthe fundamental issues in plasma physics. The electromagnetic particle-in-cellmethod with the finite-difference time-domain solver plus Monte Carlo collisionmodel would be the most accurate method to simulate the wave-plasmainteraction. However, the numerical effects of this method have not beencarefully investigated especially in two dimensions. In this paper, the 2D PICmethod is used to study the electromagnetic wave attenuation by fluorescentlamp plasma tubes. The study finds that the number of macro-particles and theincident electromagnetic wave amplitude have minor effects on the waveattenuation within a certain appropriate parameter range. Furthermore, theeffects of electromagnetic wave frequency, the plasma distribution structures,and collision types on wave attenuation are investigated. Particularly, it isfound that the staggered way of arranging the plasma tubes can achieve betterwave attenuation than the parallel way, which agrees with our recentexperimental observation.",Fei Du,2025-02-06,2025-02-06,,N/A,['physics.plasm-ph']
2502.03810v1,DeblurDiff: Real-World Image Deblurring with Generative Diffusion Models,http://arxiv.org/abs/2502.03810v1,"Diffusion models have achieved significant progress in image generation. Thepre-trained Stable Diffusion (SD) models are helpful for image deblurring byproviding clear image priors. However, directly using a blurry image orpre-deblurred one as a conditional control for SD will either hinder accuratestructure extraction or make the results overly dependent on the deblurringnetwork. In this work, we propose a Latent Kernel Prediction Network (LKPN) toachieve robust real-world image deblurring. Specifically, we co-train the LKPNin latent space with conditional diffusion. The LKPN learns a spatially variantkernel to guide the restoration of sharp images in the latent space. Byapplying element-wise adaptive convolution (EAC), the learned kernel isutilized to adaptively process the input feature, effectively preserving thestructural information of the input. This process thereby more effectivelyguides the generative process of Stable Diffusion (SD), enhancing both thedeblurring efficacy and the quality of detail reconstruction. Moreover, theresults at each diffusion step are utilized to iteratively estimate the kernelsin LKPN to better restore the sharp latent by EAC. This iterative refinementenhances the accuracy and robustness of the deblurring process. Extensiveexperimental results demonstrate that the proposed method outperformsstate-of-the-art image deblurring methods on both benchmark and real-worldimages.",Lingshun Kong,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03809v1,Bayesian Time-Varying Meta-Analysis via Hierarchical Mean-Variance Random-effects Models,http://arxiv.org/abs/2502.03809v1,"Meta-analysis is widely used to integrate results from multiple experimentsto obtain generalized insights. Since meta-analysis datasets are oftenheteroscedastic due to varying subgroups and temporal heterogeneity arisingfrom experiments conducted at different time points, the typical meta-analysisapproach, which assumes homoscedasticity, fails to adequately address thisheteroscedasticity among experiments. This paper proposes a new Bayesianestimation method that simultaneously shrinks estimates of the means andvariances of experiments using a hierarchical Bayesian approach whileaccounting for time effects through a Gaussian process. This method connectsexperiments via the hierarchical framework, enabling ""borrowing strength""between experiments to achieve high-precision estimates of each experiment'smean. The method can flexibly capture potential time trends in datasets bymodeling time effects with the Gaussian process. We demonstrate theeffectiveness of the proposed method through simulation studies and illustrateits practical utility using a real marketing promotions dataset.",Kohsuke Kubota,2025-02-06,2025-02-06,,N/A,"['stat.ME', '62-08']"
2502.03808v1,Pre-stack and post-stack seismic inversion using quantum computing,http://arxiv.org/abs/2502.03808v1,"Quantum computing harnesses the principles of quantum mechanics to solveproblems that are intractable for classical computers. Quantum annealing, aspecialized approach within quantum computing, is particularly effective foroptimization tasks, as it leverages quantum tunneling to escape local minimaand efficiently explore complex energy landscapes. In geosciences, manyproblems are framed as high-dimensional optimization problems, includingseismic inversion, which aims to estimate subsurface impedances from seismicdata for accurate geological interpretation and resource exploration. Thisstudy presents a novel application of quantum computing for seismic inversion,marking the first instance of inverting seismic data to estimate both P-waveand S-wave impedances using a quantum annealer. Building upon our prior work,which demonstrated the estimation of acoustic impedances from post-stack datausing a two-step framework, we propose an enhanced workflow capable ofinverting both post-stack and pre-stack seismic data in a single step. Thisadvancement significantly reduces the number of qubits per model parameter(from 20 to 5) while improving computational speed (from 20 seconds to 6.3seconds). The seismic inversion is implemented using the D-Wave Leap hybridsolver, achieving impedance estimation within 4-9 seconds, with the quantumprocessing unit (QPU) contributing just 0.043-0.085 seconds. Comparativeanalysis with simulated annealing reveals that quantum annealing producesimpedance models closely matching true values in a single epoch, whereassimulated annealing requires 10 epochs for improved accuracy. These findingsunderscore the transformative potential of quantum computing for real-time,high-precision seismic inversion, marking a crucial step toward fullyquantum-driven geophysical solutions.",Divakar Vashisth,2025-02-06,2025-02-06,,N/A,"['quant-ph', 'physics.geo-ph']"
2502.03806v1,Should Code Models Learn Pedagogically? A Preliminary Evaluation of Curriculum Learning for Real-World Software Engineering Tasks,http://arxiv.org/abs/2502.03806v1,"Learning-based techniques, especially advanced pre-trained models for codehave demonstrated capabilities in code understanding and generation, solvingdiverse software engineering (SE) tasks. Despite the promising results, currenttraining approaches may not fully optimize model performance, as they typicallyinvolve learning from randomly shuffled training data. Recent work shows thatCurriculum Learning (CL) can improve performance on code-related tasks throughincremental learning based on the difficulty of synthetic code. Yet, theeffectiveness of CL with conventional difficulty measures in SE tasks remainslargely unexplored. In this study, we explore two conventional code metrics:code length and cyclomatic complexity to determine the difficulty levels. Weinvestigate how the pre-trained code model (CodeT5) learns under CL, throughthe tasks of code clone detection and code summarization. Our empirical studyon the CodeXGLUE benchmark showed contrasting results to prior studies, wherethe model exhibited signs of catastrophic forgetting and shortcut learning.Surprisingly, model performance saturates after only the first quartile oftraining, potentially indicating a limit in the model's representation capacityand/or the task's inherent difficulty. Future work should further explorevarious CL strategies with different code models across a wider range of SEtasks for a more holistic understanding.",Kyi Shin Khant,2025-02-06,2025-02-06,,N/A,"['cs.SE', 'cs.LG']"
2502.03805v1,Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective,http://arxiv.org/abs/2502.03805v1,"Large language models have revolutionized natural language processing butface significant challenges of high storage and runtime costs, due to thetransformer architecture's reliance on self-attention, particularly the largeKey-Value (KV) cache for long-sequence inference. Recent efforts to reduce KVcache size by pruning less critical entries based on attention weights remainempirical and lack formal grounding. This paper presents a formal study onidentifying critical KV cache entries by analyzing attention outputperturbation. Our analysis reveals that, beyond attention weights, the valuestates within KV entries and pretrained parameter matrices are also crucial.Based on this, we propose a perturbation-constrained selection algorithm thatoptimizes the worst-case output perturbation to identify critical entries.Evaluations on the Needle-in-a-Haystack test and Longbench benchmark show ouralgorithm enhances state-of-the-art cache eviction methods. Further empiricalanalysis confirms that our algorithm achieves lower output perturbations inover 92% attention heads in Llama model, thereby providing a significantimprovement over existing methods.",Yuan Feng,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03804v2,Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions,http://arxiv.org/abs/2502.03804v2,"Replying to formal emails is time-consuming and cognitively demanding, as itrequires crafting polite phrasing and providing an adequate response to thesender's demands. Although systems with Large Language Models (LLMs) weredesigned to simplify the email replying process, users still need to providedetailed prompts to obtain the expected output. Therefore, we proposed andevaluated an LLM-powered question-and-answer (QA)-based approach for users toreply to emails by answering a set of simple and short questions generated fromthe incoming email. We developed a prototype system, ResQ, and conductedcontrolled and field experiments with 12 and 8 participants. Our resultsdemonstrated that the QA-based approach improves the efficiency of replying toemails and reduces workload while maintaining email quality, compared to aconventional prompt-based approach that requires users to craft appropriateprompts to obtain email drafts. We discuss how the QA-based approach influencesthe email reply process and interpersonal relationship dynamics, as well as theopportunities and challenges associated with using a QA-based approach inAI-mediated communication.",Yusuke Miura,2025-02-06,2025-02-07,,N/A,"['cs.HC', 'cs.AI']"
2502.03803v1,Graph Neural Network-Driven Hierarchical Mining for Complex Imbalanced Data,http://arxiv.org/abs/2502.03803v1,"This study presents a hierarchical mining framework for high-dimensionalimbalanced data, leveraging a depth graph model to address the inherentperformance limitations of conventional approaches in handling complex,high-dimensional data distributions with imbalanced sample representations. Byconstructing a structured graph representation of the dataset and integratinggraph neural network (GNN) embeddings, the proposed method effectively capturesglobal interdependencies among samples. Furthermore, a hierarchical strategy isemployed to enhance the characterization and extraction of minority classfeature patterns, thereby facilitating precise and robust imbalanced datamining. Empirical evaluations across multiple experimental scenarios validatethe efficacy of the proposed approach, demonstrating substantial improvementsover traditional methods in key performance metrics, including patterndiscovery count, average support, and minority class coverage. Notably, themethod exhibits superior capabilities in minority-class feature extraction andpattern correlation analysis. These findings underscore the potential of depthgraph models, in conjunction with hierarchical mining strategies, tosignificantly enhance the efficiency and accuracy of imbalanced data analysis.This research contributes a novel computational framework for high-dimensionalcomplex data processing and lays the foundation for future extensions todynamically evolving imbalanced data and multi-modal data applications, therebyexpanding the applicability of advanced data mining methodologies to moreintricate analytical domains.",Yijiashun Qi,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03802v1,MXMap: A Multivariate Cross Mapping Framework for Causal Discovery in Dynamical Systems,http://arxiv.org/abs/2502.03802v1,"Convergent Cross Mapping (CCM) is a powerful method for detecting causalityin coupled nonlinear dynamical systems, providing a model-free approach tocapture dynamic causal interactions. Partial Cross Mapping (PCM) was introducedas an extension of CCM to address indirect causality in three-variable systemsby comparing cross-mapping quality between direct cause-effect mapping andindirect mapping through an intermediate conditioning variable. However, PCMremains limited to univariate delay embeddings in its cross-mapping processes.In this work, we extend PCM to the multivariate setting, introducing multiPCM,which leverages multivariate embeddings to more effectively distinguishindirect causal relationships. We further propose a multivariate cross-mappingframework (MXMap) for causal discovery in dynamical systems. This two-phaseframework combines (1) pairwise CCM tests to establish an initial causal graphand (2) multiPCM to refine the graph by pruning indirect causal connections.Through experiments on simulated data and the ERA5 Reanalysis weather dataset,we demonstrate the effectiveness of MXMap. Additionally, MXMap is comparedagainst several baseline methods, showing advantages in accuracy and causalgraph refinement.",Elise Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.DS', 'stat.ME']"
2502.04396v1,On the extension of the concept of rheological connections to a finite deformation framework using multiple natural configurations,http://arxiv.org/abs/2502.04396v1,"The constitutive behaviors of materials are often modeled using a network ofdifferent rheological elements. These rheological models are mostly developedwithin a one-dimensional small strain framework. One of the key impediments ofextending these models to a three-dimensional finite deformation setting is todetermine how the different types of connections, i.e., a series and a parallelconnection, are incorporated into the material models. The primary objective ofthis article is to develop an appropriate strategy to address this issue. Weshow that both the series and the parallel connection between two rheologicalelements can be modeled within a multiple natural configurations frameworkwithout changing or introducing new configurations. The difference in a seriesand a parallel connection is manifested in the ratio of the stress powersexpended during the deformations of the associated rheological elements. Finitedeformation version of some well-known rheological models have been used todemonstrate the utility of the proposed theory.",Tarun Singh,2025-02-06,2025-02-06,,N/A,['cond-mat.mtrl-sci']
2502.03801v1,SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning,http://arxiv.org/abs/2502.03801v1,"Federated learning (FL) enables collaborative model training while preservingdata privacy, but its decentralized nature exposes it to client-side datapoisoning attacks (DPAs) and model poisoning attacks (MPAs) that degrade globalmodel performance. While numerous proposed defenses claim substantialeffectiveness, their evaluation is typically done in isolation with limitedattack strategies, raising concerns about their validity. Additionally,existing studies overlook the mutual effectiveness of defenses against bothDPAs and MPAs, causing fragmentation in this field. This paper aims to providea unified benchmark and analysis of defenses against DPAs and MPAs, clarifyingthe distinction between these two similar but slightly distinct domains. Wepresent a systematic taxonomy of poisoning attacks and defense strategies,outlining their design, strengths, and limitations. Then, a unified comparativeevaluation across FL algorithms and data heterogeneity is conducted to validatetheir individual and mutual effectiveness and derive key insights for designprinciples and future research. Along with the analysis, we frame our work to aunified benchmark, FLPoison, with high modularity and scalability to evaluate15 representative poisoning attacks and 17 defense strategies, facilitatingfuture research in this domain. Code is available athttps://github.com/vio1etus/FLPoison.",Heyi Zhang,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.AI', 'cs.LG']"
2502.03799v1,Enhancing Hallucination Detection through Noise Injection,http://arxiv.org/abs/2502.03799v1,"Large Language Models (LLMs) are prone to generating plausible yet incorrectresponses, known as hallucinations. Effectively detecting hallucinations istherefore crucial for the safe deployment of LLMs. Recent research has linkedhallucinations to model uncertainty, suggesting that hallucinations can bedetected by measuring dispersion over answer distributions obtained from a setof samples drawn from a model. While drawing from the distribution over tokensdefined by the model is a natural way to obtain samples, in this work, we arguethat it is sub-optimal for the purpose of detecting hallucinations. We showthat detection can be improved significantly by taking into account modeluncertainty in the Bayesian sense. To this end, we propose a very simple andefficient approach that perturbs an appropriate subset of model parameters, orequivalently hidden unit activations, during sampling. We demonstrate itseffectiveness across a wide range of datasets and model architectures.",Litian Liu,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.SY', 'eess.SY']"
2502.04395v1,Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting,http://arxiv.org/abs/2502.04395v1,"Recent advancements in time series forecasting have explored augmentingmodels with text or vision modalities to improve accuracy. While text providescontextual understanding, it often lacks fine-grained temporal details.Conversely, vision captures intricate temporal patterns but lacks semanticcontext, limiting the complementary potential of these modalities. To addressthis, we propose Time-VLM, a novel multimodal framework that leveragespre-trained Vision-Language Models (VLMs) to bridge temporal, visual, andtextual modalities for enhanced forecasting. Our framework comprises three keycomponents: (1) a Retrieval-Augmented Learner, which extracts enriched temporalfeatures through memory bank interactions; (2) a Vision-Augmented Learner,which encodes time series as informative images; and (3) a Text-AugmentedLearner, which generates contextual textual descriptions. These componentscollaborate with frozen pre-trained VLMs to produce multimodal embeddings,which are then fused with temporal features for final prediction. Extensiveexperiments across diverse datasets demonstrate that Time-VLM achieves superiorperformance, particularly in few-shot and zero-shot scenarios, therebyestablishing a new direction for multimodal time series forecasting.",Siru Zhong,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.03798v1,Network-Wide Traffic Flow Estimation Across Multiple Cities with Global Open Multi-Source Data: A Large-Scale Case Study in Europe and North America,http://arxiv.org/abs/2502.03798v1,"Network-wide traffic flow, which captures dynamic traffic volume on each linkof a general network, is fundamental to smart mobility applications. However,the observed traffic flow from sensors is usually limited across the entirenetwork due to the associated high installation and maintenance costs. Toaddress this issue, existing research uses various supplementary data sourcesto compensate for insufficient sensor coverage and estimate the unobservedtraffic flow. Although these studies have shown promising results, theinconsistent availability and quality of supplementary data across cities maketheir methods typically face a trade-off challenge between accuracy andgenerality. In this research, we first time advocate using the Global OpenMulti-Source (GOMS) data within an advanced deep learning framework to breakthe trade-off. The GOMS data primarily encompass geographical and demographicinformation, including road topology, building footprints, and populationdensity, which can be consistently collected across cities. More importantly,these GOMS data are either causes or consequences of transportation activities,thereby creating opportunities for accurate network-wide flow estimation.Furthermore, we use map images to represent GOMS data, instead of traditionaltabular formats, to capture richer and more comprehensive geographical anddemographic information. To address multi-source data fusion, we develop anattention-based graph neural network that effectively extracts and synthesizesinformation from GOMS maps while simultaneously capturing spatiotemporaltraffic dynamics from observed traffic data. A large-scale case study across 15cities in Europe and North America was conducted. The results demonstratestable and satisfactory estimation accuracy across these cities, which suggeststhat the trade-off challenge can be successfully addressed using our approach.",Zijian Hu,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03795v1,Distribution learning via neural differential equations: minimal energy regularization and approximation theory,http://arxiv.org/abs/2502.03795v1,"Neural ordinary differential equations (ODEs) provide expressiverepresentations of invertible transport maps that can be used to approximatecomplex probability distributions, e.g., for generative modeling, densityestimation, and Bayesian inference. We show that for a large class of transportmaps $T$, there exists a time-dependent ODE velocity field realizing astraight-line interpolation $(1-t)x + tT(x)$, $t \in [0,1]$, of thedisplacement induced by the map. Moreover, we show that such velocity fieldsare minimizers of a training objective containing a specific minimum-energyregularization. We then derive explicit upper bounds for the $C^k$ norm of thevelocity field that are polynomial in the $C^k$ norm of the correspondingtransport map $T$; in the case of triangular (Knothe--Rosenblatt) maps, we alsoshow that these bounds are polynomial in the $C^k$ norms of the associatedsource and target densities. Combining these results with stability argumentsfor distribution approximation via ODEs, we show that Wasserstein orKullback--Leibler approximation of the target distribution to any desiredaccuracy $\epsilon > 0$ can be achieved by a deep neural network representationof the velocity field whose size is bounded explicitly in terms of $\epsilon$,the dimension, and the smoothness of the source and target densities. The sameneural network ansatz yields guarantees on the value of the regularizedtraining objective.",Youssef Marzouk,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.CA', 'stat.ME', 'stat.ML']"
2502.03794v1,The GeV $γ$-ray emission from the composite SNR CTB 87,http://arxiv.org/abs/2502.03794v1,"We report the GeV $\gamma$-ray emission around the composite supernovaremnant (SNR) CTB 87 with more than 16 yrs PASS 8 data recorded by the FermiLarge Area Telescope. Two separate point sources with the different GeV spectraare identified in this region: one has a soft $\gamma$-ray spectrum, likely dueto interactions between the SNR shock and molecular clouds (MCs); and anothersource with a hard GeV $\gamma$-ray spectrum aligns with the TeV spectrum ofVER J2016+371, suggesting it as the GeV counterpart. Considering theobservations of CTB 87 in the radio and X-ray bands, VER J2016+371 is proposedto originate from the pulsar wind nebula (PWN) associated with PSR J2016+3711.A leptonic model with a broken power-law electron distribution could explainthe multi-wavelength data of VER J2016+371, with fitted parameters matchingtypical $\gamma$-ray PWNe. Deeper searching for the SNR shock of CTB 87 inother bands and the future TeV observations by LHAASO and CTA are crucial toreveal the nature of CTB 87.",Yuliang Xin,2025-02-06,2025-02-06,,N/A,['astro-ph.HE']
2502.03793v1,It's All in The [MASK]: Simple Instruction-Tuning Enables BERT-like Masked Language Models As Generative Classifiers,http://arxiv.org/abs/2502.03793v1,"While encoder-only models such as BERT and ModernBERT are ubiquitous inreal-world NLP applications, their conventional reliance on task-specificclassification heads can limit their applicability compared to decoder-basedlarge language models (LLMs). In this work, we introduceModernBERT-Large-Instruct, a 0.4B-parameter encoder model that leverages itsmasked language modelling (MLM) head for generative classification. Ourapproach employs an intentionally simple training loop and inference mechanismthat requires no heavy pre-processing, heavily engineered prompting, orarchitectural modifications. ModernBERT-Large-Instruct exhibits strongzero-shot performance on both classification and knowledge-based tasks,outperforming similarly sized LLMs on MMLU and achieving 93% of Llama3-1B'sMMLU performance with 60% less parameters. We also demonstrate that, whenfine-tuned, the generative approach using the MLM head matches or evensurpasses traditional classification-head methods across diverse NLU tasks.Thiscapability emerges specifically in models trained on contemporary, diverse datamixes, with models trained on lower volume, less-diverse data yieldingconsiderably weaker performance. Although preliminary, these resultsdemonstrate the potential of using the original generative masked languagemodelling head over traditional task-specific heads for downstream tasks. Ourwork suggests that further exploration into this area is warranted,highlighting many avenues for future improvements.",Benjamin Clavié,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03790v1,EigenCWD: a spatially-varying deconvolution algorithm for single metalens imaging,http://arxiv.org/abs/2502.03790v1,"The miniaturization of optics through the use of two-dimensional metalenseshas enabled novel applications in imaging. To date, single-lens imaging remainsthe most common configuration, in part due to the limited focusing efficiencyof metalenses. This results in limitations when it comes to wavefrontmanipulation and, thus, unavoidable aberrations in the formed image thatrequire computational deconvolution to deblur the image. For certain lensprofiles, such as the most common hyperbolic one that results in the highestefficiencies, at large fields of view, spatially-varying aberrations such ascoma or astigmatism are prominent. These aberrations cannot be corrected for bytraditional deconvolution methods, such as Wiener filtering. Here, we develop aspatially-varying deconvolution algorithm based on eigenvalue column-wisedecomposition (eigenCWD). EigenCWD solves a minimization problem of the errorbetween the measured image and the estimated image of the object to bereconstructed through an approximate forward blurring model. This approximateforward model uses an eigendecomposition of the spatially-varying point spreadfunctions for fast computation, allowing for efficient scaling to larger imagesizes and blurring kernels common in metalens imaging. We demonstrateeigenCWD's ability to correct spatially-varying blur and distortions forvarious lens profiles, surpassing that of the Wiener filter.",Joel Yeo,2025-02-06,2025-02-06,,N/A,"['physics.optics', 'physics.comp-ph']"
2502.03787v1,Iterate to Accelerate: A Unified Framework for Iterative Reasoning and Feedback Convergence,http://arxiv.org/abs/2502.03787v1,"We introduce a unified framework for iterative reasoning that leveragesnon-Euclidean geometry via Bregman divergences, higher-order operatoraveraging, and adaptive feedback mechanisms. Our analysis establishes that,under mild smoothness and contractivity assumptions, a generalized updatescheme not only unifies classical methods such as mirror descent and dynamicprogramming but also captures modern chain-of-thought reasoning processes inlarge language models. In particular, we prove that our accelerated iterativeupdate achieves an $O(1/t^2)$ convergence rate in the absence of persistentperturbations, and we further demonstrate that feedback (iterative)architectures are necessary to approximate certain fixed-point functionsefficiently. These theoretical insights bridge classical accelerationtechniques with contemporary applications in neural computation andoptimization.",Jacob Fein-Ashley,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03784v1,GistVis: Automatic Generation of Word-scale Visualizations from Data-rich Documents,http://arxiv.org/abs/2502.03784v1,"Data-rich documents are ubiquitous in various applications, yet they oftenrely solely on textual descriptions to convey data insights. Prior researchprimarily focused on providing visualization-centric augmentation to data-richdocuments. However, few have explored using automatically generated word-scalevisualizations to enhance the document-centric reading process. As anexploratory step, we propose GistVis, an automatic pipeline that extracts andvisualizes data insight from text descriptions. GistVis decomposes thegeneration process into four modules: Discoverer, Annotator, Extractor, andVisualizer, with the first three modules utilizing the capabilities of largelanguage models and the fourth using visualization design knowledge. Technicalevaluation including a comparative study on Discoverer and an ablation study onAnnotator reveals decent performance of GistVis. Meanwhile, the user study(N=12) showed that GistVis could generate satisfactory word-scalevisualizations, indicating its effectiveness in facilitating users'understanding of data-rich documents (+5.6% accuracy) while significantlyreducing their mental demand (p=0.016) and perceived effort (p=0.033).",Ruishi Zou,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.03783v1,UltraBones100k: An Ultrasound Image Dataset with CT-Derived Labels for Lower Extremity Long Bone Surface Segmentation,http://arxiv.org/abs/2502.03783v1,"Ultrasound-based bone surface segmentation is crucial in computer-assistedorthopedic surgery. However, ultrasound images have limitations, including alow signal-to-noise ratio, and acoustic shadowing, which make interpretationdifficult. Existing deep learning models for bone segmentation rely primarilyon costly manual labeling by experts, limiting dataset size and modelgeneralizability. Additionally, the complexity of ultrasound physics andacoustic shadow makes the images difficult for humans to interpret, leading toincomplete labels in anechoic regions and limiting model performance. Toadvance ultrasound bone segmentation and establish effective model benchmarks,larger and higher-quality datasets are needed.  We propose a methodology for collecting ex-vivo ultrasound datasets withautomatically generated bone labels, including anechoic regions. The proposedlabels are derived by accurately superimposing tracked bone CT models onto thetracked ultrasound images. These initial labels are refined to account forultrasound physics. A clinical evaluation is conducted by an expert physicianspecialized on orthopedic sonography to assess the quality of the generatedbone labels. A neural network for bone segmentation is trained on the collecteddataset and its predictions are compared to expert manual labels, evaluatingaccuracy, completeness, and F1-score.  We collected the largest known dataset of 100k ultrasound images of humanlower limbs with bone labels, called UltraBones100k. A Wilcoxon signed-ranktest with Bonferroni correction confirmed that the bone alignment after ourmethod significantly improved the quality of bone labeling (p < 0.001). Themodel trained on UltraBones100k consistently outperforms manual labeling in allmetrics, particularly in low-intensity regions (320% improvement incompleteness at a distance threshold of 0.5 mm).",Luohong Wu,2025-02-06,2025-02-06,,N/A,"['eess.IV', 'cs.CV']"
2502.03782v1,Classification of Solar Radio Spectrum Based on Swin Transformer,http://arxiv.org/abs/2502.03782v1,"Solar radio observation is a method used to study the Sun. It is veryimportant for space weather early warning and solar physics research toautomatically classify solar radio spectrums in real time and judge whetherthere is a solar radio burst. As the number of solar radio burst spectrums issmall and uneven, this paper proposes a classification method for solar radiospectrums based on the Swin transformer. First, the method transfers theparameters of the pretrained model to the Swin transformer model. Then, thehidden layer weights of the Swin transformer are frozen, and the fullyconnected layer of the Swin transformer is trained on the target dataset.Finally, pa-rameter tuning is performed. The experimental results show that themethod can achieve a true positive rate of 100%, which is more accurate thanprevious methods. Moreover, the number of our model parameters is only 20million, which is 80% lower than that of the traditional VGG16 con-volutionalneural network with more than 130 million parameters.",Jian Chen,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'astro-ph.SR']"
2502.03781v1,Gaze-Assisted Human-Centric Domain Adaptation for Cardiac Ultrasound Image Segmentation,http://arxiv.org/abs/2502.03781v1,"Domain adaptation (DA) for cardiac ultrasound image segmentation isclinically significant and valuable. However, previous domain adaptationmethods are prone to be affected by the incomplete pseudo-label and low-qualitytarget to source images. Human-centric domain adaptation has great advantagesof human cognitive guidance to help model adapt to target domain and reducereliance on labels. Doctor gaze trajectories contains a large amount ofcross-domain human guidance. To leverage gaze information and human cognitionfor guiding domain adaptation, we propose gaze-assisted human-centric domainadaptation (GAHCDA), which reliably guides the domain adaptation of cardiacultrasound images. GAHCDA includes following modules: (1) Gaze AugmentAlignment (GAA): GAA enables the model to obtain human cognition generalfeatures to recognize segmentation target in different domain of cardiacultrasound images like humans. (2) Gaze Balance Loss (GBL): GBL fused gazeheatmap with outputs which makes the segmentation result structurally closer tothe target domain. The experimental results illustrate that our proposedframework is able to segment cardiac ultrasound images more effectively in thetarget domain than GAN-based methods and other self-train based methods,showing great potential in clinical application.",Ruiyi Li,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'eess.IV']"
2502.03779v1,Out-of-phase Plasmon Excitations in the Trilayer Cuprate Bi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+δ}$,http://arxiv.org/abs/2502.03779v1,"Within a homologous series of cuprate superconductors, variations in thestacking of CuO$_2$ layers influence the collective charge dynamics through thelong-range Coulomb interactions. We use O $K$-edge resonant inelastic x-rayscattering to reveal plasmon excitations in the optimally-doped trilayerBi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+\delta}$. The observed plasmon exhibits nearly$q_z$-independent dispersion and a large excitation gap of approximately 300meV. This mode is primarily ascribed to the $\omega_{-}$ mode, where the chargedensity on the outer CuO$_2$ sheets oscillates out of phase while the densityin the inner sheet remains unaltered at $q_z=0$. The intensity of the acoustic$\omega_3$ mode is relatively weak and becomes vanishingly small near $(q_x,q_y)=(0, 0)$. This result highlights a qualitative change in the eigenmode ofthe dominant low-energy plasmon with the number of CuO$_2$ layers.",S. Nakata,2025-02-06,2025-02-06,,N/A,['cond-mat.str-el']
2502.03778v1,Self-Supervised Learning for Solar Radio Spectrum Classification,http://arxiv.org/abs/2502.03778v1,"Solar radio observation is an important way to study the Sun. Solar radiobursts contain important information about solar activity. Therefore, real-timeautomatic detection and classification of solar radio bursts are of great valuefor subsequent solar physics research and space weather warnings. Traditionalimage classification methods based on deep learning often require consid-erabletraining data. To address insufficient solar radio spectrum images, transferlearning is generally used. However, the large difference between naturalimages and solar spectrum images has a large impact on the transfer learningeffect. In this paper, we propose a self-supervised learning method for solarradio spectrum classification. Our method uses self-supervised training with aself-masking approach in natural language processing. Self-supervised learningis more conducive to learning the essential information about images comparedwith supervised methods, and it is more suitable for transfer learning. First,the method pre-trains using a large amount of other existing data. Then, thetrained model is fine-tuned on the solar radio spectrum dataset. Experimentsshow that the method achieves a classification accuracy similar to that ofconvolutional neural networks and Transformer networks with supervisedtraining.",Siqi Li,2025-02-06,2025-02-06,,N/A,"['astro-ph.IM', 'astro-ph.SR']"
2502.03777v1,Multi-Label Test-Time Adaptation with Bound Entropy Minimization,http://arxiv.org/abs/2502.03777v1,"Mainstream test-time adaptation (TTA) techniques endeavor to mitigatedistribution shifts via entropy minimization for multi-class classification,inherently increasing the probability of the most confident class. However,when encountering multi-label instances, the primary challenge stems from thevarying number of labels per image, and prioritizing only the highestprobability class inevitably undermines the adaptation of other positivelabels. To address this issue, we investigate TTA within multi-label scenario(ML--TTA), developing Bound Entropy Minimization (BEM) objective tosimultaneously increase the confidence of multiple top predicted labels.Specifically, to determine the number of labels for each augmented view, weretrieve a paired caption with yielded textual labels for that view. Theselabels are allocated to both the view and caption, called weak label set andstrong label set with the same size k. Following this, the proposed BEMconsiders the highest top-k predicted labels from view and caption as a singleentity, respectively, learning both view and caption prompts concurrently. Bybinding top-k predicted labels, BEM overcomes the limitation of vanilla entropyminimization, which exclusively optimizes the most confident class. Across theMSCOCO, VOC, and NUSWIDE multi-label datasets, our ML--TTA framework equippedwith BEM exhibits superior performance compared to the latest SOTA methods,across various model architectures, prompt initialization, and varying labelscenarios. The code is available at https://github.com/Jinx630/ML-TTA.",Xiangyu Wu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03775v1,Accretion disk dynamics in Teleparallel Born-Infeld gravity,http://arxiv.org/abs/2502.03775v1,"Teleparallel Born-Infeld gravity (TBI) is a modified theory of gravity thataims to maintain second-order field equations, leading to alternative scenariosfor strong gravity and cosmological settings. In this study, we examine theimpact of TBI gravity on the physical characteristics of thin (Novikov-Thorne)accretion disks, focusing on quantities such as flux, pressure, temperature,etc. We also examine the spectral luminosity, comparing it to disks around theSchwarzschild black holes. The analysis indicates that smaller values of$\lambda$ lead to more noticeable effects in the inner disk regions. Bycomparing the theoretical predictions to observational data in thelow-frequency regime, we demonstrate ability of the model to align with realastrophysical systems and distinguish subtle differences between TBI gravityand general relativity. Furthermore, the results suggest that observations ofX-ray spectra from the inner disk regions can provide valuable insights intothe properties of TBI gravity, potentially offering constraints on thismodified gravity theory through future astrophysical observations.",Ruijing Tang,2025-02-06,2025-02-06,,N/A,['gr-qc']
2502.03773v1,ExpProof : Operationalizing Explanations for Confidential Models with ZKPs,http://arxiv.org/abs/2502.03773v1,"In principle, explanations are intended as a way to increase trust in machinelearning models and are often obligated by regulations. However, manycircumstances where these are demanded are adversarial in nature, meaning theinvolved parties have misaligned interests and are incentivized to manipulateexplanations for their purpose. As a result, explainability methods fail to beoperational in such settings despite the demand \cite{bordt2022post}. In thispaper, we take a step towards operationalizing explanations in adversarialscenarios with Zero-Knowledge Proofs (ZKPs), a cryptographic primitive.Specifically we explore ZKP-amenable versions of the popular explainabilityalgorithm LIME and evaluate their performance on Neural Networks and RandomForests.",Chhavi Yadav,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CR']"
2502.03772v1,A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma,http://arxiv.org/abs/2502.03772v1,"Hepatocellular carcinoma (HCC) ranks as the third leading cause ofcancer-related mortality worldwide, with early detection being crucial forimproving patient survival rates. However, early screening for HCC usingultrasound suffers from insufficient sensitivity and is highly dependent on theexpertise of radiologists for interpretation. Leveraging the latestadvancements in artificial intelligence (AI) in medical imaging, this studyproposes an innovative Hierarchical Sparse Query Transformer (HSQformer) modelthat combines the strengths of Convolutional Neural Networks (CNNs) and VisionTransformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasoundscreening. The HSQformer leverages sparse latent space representations tocapture hierarchical details at various granularities without the need forcomplex adjustments, and adopts a modular, plug-and-play design philosophy,ensuring the model's versatility and ease of use. The HSQformer's performancewas rigorously tested across three distinct clinical scenarios: single-center,multi-center, and high-risk patient testing. In each of these settings, itconsistently outperformed existing state-of-the-art models, such as ConvNextand SwinTransformer. Notably, the HSQformer even matched the diagnosticcapabilities of senior radiologists and comprehensively surpassed those ofjunior radiologists. The experimental results from this study stronglydemonstrate the effectiveness and clinical potential of AI-assisted tools inHCC screening. The full code is available athttps://github.com/Asunatan/HSQformer.",Chaoyin She,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.03771v1,Adaptive Semantic Prompt Caching with VectorQ,http://arxiv.org/abs/2502.03771v1,"Semantic prompt caches reduce the latency and cost of large language model(LLM) inference by reusing cached LLM-generated responses for semanticallysimilar prompts. Vector similarity metrics assign a numerical score to quantifythe similarity between an embedded prompt and its nearest neighbor in thecache. Existing systems rely on a static threshold to classify whether thesimilarity score is sufficiently high to result in a cache hit. We show thatthis one-size-fits-all threshold is insufficient across different prompts. Wepropose VectorQ, a framework to learn embedding-specific threshold regions thatadapt to the complexity and uncertainty of an embedding. Through evaluations ona combination of four diverse datasets, we show that VectorQ consistentlyoutperforms state-of-the-art systems across all static thresholds, achieving upto 12x increases in cache hit rate and error rate reductions up to 92%.",Luis Gaspar Schroeder,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL']"
2502.03769v1,"Measurements of $\varUpsilon$ States Production in $\textit{p+p}$ Collisions at $\sqrt{s} = 500\:\mathrm{GeV}$ with STAR: Cross Sections, Ratios, and Multiplicity Dependence",http://arxiv.org/abs/2502.03769v1,"We report measurements of $\varUpsilon(1S)$, $\varUpsilon(2S)$ and$\varUpsilon(3S)$ production in $\textit{p+p}$ collisions at$\sqrt{s}=500\:\mathrm{GeV}$ by the STAR experiment in year 2011, correspondingto an integrated luminosity $\mathcal{L}_{int}=13\:\mathrm{pb^{-1}}$. Theresults provide precise cross sections, transverse momentum ($p_{T}$) andrapidity ($y$) spectra, as well as cross section ratios for$p_{\mathrm{T}}<10\:\mathrm{GeV/c}$ and $|y|<1$. The dependence of the$\varUpsilon$ yield on charged particle multiplicity has also been measured,offering new insights into the mechanisms of quarkonium production. The dataare compared to various theoretical models: the Color Evaporation Model (CEM)accurately describes the $\varUpsilon(1S)$ production, while the Color GlassCondensate + Non-relativistic Quantum Chromodynamics (CGC+NRQCD) modeloverestimates the data, particularly at low $p_{T}$. Conversely, the ColorSinglet Model (CSM) underestimates the rapidity dependence. These discrepancieshighlight the need for further development in understanding the productiondynamics of heavy quarkonia in high-energy hadronic collisions. The trend inthe multiplicity dependence is consistent with CGC/Saturation and StringPercolation models or $\varUpsilon$ production happening in multiple partoninteractions modeled by PYTHIA8.",The STAR Collaboration,2025-02-06,2025-02-06,,N/A,"['hep-ex', 'nucl-ex']"
2502.03768v1,Quantum integrable model for the quantum cohomology/quantum K-theory of flag varieties and the double $β$-Grothendieck polynomials,http://arxiv.org/abs/2502.03768v1,A GL$(n)$ quantum integrable system generalizing the asymmetric five vertexspin chain is shown to encode the ring relations of the equivariant quantumcohomology and quantum K-theory ring of flag varieties. We also show that theBethe ansatz states of this system generate the double $\beta$-Grothendieckpolynomials.,Jirui Guo,2025-02-06,2025-02-06,,N/A,"['math-ph', 'hep-th', 'math.AG', 'math.CO', 'math.MP', 'nlin.SI']"
2502.03766v1,Hierarchical Contextual Manifold Alignment for Structuring Latent Representations in Large Language Models,http://arxiv.org/abs/2502.03766v1,"The organization of latent token representations plays a crucial role indetermining the stability, generalization, and contextual consistency oflanguage models, yet conventional approaches to embedding refinement often relyon parameter modifications that introduce additional computational overhead. Ahierarchical alignment method was introduced to restructure token embeddingswithout altering core model weights, ensuring that representationaldistributions maintained coherence across different linguistic contexts.Experimental evaluations demonstrated improvements in rare token retrieval,adversarial robustness, and long-range dependency tracking, highlighting theadvantages of hierarchical structuring in mitigating inconsistencies in latentspace organization. The comparative analysis against conventional fine-tuningand embedding perturbation methods revealed that hierarchical restructuringmaintained computational efficiency while achieving measurable gains inrepresentation quality. Structural refinements introduced through the alignmentprocess resulted in improved contextual stability across varied linguistictasks, reducing inconsistencies in token proximity relationships and enhancinginterpretability in language generation. A detailed computational assessmentconfirmed that the realignment process introduced minimal inference overhead,ensuring that representational improvements did not compromise modelefficiency. The findings reinforced the broader significance of structuredrepresentation learning, illustrating that hierarchical embedding modificationscould serve as an effective strategy for refining latent space distributionswhile preserving pre-learned semantic associations.",Meiquan Dong,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.04394v1,DECT: Harnessing LLM-assisted Fine-Grained Linguistic Knowledge and Label-Switched and Label-Preserved Data Generation for Diagnosis of Alzheimer's Disease,http://arxiv.org/abs/2502.04394v1,"Alzheimer's Disease (AD) is an irreversible neurodegenerative diseaseaffecting 50 million people worldwide. Low-cost, accurate identification of keymarkers of AD is crucial for timely diagnosis and intervention. Languageimpairment is one of the earliest signs of cognitive decline, which can be usedto discriminate AD patients from normal control individuals.Patient-interviewer dialogues may be used to detect such impairments, but theyare often mixed with ambiguous, noisy, and irrelevant information, making theAD detection task difficult. Moreover, the limited availability of AD speechsamples and variability in their speech styles pose significant challenges indeveloping robust speech-based AD detection models. To address thesechallenges, we propose DECT, a novel speech-based domain-specific approachleveraging large language models (LLMs) for fine-grained linguistic analysisand label-switched label-preserved data generation. Our study presents fournovelties: We harness the summarizing capabilities of LLMs to identify anddistill key Cognitive-Linguistic information from noisy speech transcripts,effectively filtering irrelevant information. We leverage the inherentlinguistic knowledge of LLMs to extract linguistic markers from unstructuredand heterogeneous audio transcripts. We exploit the compositional ability ofLLMs to generate AD speech transcripts consisting of diverse linguisticpatterns to overcome the speech data scarcity challenge and enhance therobustness of AD detection models. We use the augmented AD textual speechtranscript dataset and a more fine-grained representation of AD textual speechtranscript data to fine-tune the AD detection model. The results have shownthat DECT demonstrates superior model performance with an 11% improvement in ADdetection accuracy on the datasets from DementiaBank compared to the baselines.",Tingyu Mo,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.04393v1,UniCP: A Unified Caching and Pruning Framework for Efficient Video Generation,http://arxiv.org/abs/2502.04393v1,"Diffusion Transformers (DiT) excel in video generation but encountersignificant computational challenges due to the quadratic complexity ofattention. Notably, attention differences between adjacent diffusion stepsfollow a U-shaped pattern. Current methods leverage this property by cachingattention blocks, however, they still struggle with sudden error spikes andlarge discrepancies. To address these issues, we propose UniCP a unifiedcaching and pruning framework for efficient video generation. UniCP optimizesboth temporal and spatial dimensions through. Error Aware Dynamic Cache Window(EDCW): Dynamically adjusts cache window sizes for different blocks at varioustimesteps, adapting to abrupt error changes. PCA based Slicing (PCAS) andDynamic Weight Shift (DWS): PCAS prunes redundant attention components, and DWSintegrates caching and pruning by enabling dynamic switching between pruned andcached outputs. By adjusting cache windows and pruning redundant components,UniCP enhances computational efficiency and maintains video detail fidelity.Experimental results show that UniCP outperforms existing methods in bothperformance and efficiency.",Wenzhang Sun,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03763v1,Systolic Sparse Tensor Slices: FPGA Building Blocks for Sparse and Dense AI Acceleration,http://arxiv.org/abs/2502.03763v1,"FPGA architectures have recently been enhanced to meet the substantialcomputational demands of modern deep neural networks (DNNs). To this end, bothFPGA vendors and academic researchers have proposed in-fabric blocks thatperform efficient tensor computations. However, these blocks are primarilyoptimized for dense computation, while most DNNs exhibit sparsity. To addressthis limitation, we propose incorporating structured sparsity support into FPGAarchitectures. We architect 2D systolic in-fabric blocks, named systolic sparsetensor (SST) slices, that support multiple degrees of sparsity to efficientlyaccelerate a wide variety of DNNs. SSTs support dense operation, 2:4 (50%) and1:4 (75%) sparsity, as well as a new 1:3 (66.7%) sparsity level to furtherincrease flexibility. When demonstrating on general matrix multiplication(GEMM) accelerators, which are the heart of most current DNN accelerators, oursparse SST-based designs attain up to 5x higher FPGA frequency and 10.9x lowerarea, compared to traditional FPGAs. Moreover, evaluation of the proposed SSTson state-of-the-art sparse ViT and CNN models exhibits up to 3.52x speedup withminimal area increase of up to 13.3%, compared to dense in-fabric acceleration.",Endri Taka,2025-02-06,2025-02-06,,N/A,['cs.AR']
2502.03762v1,Learning Reward Machines from Partially Observed Optimal Policies,http://arxiv.org/abs/2502.03762v1,"Inverse reinforcement learning is the problem of inferring a reward functionfrom an optimal policy. In this work, it is assumed that the reward isexpressed as a reward machine whose transitions depend on atomic propositionsassociated with the state of a Markov Decision Process (MDP). Our goal is toidentify the true reward machine using finite information. To this end, wefirst introduce the notion of a prefix tree policy which associates adistribution of actions to each state of the MDP and each attainable finitesequence of atomic propositions. Then, we characterize an equivalence class ofreward machines that can be identified given the prefix tree policy. Finally,we propose a SAT-based algorithm that uses information extracted from theprefix tree policy to solve for a reward machine. It is proved that if theprefix tree policy is known up to a sufficient (but finite) depth, ouralgorithm recovers the exact reward machine up to the equivalence class. Thissufficient depth is derived as a function of the number of MDP states and (anupper bound on) the number of states of the reward machine. Several examplesare used to demonstrate the effectiveness of the approach.",Mohamad Louai Shehab,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.FL']"
2502.03760v1,RAMOTS: A Real-Time System for Aerial Multi-Object Tracking based on Deep Learning and Big Data Technology,http://arxiv.org/abs/2502.03760v1,"Multi-object tracking (MOT) in UAV-based video is challenging due tovariations in viewpoint, low resolution, and the presence of small objects.While other research on MOT dedicated to aerial videos primarily focuses on theacademic aspect by developing sophisticated algorithms, there is a lack ofattention to the practical aspect of these systems. In this paper, we propose anovel real-time MOT framework that integrates Apache Kafka and Apache Spark forefficient and fault-tolerant video stream processing, along withstate-of-the-art deep learning models YOLOv8/YOLOv10 and BYTETRACK/BoTSORT foraccurate object detection and tracking. Our work highlights the importance ofnot only the advanced algorithms but also the integration of these methods withscalable and distributed systems. By leveraging these technologies, our systemachieves a HOTA of 48.14 and a MOTA of 43.51 on the Visdrone2019-MOT test setwhile maintaining a real-time processing speed of 28 FPS on a single GPU. Ourwork demonstrates the potential of big data technologies and deep learning foraddressing the challenges of MOT in UAV applications.",Nhat-Tan Do,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03758v1,Improving Adversarial Robustness via Phase and Amplitude-aware Prompting,http://arxiv.org/abs/2502.03758v1,"Deep neural networks are found to be vulnerable to adversarial noises. Theprompt-based defense has been increasingly studied due to its high efficiency.However, existing prompt-based defenses mainly exploited mixed prompt patterns,where critical patterns closely related to object semantics lack sufficientfocus. The phase and amplitude spectra have been proven to be highly related tospecific semantic patterns and crucial for robustness. To this end, in thispaper, we propose a Phase and Amplitude-aware Prompting (PAP) defense.Specifically, we construct phase-level and amplitude-level prompts for eachclass, and adjust weights for prompting according to the model's robustperformance under these prompts during training. During testing, we selectprompts for each image using its predicted label to obtain the prompted image,which is inputted to the model to get the final prediction. Experimentalresults demonstrate the effectiveness of our method.",Yibo Xu,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03755v1,Regularization via f-Divergence: An Application to Multi-Oxide Spectroscopic Analysis,http://arxiv.org/abs/2502.03755v1,"In this paper, we address the task of characterizing the chemical compositionof planetary surfaces using convolutional neural networks (CNNs). Specifically,we seek to predict the multi-oxide weights of rock samples based onspectroscopic data collected under Martian conditions. We frame this problem asa multi-target regression task and propose a novel regularization method basedon f-divergence. The f-divergence regularization is designed to constrain thedistributional discrepancy between predictions and noisy targets. Thisregularizer serves a dual purpose: on the one hand, it mitigates overfitting byenforcing a constraint on the distributional difference between predictions andnoisy targets. On the other hand, it acts as an auxiliary loss function,penalizing the neural network when the divergence between the predicted andtarget distributions becomes too large. To enable backpropagation during neuralnetwork training, we develop a differentiable f-divergence and incorporate itinto the f-divergence regularization, making the network training feasible. Weconduct experiments using spectra collected in a Mars-like environment by theremote-sensing instruments aboard the Curiosity and Perseverance rovers.Experimental results on multi-oxide weight prediction demonstrate that theproposed $f$-divergence regularization performs better than or comparable tostandard regularization methods including $L_1$, $L_2$, and dropout. Notably,combining the $f$-divergence regularization with these standard regularizationfurther enhances performance, outperforming each regularization method usedindependently.",Weizhi Li,2025-02-06,2025-02-06,,N/A,['cs.LG']
2502.03754v1,Parametric reduced-order modeling and mode sensitivity of actuated cylinder flow from a matrix manifold perspective,http://arxiv.org/abs/2502.03754v1,"We present a framework for parametric proper orthogonal decomposition(POD)-Galerkin reduced-order modeling (ROM) of fluid flows that accommodatesvariations in flow parameters and control inputs. As an initial step, toexplore how the locally optimal POD modes vary with parameter changes, wedemonstrate a sensitivity analysis of POD modes and their spanned subspace,respectively rooted in Stiefel and Grassmann manifolds. The sensitivityanalysis, by defining distance between POD modes for different parameters, isapplied to the flow around a rotating cylinder with varying Reynolds numbersand rotation rates. The sensitivity of the subspace spanned by POD modes toparameter changes is represented by a tangent vector on the Grassmann manifold.For the cylinder case, the inverse of the subspace sensitivity on the Grassmannmanifold is proportional to the Roshko number, highlighting the connectionbetween geometric properties and flow physics. Furthermore, the Reynolds numberat which the subspace sensitivity approaches infinity corresponds to the lowerbound at which the characteristic frequency of the K\'arm\'an vortex streetexists (Noack & Eckelmann, JFM, 1994). From the Stiefel manifold perspective,sensitivity modes are derived to represent the flow field sensitivity,comprising the sensitivities of the POD modes and expansion coefficients. Thetemporal evolution of the flow field sensitivity is represented by superposingthe sensitivity modes. Lastly, we devise a parametric POD-Galerkin ROM based onsubspace interpolation on the Grassmann manifold. The reconstruction error ofthe ROM is intimately linked to the subspace-estimation error, which is in turnclosely related to subspace sensitivity.",Shintaro Sato,2025-02-06,2025-02-06,,N/A,['physics.flu-dyn']
2502.03750v1,Principal Curvatures Estimation with Applications to Single Cell Data,http://arxiv.org/abs/2502.03750v1,"The rapidly growing field of single-cell transcriptomic sequencing (scRNAseq)presents challenges for data analysis due to its massive datasets. A commonmethod in manifold learning consists in hypothesizing that datasets lie on alower dimensional manifold. This allows to study the geometry of point cloudsby extracting meaningful descriptors like curvature. In this work, we willpresent Adaptive Local PCA (AdaL-PCA), a data-driven method for accuratelyestimating various notions of intrinsic curvature on data manifolds, inparticular principal curvatures for surfaces. The model relies on local PCA toestimate the tangent spaces. The evaluation of AdaL-PCA on sampled surfacesshows state-of-the-art results. Combined with a PHATE embedding, the modelapplied to single-cell RNA sequencing data allows us to identify key variationsin the cellular differentiation.",Yanlei Zhang,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI']"
2502.03749v1,PINS: Proximal Iterations with Sparse Newton and Sinkhorn for Optimal Transport,http://arxiv.org/abs/2502.03749v1,"Optimal transport (OT) is a critical problem in optimization and machinelearning, where accuracy and efficiency are paramount. Although entropicregularization and the Sinkhorn algorithm improve scalability, they frequentlyencounter numerical instability and slow convergence, especially when theregularization parameter is small. In this work, we introduce ProximalIterations with Sparse Newton and Sinkhorn methods (PINS) to efficientlycompute highly accurate solutions for large-scale OT problems. A reducedcomputational complexity through overall sparsity and global convergence areguaranteed by rigorous theoretical analysis. Our approach offers three keyadvantages: it achieves accuracy comparable to exact solutions, progressivelyaccelerates each iteration for greater efficiency, and enhances robustness byreducing sensitivity to regularization parameters. Extensive experimentsconfirm these advantages, demonstrating superior performance compared torelated methods.",Di Wu,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'math.OC']"
2502.03748v1,Rethinking the Residual Distribution of Locate-then-Editing Methods in Model Editing,http://arxiv.org/abs/2502.03748v1,"Model editing is a powerful technique for updating the knowledge of LargeLanguage Models (LLMs). Locate-then-edit methods are a popular class ofapproaches that first identify the critical layers storing knowledge, thencompute the residual of the last critical layer based on the edited knowledge,and finally perform multi-layer updates using a least-squares solution byevenly distributing the residual from the first critical layer to the last.Although these methods achieve promising results, they have been shown todegrade the original knowledge of LLMs. We argue that residual distributionleads to this issue. To explore this, we conduct a comprehensive analysis ofresidual distribution in locate-then-edit methods from both empirical andtheoretical perspectives, revealing that residual distribution introducesediting errors, leading to inaccurate edits. To address this issue, we proposethe Boundary Layer UpdatE (BLUE) strategy to enhance locate-then-edit methods.Sequential batch editing experiments on three LLMs and two datasets demonstratethat BLUE not only delivers an average performance improvement of 35.59\%,significantly advancing the state of the art in model editing, but alsoenhances the preservation of LLMs' general capabilities. Our code is availableat https://github.com/xpq-tech/BLUE.",Xiaopeng Li,2025-02-06,2025-02-06,,N/A,['cs.CL']
2502.03746v1,Brain Tumor Identification using Improved YOLOv8,http://arxiv.org/abs/2502.03746v1,"Identifying the extent of brain tumors is a significant challenge in braincancer treatment. The main difficulty is in the approximate detection of tumorsize. Magnetic resonance imaging (MRI) has become a critical diagnostic tool.However, manually detecting the boundaries of brain tumors from MRI scans is alabor-intensive task that requires extensive expertise. Deep learning andcomputer-aided detection techniques have led to notable advances in machinelearning for this purpose. In this paper, we propose a modified You Only LookOnce (YOLOv8) model to accurately detect the tumors within the MRI images. Theproposed model replaced the Non-Maximum Suppression (NMS) algorithm with aReal-Time Detection Transformer (RT- DETR) in the detection head. NMS filtersout redundant or overlapping bounding boxes in the detected tumors, but theyare hand-designed and pre-set. RT-DETR removes hand-designed components. Thesecond improvement was made by replacing the normal convolution block withghost convolution. Ghost Convolution reduces computational and memory costswhile maintaining high accuracy and enabling faster inference, making it idealfor resource-constrained environments and real-time applications. The thirdimprovement was made by introducing a vision transformer block in the backboneof YOLOv8 to extract context-aware features. We used a publicly availabledataset of brain tumors in the proposed model. The proposed model performedbetter than the original YOLOv8 model and also performed better than otherobject detectors (Faster R- CNN, Mask R-CNN, YOLO, YOLOv3, YOLOv4, YOLOv5, SSD,RetinaNet, EfficientDet, and DETR). The proposed model achieved 0.91 mAP (meanAverage Precision)@0.5.",Rupesh Dulal,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.03745v1,Identifying Compton-thick AGNs in the COSMOS. I. Among X-ray AGNs with Low Photon Counts,http://arxiv.org/abs/2502.03745v1,"Compton-thick active galactic nuclei (CT-AGNs), characterized by asignificant absorption with column densities of $\mathrm{N_H}\geqslant1.5\times 10^{24} \ \mathrm{cm}^{-2}$, emit feeble X-ray radiation and are evenundetectable by X-ray instruments, making them difficult to identify. X-rayradiation from AGNs is the predominant source of the cosmic X-ray background(CXB). Based on AGN synthesis models for the CXB, the fraction of CT-AGNsshould constitute a substantial portion of AGN population, approximately 30\%or more. The fraction of CT-AGNs discovered in the Cosmological EvolutionSurvey (COSMOS) is significantly lower than this value. This means that manyCT-AGNs may be hidden in AGNs that exhibit low photon counts or that have notbeen detected by X-ray instruments. This work focuses on identifying CT-AGNshidden in AGNs with low photon counts. Firstly, we selected 440 AGNs withabundant multiwavelength data as our sample. Secondly, we analyzedmultiwavelength data, extracting crucial physical parameters required for theCT-AGN diagnosis. Finally, we used multiwavelength approaches to identifyCT-AGNs. We have successfully identified 18 CT-AGNs in our sample. Among theCT-AGNs, four AGNs show discrepant results across different diagnostic methods.We discuss the potential reasons behind these diagnostic discrepancies. Weexplore the impact of estimating [O~III]$\lambda~5007$ luminosities based on[O~II]$\lambda~3727$ luminosities for the CT-AGN diagnosis. We have also foundthat the properties of host galaxies for CT-AGNs and non-CT-AGNs do not showsignificant discrepancies.",Xiaotong Guo,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.03738v1,"Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More",http://arxiv.org/abs/2502.03738v1,"Since the introduction of Vision Transformer (ViT), patchification has longbeen regarded as a de facto image tokenization approach for plain visualarchitectures. By compressing the spatial size of images, this approach caneffectively shorten the token sequence and reduce the computational cost ofViT-like plain architectures. In this work, we aim to thoroughly examine theinformation loss caused by this patchification-based compressive encodingparadigm and how it affects visual understanding. We conduct extensive patchsize scaling experiments and excitedly observe an intriguing scaling law inpatchification: the models can consistently benefit from decreased patch sizesand attain improved predictive performance, until it reaches the minimum patchsize of 1x1, i.e., pixel tokenization. This conclusion is broadly applicableacross different vision tasks, various input scales, and diverse architecturessuch as ViT and the recent Mamba models. Moreover, as a by-product, we discoverthat with smaller patches, task-specific decoder heads become less critical fordense prediction. In the experiments, we successfully scale up the visualsequence to an exceptional length of 50,176 tokens, achieving a competitivetest accuracy of 84.6% with a base-sized model on the ImageNet-1k benchmark. Wehope this study can provide insights and theoretical foundations for futureworks of building non-compressive vision models. Code is available athttps://github.com/wangf3014/Patch_Scaling.",Feng Wang,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03735v1,Existence and stability of various models describing behaviour of the thermoviscoelastic-rate type fluids,http://arxiv.org/abs/2502.03735v1,"Viscoelastic rate-type fluid models are used to describe the behaviour ofmany complex materials from engineering up to application in biomaterials andmedicine. A classical model that belongs to the category of viscoelasticrate-type fluid models is the Giesekus model. Furthermore, in all theseapplications, the heat conduction frequently takes place and all materialcoefficients depend heavily on the temperature, and therefore, we introducehere a thermodynamically compatible model for viscoelastic rate-type andheat-conducting fluid for which we show the existence of global weak solutionin two-dimensional setting whenever the initial energy and entropy arecontrolled in natural norms.",Miroslav Bulìček,2025-02-06,2025-02-06,,N/A,"['math.AP', '35A01, 35Q35, 76A10, 76D03']"
2502.03734v1,Improving noisy free-energy measurements by adding more noise,http://arxiv.org/abs/2502.03734v1,"Estimating free-energy differences using nonequilibrium work relations, suchas the Jarzynski equality, is hindered by poor convergence when workfluctuations are large. For systems governed by overdamped Langevin dynamics,we propose the counterintuitive approach of adding noise in order to increasethe precision of such calculations. By introducing additional stochasticfluctuations to the system and rescaling its potential energy, we leave thethermodynamics of the system unchanged while increasing its relaxation rate.For a given time-dependent protocol this modification reduces dissipated work,leading to more accurate free-energy estimates. We demonstrate this principleusing computer simulations applied to two model systems. However, the regime ofapplicability of this strategy is likely limited, because it requires controlof the system's potential energy in a way that is feasible in only a fewexperimental settings.",Stephen Whitelam,2025-02-06,2025-02-06,,N/A,['cond-mat.stat-mech']
2502.03732v1,"More Modality, More AI: Exploring Design Opportunities of AI-Based Multi-modal Remote Monitoring Technologies for Early Detection of Mental Health Sequelae in Youth Concussion Patients",http://arxiv.org/abs/2502.03732v1,"Anxiety, depression, and suicidality are common mental health sequelaefollowing concussion in youth patients, often exacerbating concussion symptomsand prolonging recovery. Despite the critical need for early detection of thesemental health symptoms, clinicians often face challenges in accuratelycollecting patients' mental health data and making clinical decision-making ina timely manner. Today's remote patient monitoring (RPM) technologies offeropportunities to objectively monitor patients' activities, but they were notspecifically designed for youth concussion patients; moreover, the large amountof data collected by RPM technologies may also impose significant workloads onclinicians to keep up with and use the data. To address these gaps, we employeda three-stage study consisting of a formative study, interface design, anddesign evaluation. We first conducted a formative study through semi-structuredinterviews with six highly professional concussion clinicians and identifiedclinicians' key challenges in remotely collecting patient information andaccessing patient treatment compliance. Subsequently, we proposed preliminaryclinician-facing interface designs with the integration of AI-based RPMtechnologies (AI-RPM), followed by design evaluation sessions with highlyprofessional concussion clinicians. Clinicians underscored the value ofintegrating multi-modal AI-RPM technologies to support clinicians'decision-making while emphasizing the importance of customizable interfaceswith explainability and multiple responsible design considerations.",Bingsheng Yao,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.03731v1,A Physiological-Model-Based Neural Network Framework for Blood Pressure Estimation from Photoplethysmography Signals,http://arxiv.org/abs/2502.03731v1,"Continuous blood pressure (BP) estimation via photoplethysmography (PPG)remains a significant challenge, particularly in providing comprehensivecardiovascular insights for hypertensive complications. This study presents anovel physiological model-based neural network (PMB-NN) framework for BPestimation from PPG signals, incorporating the identification of totalperipheral resistance (TPR) and arterial compliance (AC) to enhancephysiological interpretability. Preliminary experimental results, obtained froma single healthy participant under varying activity intensities, demonstratedpromising accuracy, with a median root mean square error of 6.69 mmHg forsystolic BP and 3.26 mmHg for diastolic BP. The median (min, max) differencebetween estimated and measured TPR was 0.043 (0.024, 0.061) mmHg*s/cm^3. Asexpected, estimated TPR decreased with increasing activity intensity, while ACincreased within a physiologically plausible range (0.5-2.5 cm^3/mmHg).",Yaowen Zhang,2025-02-06,2025-02-06,,N/A,['physics.med-ph']
2502.03730v1,On the relationship between the cosmic web and the alignment of galaxies and AGN jets,http://arxiv.org/abs/2502.03730v1,"The impact of active galactic nuclei (AGN) on the evolution of galaxiesexplains the steep decrease in the number density of the most massive galaxiesin the Universe. However, the fueling of the AGN and the efficiency of thisfeedback largely depend on their environment. We use data from the LowFrequency Array (LOFAR) Two-metre Sky Survey Data Release 2 (LoTSS DR2), theDark Energy Spectroscopic Instrument (DESI) Legacy Imaging Surveys, and theSloan Digital Sky Survey (SDSS) DR12 to make the first study of theorientations of radio jets and their optical counterpart in relation to thecosmic web environment. We find that close to filaments ($\lesssim 11 \,\rmMpc$), galaxies tend to have their optical major axes aligned with the nearestfilaments. On the other hand, radio jets, which are generally alignedperpendicularly to the optical major axis of the host galaxy, show morerandomised orientations with respect to host galaxies within $\lesssim 8 \,\rmMpc$ of filaments. These results support the scenario that massive galaxies incosmic filaments grow by numerous mergers directed along the orientation of thefilaments while experiencing chaotic accretion of gas onto the central blackhole. The AGN-driven jets consequently have a strong impact preferentiallyalong the minor axes of dark matter halos within filaments. We discuss theimplications of these results for large-scale radio jet alignments, intrinsicalignments between galaxies, and the azimuthal anisotropy of the distributionof circumgalactic medium and anisotropic quenching.",Seoyoung Lyla Jung,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.03729v1,Action-Free Reasoning for Policy Generalization,http://arxiv.org/abs/2502.03729v1,"End-to-end imitation learning offers a promising approach for training robotpolicies. However, generalizing to new settings remains a significantchallenge. Although large-scale robot demonstration datasets have shownpotential for inducing generalization, they are resource-intensive to scale. Incontrast, human video data is abundant and diverse, presenting an attractivealternative. Yet, these human-video datasets lack action labels, complicatingtheir use in imitation learning. Existing methods attempt to extract groundedaction representations (e.g., hand poses), but resulting policies struggle tobridge the embodiment gap between human and robot actions. We propose analternative approach: leveraging language-based reasoning from humanvideos-essential for guiding robot actions-to train generalizable robotpolicies. Building on recent advances in reasoning-based policy architectures,we introduce Reasoning through Action-free Data (RAD). RAD learns from bothrobot demonstration data (with reasoning and action labels) and action-freehuman video data (with only reasoning labels). The robot data teaches the modelto map reasoning to low-level actions, while the action-free data enhancesreasoning capabilities. Additionally, we will release a new dataset of 3,377human-hand demonstrations with reasoning annotations compatible with the BridgeV2 benchmark and aimed at facilitating future research on reasoning-drivenrobot learning. Our experiments show that RAD enables effective transfer acrossthe embodiment gap, allowing robots to perform tasks seen only in action-freedata. Furthermore, scaling up action-free reasoning data significantly improvespolicy performance and generalization to novel tasks. These results highlightthe promise of reasoning-driven learning from action-free datasets foradvancing generalizable robot control. Project page:https://rad-generalization.github.io",Jaden Clark,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.04392v1,Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents,http://arxiv.org/abs/2502.04392v1,"The rapid expansion of web content has made on-device AI assistantsindispensable for helping users manage the increasing complexity of onlinetasks. The emergent reasoning ability in large language models offer apromising path for next-generation on-device AI agents. However, deployingfull-scale Large Language Models (LLMs) on resource-limited local devices ischallenging. In this paper, we propose Division-of-Thoughts (DoT), acollaborative reasoning framework leveraging the synergy between locallydeployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoTleverages a Task Decomposer to elicit the inherent planning abilities inlanguage models to decompose user queries into smaller sub-tasks, which allowshybrid language models to fully exploit their respective strengths. Besides,DoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasksand create a dependency graph, facilitating parallel reasoning of sub-tasks andthe identification of key steps. To allocate the appropriate model based on thedifficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is anadditional task head attached to the SLM that does not alter the SLM'sparameters. To boost adapter's task allocation capability, we propose aself-reinforced training method that relies solely on task execution feedback.Extensive experiments on various benchmarks demonstrate that our DoTsignificantly reduces LLM costs while maintaining competitive reasoningaccuracy. Specifically, DoT reduces the average reasoning time and API costs by66.12% and 83.57%, while achieving comparable reasoning accuracy with the bestbaseline methods.",Chenyang Shao,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03727v1,Microstructure-Aware Bayesian Materials Design,http://arxiv.org/abs/2502.03727v1,"In this study, we propose a novel microstructure-sensitive Bayesianoptimization (BO) framework designed to enhance the efficiency of materialsdiscovery by explicitly incorporating microstructural information. Traditionalmaterials design approaches often focus exclusively on directchemistry-process-property relationships, overlooking the critical role ofmicrostructures. To address this limitation, our framework integratesmicrostructural descriptors as latent variables, enabling the construction of acomprehensive process-structure-property mapping that improves both predictiveaccuracy and optimization outcomes. By employing the active subspace method fordimensionality reduction, we identify the most influential microstructuralfeatures, thereby reducing computational complexity while maintaining highaccuracy in the design process. This approach also enhances the probabilisticmodeling capabilities of Gaussian processes, accelerating convergence tooptimal material configurations with fewer iterations and experimentalobservations. We demonstrate the efficacy of our framework through syntheticand real-world case studies, including the design of Mg$_2$Sn$_x$Si$_{1-x}$thermoelectric materials for energy conversion. Our results underscore thecritical role of microstructures in linking processing conditions to materialproperties, highlighting the potential of a microstructure-aware designparadigm to revolutionize materials discovery. Furthermore, this work suggeststhat since incorporating microstructure awareness improves the efficiency ofBayesian materials discovery, microstructure characterization stages should beintegral to automated -- and eventually autonomous -- platforms for materialsdevelopment.",Danial Khatamsaz,2025-02-06,2025-02-06,,N/A,['cond-mat.mtrl-sci']
2502.03726v1,DICE: Distilling Classifier-Free Guidance into Text Embeddings,http://arxiv.org/abs/2502.03726v1,"Text-to-image diffusion models are capable of generating high-quality images,but these images often fail to align closely with the given text prompts.Classifier-free guidance (CFG) is a popular and effective technique forimproving text-image alignment in the generative process. However, using CFGintroduces significant computational overhead and deviates from the establishedtheoretical foundations of diffusion models. In this paper, we presentDIstilling CFG by enhancing text Embeddings (DICE), a novel approach thatremoves the reliance on CFG in the generative process while maintaining thebenefits it provides. DICE distills a CFG-based text-to-image diffusion modelinto a CFG-free version by refining text embeddings to replicate CFG-baseddirections. In this way, we avoid the computational and theoretical drawbacksof CFG, enabling high-quality, well-aligned image generation at a fast samplingspeed. Extensive experiments on multiple Stable Diffusion v1.5 variants, SDXLand PixArt-$\alpha$ demonstrate the effectiveness of our method. Furthermore,DICE supports negative prompts for image editing to improve image qualityfurther. Code will be available soon.",Zhenyu Zhou,2025-02-06,2025-02-06,,N/A,['cs.CV']
2502.03723v1,Speaking the Language of Teamwork: LLM-Guided Credit Assignment in Multi-Agent Reinforcement Learning,http://arxiv.org/abs/2502.03723v1,"Credit assignment, the process of attributing credit or blame to individualagents for their contributions to a team's success or failure, remains afundamental challenge in multi-agent reinforcement learning (MARL),particularly in environments with sparse rewards. Commonly-used approaches suchas value decomposition often lead to suboptimal policies in these settings, anddesigning dense reward functions that align with human intuition can be complexand labor-intensive. In this work, we propose a novel framework where a largelanguage model (LLM) generates dense, agent-specific rewards based on a naturallanguage description of the task and the overall team goal. By learning apotential-based reward function over multiple queries, our method reduces theimpact of ranking errors while allowing the LLM to evaluate each agent'scontribution to the overall task. Through extensive experiments, we demonstratethat our approach achieves faster convergence and higher policy returnscompared to state-of-the-art MARL baselines.",Muhan Lin,2025-02-06,2025-02-06,,N/A,['cs.MA']
2502.03724v1,MD-BERT: Action Recognition in Dark Videos via Dynamic Multi-Stream Fusion and Temporal Modeling,http://arxiv.org/abs/2502.03724v1,"Action recognition in dark, low-light (under-exposed) or noisy videos is achallenging task due to visibility degradation, which can hinder criticalspatiotemporal details. This paper proposes MD-BERT, a novel multi-streamapproach that integrates complementary pre-processing techniques such as gammacorrection and histogram equalization alongside raw dark frames to addressthese challenges. We introduce the Dynamic Feature Fusion (DFF) module,extending existing attentional fusion methods to a three-stream setting,thereby capturing fine-grained and global contextual information acrossdifferent brightness and contrast enhancements. The fused spatiotemporalfeatures are then processed by a BERT-based temporal model, which leverages itsbidirectional self-attention to effectively capture long-range dependencies andcontextual relationships across frames. Extensive experiments on the ARID V1.0and ARID V1.5 dark video datasets show that MD-BERT outperforms existingmethods, establishing a new state-of-the-art performance. Ablation studiesfurther highlight the individual contributions of each input stream and theeffectiveness of the proposed DFF and BERT modules. The official website ofthis work is available at: https://github.com/HrishavBakulBarua/DarkBERT",Sharana Dharshikgan Suresh Dass,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI', 'cs.HC', 'cs.LG', 'cs.MM', 'Artificial intelligence, Computer vision, Machine learning, Deep\n  learning, Human-computer Interaction', 'I.2; I.2.9; I.2.10; I.3.3; I.4.5']"
2502.03721v1,Detecting Backdoor Attacks via Similarity in Semantic Communication Systems,http://arxiv.org/abs/2502.03721v1,"Semantic communication systems, which leverage Generative AI (GAI) totransmit semantic meaning rather than raw data, are poised to revolutionizemodern communications. However, they are vulnerable to backdoor attacks, a typeof poisoning manipulation that embeds malicious triggers into trainingdatasets. As a result, Backdoor attacks mislead the inference for poisonedsamples while clean samples remain unaffected. The existing defenses may alterthe model structure (such as neuron pruning that potentially degrades inferenceperformance on clean inputs, or impose strict requirements on data formats(such as ``Semantic Shield"" that requires image-text pairs). To address theselimitations, this work proposes a defense mechanism that leverages semanticsimilarity to detect backdoor attacks without modifying the model structure orimposing data format constraints. By analyzing deviations in semantic featurespace and establishing a threshold-based detection framework, the proposedapproach effectively identifies poisoned samples. The experimental resultsdemonstrate high detection accuracy and recall across varying poisoning ratios,underlining the significant effectiveness of our proposed solution.",Ziyang Wei,2025-02-06,2025-02-06,,N/A,"['cs.CR', 'cs.LG']"
2502.03719v1,Code Shaping: Iterative Code Editing with Free-form AI-Interpreted Sketching,http://arxiv.org/abs/2502.03719v1,"We introduce the concept of code shaping, an interaction paradigm for editingcode using free-form sketch annotations directly on top of the code and consoleoutput. To evaluate this concept, we conducted a three-stage design study with18 different programmers to investigate how sketches can communicate intendedcode edits to an AI model for interpretation and execution. The results showhow different sketches are used, the strategies programmers employ duringiterative interactions with AI interpretations, and interaction designprinciples that support the reconciliation between the code editor andsketches. Finally, we demonstrate the practical application of the code shapingconcept with two use case scenarios, illustrating design implications from thestudy.",Ryan Yen,2025-02-06,2025-02-06,,N/A,['cs.HC']
2502.03717v1,Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning,http://arxiv.org/abs/2502.03717v1,"Expressive robotic behavior is essential for the widespread acceptance ofrobots in social environments. Recent advancements in learned legged locomotioncontrollers have enabled more dynamic and versatile robot behaviors. However,determining the optimal behavior for interactions with different users acrossvaried scenarios remains a challenge. Current methods either rely on naturallanguage input, which is efficient but low-resolution, or learn from humanpreferences, which, although high-resolution, is sample inefficient. This paperintroduces a novel approach that leverages priors generated by pre-trained LLMsalongside the precision of preference learning. Our method, termedLanguage-Guided Preference Learning (LGPL), uses LLMs to generate initialbehavior samples, which are then refined through preference-based feedback tolearn behaviors that closely align with human expectations. Our core insight isthat LLMs can guide the sampling process for preference learning, leading to asubstantial improvement in sample efficiency. We demonstrate that LGPL canquickly learn accurate and expressive behaviors with as few as four queries,outperforming both purely language-parameterized models and traditionalpreference learning approaches. Website with videos:https://lgpl-gaits.github.io/",Jaden Clark,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.AI']"
2502.03716v1,Optimal Constructions for DNA Self-Assembly of $k$-Regular Graphs,http://arxiv.org/abs/2502.03716v1,"Within biology, it is of interest to construct DNA complexes of a certainshape. These complexes can be represented through graph theory, using edges tomodel strands of DNA joined at junctions, represented by vertices. Becauseguided construction is inefficient, design strategies for DNA self-assembly aredesirable. In the flexible tile model, branched DNA molecules are referred toas tiles, each consisting of flexible unpaired cohesive ends with the abilityto form bond-edges. We thus consider the minimum number of tile and bond-edgetypes necessary to construct a graph $G$ (i.e. a target structure) withoutallowing the formation of graphs of lesser order, or nonisomorphic graphs ofequal order. We emphasize the concept of (un)swappable graphs, establishinglower bounds for unswappable graphs. We also introduce a method of establishingupper bounds via vertex covers. We apply both of these methods to prove newbounds on rook's graphs and Kneser graphs.",Lisa Baek,2025-02-06,2025-02-06,,N/A,['math.CO']
2502.03715v1,Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models,http://arxiv.org/abs/2502.03715v1,"Knowledge Graph-based recommendations have gained significant attention dueto their ability to leverage rich semantic relationships. However, constructingand maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracyof KGs can suffer from noisy, outdated, or irrelevant triplets. Recentadvancements in Large Language Models (LLMs) offer a promising way to improvethe quality and relevance of KGs for recommendation tasks. Despite this,integrating LLMs into KG-based systems presents challenges, such as efficientlyaugmenting KGs, addressing hallucinations, and developing effective jointlearning methods. In this paper, we propose the Confidence-aware KG-basedRecommendation Framework with LLM Augmentation (CKG-LLMA), a novel frameworkthat combines KGs and LLMs for recommendation task. The framework includes: (1)an LLM-based subgraph augmenter for enriching KGs with high-qualityinformation, (2) a confidence-aware message propagation mechanism to filternoisy triplets, and (3) a dual-view contrastive learning method to integrateuser-item interactions and KG data. Additionally, we employ a confidence-awareexplanation generation process to guide LLMs in producing realisticexplanations for recommendations. Finally, extensive experiments demonstratethe effectiveness of CKG-LLMA across multiple public datasets.",Rui Cai,2025-02-06,2025-02-06,,N/A,"['cs.IR', 'cs.AI']"
2502.03714v1,Universal Sparse Autoencoders: Interpretable Cross-Model Concept Alignment,http://arxiv.org/abs/2502.03714v1,"We present Universal Sparse Autoencoders (USAEs), a framework for uncoveringand aligning interpretable concepts spanning multiple pretrained deep neuralnetworks. Unlike existing concept-based interpretability methods, which focuson a single model, USAEs jointly learn a universal concept space that canreconstruct and interpret the internal activations of multiple models at once.Our core insight is to train a single, overcomplete sparse autoencoder (SAE)that ingests activations from any model and decodes them to approximate theactivations of any other model under consideration. By optimizing a sharedobjective, the learned dictionary captures common factors ofvariation-concepts-across different tasks, architectures, and datasets. We showthat USAEs discover semantically coherent and important universal conceptsacross vision models; ranging from low-level features (e.g., colors andtextures) to higher-level structures (e.g., parts and objects). Overall, USAEsprovide a powerful new method for interpretable cross-model analysis and offersnovel applications, such as coordinated activation maximization, that openavenues for deeper insights in multi-model AI systems",Harrish Thasarathan,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.03713v1,A discrete Perfectly Matched Layer for peridynamic scalar waves in two-dimensional viscous media,http://arxiv.org/abs/2502.03713v1,"In this paper, we propose a discrete perfectly matched layer (PML) for theperidynamic scalar wave-type problems in viscous media. Constructing PMLs fornonlocal models is often challenging, mainly due to the fact that nonlocaloperators are usually associated with various kernels. We first convert thecontinua model to a spatial semi-discretized version by adoptingquadrature-based finite difference scheme, and then derive the PML equationsfrom the semi-discretized equations using discrete analytic continuation. Theharmonic exponential fundamental solutions (plane wave modes) of thesemi-discretized equations are absorbed by the PML layer without reflection andare exponentially damped. The excellent efficiency and stability of discretePML are demonstrated in numerical tests by comparison with exact absorbingboundary conditions.",Yu Du,2025-02-06,2025-02-06,,N/A,"['math.NA', 'cs.NA', '65N30, 65R20, 46N20, 45A05, 78A40', 'G.1.0; G.1.8']"
2502.03711v1,MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers,http://arxiv.org/abs/2502.03711v1,"One critical challenge in the institutional adoption journey of LargeLanguage Models (LLMs) stems from their propensity to hallucinate in generatedresponses. To address this, we propose MultiQ&A, a systematic approach forevaluating the robustness and consistency of LLM-generated answers. Wedemonstrate MultiQ&A's ability to crowdsource question perturbations and theirrespective answers through independent LLM agents at scale. Our experimentsculminated in the examination of 1.9 million question perturbations and 2.3million answers. Furthermore, MultiQ&A shows that ensembled LLMs, such asgpt-3.5-turbo, remain relatively robust and consistent under perturbations.MultiQ&A provides clarity in the response generation space, offering aneffective method for inspecting disagreements and variability. Therefore, oursystem offers a potential framework for institutional LLM adoption with theability to measure confidence, consistency, and the quantification ofhallucinations.",Nicole Cho,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.03708v1,Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers,http://arxiv.org/abs/2502.03708v1,"A trained Large Language Model (LLM) contains much of human knowledge. Yet,it is difficult to gauge the extent or accuracy of that knowledge, as LLMs donot always ``know what they know'' and may even be actively misleading. In thiswork, we give a general method for detecting semantic concepts in the internalactivations of LLMs. Furthermore, we show that our methodology can be easilyadapted to steer LLMs toward desirable outputs. Our innovations are thefollowing: (1) we use a nonlinear feature learning method to identify importantlinear directions for predicting concepts from each layer; (2) we aggregatefeatures across layers to build powerful concept detectors and steeringmechanisms. We showcase the power of our approach by attaining state-of-the-artresults for detecting hallucinations, harmfulness, toxicity, and untruthfulcontent on seven benchmarks. We highlight the generality of our approach bysteering LLMs towards new concepts that, to the best of our knowledge, have notbeen previously considered in the literature, including: semanticdisambiguation, human languages, programming languages, hallucinated responses,science subjects, poetic/Shakespearean English, and even multiple conceptssimultaneously. Moreover, our method can steer concepts with numericalattributes such as product reviews. We provide our code (including a simple APIfor our methods) at https://github.com/dmbeaglehole/neural_controllers .",Daniel Beaglehole,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'stat.ML']"
2502.03706v1,Novel echoes from black holes in conformal Weyl gravity,http://arxiv.org/abs/2502.03706v1,"We reveal a novel class of echoes from black holes in conformal Weyl gravityand show that they are generated due to the large-scale structure of thecosmos, rather than near-horizon modifications of black holes as well aswormhole spacetimes. To this end, we take into account the evolution of amassive scalar perturbation on the background geometry of conformal Weyl blackholes and show that the corresponding effective potential enjoys a double-peakbarrier against the incident scalar waves. We perform the calculations for thetime evolution profiles of scalar perturbations to understand how the linearterm in the metric function and the cosmological constant produce echoes. TheProny method is also employed to calculate the quasinormal frequencies of theearly-stage quasinormal ringing phase.",Mehrab Momennia,2025-02-06,2025-02-06,,N/A,"['gr-qc', 'hep-th']"
2502.03705v2,Dependence of Multi-band Absolute Magnitudes and Color Indexes of the Tip of Red Giant Branch Stars on Metallicity in the Galactic Globular Clusters,http://arxiv.org/abs/2502.03705v2,"The tip of red giant branch (TRGB) stars have attracted intensive attentionin recent years because their $I$-band absolute magnitudes, $M_\rm I$, areoften used for distance calibration in the Hubble constant measurements becauseof its almost independence on metallicity ([Fe/H]). However, a discrepancyexists between various studies and the theoretical stellar model predictsdependence of their luminosity on [Fe/H]. Here we present a careful study ofthe dependence of absolute magnitudes and color indexes on metallicity inoptical and near-infrared bands. With the TRGB stars identified in 33 Galacticglobular clusters by the reddest color in the $G_{\rm BP}-G_{\rm RP}$ vs.$G_{\rm RP}$ diagram, it is confirmed that $M_\rm I$ is almost constant of$-4.017 \pm 0.036 \pm 0.027$ mag when $[\rm Fe/H]<-1.2$, which would give$H_0=70.86\pm 1.2\pm0.9$ $\rm kms^{-1} Mp c^{-1}$ with this updated luminositycalibration for type Ia supernovae. However, for $[\rm Fe/H]>-1.2$, $M_\rm I$is found to become fainter with lower metallicity, which would lead to a largerHubble constant. In the optical $G_{\rm BP}, G_{\rm RP}$ and $V$ bands, theabsolute magnitude of TRGB stars tends to increase with metallicity, while inthe infrared $J, H$, and $K_{\rm S}$ bands, the variation with metallicityshows an inverse tendency. In addition, the analytical relations of the colorindexes with metallicity are presented, which have smaller dispersion thanthose derived for the corresponding absolute magnitudes.",Zhenzhen Shao,2025-02-06,2025-02-07,,N/A,"['astro-ph.SR', 'astro-ph.GA']"
2502.03701v1,First-ish Order Methods: Hessian-aware Scalings of Gradient Descent,http://arxiv.org/abs/2502.03701v1,"Gradient descent is the primary workhorse for optimizing large-scale problemsin machine learning. However, its performance is highly sensitive to the choiceof the learning rate. A key limitation of gradient descent is its lack ofnatural scaling, which often necessitates expensive line searches or heuristictuning to determine an appropriate step size. In this paper, we address thislimitation by incorporating Hessian information to scale the gradientdirection. By accounting for the curvature of the function along the gradient,our adaptive, Hessian-aware scaling method ensures a local unit step sizeguarantee, even in nonconvex settings. Near a local minimum that satisfies thesecond-order sufficient conditions, our approach achieves linear convergencewith a unit step size. We show that our method converges globally under asignificantly weaker version of the standard Lipschitz gradient smoothnessassumption. Even when Hessian information is inexact, the local unit step sizeguarantee and global convergence properties remain valid under mild conditions.Finally, we validate our theoretical results empirically on a range of convexand nonconvex machine learning tasks, showcasing the effectiveness of theapproach.",Oscar Smee,2025-02-06,2025-02-06,,N/A,"['math.OC', 'cs.LG', '49']"
2502.03700v1,Spectral parameters of the $ρ$ resonance from lattice QCD,http://arxiv.org/abs/2502.03700v1,"We present a lattice QCD investigation of the $\rho$ resonance using nine$N_f = 2 + 1$ Wilson-Clover ensembles with three lattice spacings and variouspion masses ranging from $135$ to $320$ MeV. For each ensemble, a large numberof finite volume energy levels are determined and the energy dependence of thephase shift obtained from L\""uscher's finite volume method. The mass and widthof the $\rho$ resonance are then extracted by assuming the Breit-Wigner form.The mass and width are extrapolated to the physical pion mass and continuumlimit ($\mathcal{O}(a^2)$) using a linear function of $a^2$ and $m^2_\pi$. Theextrapolated values for the mass and width in the Breit-Wigner form are$(m_\rho,\,\Gamma_\rho) = (781.6\pm10.0,\, 146.5\pm 9.9)$ MeV, which are ingood agreement with experiment. An alternative method of analysis, based onHamiltonian effective field theory, involves directly fitting the latticeenergy levels and accounting for the quark mass dependence of the hadronic loopdiagrams which yield the leading and next-to-leading non-analytic behaviour.This approach also yields consistent $\rho$ parameters at the physical point.This represents the most precise determination to date of the mass and width ofa hadron which is unstable under strong decay, achieved through comprehensivelattice QCD calculations and methods of analysis.",Zhengli Wang,2025-02-06,2025-02-06,,N/A,"['hep-lat', 'hep-ph']"
2502.03699v1,LLM Alignment as Retriever Optimization: An Information Retrieval Perspective,http://arxiv.org/abs/2502.03699v1,"Large Language Models (LLMs) have revolutionized artificial intelligence withcapabilities in reasoning, coding, and communication, driving innovation acrossindustries. Their true potential depends on effective alignment to ensurecorrect, trustworthy and ethical behavior, addressing challenges likemisinformation, hallucinations, bias and misuse. While existing ReinforcementLearning (RL)-based alignment methods are notoriously complex, directoptimization approaches offer a simpler alternative. In this work, we introducea novel direct optimization approach for LLM alignment by drawing onestablished Information Retrieval (IR) principles. We present a systematicframework that bridges LLM alignment and IR methodologies, mapping LLMgeneration and reward models to IR's retriever-reranker paradigm. Building onthis foundation, we propose LLM Alignment as Retriever Preference Optimization(LarPO), a new alignment method that enhances overall alignment quality.Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 %averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our workopens new avenues for advancing LLM alignment by integrating IR foundations,offering a promising direction for future research.",Bowen Jin,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI', 'cs.IR']"
2502.03698v1,How vulnerable is my policy? Adversarial attacks on modern behavior cloning policies,http://arxiv.org/abs/2502.03698v1,"Learning from Demonstration (LfD) algorithms have shown promising results inrobotic manipulation tasks, but their vulnerability to adversarial attacksremains underexplored. This paper presents a comprehensive study of adversarialattacks on both classic and recently proposed algorithms, including BehaviorCloning (BC), LSTM-GMM, Implicit Behavior Cloning (IBC), Diffusion Policy (DP),and VQ-Behavior Transformer (VQ-BET). We study the vulnerability of thesemethods to untargeted, targeted and universal adversarial perturbations. Whileexplicit policies, such as BC, LSTM-GMM and VQ-BET can be attacked in the samemanner as standard computer vision models, we find that attacks for implicitand denoising policy models are nuanced and require developing novel attackmethods. Our experiments on several simulated robotic manipulation tasks revealthat most of the current methods are highly vulnerable to adversarialperturbations. We also show that these attacks are transferable acrossalgorithms, architectures, and tasks, raising concerning securityvulnerabilities with potentially a white-box threat model. In addition, we testthe efficacy of a randomized smoothing, a widely used adversarial defensetechnique, and highlight its limitation in defending against attacks on complexand multi-modal action distribution common in complex control tasks. Insummary, our findings highlight the vulnerabilities of modern BC algorithms,paving way for future work in addressing such limitations.",Basavasagar Patil,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CR', 'cs.RO']"
2502.03696v1,Cascaded Learned Bloom Filter for Optimal Model-Filter Size Balance and Fast Rejection,http://arxiv.org/abs/2502.03696v1,"Recent studies have demonstrated that learned Bloom filters, which combinemachine learning with the classical Bloom filter, can achieve superior memoryefficiency. However, existing learned Bloom filters face two criticalunresolved challenges: the balance between the machine learning model size andthe Bloom filter size is not optimal, and the reject time cannot be minimizedeffectively. We propose the Cascaded Learned Bloom Filter (CLBF) to addressthese issues. Our dynamic programming-based optimization automatically selectsconfigurations that achieve an optimal balance between the model and filtersizes while minimizing reject time. Experiments on real-world datasets showthat CLBF reduces memory usage by up to 24% and decreases reject time by up to14 times compared to state-of-the-art learned Bloom filters.",Atsuki Sato,2025-02-06,2025-02-06,,N/A,"['cs.DS', 'cs.CC', 'cs.LG']"
2502.03695v1,Reduce Lap Time for Autonomous Racing with Curvature-Integrated MPCC Local Trajectory Planning Method,http://arxiv.org/abs/2502.03695v1,"The widespread application of autonomous driving technology has significantlyadvanced the field of autonomous racing. Model Predictive Contouring Control(MPCC) is a highly effective local trajectory planning method for autonomousracing. However, the traditional MPCC method struggles with racetracks thathave significant curvature changes, limiting the performance of the vehicleduring autonomous racing. To address this issue, we propose acurvature-integrated MPCC (CiMPCC) local trajectory planning method forautonomous racing. This method optimizes the velocity of the local trajectorybased on the curvature of the racetrack centerline. The specific implementationinvolves mapping the curvature of the racetrack centerline to a referencevelocity profile, which is then incorporated into the cost function foroptimizing the velocity of the local trajectory. This reference velocityprofile is created by normalizing and mapping the curvature of the racetrackcenterline, thereby ensuring efficient and performance-oriented localtrajectory planning in racetracks with significant curvature. The proposedCiMPCC method has been experimented on a self-built 1:10 scale F1TENTH racingvehicle deployed with ROS platform. The experimental results demonstrate thatthe proposed method achieves outstanding results on a challenging racetrackwith sharp curvature, improving the overall lap time by 11.4%-12.5% compared toother autonomous racing trajectory planning methods. Our code is available athttps://github.com/zhouhengli/CiMPCC.",Zhouheng Li,2025-02-06,2025-02-06,,N/A,"['cs.RO', 'cs.SY', 'eess.SY']"
2502.03693v1,Misspecification-Robust Shrinkage and Selection for VAR Forecasts and IRFs,http://arxiv.org/abs/2502.03693v1,"VARs are often estimated with Bayesian techniques to cope with modeldimensionality. The posterior means define a class of shrinkage estimators,indexed by hyperparameters that determine the relative weight on maximumlikelihood estimates and prior means. In a Bayesian setting, it is natural tochoose these hyperparameters by maximizing the marginal data density. However,this is undesirable if the VAR is misspecified. In this paper, we deriveasymptotically unbiased estimates of the multi-step forecasting risk and theimpulse response estimation risk to determine hyperparameters in settings wherethe VAR is (potentially) misspecified. The proposed criteria can be used tojointly select the optimal shrinkage hyperparameter, VAR lag length, and tochoose among different types of multi-step-ahead predictors; or among IRFestimates based on VARs and local projections. The selection approach isillustrated in a Monte Carlo study and an empirical application.",Oriol González-Casasús,2025-02-06,2025-02-06,,N/A,['econ.EM']
2502.03692v1,DocMIA: Document-Level Membership Inference Attacks against DocVQA Models,http://arxiv.org/abs/2502.03692v1,"Document Visual Question Answering (DocVQA) has introduced a new paradigm forend-to-end document understanding, and quickly became one of the standardbenchmarks for multimodal LLMs. Automating document processing workflows,driven by DocVQA models, presents significant potential for many businesssectors. However, documents tend to contain highly sensitive information,raising concerns about privacy risks associated with training such DocVQAmodels. One significant privacy vulnerability, exploited by the membershipinference attack, is the possibility for an adversary to determine if aparticular record was part of the model's training data. In this paper, weintroduce two novel membership inference attacks tailored specifically toDocVQA models. These attacks are designed for two different adversarialscenarios: a white-box setting, where the attacker has full access to the modelarchitecture and parameters, and a black-box setting, where only the model'soutputs are available. Notably, our attacks assume the adversary lacks accessto auxiliary datasets, which is more realistic in practice but also morechallenging. Our unsupervised methods outperform existing state-of-the-artmembership inference attacks across a variety of DocVQA models and datasets,demonstrating their effectiveness and highlighting the privacy risks in thisdomain.",Khanh Nguyen,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.CL', 'cs.CR']"
2502.04391v1,Towards Fair and Robust Face Parsing for Generative AI: A Multi-Objective Approach,http://arxiv.org/abs/2502.04391v1,"Face parsing is a fundamental task in computer vision, enabling applicationssuch as identity verification, facial editing, and controllable imagesynthesis. However, existing face parsing models often lack fairness androbustness, leading to biased segmentation across demographic groups and errorsunder occlusions, noise, and domain shifts. These limitations affect downstreamface synthesis, where segmentation biases can degrade generative model outputs.We propose a multi-objective learning framework that optimizes accuracy,fairness, and robustness in face parsing. Our approach introduces ahomotopy-based loss function that dynamically adjusts the importance of theseobjectives during training. To evaluate its impact, we compare multi-objectiveand single-objective U-Net models in a GAN-based face synthesis pipeline(Pix2PixHD). Our results show that fairness-aware and robust segmentationimproves photorealism and consistency in face generation. Additionally, weconduct preliminary experiments using ControlNet, a structured conditioningmodel for diffusion-based synthesis, to explore how segmentation qualityinfluences guided image generation. Our findings demonstrate thatmulti-objective face parsing improves demographic consistency and robustness,leading to higher-quality GAN-based synthesis.",Sophia J. Abraham,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.AI']"
2502.03688v1,A Comparison of DeepSeek and Other LLMs,http://arxiv.org/abs/2502.03688v1,"Recently, DeepSeek has been the focus of attention in and beyond the AIcommunity. An interesting problem is how DeepSeek compares to other largelanguage models (LLMs). There are many tasks an LLM can do, and in this paper,we use the task of predicting an outcome using a short text for comparison. Weconsider two settings, an authorship classification setting and a citationclassification setting. In the first one, the goal is to determine whether ashort text is written by human or AI. In the second one, the goal is toclassify a citation to one of four types using the textual content. For eachexperiment, we compare DeepSeek with $4$ popular LLMs: Claude, Gemini, GPT, andLlama.  We find that, in terms of classification accuracy, DeepSeek outperformsGemini, GPT, and Llama in most cases, but underperforms Claude. We also findthat DeepSeek is comparably slower than others but with a low cost to use,while Claude is much more expensive than all the others. Finally, we find thatin terms of similarity, the output of DeepSeek is most similar to those ofGemini and Claude (and among all $5$ LLMs, Claude and Gemini have the mostsimilar outputs).  In this paper, we also present a fully-labeled dataset collected byourselves, and propose a recipe where we can use the LLMs and a recent dataset, MADStat, to generate new data sets. The datasets in our paper can be usedas benchmarks for future study on LLMs.",Tianchen Gao,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.AI']"
2502.03687v1,Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free,http://arxiv.org/abs/2502.03687v1,"Discriminative classifiers have become a foundational tool in deep learningfor medical imaging, excelling at learning separable features of complex datadistributions. However, these models often need careful design, augmentation,and training techniques to ensure safe and reliable deployment. Recently,diffusion models have become synonymous with generative modeling in 2D. Thesemodels showcase robustness across a range of tasks including natural imageclassification, where classification is performed by comparing reconstructionerrors across images generated for each possible conditioning input. This workpresents the first exploration of the potential of class conditional diffusionmodels for 2D medical image classification. First, we develop a novel majorityvoting scheme shown to improve the performance of medical diffusionclassifiers. Next, extensive experiments on the CheXpert and ISIC Melanoma skincancer datasets demonstrate that foundation and trained-from-scratch diffusionmodels achieve competitive performance against SOTA discriminative classifierswithout the need for explicit supervision. In addition, we show that diffusionclassifiers are intrinsically explainable, and can be used to quantify theuncertainty of their predictions, increasing their trustworthiness andreliability in safety-critical, clinical contexts. Further information isavailable on our project page:https://faverogian.github.io/med-diffusion-classifier.github.io/",Gian Mario Favero,2025-02-06,2025-02-06,,N/A,"['cs.CV', 'cs.LG']"
2502.03686v1,Variational Control for Guidance in Diffusion Models,http://arxiv.org/abs/2502.03686v1,"Diffusion models exhibit excellent sample quality, but existing guidancemethods often require additional model training or are limited to specifictasks. We revisit guidance in diffusion models from the perspective ofvariational inference and control, introducing Diffusion Trajectory Matching(DTM) that enables guiding pretrained diffusion trajectories to satisfy aterminal cost. DTM unifies a broad class of guidance methods and enables novelinstantiations. We introduce a new method within this framework that achievesstate-of-the-art results on several linear and (blind) non-linear inverseproblems without requiring additional model training or modifications. Forinstance, in ImageNet non-linear deblurring, our model achieves an FID score of34.31, significantly improving over the best pretrained-method baseline (FID78.07). We will make the code available in a future update.",Kushagra Pandey,2025-02-06,2025-02-06,,N/A,"['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']"
2502.03685v1,Controlled LLM Decoding via Discrete Auto-regressive Biasing,http://arxiv.org/abs/2502.03685v1,"Controlled text generation allows for enforcing user-defined constraints onlarge language model outputs, an increasingly important field as LLMs becomemore prevalent in everyday life. One common approach uses energy-baseddecoding, which defines a target distribution through an energy function thatcombines multiple constraints into a weighted average. However, these methodsoften struggle to balance fluency with constraint satisfaction, even withextensive tuning of the energy function's coefficients. In this paper, weidentify that this suboptimal balance arises from sampling in continuous spacerather than the natural discrete space of text tokens. To address this, wepropose Discrete Auto-regressive Biasing, a controlled decoding algorithm thatleverages gradients while operating entirely in the discrete text domain.Specifically, we introduce a new formulation for controlled text generation bydefining a joint distribution over the generated sequence and an auxiliary biassequence. To efficiently sample from this joint distribution, we propose aLangevin-within-Gibbs sampling algorithm using gradient-based discrete MCMC.Our method significantly improves constraint satisfaction while maintainingcomparable or better fluency, all with even lower computational costs. Wedemonstrate the advantages of our controlled decoding method on sentimentcontrol, language detoxification, and keyword-guided generation.",Patrick Pynadath,2025-02-06,2025-02-06,,N/A,"['cs.CL', 'cs.LG', 'stat.ML']"
2502.03683v1,Ruling out AGNs as the dominant source of cosmic reionization with JWST,http://arxiv.org/abs/2502.03683v1,"Cosmic reionization represents the latest phase transition of theintergalactic medium (IGM) in the Universe. It has long been debated whethergalaxies or active galactic nuclei (AGNs) are the major source of Lymancontinuum (LyC) photons responsible for reionization. Previous observationsslightly favored galaxies as the major ionizing source. However, the James WebbSpace Telescope (JWST) recently discovered an unexpectedly high density of AGNcandidates at high redshift, which has largely enhanced the influence of AGNs.Here we derive a definitive upper bound on the AGN contribution to reionizationusing the latest JWST data, and conclusively rule out AGNs as the dominantionizing source during the epoch of reionization (EoR). We build a sample ofobjects (including galaxies and AGNs) in a specific redshift range between 7.15and 7.75 that has a high completeness. Each object is then decomposed into apoint-source component and an extended component in their rest-frame far-UVJWST images. Assuming all point-source components are AGNs, we obtain anabsolute upper limit for the density of the AGN population. This fiducial AGNsample reaches an unprecedentedly low luminosity of $M_{\rm UV} \approx -15$mag. Based on this sample, we find that AGNs can contribute at most one thirdof the LyC photons required to ionize the Universe in this redshift range. Ourresult implies that galaxies dominate the ionizing source during the EoR.",Danyang Jiang,2025-02-06,2025-02-06,,N/A,['astro-ph.GA']
2502.03680v1,Emulators for scarce and noisy data II: Application to auxiliary-field diffusion Monte Carlo for neutron matter,http://arxiv.org/abs/2502.03680v1,"Understanding the equation of state (EOS) of pure neutron matter is necessaryfor interpreting multi-messenger observations of neutron stars. Reliable dataanalyses of these observations require well-quantified uncertainties for theEOS input, ideally propagating uncertainties from nuclear interactions directlyto the EOS. This, however, requires calculations of the EOS for a prohibitivelylarger number of nuclear Hamiltonians, solving the nuclear many-body problemfor each one. Quantum Monte Carlo methods, such as Auxiliary field diffusionMonte Carlo (AFDMC), provide precise and accurate results for the neutronmatter EOS but they are very computationally expensive, making them unsuitablefor the fast evaluations necessary for uncertainty propagation. Here, we employparametric matrix models to develop fast emulators for AFDMC calculations ofneutron matter, and use them to directly propagate uncertainties of couplingconstants in the Hamiltonian to the EOS. As these uncertainties includeestimates of the EFT truncation uncertainty, this approach provides robustuncertainty estimates for use in astrophysical data analyses. This work willenable novel applications such as using astrophysical observations to putconstraints on coupling constants for nuclear interactions.",Cassandra L. Armstrong,2025-02-05,2025-02-05,,N/A,['nucl-th']
2502.03679v1,The relationship between galaxy size and halo properties: Insights from the IllustrisTNG simulations and differential clustering,http://arxiv.org/abs/2502.03679v1,"The physical origin of the radial sizes of galaxies and how galaxy sizes arecorrelated with the properties of their host dark matter halos is an openquestion in galaxy formation. In observations, the large-scale clustering ofgalaxies selected by stellar mass is significantly different for large andsmall galaxies, and Behroozi et al. (2022) showed that these results are intension with some of the correlations between galaxy size and halo propertiesin the literature. We analyze the IllustrisTNG suite of large volumecosmological hydrodynamic simulations along with dark matter only simulationswith matched initial conditions. We investigate correlations between the ratioof galaxy size to halo virial radius ($r_{\rm gal}/R_{\rm vir}$) and halo spin,concentration, and formation time at redshift 0-3. We find a significantcorrelation between $r_{\rm gal}/R_{\rm vir}$ and concentration, but only abovea critical value $c \simeq 16$, and we also find a correlation between $r_{\rmgal}/R_{\rm vir}$ and halo formation time. We suggest that galaxy formationhistory and environment, in addition to halo properties at a given output time,play an important role in shaping galaxy size. In addition, we directly measuresize-based differential clustering in the TNG300 simulation and comparedirectly with the observational results. We find significant scale-dependentsize-based differential clustering in TNG, in qualitative agreement withobservations. However, correlations between $r_{\rm gal}/R_{\rm vir}$ andsecondary halo properties are not the drivers of the differential clustering inthe simulations; instead, we find that most of this signal in TNG arises fromsatellite galaxies.",Rachel S. Somerville,2025-02-05,2025-02-05,,N/A,['astro-ph.GA']
2502.03678v1,Reflection-Window Decoding: Text Generation with Selective Refinement,http://arxiv.org/abs/2502.03678v1,"The autoregressive decoding for text generation in large language models(LLMs), while widely used, is inherently suboptimal due to the lack of abuilt-in mechanism to perform refinement and/or correction of the generatedcontent. In this paper, we consider optimality in terms of the jointprobability over the generated response, when jointly considering all tokens atthe same time. We theoretically characterize the potential deviation of theautoregressively generated response from its globally optimal counterpart thatis of the same length. Our analysis suggests that we need to be cautious whennoticeable uncertainty arises during text generation, which may signal thesub-optimality of the generation history. To address the pitfall ofautoregressive decoding for text generation, we propose an approach thatincorporates a sliding reflection window and a pausing criterion, such thatrefinement and generation can be carried out interchangeably as the decodingproceeds. Our selective refinement framework strikes a balance betweenefficiency and optimality, and our extensive experimental results demonstratethe effectiveness of our approach.",Zeyu Tang,2025-02-05,2025-02-05,,N/A,"['cs.CL', 'cs.AI', 'cs.LG']"
2502.03677v1,COMNETS: COst-sensitive decision trees approach to throughput optimization for Multi-radio IoT NETworkS,http://arxiv.org/abs/2502.03677v1,"Mesoscale IoT applications, such as P2P energy trade and real-time industrialcontrol systems, demand high throughput and low latency, with a secondaryemphasis on energy efficiency as they rely on grid power or large-capacitybatteries. MARS, a multi-radio architecture, leverages ML to instantaneouslyselect the optimal radio for transmission, outperforming the single-radiosystems. However, MARS encounters a significant issue with cost sensitivity,where high-cost errors account for 40% throughput loss. Current cost-sensitiveML algorithms assign a misclassification cost for each class but not for eachdata sample. In MARS, each data sample has different costs, making it tediousto employ existing cost-sensitive ML algorithms. First, we address this issueby developing COMNETS, an ML-based radio selector using oblique trees optimizedby Tree Alternating Optimization (TAO). TAO incorporates sample-specificmisclassification costs to avert high-cost errors and achieves a 50% reductionin the decision tree size, making it more suitable for resource-constrained IoTdevices. Second, we prove the stability property of TAO and leverage it tounderstand the critical factors affecting the radio-selection problem. Finally,our real-world evaluation of COMNETS at two different locations shows anaverage throughput gain of 20.83%, 17.39% than MARS.",Jothi Prasanna Shanmuga Sundaram,2025-02-05,2025-02-05,,N/A,['cs.NI']
2502.04390v1,In Praise of Stubbornness: The Case for Cognitive-Dissonance-Aware Knowledge Updates in LLMs,http://arxiv.org/abs/2502.04390v1,"Despite remarkable capabilities, large language models (LLMs) struggle tocontinually update their knowledge without catastrophic forgetting. Incontrast, humans effortlessly integrate new information, detect conflicts withexisting beliefs, and selectively update their mental models. This paperintroduces a cognitive-inspired investigation paradigm to study continualknowledge updating in LLMs. We implement two key components inspired by humancognition: (1) Dissonance and Familiarity Awareness, analyzing model behaviorto classify information as novel, familiar, or dissonant; and (2) TargetedNetwork Updates, which track neural activity to identify frequently used(stubborn) and rarely used (plastic) neurons. Through carefully designedexperiments in controlled settings, we uncover a number of empirical findingsdemonstrating the potential of this approach. First, dissonance detection isfeasible using simple activation and gradient features, suggesting potentialfor cognitive-inspired training. Second, we find that non-dissonant updateslargely preserve prior knowledge regardless of targeting strategy, revealinginherent robustness in LLM knowledge integration. Most critically, we discoverthat dissonant updates prove catastrophically destructive to the model'sknowledge base, indiscriminately affecting even information unrelated to thecurrent updates. This suggests fundamental limitations in how neural networkshandle contradictions and motivates the need for new approaches to knowledgeupdating that better mirror human cognitive mechanisms.",Simone Clemente,2025-02-05,2025-02-05,,N/A,"['cs.CL', 'cs.AI', 'cs.LG', 'q-bio.NC']"
2502.04389v1,Overcoming Vision Language Model Challenges in Diagram Understanding: A Proof-of-Concept with XML-Driven Large Language Models Solutions,http://arxiv.org/abs/2502.04389v1,"Diagrams play a crucial role in visually conveying complex relationships andprocesses within business documentation. Despite recent advances inVision-Language Models (VLMs) for various image understanding tasks, accuratelyidentifying and extracting the structures and relationships depicted indiagrams continues to pose significant challenges. This study addresses thesechallenges by proposing a text-driven approach that bypasses reliance on VLMs'visual recognition capabilities. Instead, it utilizes the editable sourcefiles--such as xlsx, pptx or docx--where diagram elements (e.g., shapes, lines,annotations) are preserved as textual metadata. In our proof-of-concept, weextracted diagram information from xlsx-based system design documents andtransformed the extracted shape data into textual input for Large LanguageModels (LLMs). This approach allowed the LLM to analyze relationships andgenerate responses to business-oriented questions without the bottleneck ofimage-based processing. Experimental comparisons with a VLM-based methoddemonstrated that the proposed text-driven framework yielded more accurateanswers for questions requiring detailed comprehension of diagramstructures.The results obtained in this study are not limited to the tested.xlsx files but can also be extended to diagrams in other documents with sourcefiles, such as Office pptx and docx formats. These findings highlight thefeasibility of circumventing VLM constraints through direct textual extractionfrom original source files. By enabling robust diagram understanding throughLLMs, our method offers a promising path toward enhanced workflow efficiencyand information analysis in real-world business scenarios.",Shue Shiinoki,2025-02-05,2025-02-05,,N/A,"['cs.SE', 'cs.AI']"
2502.03672v1,Physically consistent predictive reduced-order modeling by enhancing Operator Inference with state constraints,http://arxiv.org/abs/2502.03672v1,"Numerical simulations of complex multiphysics systems, such as charcombustion considered herein, yield numerous state variables that inherentlyexhibit physical constraints. This paper presents a new approach to augmentOperator Inference -- a methodology within scientific machine learning thatenables learning from data a low-dimensional representation of ahigh-dimensional system governed by nonlinear partial differential equations --by embedding such state constraints in the reduced-order model predictions. Inthe model learning process, we propose a new way to choose regularizationhyperparameters based on a key performance indicator. Since embedding stateconstraints improves the stability of the Operator Inference reduced-ordermodel, we compare the proposed state constraints-embedded Operator Inferencewith the standard Operator Inference and other stability-enhancing approaches.For an application to char combustion, we demonstrate that the proposedapproach yields state predictions superior to the other methods regardingstability and accuracy. It extrapolates over 200\% past the training regimewhile being computationally efficient and physically consistent.",Hyeonghun Kim,2025-02-05,2025-02-05,,N/A,"['physics.comp-ph', 'cs.LG', 'cs.NA', 'math.NA']"
2502.03671v1,Advancing Reasoning in Large Language Models: Promising Methods and Approaches,http://arxiv.org/abs/2502.03671v1,"Large Language Models (LLMs) have succeeded remarkably in various naturallanguage processing (NLP) tasks, yet their reasoning capabilities remain afundamental challenge. While LLMs exhibit impressive fluency and factualrecall, their ability to perform complex reasoning-spanning logical deduction,mathematical problem-solving, commonsense inference, and multi-stepreasoning-often falls short of human expectations. This survey provides acomprehensive review of emerging techniques enhancing reasoning in LLMs. Wecategorize existing methods into key approaches, including prompting strategies(e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thoughtreasoning), architectural innovations (e.g., retrieval-augmented models,modular reasoning networks, and neuro-symbolic integration), and learningparadigms (e.g., fine-tuning with reasoning-specific datasets, reinforcementlearning, and self-supervised reasoning objectives). Additionally, we exploreevaluation frameworks used to assess reasoning in LLMs and highlight openchallenges, such as hallucinations, robustness, and reasoning generalizationacross diverse tasks. By synthesizing recent advancements, this survey aims toprovide insights into promising directions for future research and practicalapplications of reasoning-augmented LLMs.",Avinash Patil,2025-02-05,2025-02-05,,N/A,"['cs.CL', 'cs.AI']"
2502.03670v1,Chaos into Order: Neural Framework for Expected Value Estimation of Stochastic Partial Differential Equations,http://arxiv.org/abs/2502.03670v1,"Stochastic Partial Differential Equations (SPDEs) are fundamental to modelingcomplex systems in physics, finance, and engineering, yet their numericalestimation remains a formidable challenge. Traditional methods rely ondiscretization, introducing computational inefficiencies, and limitingapplicability in high-dimensional settings. In this work, we introduce a novelneural framework for SPDE estimation that eliminates the need fordiscretization, enabling direct estimation of expected values across arbitraryspatio-temporal points. We develop and compare two distinct neuralarchitectures: Loss Enforced Conditions (LEC), which integrates physicalconstraints into the loss function, and Model Enforced Conditions (MEC), whichembeds these constraints directly into the network structure. Through extensiveexperiments on the stochastic heat equation, Burgers' equation, andKardar-Parisi-Zhang (KPZ) equation, we reveal a trade-off: While LEC achievessuperior residual minimization and generalization, MEC enforces initialconditions with absolute precision and exceptionally high accuracy in boundarycondition enforcement. Our findings highlight the immense potential ofneural-based SPDE solvers, particularly for high-dimensional problems whereconventional techniques falter. By circumventing discretization and explicitlymodeling uncertainty, our approach opens new avenues for solving SPDEs infields ranging from quantitative finance to turbulence modeling. To the best ofour knowledge, this is the first neural framework capable of directlyestimating the expected values of SPDEs in an entirely non-discretized manner,offering a step forward in scientific computing.",Ísak Pétursson,2025-02-05,2025-02-05,,N/A,['cs.LG']
2502.03669v1,Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set,http://arxiv.org/abs/2502.03669v1,"AI methods, such as generative models and reinforcement learning, haverecently been applied to combinatorial optimization (CO) problems, especiallyNP-hard ones. This paper compares such GPU-based methods with classicalCPU-based methods on Maximum Independent Set (MIS). Experiments on standardgraph families show that AI-based algorithms fail to outperform and, in manycases, to match the solution quality of the state-of-art classical solver KaMISrunning on a single CPU. Some GPU-based methods even perform similarly to thesimplest heuristic, degree-based greedy. Even with post-processing techniqueslike local search, AI-based methods still perform worse than CPU-based solvers.  We develop a new mode of analysis to reveal that non-backtracking AI methods,e.g. LTFT (which is based on GFlowNets), end up reasoning similarly to thesimplest degree-based greedy approach, and thus worse than KaMIS. We also findthat CPU-based algorithms, notably KaMIS, have strong performance on sparserandom graphs, which appears to refute a well-known conjectured upper bound forefficient algorithms from Coja-Oghlan & Efthymiou (2015).",Yikai Wu,2025-02-05,2025-02-05,,N/A,"['cs.LG', 'cs.AI', 'cs.DM', 'math.OC', 'stat.ML']"
2502.03668v1,Privacy-Preserving Generative Models: A Comprehensive Survey,http://arxiv.org/abs/2502.03668v1,"Despite the generative model's groundbreaking success, the need to study itsimplications for privacy and utility becomes more urgent. Although many studieshave demonstrated the privacy threats brought by GANs, no existing survey hassystematically categorized the privacy and utility perspectives of GANs andVAEs. In this article, we comprehensively study privacy-preserving generativemodels, articulating the novel taxonomies for both privacy and utility metricsby analyzing 100 research publications. Finally, we discuss the currentchallenges and future research directions that help new researchers gaininsight into the underlying concepts.",Debalina Padariya,2025-02-05,2025-02-05,,N/A,"['cs.LG', 'cs.CR']"
2502.03664v1,Contrastive Learning for Cold Start Recommendation with Adaptive Feature Fusion,http://arxiv.org/abs/2502.03664v1,"This paper proposes a cold start recommendation model that integratescontrastive learning, aiming to solve the problem of performance degradation ofrecommendation systems in cold start scenarios due to the scarcity of user anditem interaction data. The model dynamically adjusts the weights of keyfeatures through an adaptive feature selection module and effectivelyintegrates user attributes, item meta-information, and contextual features bycombining a multimodal feature fusion mechanism, thereby improvingrecommendation performance. In addition, the model introduces a contrastivelearning mechanism to enhance the robustness and generalization ability offeature representation by constructing positive and negative sample pairs.Experiments are conducted on the MovieLens-1M dataset. The results show thatthe proposed model significantly outperforms mainstream recommendation methodssuch as Matrix Factorization, LightGBM, DeepFM, and AutoRec in terms of HR,NDCG, MRR, and Recall, especially in cold start scenarios. Ablation experimentsfurther verify the key role of each module in improving model performance, andthe learning rate sensitivity analysis shows that a moderate learning rate iscrucial to the optimization effect of the model. This study not only provides anew solution to the cold start problem but also provides an important referencefor the application of contrastive learning in recommendation systems. In thefuture, this model is expected to play a role in a wider range of scenarios,such as real-time recommendation and cross-domain recommendation.",Jiacheng Hu,2025-02-05,2025-02-05,,N/A,"['cs.IR', 'cs.LG']"
2502.03663v1,Fast Geographic Routing in Fixed-Growth Graphs,http://arxiv.org/abs/2502.03663v1,"In the 1960s, the social scientist Stanley Milgram performed his famous""small-world"" experiments where he found that people in the US who are farapart geographically are nevertheless connected by remarkably short chains ofacquaintances. Since then, there has been considerable work to design networksthat accurately model the phenomenon that Milgram observed. One well-knownapproach was Barab{\'a}si and Albert's preferential attachment model, which hassmall diameter yet lacks an algorithm that can efficiently find those shortconnections between nodes. Jon Kleinberg, in contrast, proposed a small-worldgraph formed from an $n \times n$ lattice that guarantees that greedy routingcan navigate between any two nodes in $\mathcal{O}(\log^2 n)$ time with highprobability. Further work by Goodrich and Ozel and by Gila, Goodrich, and Ozelpresent a hybrid technique that combines elements from these previousapproaches to improve greedy routing time to $\mathcal{O}(\log n)$ hops. Theseare important theoretical results, but we believe that their reliance on thesquare lattice limits their application in the real world. In this work, wegeneralize the model of Gila, Ozel, and Goodrich to any class of what we callfixed-growth graphs of dimensionality $\alpha$, a subset of bounded-growthgraphs introduced in several prior papers. We prove tight bounds for greedyrouting and diameter in these graphs, both in expectation and with highprobability. We then apply our model to the U.S. road network to show that bymodeling the network as a fixed-growth graph rather than as a lattice, we areable to improve greedy routing performance over all 50 states. We also showempirically that the optimal clustering exponent for the U.S. road network ismuch better modeled by the dimensionality of the network $\alpha$ than by thenetwork's size, as was conjectured in a previous work.",Ofek Gila,2025-02-05,2025-02-05,,N/A,"['cs.DS', 'E.1']"
2502.03662v1,EC-SBM Synthetic Network Generator,http://arxiv.org/abs/2502.03662v1,"Generating high-quality synthetic networks with realistic community structureis vital to effectively evaluate community detection algorithms. In this study,we propose a new synthetic network generator called the Edge-ConnectedStochastic Block Model (EC-SBM). The goal of EC-SBM is to take a givenclustered real-world network and produce a synthetic network that resembles theclustered real-world network with respect to both network andcommunity-specific criteria. In particular, we focus on simulating the internaledge connectivity of the clusters in the reference clustered network. Ourextensive performance study on large real-world networks shows that EC-SBM hashigh accuracy in both network and community-specific criteria, and is generallymore accurate than current alternative approaches for this problem.Furthermore, EC-SBM is fast enough to scale to real-world networks withmillions of nodes.",The-Anh Vu-Le,2025-02-05,2025-02-05,,N/A,['cs.SI']
2502.03660v1,Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials,http://arxiv.org/abs/2502.03660v1,"Universal Machine Learning Interactomic Potentials (MLIPs) enable acceleratedsimulations for materials discovery. However, current research efforts fail toimpactfully utilize MLIPs due to: 1. Overreliance on Density Functional Theory(DFT) for MLIP training data creation; 2. MLIPs' inability to reliably andaccurately perform large-scale molecular dynamics (MD) simulations for diversematerials; 3. Limited understanding of MLIPs' underlying capabilities. Toaddress these shortcomings, we aargue that MLIP research efforts shouldprioritize: 1. Employing more accurate simulation methods for large-scale MLIPtraining data creation (e.g. Coupled Cluster Theory) that cover a wide range ofmaterials design spaces; 2. Creating MLIP metrology tools that leveragelarge-scale benchmarking, visualization, and interpretability analyses toprovide a deeper understanding of MLIPs' inner workings; 3. Developingcomputationally efficient MLIPs to execute MD simulations that accurately modela broad set of materials properties. Together, these interdisciplinary researchdirections can help further the real-world application of MLIPs to accuratelymodel complex materials at device scale.",Santiago Miret,2025-02-05,2025-02-05,,N/A,"['cond-mat.mtrl-sci', 'cs.AI', 'cs.LG']"
2502.03658v1,Advancing Weight and Channel Sparsification with Enhanced Saliency,http://arxiv.org/abs/2502.03658v1,"Pruning aims to accelerate and compress models by removing redundantparameters, identified by specifically designed importance scores which areusually imperfect. This removal is irreversible, often leading to subparperformance in pruned models. Dynamic sparse training, while attempting toadjust sparse structures during training for continual reassessment andrefinement, has several limitations including criterion inconsistency betweenpruning and growth, unsuitability for structured sparsity, and short-sightedgrowth strategies. Our paper introduces an efficient, innovative paradigm toenhance a given importance criterion for either unstructured or structuredsparsity. Our method separates the model into an active structure forexploitation and an exploration space for potential updates. Duringexploitation, we optimize the active structure, whereas in exploration, wereevaluate and reintegrate parameters from the exploration space through apruning and growing step consistently guided by the same given importancecriterion. To prepare for exploration, we briefly ""reactivate"" all parametersin the exploration space and train them for a few iterations while keeping theactive part frozen, offering a preview of the potential performance gains fromreintegrating these parameters. We show on various datasets and configurationsthat existing importance criterion even simple as magnitude can be enhancedwith ours to achieve state-of-the-art performance and training cost reductions.Notably, on ImageNet with ResNet50, ours achieves an +1.3 increase in Top-1accuracy over prior art at 90% ERK sparsity. Compared with the SOTA latencypruning method HALP, we reduced its training cost by over 70% while attaining afaster and more accurate pruned model.",Xinglong Sun,2025-02-05,2025-02-05,,N/A,"['cs.LG', 'cs.CV']"
2502.03656v1,A Study in Dataset Distillation for Image Super-Resolution,http://arxiv.org/abs/2502.03656v1,"Dataset distillation is the concept of condensing large datasets into smallerbut highly representative synthetic samples. While previous research hasprimarily focused on image classification, its application to imageSuper-Resolution (SR) remains underexplored. This exploratory work studiesmultiple dataset distillation techniques applied to SR, including pixel- andlatent-space approaches under different aspects. Our experiments demonstratethat a 91.12% dataset size reduction can be achieved while maintainingcomparable SR performance to the full dataset. We further analyzeinitialization strategies and distillation methods to optimize memoryefficiency and computational costs. Our findings provide new insights intodataset distillation for SR and set the stage for future advancements.",Tobias Dietz,2025-02-05,2025-02-05,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.03654v1,Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics,http://arxiv.org/abs/2502.03654v1,"Activation functions are fundamental elements of deep learning architecturesas they significantly influence training dynamics. ReLU, while widely used, isprone to the dying neuron problem, which has been mitigated by variants such asLeakyReLU, PReLU, and ELU that better handle negative neuron outputs. Recently,self-gated activations like GELU and Swish have emerged as state-of-the-artalternatives, leveraging their smoothness to ensure stable gradient flow andprevent neuron inactivity. In this work, we introduce the Gompertz Linear Unit(GoLU), a novel self-gated activation function defined as $\mathrm{GoLU}(x) = x\, \mathrm{Gompertz}(x)$, where $\mathrm{Gompertz}(x) = e^{-e^{-x}}$. The GoLUactivation leverages the asymmetry in the Gompertz function to reduce variancein the latent space more effectively compared to GELU and Swish, whilepreserving robust gradient flow. Extensive experiments across diverse tasks,including Image Classification, Language Modeling, Semantic Segmentation,Object Detection, Instance Segmentation, and Diffusion, highlight GoLU'ssuperior performance relative to state-of-the-art activation functions,establishing GoLU as a robust alternative to existing activation functions.",Indrashis Das,2025-02-05,2025-02-05,,N/A,"['cs.LG', 'cs.AI', 'cs.CV']"
2502.03653v1,Tilt in quadratic gravity II,http://arxiv.org/abs/2502.03653v1,"We investigate a tilted fluid component on a Bianchi V geometry in thetheories of General Relativity (GR) and Quadratic Gravity (QG). The numericaltime evolution is to the future. As is well known, QG contains theRuzmaikina-Ruzmaikin (RR) solution. This solution describes the slow-rollregime of Starobinsky's inflationary model, which is currently the best one dueto the excellent agreement with Cosmic Microwave Background Radiation (CMBR)data. In QG, we found universes that can be attracted to the RR solution orrecollapse toward the isotropic singularity attractor. If the Equation of State(EoS) parameter is ultra-radiative w>1/3, the tilt variable increases both inRR and Milne for QG or GR, respectively. In both cases, the fluid expansion andacceleration diverge, while the vorticity initially increases and thendecreases to zero.",Waleska P. F. de Medeiros,2025-02-05,2025-02-05,,N/A,['gr-qc']
2502.03651v1,Characterization of Starlink Direct-to-Cell Satellites In Brightness Mitigation Mode,http://arxiv.org/abs/2502.03651v1,"The mean apparent magnitude of Starlink Mini Direct-To-Cell (DTC) satellitesobserved in brightness mitigation mode is 5.16, while the mean of magnitudesadjusted to a uniform distance of 1,000 km is 6.47. The DTCs have faded sinceearly in 2024 because SpaceX subsequently adjusted the spacecraft attitudes todim them. A physical model for satellite brightness that fits the observationsis described.",Anthony Mallama,2025-02-05,2025-02-05,,N/A,['astro-ph.IM']
2502.03650v1,Rule-based Evolving Fuzzy System for Time Series Forecasting: New Perspectives Based on Type-2 Fuzzy Sets Measures Approach,http://arxiv.org/abs/2502.03650v1,"Real-world data contain uncertainty and variations that can be correlated toexternal variables, known as randomness. An alternative cause of randomness ischaos, which can be an important component of chaotic time series. One of theexisting methods to deal with this type of data is the use of the evolvingFuzzy Systems (eFSs), which have been proven to be a powerful class of modelsfor time series forecasting, due to their autonomy to handle the data andhighly complex problems in real-world applications. However, due to its workingstructure, type-2 fuzzy sets can outperform type-1 fuzzy sets for highlyuncertain scenarios. We then propose ePL-KRLS-FSM+, an enhanced class ofevolving fuzzy modeling approach that combines participatory learning (PL), akernel recursive least squares method (KRLS), type-2 fuzzy logic and datatransformation into fuzzy sets (FSs). This improvement allows to create andmeasure type-2 fuzzy sets for better handling uncertainties in the data,generating a model that can predict chaotic data with increased accuracy. Themodel is evaluated using two complex datasets: the chaotic time seriesMackey-Glass delay differential equation with different degrees of chaos, andthe main stock index of the Taiwan Capitalization Weighted Stock Index - TAIEX.Model performance is compared to related state-of-the-art rule-based eFS modelsand classical approaches and is analyzed in terms of error metrics, runtime andthe number of final rules. Forecasting results show that the proposed model iscompetitive and performs consistently compared with type-1 models, alsooutperforming other forecasting methods by showing the lowest error metrics andnumber of final rules.",Eduardo Santos de Oliveira Marques,2025-02-05,2025-02-05,,N/A,"['stat.ML', 'cs.LG']"
2502.03649v1,All-in-One Image Compression and Restoration,http://arxiv.org/abs/2502.03649v1,"Visual images corrupted by various types and levels of degradations arecommonly encountered in practical image compression. However, most existingimage compression methods are tailored for clean images, therefore strugglingto achieve satisfying results on these images. Joint compression andrestoration methods typically focus on a single type of degradation and fail toaddress a variety of degradations in practice. To this end, we propose aunified framework for all-in-one image compression and restoration, whichincorporates the image restoration capability against various degradations intothe process of image compression. The key challenges involve distinguishingauthentic image content from degradations, and flexibly eliminating variousdegradations without prior knowledge. Specifically, the proposed frameworkapproaches these challenges from two perspectives: i.e., content informationaggregation, and degradation representation aggregation. Extensive experimentsdemonstrate the following merits of our model: 1) superior rate-distortion (RD)performance on various degraded inputs while preserving the performance onclean data; 2) strong generalization ability to real-world and unseenscenarios; 3) higher computing efficiency over compared methods. Our code isavailable at https://github.com/ZeldaM1/All-in-one.",Huimin Zeng,2025-02-05,2025-02-05,,N/A,['cs.CV']
2502.03647v1,Looking for the Inner Music: Probing LLMs' Understanding of Literary Style,http://arxiv.org/abs/2502.03647v1,"Recent work has demonstrated that language models can be trained to identifythe author of much shorter literary passages than has been thought feasible fortraditional stylometry. We replicate these results for authorship and extendthem to a new dataset measuring novel genre. We find that LLMs are able todistinguish authorship and genre, but they do so in different ways. Some modelsseem to rely more on memorization, while others benefit more from training tolearn author/genre characteristics. We then use three methods to probe onehigh-performing LLM for features that define style. These include directsyntactic ablations to input text as well as two methods that look at modelinternals. We find that authorial style is easier to define than genre-levelstyle and is more impacted by minor syntactic decisions and contextual wordusage. However, some traits like pronoun usage and word order prove significantfor defining both kinds of literary style.",Rebecca M. M. Hicke,2025-02-05,2025-02-05,,N/A,"['cs.CL', 'cs.LG']"
2502.04388v1,Position: Emergent Machina Sapiens Urge Rethinking Multi-Agent Paradigms,http://arxiv.org/abs/2502.04388v1,"Artificially intelligent (AI) agents that are capable of autonomous learningand independent decision-making hold great promise for addressing complexchallenges across domains like transportation, energy systems, andmanufacturing. However, the surge in AI systems' design and deployment drivenby various stakeholders with distinct and unaligned objectives introduces acrucial challenge: how can uncoordinated AI systems coexist and evolveharmoniously in shared environments without creating chaos? To address this, weadvocate for a fundamental rethinking of existing multi-agent frameworks, suchas multi-agent systems and game theory, which are largely limited to predefinedrules and static objective structures. We posit that AI agents should beempowered to dynamically adjust their objectives, make compromises, formcoalitions, and safely compete or cooperate through evolving relationships andsocial feedback. Through this paper, we call for a shift toward the emergent,self-organizing, and context-aware nature of these systems.",Hepeng Li,2025-02-05,2025-02-05,,N/A,"['cs.MA', 'cs.AI']"
2502.03644v1,"Quasi-Monte Carlo Methods: What, Why, and How?",http://arxiv.org/abs/2502.03644v1,"Many questions in quantitative finance, uncertainty quantification, and otherdisciplines are answered by computing the population mean, $\mu :=\mathbb{E}(Y)$, where instances of $Y:=f(\boldsymbol{X})$ may be generated bynumerical simulation and $\boldsymbol{X}$ has a simple probabilitydistribution. The population mean can be approximated by the sample mean,$\hat{\mu}_n := n^{-1} \sum_{i=0}^{n-1} f(\boldsymbol{x}_i)$ for a well chosensequence of nodes, $\{\boldsymbol{x}_0, \boldsymbol{x}_1, \ldots\}$ and asufficiently large sample size, $n$. Computing $\mu$ is equivalent to computinga $d$-dimensional integral, $\int f(\boldsymbol{x}) \varrho(\boldsymbol{x}) \,\mathrm{d} \boldsymbol{x}$, where $\varrho$ is the probability density for$\boldsymbol{X}$.  Quasi-Monte Carlo methods replace independent and identically distributedsequences of random vector nodes, $\{\boldsymbol{x}_i \}_{i = 0}^{\infty}$, bylow discrepancy sequences. This accelerates the convergence of $\hat{\mu}_n$ to$\mu$ as $n \to \infty$.  This tutorial describes low discrepancy sequences and their quality measures.We demonstrate the performance gains possible with quasi-Monte Carlo methods.Moreover, we describe how to formulate problems to realize the greatestperformance gains using quasi-Monte Carlo. We also briefly describe the use ofquasi-Monte Carlo methods for problems beyond computing the mean, $\mu$.",Fred J. Hickernell,2025-02-05,2025-02-05,,N/A,"['math.NA', 'cs.NA', 'stat.CO', '65C05']"
2502.03643v1,Context-Preserving Gradient Modulation for Large Language Models: A Novel Approach to Semantic Consistency in Long-Form Text Generation,http://arxiv.org/abs/2502.03643v1,"Maintaining semantic consistency over extended text sequences remains afundamental challenge in long-form text generation, where conventional trainingmethodologies often struggle to prevent contextual drift and coherencedegradation. A novel gradient modulation approach is introduced, designed toadjust parameter updates dynamically in response to contextual relevance,ensuring that generated text remains aligned with prior discourse. Byintegrating a modulation function that selectively amplifies or attenuatesgradients based on learned contextual dependencies, the proposed methodenhances the stability of model-generated narratives without imposingsignificant computational overhead. Comparative evaluations against baselinemodels reveal improvements in coherence, contextual retention, and long-rangedependency tracking, demonstrating the effectiveness of modifying the learningprocess at the gradient level. The results indicate that sentence structurevariability and lexical diversity benefit from this approach, mitigatingrepetitive phrasing and improving adaptability across diverse linguisticcontexts. Statistical validation of coherence metrics further substantiates theobserved enhancements, with a significant reduction in inconsistencies emergingas a direct consequence of the modulation mechanism. Computational efficiencyassessments confirm that the framework achieves these gains without requiringsubstantial modifications to the underlying architecture, ensuringcompatibility with existing optimization workflows.",Nirola Kobanov,2025-02-05,2025-02-05,,N/A,['cs.CL']
2502.03641v1,Good Data and Bad Data: The Welfare Effects of Price Discrimination,http://arxiv.org/abs/2502.03641v1,"We ask when additional data collection by a monopolist to engage in pricediscrimination monotonically increases or decreases weighted surplus. To answerthis question, we develop a model to study endogenous market segmentationsubject to residual uncertainty. We give a complete characterization of whendata collection is good or bad for surplus, which consists of a reduction ofthe problem to one with only two demand curves, and a condition for thetwo-demand-curves case that highlights three distinct effects of information onwelfare. These results provide insights into when data collection and usage forprice discrimination should be allowed.",Maryam Farboodi,2025-02-05,2025-02-05,,N/A,['econ.TH']
2502.03639v1,Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach,http://arxiv.org/abs/2502.03639v1,"We present a novel video generation framework that integrates 3-dimensionalgeometry and dynamic awareness. To achieve this, we augment 2D videos with 3Dpoint trajectories and align them in pixel space. The resulting 3D-aware videodataset, PointVid, is then used to fine-tune a latent diffusion model, enablingit to track 2D objects with 3D Cartesian coordinates. Building on this, weregularize the shape and motion of objects in the video to eliminate undesiredartifacts, \eg, nonphysical deformation. Consequently, we enhance the qualityof generated RGB videos and alleviate common issues like object morphing, whichare prevalent in current video models due to a lack of shape awareness. Withour 3D augmentation and regularization, our model is capable of handlingcontact-rich scenarios such as task-oriented videos. These videos involvecomplex interactions of solids, where 3D information is essential forperceiving deformation and contact. Furthermore, our model improves the overallquality of video generation by promoting the 3D consistency of moving objectsand reducing abrupt changes in shape and motion.",Yunuo Chen,2025-02-05,2025-02-05,,N/A,['cs.CV']
2502.03638v1,SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models,http://arxiv.org/abs/2502.03638v1,"Generating novel crystalline materials has potential to lead to advancementsin fields such as electronics, energy storage, and catalysis. The definingcharacteristic of crystals is their symmetry, which plays a central role indetermining their physical properties. However, existing crystal generationmethods either fail to generate materials that display the symmetries ofreal-world crystals, or simply replicate the symmetry information from examplesin a database. To address this limitation, we propose SymmCD, a noveldiffusion-based generative model that explicitly incorporates crystallographicsymmetry into the generative process. We decompose crystals into two componentsand learn their joint distribution through diffusion: 1) the asymmetric unit,the smallest subset of the crystal which can generate the whole crystal throughsymmetry transformations, and; 2) the symmetry transformations needed to beapplied to each atom in the asymmetric unit. We also use a novel andinterpretable representation for these transformations, enabling generalizationacross different crystallographic symmetry groups. We showcase the competitiveperformance of SymmCD on a subset of the Materials Project, obtaining diverseand valid crystals with realistic symmetries and predicted properties.",Daniel Levy,2025-02-05,2025-02-05,,N/A,"['cond-mat.mtrl-sci', 'cs.LG']"
2502.03636v1,Measuring the Sun's Core with Neutrino Measurements: A Solar Orbiter Concept,http://arxiv.org/abs/2502.03636v1,"Traditional neutrino detectors are built deep underground to reducebackgrounds. The neutrino solar orbiting laboratory ($\nu$SOL) collaborationhas been developing a concept to improve neutrino measurement not with a largerdetector underground, but instead we use the nuclear excitation from theneutrino interaction to produce a multi-pulse signal. Cerium-doped gadoliniumaluminum gallium garnet (GAGG) is a new scintillator which has 23\% gallium bymass. When a neutrino interacts with the GAGG, about 10\% of the time it willbe in an excited nuclear state rather than in the base energy level. Asegmented detector looking for the pulses separated by distance and time hasthe potential to greatly limit background noise from solar wind, cosmic rays,and galactic gamma rays. A polar LEO CubeSat mission is currently indevelopment to measure the GCR backgrounds outside the Van Allen Belts.  In this summary of my presentation I will quickly lay the groundwork of theinteraction of interest and what a solar orbiter's detector could look like. Iwill then explore what measurements a near-solar orbiter could make. With thesemeasurements in mind, I will discuss the feasibility of a direct observation ofthe core's shape, and I will discuss how a solar orbiter's measurements couldimprove a Standard Solar Model search and compare that measurement with thecurrent global neutrino measurements. I will conclude with a discussion of whatthese observables could tell us about the solar interior.",Jonathan Folkerts,2025-02-05,2025-02-05,,N/A,['astro-ph.SR']
2502.03635v1,UX Challenges in Implementing an Interactive B2B Customer Segmentation Tool,http://arxiv.org/abs/2502.03635v1,"In our effort to implement an interactive customer segmentation tool for aglobal manufacturing company, we identified user experience (UX) challengeswith technical implications. The main challenge relates to domain users'effort, in our case sales experts, to interpret the clusters produced by anunsupervised Machine Learning (ML) algorithm, for creating a customersegmentation. An additional challenge is what sort of interactions should sucha tool support to enable meaningful interpretations of the output of clusteringmodels. In this case study, we describe what we learned from implementing anInteractive Machine Learning (IML) prototype to address such UX challenges. Weleverage a multi-year real-world dataset and domain experts' feedback from aglobal manufacturing company to evaluate our tool. We report what we found tobe effective and wish to inform designers of IML systems in the context ofcustomer segmentation and other related unsupervised ML tools.",Muhammad Raees,2025-02-05,2025-02-05,,N/A,['cs.HC']
2502.03631v1,Investigating the 95 GeV Higgs Boson Excesses within the I(1+2)HDM,http://arxiv.org/abs/2502.03631v1,"In this work, we explore how the 2-Higgs Doublet Model (2HDM) Type-I,extended by an inert doublet, can provide an explanation for the recentlyobserved excesses at the Large Hadron Collider (LHC) in the $\gamma\gamma$ and$\tau^+ \tau^- $ final states. Hence, by imposing theoretical constraints andexperimental bounds on the model parameter space, our findings show that alight CP-even Higgs boson, $h$, with a mass around 95 GeV, can account forthese anomalies. This result aligns with the excess in $b\bar b$ signaturesreported in earlier data from the Large Electron-Positron (LEP) collider.",Ayoub Hmissou,2025-02-05,2025-02-05,,N/A,['hep-ph']
2502.03630v1,The Lagrangian approach to the compressible primitive equations,http://arxiv.org/abs/2502.03630v1,"This article develops the hydrostatic Lagrangian approach to the compressibleprimitive equations. A fundamental aspect in the analysis is the investigationof the compressible hydrostatic Lam\'{e} and Stokes operators. Local strongwell-posedness for large data and global strong well-posedness for small dataare established under various assumptions on the pressure law, both in thepresence and absence of gravity.",Matthias Hieber,2025-02-05,2025-02-05,,N/A,['math.AP']
2502.04387v1,FedP$^2$EFT: Federated Learning to Personalize Parameter Efficient Fine-Tuning for Multilingual LLMs,http://arxiv.org/abs/2502.04387v1,"Federated learning (FL) has enabled the training of multilingual largelanguage models (LLMs) on diverse and decentralized multilingual data,especially on low-resource languages. To improve client-specific performance,personalization via the use of parameter-efficient fine-tuning (PEFT) modulessuch as LoRA is common. This involves a personalization strategy (PS), such asthe design of the PEFT adapter structures (e.g., in which layers to add LoRAsand what ranks) and choice of hyperparameters (e.g., learning rates) forfine-tuning. Instead of manual PS configuration, we propose FedP$^2$EFT, afederated learning-to-personalize method for multilingual LLMs in cross-deviceFL settings. Unlike most existing PEFT structure selection methods, which areprone to overfitting low-data regimes, FedP$^2$EFT collaboratively learns theoptimal personalized PEFT structure for each client via Bayesian sparse rankselection. Evaluations on both simulated and real-world multilingual FLbenchmarks demonstrate that FedP$^2$EFT largely outperforms existingpersonalized fine-tuning methods, while complementing a range of existing FLmethods.",Royson Lee,2025-02-05,2025-02-05,,N/A,"['cs.CL', 'cs.AI']"
2502.03629v1,REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations,http://arxiv.org/abs/2502.03629v1,"Existing image editing models struggle to meet real-world demands. Despiteexcelling in academic benchmarks, they have yet to be widely adopted for realuser needs. Datasets that power these models use artificial edits, lacking thescale and ecological validity necessary to address the true diversity of userrequests. We introduce REALEDIT, a large-scale image editing dataset withauthentic user requests and human-made edits sourced from Reddit. REALEDITincludes a test set of 9300 examples to evaluate models on real user requests.Our results show that existing models fall short on these tasks, highlightingthe need for realistic training data. To address this, we introduce 48Ktraining examples and train our REALEDIT model, achieving substantial gains -outperforming competitors by up to 165 Elo points in human judgment and 92percent relative improvement on the automated VIEScore metric. We deploy ourmodel on Reddit, testing it on new requests, and receive positive feedback.Beyond image editing, we explore REALEDIT's potential in detecting editedimages by partnering with a deepfake detection non-profit. Finetuning theirmodel on REALEDIT data improves its F1-score by 14 percentage points,underscoring the dataset's value for broad applications.",Peter Sushko,2025-02-05,2025-02-05,,N/A,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']"
2502.03628v1,The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering,http://arxiv.org/abs/2502.03628v1,"Large Vision-Language Models (LVLMs) can reason effectively over both textualand visual inputs, but they tend to hallucinate syntactically coherent yetvisually ungrounded contents. In this paper, we investigate the internaldynamics of hallucination by examining the tokens logits rankings throughoutthe generation process, revealing three key patterns in how LVLMs processinformation: (1) gradual visual information loss -- visually grounded tokensgradually become less favored throughout generation, and (2) early excitation-- semantically meaningful tokens achieve peak activation in the layers earlierthan the final layer. (3) hidden genuine information -- visually groundedtokens though not being eventually decided still retain relatively highrankings at inference. Based on these insights, we propose VISTA (VisualInformation Steering with Token-logit Augmentation), a training-freeinference-time intervention framework that reduces hallucination whilepromoting genuine information. VISTA works by combining two complementaryapproaches: reinforcing visual information in activation space and leveragingearly layer activations to promote semantically meaningful decoding. Comparedto existing methods, VISTA requires no external supervision and is applicableto various decoding strategies. Extensive experiments show that VISTA onaverage reduces hallucination by abount 40% on evaluated open-ended generationtask, and it consistently outperforms existing methods on four benchmarksacross four architectures under three decoding strategies.",Zhuowei Li,2025-02-05,2025-02-05,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.03627v1,Sorting the Babble in Babel: Assessing the Performance of Language Detection Algorithms on the OpenAlex Database,http://arxiv.org/abs/2502.03627v1,"Following a recent study on the quality of OpenAlex linguistic metadata(C\'espedes et al., 2025), the present paper aims to optimize the latterthrough the design, use, and evaluation of various linguistic classificationprocedures based on the latest and most efficient automatic language detectionalgorithms. Starting from a multilingual set of manually-annotated samples ofarticles indexed in the database, different classification procedures are thendesigned, based on the application of a set of language detection algorithms ona series of corpora generated from different combinations of textual metadataof indexed articles. At sample level first, the performance of these differentprocedures for each of the main languages in the database is evaluated in termsof precision, recall, and processing time. Then, overall procedure performanceis estimated at the database level by means of a probabilistic simulation ofharmonically aggregated and weighted scores. Results show that procedureperformance strongly depends on the importance given to each of the measuresimplemented: for contexts where precision is preferred, using the LangIDalgorithm on article titles, abstracts as well as journal names gives the bestresults; however, for all cases where recall is considered at least slightlymore important than precision or as soon as processing times are given any kindof consideration, use of the FastSpell algorithm on article titles onlyoutperforms all other alternatives. Given the lack of truly multilingual,large-scale bibliographic databases, it is hoped that these results helpconfirm and foster the unparalleled potential of the OpenAlex database forcross-linguistic, bibliometric-based research and analysis.",Maxime Holmberg Sainte-Marie,2025-02-05,2025-02-05,,N/A,['cs.CL']
2502.03624v1,The Feynman-Kac formula in deformation quantization,http://arxiv.org/abs/2502.03624v1,"We introduce the Feynman-Kac formula within the deformation quantizationprogram. Constructing on previous work it is shown that, upon a Wick rotation,the ground state energy of any prescribed physical system can be obtained fromthe asymptotic limit of the phase space integration of the star exponential ofthe Hamiltonian operator. Some examples of this correspondence are providedshowing a novel and efficient way of computing the ground state energy for somephysical models.",Jasel Berra-Montiel,2025-02-05,2025-02-05,,N/A,"['math-ph', 'math.MP', 'quant-ph', '81S30, 81S40']"
2502.03623v1,Large Teams Overshadow Individual Recognition,http://arxiv.org/abs/2502.03623v1,"In an ideal world, every scientist's contribution would be fully recognized,driving collective scientific progress. In reality, however, only a fewscientists are recognized and remembered. Sociologist Robert Merton firstdescribed this disparity between contribution and recognition as the MatthewEffect, where citations disproportionately favor established scientists, evenwhen their contributions are no greater than those of junior peers. Merton'swork, however, did not account for coauthored papers, where citationsacknowledge teams rather than individual authors. How do teams affect rewardsystems in science? We hypothesize that teams will divide and obscureintellectual credit, making it even harder to recognize individualcontributions. To test this, we developed and analyzed the world's firstlarge-scale observational dataset on author contributions, derived from LaTeXsource files of 1.6 million papers authored by 2 million scientists. We alsoquantified individual credits within teams using a validated algorithm andexamined their relationship to contributions, accounting for factors such asteam size, career stage, and historical time. Our findings confirm that teamsamplify the Matthew Effect and overshadow individual contributions. Asscientific research shifts from individual efforts to collaborative teamwork,this study highlights the urgent need for effective credit assignment practicesin team-based science.",Lulin Yang,2025-02-05,2025-02-05,,N/A,"['cs.SI', 'H.2.8; J.4']"
2502.03622v1,AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails,http://arxiv.org/abs/2502.03622v1,"Phishing attacks remain a significant threat in the digital age, yetorganizations lack effective methods to tackle phishing attacks without leakingsensitive information. Phish bowl initiatives are a vital part of cybersecurityefforts against these attacks. However, traditional phish bowls require manualanonymization and are often limited to internal use. To overcome theselimitations, we introduce AdaPhish, an AI-powered phish bowl platform thatautomatically anonymizes and analyzes phishing emails using large languagemodels (LLMs) and vector databases. AdaPhish achieves real-time detection andadaptation to new phishing tactics while enabling long-term tracking ofphishing trends. Through automated reporting, adaptive analysis, and real-timealerts, AdaPhish presents a scalable, collaborative solution for phishingdetection and cybersecurity education.",Rei Meguro,2025-02-05,2025-02-05,,N/A,"['cs.CR', 'cs.AI']"
2502.03621v1,DynVFX: Augmenting Real Videos with Dynamic Content,http://arxiv.org/abs/2502.03621v1,"We present a method for augmenting real-world videos with newly generateddynamic content. Given an input video and a simple user-provided textinstruction describing the desired content, our method synthesizes dynamicobjects or complex scene effects that naturally interact with the existingscene over time. The position, appearance, and motion of the new content areseamlessly integrated into the original footage while accounting for cameramotion, occlusions, and interactions with other dynamic objects in the scene,resulting in a cohesive and realistic output video. We achieve this via azero-shot, training-free framework that harnesses a pre-trained text-to-videodiffusion transformer to synthesize the new content and a pre-trained VisionLanguage Model to envision the augmented scene in detail. Specifically, weintroduce a novel inference-based method that manipulates features within theattention mechanism, enabling accurate localization and seamless integration ofthe new content while preserving the integrity of the original scene. Ourmethod is fully automated, requiring only a simple user instruction. Wedemonstrate its effectiveness on a wide range of edits applied to real-worldvideos, encompassing diverse objects and scenarios involving both camera andobject motion.",Danah Yatim,2025-02-05,2025-02-05,,N/A,['cs.CV']
2502.03618v1,The Logical Implication Steering Method for Conditional Interventions on Transformer Generation,http://arxiv.org/abs/2502.03618v1,"The field of mechanistic interpretability in pre-trained transformer modelshas demonstrated substantial evidence supporting the ''linear representationhypothesis'', which is the idea that high level concepts are encoded as vectorsin the space of activations of a model. Studies also show that model generationbehavior can be steered toward a given concept by adding the concept's vectorto the corresponding activations. We show how to leverage these properties tobuild a form of logical implication into models, enabling transparent andinterpretable adjustments that induce a chosen generation behavior in responseto the presence of any given concept. Our method, Logical Implication ModelSteering (LIMS), unlocks new hand engineered reasoning capabilities byintegrating neuro-symbolic logic into pre-trained transformer models.",Damjan Kalajdzievski,2025-02-05,2025-02-05,,N/A,['cs.LG']
2502.03617v1,Resource-Efficient & Effective Code Summarization,http://arxiv.org/abs/2502.03617v1,"Code Language Models (CLMs) have demonstrated high effectiveness inautomating software engineering tasks such as bug fixing, code generation, andcode documentation. This progress has been driven by the scaling of largemodels, ranging from millions to trillions of parameters (e.g., GPT-4).However, as models grow in scale, sustainability concerns emerge, as they areextremely resource-intensive, highlighting the need for efficient,environmentally conscious solutions. GreenAI techniques, such as QLoRA(Quantized Low-Rank Adaptation), offer a promising path for dealing with largemodels' sustainability as they enable resource-efficient model fine-tuning.Previous research has shown the effectiveness of QLoRA in code-related tasks,particularly those involving natural language inputs and code as the targetoutput (NL-to-Code), such as code generation. However, no studies have exploredits application to tasks that are fundamentally similar to NL-to-Code (naturallanguage to code) but operate in the opposite direction, such as codesummarization. This leaves a gap in understanding how well QLoRA can generalizeto Code-to-NL tasks, which are equally important for supporting developers inunderstanding and maintaining code. To address this gap, we investigate theextent to which QLoRA's capabilities in NL-to-Code tasks can be leveraged andtransferred to code summarization, one representative Code-to-NL task. Ourstudy evaluates two state-of-the-art CLMs (CodeLlama and DeepSeek-Coder) acrosstwo programming languages: Python and Java. Our research tasked models withgenerating descriptions for Python and Java code methods. The results alignwith prior findings on QLoRA for source code generation, showing that QLoRAenables efficient fine-tuning of CLMs for code summarization.",Saima Afrin,2025-02-05,2025-02-05,,N/A,['cs.SE']
2502.03614v1,"A Novel Zero-Touch, Zero-Trust, AI/ML Enablement Framework for IoT Network Security",http://arxiv.org/abs/2502.03614v1,"The IoT facilitates a connected, intelligent, and sustainable society;therefore, it is imperative to protect the IoT ecosystem. The IoT-based 5G and6G will leverage the use of machine learning and artificial intelligence(ML/AI) more to pave the way for autonomous and collaborative secure IoTnetworks. Zero-touch, zero-trust IoT security with AI and machine learning (ML)enablement frameworks offers a powerful approach to securing the expandinglandscape of Internet of Things (IoT) devices. This paper presents a novelframework based on the integration of Zero Trust, Zero Touch, and AI/ML poweredfor the detection, mitigation, and prevention of DDoS attacks in modern IoTecosystems. The focus will be on the new integrated framework by establishingzero trust for all IoT traffic, fixed and mobile 5G/6G IoT network traffic, anddata security (quarantine-zero touch and dynamic policy enforcement). Weperform a comparative analysis of five machine learning models, namely,XGBoost, Random Forest, K-Nearest Neighbors, Stochastic Gradient Descent, andNative Bayes, by comparing these models based on accuracy, precision, recall,F1-score, and ROC-AUC. Results show that the best performance in detecting andmitigating different DDoS vectors comes from the ensemble-based approaches.",Sushil Shakya,2025-02-05,2025-02-05,,N/A,"['cs.LG', 'cs.AI', 'cs.CR']"
2502.03611v1,An Efficient Quasi-Newton Method with Tensor Product Implementation for Solving Quasi-Linear Elliptic Equations and Systems,http://arxiv.org/abs/2502.03611v1,"In this paper, we introduce a quasi-Newton method optimized for efficientlysolving quasi-linear elliptic equations and systems, with a specific focus onGPU-based computation. By approximating the Jacobian matrix with a combinationof linear Laplacian and simplified nonlinear terms, our method reduces thecomputational overhead typical of traditional Newton methods while handling thelarge, sparse matrices generated from discretized PDEs. We also provide aconvergence analysis demonstrating local convergence to the exact solutionunder optimal choices for the regularization parameter, ensuring stability andefficiency in each iteration. Numerical experiments in two- andthree-dimensional domains validate the proposed method's robustness andcomputational gains with tensor-product implementation. This approach offers apromising pathway for accelerating quasi-linear elliptic equation and systemsolvers, expanding the feasibility of complex simulations in physics,engineering, and other fields leveraging advanced hardware capabilities.",Wenrui Hao,2025-02-05,2025-02-05,,N/A,"['math.NA', 'cs.NA']"
2502.03610v1,Modeling the prion protein-mediated transport of extracellular vesicles on the neuron surface,http://arxiv.org/abs/2502.03610v1,"Neurodegenerative diseases are among the leading causes of global mortality.They are characterized by the progressive deterioration of specific neuronpopulations, ultimately leading to cognitive decline and dementia.Extracellular vesicles (EVs) are crucial players in the early stages of suchdiseases, acting as carriers of pathogens and contributing to neuroinflammationand disease propagation. This study proposes a mathematical model to elucidatethe movement of EVs bearing prion protein (PrP) on their surface along neuronalsurfaces. Supported by experimental data, the model explores the role of theactin polymerization on the EVs transport dynamics. EVs isolated from non-humanastrocytes were analyzed under three conditions: untreated control (Ctrl),neurons treated with Cytochalasin D (CytoD-HN), and EVs treated withCytochalasin D (CytoD-EV). Our mathematical model effectively explained theexperimental data. In the CytoD-EV dataset, EV movement was modeled using aflashing Brownian ratchet, reflecting directed movement. For active transportin the CytoD-HN set, a symmetric periodic potential models the rolling of theEvs on the neuron surface. The Ctrl scenario results in a combination of thetwo mechanisms. Finally, a sensitivity and comparative analysis betweennumerical results and experimental data showed that the model effectivelyreplicates the Evs motion.",Giulia Pozzi,2025-02-05,2025-02-05,,N/A,['physics.bio-ph']
2502.03609v1,Multivariate Conformal Prediction using Optimal Transport,http://arxiv.org/abs/2502.03609v1,"Conformal prediction (CP) quantifies the uncertainty of machine learningmodels by constructing sets of plausible outputs. These sets are constructed byleveraging a so-called conformity score, a quantity computed using the inputpoint of interest, a prediction model, and past observations. CP sets are thenobtained by evaluating the conformity score of all possible outputs, andselecting them according to the rank of their scores. Due to this ranking step,most CP approaches rely on a score functions that are univariate. The challengein extending these scores to multivariate spaces lies in the fact that nocanonical order for vectors exists. To address this, we leverage a naturalextension of multivariate score ranking based on optimal transport (OT). Ourmethod, OTCP, offers a principled framework for constructing conformalprediction sets in multidimensional settings, preserving distribution-freecoverage guarantees with finite data samples. We demonstrate tangible gains ina benchmark dataset of multivariate regression problems and addresscomputational \& statistical trade-offs that arise when estimating conformityscores through OT maps.",Michal Klein,2025-02-05,2025-02-05,,N/A,"['stat.ML', 'cs.LG']"
2502.03608v1,(GG) MoE vs. MLP on Tabular Data,http://arxiv.org/abs/2502.03608v1,"In recent years, significant efforts have been directed toward adaptingmodern neural network architectures for tabular data. However, despite theirlarger number of parameters and longer training and inference times, thesemodels often fail to consistently outperform vanilla multilayer perceptron(MLP) neural networks. Moreover, MLP-based ensembles have recently demonstratedsuperior performance and efficiency compared to advanced deep learning methods.Therefore, rather than focusing on building deeper and more complex deeplearning models, we propose investigating whether MLP neural networks can bereplaced with more efficient architectures without sacrificing performance. Inthis paper, we first introduce GG MoE, a mixture-of-experts (MoE) model with aGumbel-Softmax gating function. We then demonstrate that GG MoE with anembedding layer achieves the highest performance across $38$ datasets comparedto standard MoE and MLP models. Finally, we show that both MoE and GG MoEutilize significantly fewer parameters than MLPs, making them a promisingalternative for scaling and ensemble methods.",Andrei Chernov,2025-02-05,2025-02-05,,N/A,"['cs.LG', 'cs.AI']"
2502.03607v1,Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models,http://arxiv.org/abs/2502.03607v1,"Recent advances in diffusion models hold significant potential in robotics,enabling the generation of diverse and smooth trajectories directly from rawrepresentations of the environment. Despite this promise, applying diffusionmodels to motion planning remains challenging due to their difficulty inenforcing critical constraints, such as collision avoidance and kinematicfeasibility. These limitations become even more pronounced in Multi-RobotMotion Planning (MRMP), where multiple robots must coordinate in shared spaces.To address this challenge, this work proposes Simultaneous MRMP Diffusion(SMD), a novel approach integrating constrained optimization into the diffusionsampling process to produce collision-free, kinematically feasibletrajectories. Additionally, the paper introduces a comprehensive MRMP benchmarkto evaluate trajectory planning algorithms across scenarios with varying robotdensities, obstacle complexities, and motion constraints. Experimental resultsshow SMD consistently outperforms classical and learning-based motion planners,achieving higher success rates and efficiency in complex multi-robotenvironments.",Jinhao Liang,2025-02-05,2025-02-05,,N/A,"['cs.RO', 'cs.AI', 'cs.LG']"
2502.03606v1,Artificial Intelligence Approaches for Anti-Addiction Drug Discovery,http://arxiv.org/abs/2502.03606v1,"Drug addiction is a complex and pervasive global challenge that continues topose significant public health concerns. Traditional approaches toanti-addiction drug discovery have struggled to deliver effective therapeutics,facing high attrition rates, long development timelines, and inefficiencies inprocessing large-scale data. Artificial intelligence (AI) has emerged as atransformative solution to address these issues. Using advanced algorithms, AIis revolutionizing drug discovery by enhancing the speed and precision of keyprocesses. This review explores the transformative role of AI in the pipelinefor anti-addiction drug discovery, including data collection, targetidentification, and compound optimization. By highlighting the potential of AIto overcome traditional barriers, this review systematically examines how AIaddresses critical gaps in anti-addiction research, emphasizing its potentialto revolutionize drug discovery and development, overcome challenges, andadvance more effective therapeutic strategies.",Dong Chen,2025-02-05,2025-02-05,,N/A,['q-bio.BM']
2502.03605v1,Accelerating OTA Circuit Design: Transistor Sizing Based on a Transformer Model and Precomputed Lookup Tables,http://arxiv.org/abs/2502.03605v1,"Device sizing is crucial for meeting performance specifications inoperational transconductance amplifiers (OTAs), and this work proposes anautomated sizing framework based on a transformer model. The approach firstleverages the driving-point signal flow graph (DP-SFG) to map an OTA circuitand its specifications into transformer-friendly sequential data. A specializedtokenization approach is applied to the sequential data to expedite thetraining of the transformer on a diverse range of OTA topologies, undermultiple specifications. Under specific performance constraints, the trainedtransformer model is used to accurately predict DP-SFG parameters in theinference phase. The predicted DP-SFG parameters are then translated totransistor sizes using a precomputed look-up table-based approach inspired bythe gm/Id methodology. In contrast to previous conventional ormachine-learning-based methods, the proposed framework achieves significantimprovements in both speed and computational efficiency by reducing the needfor expensive SPICE simulations within the optimization loop; instead, almostall SPICE simulations are confined to the one-time training phase. The methodis validated on a variety of unseen specifications, and the sizing solutiondemonstrates over 90% success in meeting specifications with just one SPICEsimulation for validation, and 100% success with 3-5 additional SPICEsimulations.",Subhadip Ghosh,2025-02-05,2025-02-05,,N/A,"['cs.AR', 'B.7.2']"
2502.03604v1,Bilevel ZOFO: Bridging Parameter-Efficient and Zeroth-Order Techniques for Efficient LLM Fine-Tuning and Meta-Training,http://arxiv.org/abs/2502.03604v1,"Fine-tuning pre-trained Large Language Models (LLMs) for downstream tasksusing First-Order (FO) optimizers presents significant computationalchallenges. Parameter-Efficient Fine-Tuning(PEFT) methods have been proposed toaddress these challenges by freezing most model parameters and training only asmall subset. While PEFT is efficient, it may not outperform full fine-tuningwhen high task-specific performance is required. Zeroth-Order (ZO) methodsoffer an alternative for fine-tuning the entire pre-trained model byapproximating gradients using only the forward pass, thus eliminating thecomputational burden of back-propagation in first-order methods. However, whenimplementing ZO methods, a hard prompt is crucial, and relying on simple, fixedhard prompts may not be optimal. In this paper, we propose a bileveloptimization framework that complements ZO methods with PEFT to mitigatesensitivity to hard prompts while efficiently and effectively fine-tuning LLMs.Our Bilevel ZOFO (Zeroth-Order-First-Order) method employs a double-loopoptimization strategy, where only the gradient of the PEFT model and theforward pass of the base model are required. We provide convergence guaranteesfor Bilevel ZOFO. Empirically, we demonstrate that Bilevel ZOFO outperformsboth PEFT and ZO methods in single-task settings while maintaining similarmemory efficiency. Additionally, we show its strong potential for multitasklearning. Compared to current first-order meta-training algorithms formultitask learning, our method has significantly lower computational demandswhile maintaining or improving performance.",Reza Shirkavand,2025-02-05,2025-02-05,,N/A,['cs.LG']
2502.03601v1,Local L2-bounded commuting projections using discrete local problems on Alfeld splits,http://arxiv.org/abs/2502.03601v1,"We construct projections onto the classical finite element spaces based onLagrange, N\'ed\'elec, Raviart--Thomas, and discontinuous elements onshape-regular simplicial meshes. Our projections are defined locally, arebounded in the L2-norm, and commute with the corresponding differentialoperators. The cornerstone of the construction are local weight functions whichare piecewise polynomials built using the Alfeld split of local patches fromthe original simplicial mesh. This way, the L2-stability of the projections isestablished by invoking discrete Poincar\'e inequalities on these local stars,for which we provide constructive proofs. We also show how to modify theconstruction to preserve homogeneous boundary conditions. The material ispresented using the language of vector calculus, and links to the formalism offinite element exterior calculus are provided.",Alexandre Ern,2025-02-05,2025-02-05,,N/A,"['math.NA', 'cs.NA', '65N30']"
2502.03600v1,Type 2 Tobit Sample Selection Models with Bayesian Additive Regression Trees,http://arxiv.org/abs/2502.03600v1,"This paper introduces Type 2 Tobit Bayesian Additive Regression Trees(TOBART-2). BART can produce accurate individual-specific treatment effectestimates. However, in practice estimates are often biased by sample selection.We extend the Type 2 Tobit sample selection model to account for nonlinearitiesand model uncertainty by including sums of trees in both the selection andoutcome equations. A Dirichlet Process Mixture distribution for the error termsallows for departure from the assumption of bivariate normally distributederrors. Soft trees and a Dirichlet prior on splitting probabilities improvemodeling of smooth and sparse data generating processes. We include asimulation study and an application to the RAND Health Insurance Experimentdata set.",Eoghan O'Neill,2025-02-05,2025-02-05,,N/A,"['econ.EM', 'stat.ML']"
2502.03598v1,Higgs Thermal Nonequilibrium in Primordial QGP,http://arxiv.org/abs/2502.03598v1,"In this work we investigate the chemical and kinetic nonequilibrium dynamicsof the Higgs boson during the primordial Universe QGP (quark-gluon plasma)epoch $130\mathrm{\,GeV}>T>10\mathrm{\,GeV}$. We show that the Higgs bosons isalways out of chemical abundance equilibrium with a fugacity $\Upsilon_h =0.69$ due to virtual decay channels. Additionally, Higgs momentum distributionis found to be ``cold'' for $T<40$\,GeV, since the scattering rate drops belowthe production rate.",Cheng Tao Yang,2025-02-05,2025-02-05,,N/A,"['hep-ph', 'astro-ph.CO', 'nucl-th']"
2502.04386v1,Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings,http://arxiv.org/abs/2502.04386v1,"Self-supervised learning has revolutionized medical imaging by enablingefficient and generalizable feature extraction from large-scale unlabeleddatasets. Recently, self-supervised foundation models have been extended tothree-dimensional (3D) computed tomography (CT) data, generating compact,information-rich embeddings with 1408 features that achieve state-of-the-artperformance on downstream tasks such as intracranial hemorrhage detection andlung cancer risk forecasting. However, these embeddings have been shown toencode demographic information, such as age, sex, and race, which poses asignificant risk to the fairness of clinical applications.  In this work, we propose a Variation Autoencoder (VAE) based adversarialdebiasing framework to transform these embeddings into a new latent space wheredemographic information is no longer encoded, while maintaining the performanceof critical downstream tasks. We validated our approach on the NLST lung cancerscreening dataset, demonstrating that the debiased embeddings effectivelyeliminate multiple encoded demographic information and improve fairness withoutcompromising predictive accuracy for lung cancer risk at 1-year and 2-yearintervals. Additionally, our approach ensures the embeddings are robust againstadversarial bias attacks. These results highlight the potential of adversarialdebiasing techniques to ensure fairness and equity in clinical applications ofself-supervised 3D CT embeddings, paving the way for their broader adoption inunbiased medical decision-making.",Guangyao Zheng,2025-02-05,2025-02-05,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.03597v1,Aging in coevolving voter models,http://arxiv.org/abs/2502.03597v1,"Aging, understood as the tendency to remain in a given state the longer thepersistence time in that state, plays a crucial role in the dynamics of complexsystems. In this paper, we explore the influence of aging on coevolutionmodels, that is, models in which the dynamics of the states of the nodes in acomplex network is coupled to the dynamics of the structure of the network. Inparticular we consider the coevolving voter model, and we introduce twoversions of this model that include aging effects: the Link Aging Model (LAM)and the Node Aging Model (NAM). In the LAM, aging is associated with thepersistence time of a link in the evolving network, while in the NAM, aging isassociated with the persistence time of a node in a given state. We show thataging significantly affects the absorbing phase transition of the coevolutionvoter model, shifting the transition point in opposite directions for the LAMand NAM. We also show that the generic absorbing phase transition can disappeardue to aging effects.",Byungjoon Min,2025-02-05,2025-02-05,,N/A,"['physics.soc-ph', 'cond-mat.stat-mech']"
2502.03591v1,Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function,http://arxiv.org/abs/2502.03591v1,"In this work, we present a novel approach to multi-label chest X-ray (CXR)image classification that enhances clinical interpretability while maintaininga streamlined, single-model, single-run training pipeline. Leveraging theCheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchicallabel groupings to capture clinically meaningful relationships betweendiagnoses. To achieve this, we designed a custom hierarchical binarycross-entropy (HBCE) loss function that enforces label dependencies usingeither fixed or data-driven penalty types. Our model achieved a mean area underthe receiver operating characteristic curve (AUROC) of 0.903 on the test set.Additionally, we provide visual explanations and uncertainty estimations tofurther enhance model interpretability. All code, model configurations, andexperiment details are made available.",Mehrdad Asadi,2025-02-05,2025-02-05,,N/A,"['cs.CV', 'cs.AI', 'cs.LG']"
2502.03589v1,HACK: Homomorphic Acceleration via Compression of the Key-Value Cache for Disaggregated LLM Inference,http://arxiv.org/abs/2502.03589v1,"Disaggregated Large Language Model (LLM) inference has gained popularity asit separates the computation-intensive prefill stage from the memory-intensivedecode stage, avoiding the prefill-decode interference and improving resourceutilization. However, transmitting Key-Value (KV) data between the two stagescan be a bottleneck, especially for long prompts. Additionally, the computationtime overhead for prefill and decode is key for optimizing Job Completion Time(JCT), and KV data size can become prohibitive for long prompts and sequences.Existing KV quantization methods can alleviate the transmission bottleneck andreduce memory requirements, but they introduce significant dequantizationoverhead, exacerbating the computation time.  We propose Homomorphic Acceleration via Compression of the KV cache (HACK)for disaggregated LLM inference. HACK eliminates the heavy KV dequantizationstep, and directly performs computations on quantized KV data to approximateand reduce the cost of the expensive matrix-multiplication step. Extensivetrace-driven experiments show that HACK reduces JCT by up to 70.9% compared todisaggregated LLM inference baseline and by up to 52.3% compared tostate-of-the-art KV quantization methods.",Zeyu Zhang,2025-02-05,2025-02-05,,N/A,"['cs.DC', 'cs.LG']"
2502.03588v1,"Complementary Probes of Warped Extra Dimension: Colliders, Gravitational Waves and Primordial Black Holes from Phase Transitions",http://arxiv.org/abs/2502.03588v1,"We study the formation of primordial black holes (PBHs) and stochasticgravitational waves background (SGWB) produced by the supercooled radion phasetransition (PT) in warped extra-dimension models solving the gauge hierarchyproblem. We first determine how the SGWB and the produced PBH mass andabundance depend on the warped model's infrared energy scale $\rho$, and thenumber of holographic colors $N$. With this finding, we recast on the plane$\{\rho, N\}$ the current SGWB and PBH constraints, as well as the expectedparameter reaches of GW detectors, as LISA and ET, and the gravitationallensing ones, such as NGRST. On the same plane, we also map the collider boundson massive graviton production, and cosmological bounds on the radionphenomenology. We find that, for $N \sim 10-50$, the considered PT predicts aPBH population mass in the range $M_{\rm PBH}\sim(10^{-1} - 10^{-25})M_{\odot}$ for $\rho \sim (10^{-4} - 10^{8})\textrm{ TeV}$. In the range $\rho\simeq (0.05 - 0.5)$ GeV, it can explain the recent SGWB hint at nHzfrequencies and generate PBH binaries with mass $M_{\rm PBH}\sim(0.1 - 1 )M_\odot$ detectable at LISA and ET. The experimentally allowed mass regionwhere PBHs can account for the whole dark matter abundance, and are producedwith a tuning $\lesssim 10^{-4}$, corresponds to $10$ TeV $\lesssim\rho\lesssim$ $10^4$ TeV. These PBHs can compensate the lack of naturalcandidates for dark matter in warped extra dimensional models. Such a regionrepresents a great science case where forthcoming and future colliders likeHE-LHC and FCC-hh, gravitational-wave observatories and other PBHs probes playa key complementary role.",Anish Ghoshal,2025-02-05,2025-02-05,,N/A,"['hep-ph', 'astro-ph.CO']"
2502.03582v1,Designing Illumination Patterns for Single-Pixel Imaging Using Lattice Models,http://arxiv.org/abs/2502.03582v1,"Single-pixel imaging leverages a single-pixel detector and structuredillumination patterns to reconstruct images, offering a cost-effective solutionfor imaging across a wide range of wavelengths, such as x-ray and terahertz.However, the technique faces challenges in efficiency due to the need fornumerous patterns to achieve high-quality image reconstruction. In this study,we explore the use of spin lattice models from statistical mechanics to designillumination patterns for single-pixel imaging. By employing models like Ising,Potts, XY, and Heisenberg, we generate structured patterns that are adaptablefor binary, grayscale, and color imaging. This work creates a direct connectionbetween lattice models and imaging applications, providing a systematicapproach to pattern generation that can enhance single-pixel imagingefficiency.",Hamidreza Oliaei-Moghadam,2025-02-05,2025-02-05,,N/A,['physics.optics']
2502.03581v1,Extended Massive Ambitwistor String II,http://arxiv.org/abs/2502.03581v1,"This article continues previous work done in arXiv:2406.01907. It is shown inmore detail how vacuum partition functions and the cosmological constant vanishat all orders of perturbation theory. Further, all-multiplicity higher-loopamplitudes are given and shown to be modular invariant, to have properfactorization, and to be UV-finite at least up to one-loop level, formally evento all levels. Therefore, the model provides a modular invariant and unitaryN=8 supergravity theory in twistor space with embedded Super-Yang-Mills andpromising UV-finiteness behavior.",Christian Kunz,2025-02-05,2025-02-05,,N/A,['hep-th']
2502.03579v1,A Mixed-Methods Evaluation of LLM-Based Chatbots for Menopause,http://arxiv.org/abs/2502.03579v1,"The integration of Large Language Models (LLMs) into healthcare settings hasgained significant attention, particularly for question-answering tasks. Giventhe high-stakes nature of healthcare, it is essential to ensure thatLLM-generated content is accurate and reliable to prevent adverse outcomes.However, the development of robust evaluation metrics and methodologies remainsa matter of much debate. We examine the performance of publicly availableLLM-based chatbots for menopause-related queries, using a mixed-methodsapproach to evaluate safety, consensus, objectivity, reproducibility, andexplainability. Our findings highlight the promise and limitations oftraditional evaluation metrics for sensitive health topics. We propose the needfor customized and ethically grounded evaluation frameworks to assess LLMs toadvance safe and effective use in healthcare.",Roshini Deva,2025-02-05,2025-02-05,,N/A,"['cs.CY', 'cs.HC']"
2502.03578v1,Universal machine learning interatomic potentials poised to supplant DFT in modeling general defects in metals and random alloys,http://arxiv.org/abs/2502.03578v1,"Recent advances in machine learning, combined with the generation ofextensive density functional theory (DFT) datasets, have enabled thedevelopment of universal machine learning interatomic potentials (uMLIPs).These models offer broad applicability across the periodic table, achievingfirst-principles accuracy at a fraction of the computational cost oftraditional DFT calculations. In this study, we demonstrate thatstate-of-the-art pretrained uMLIPs can effectively replace DFT for accuratelymodeling complex defects in a wide range of metals and alloys. Ourinvestigation spans diverse scenarios, including grain boundaries and generaldefects in pure metals, defects in high-entropy alloys, hydrogen-alloyinteractions, and solute-defect interactions. Remarkably, the latestEquiformerV2 models achieve DFT-level accuracy on comprehensive defectdatasets, with root mean square errors (RMSE) below 5 meV/atom for energies and100 meV/{\AA} for forces, outperforming specialized machine learning potentialssuch as moment tensor potential and atomic cluster expansion. We also present asystematic analysis of accuracy versus computational cost and exploreuncertainty quantification for uMLIPs. A detailed case study of tungsten (W)demonstrates that data on pure W alone is insufficient for modeling complexdefects in uMLIPs, underscoring the critical importance of advanced machinelearning architectures and diverse datasets, which include over 100 millionstructures spanning all elements. These findings establish uMLIPs as a robustalternative to DFT and a transformative tool for accelerating the discovery anddesign of high-performance materials.",Fei Shuang,2025-02-05,2025-02-05,,N/A,"['cond-mat.mtrl-sci', 'physics.comp-ph']"
2502.03577v1,Multidisciplinary Science in the Multimessenger Era,http://arxiv.org/abs/2502.03577v1,"Astrophysical observations of the cosmos allow us to probe extreme physicsand answer foundational questions on our universe. Modern astronomy isincreasingly operating under a holistic approach, probing the same questionwith multiple diagnostics including how sources vary over time, how they appearacross the electromagnetic spectrum, and through their other signatures,including gravitational waves, neutrinos, cosmic rays, and dust on Earth.Astrophysical observations are now reaching the point where approximate physicsmodels are insufficient. Key sources of interest are explosive transients,whose understanding requires multidisciplinary studies at the intersection ofastrophysics, gravity, nuclear science, plasma physics, fluid dynamics andturbulence, computation, particle physics, atomic, molecular, and opticalscience, condensed matter and materials science, radiation transport, and highenergy density physics. This white paper provides an overview of the majorscientific advances that lay at the intersection of physics and astronomy andare best probed through time-domain and multimessenger astrophysics, anexploration of how multidisciplinary science can be fostered, and introductorydescriptions of the relevant scientific disciplines and key astrophysicalsources of interest.",Eric Burns,2025-02-05,2025-02-05,,N/A,"['astro-ph.HE', 'gr-qc', 'nucl-ex', 'nucl-th', 'physics.atom-ph']"
