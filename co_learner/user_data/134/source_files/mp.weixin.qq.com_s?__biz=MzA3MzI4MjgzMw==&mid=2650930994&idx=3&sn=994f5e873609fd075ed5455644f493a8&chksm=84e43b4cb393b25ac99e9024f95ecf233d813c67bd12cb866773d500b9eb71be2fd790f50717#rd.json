{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930994&idx=3&sn=994f5e873609fd075ed5455644f493a8&chksm=84e43b4cb393b25ac99e9024f95ecf233d813c67bd12cb866773d500b9eb71be2fd790f50717#rd",
    "title": "支持1024帧、准确率近100％，英伟达「LongVILA」开始发力长视频",
    "summary": "研究人员推出了LongVILA，这是一个全栈解决方案，用于训练和部署长上下文视觉语言模型（VLM）。LongVILA包括系统设计、模型训练策略和数据集构建，旨在处理长文档和视频。研究中，他们建立了一个名为多模态序列并行（MM-SP）的高效框架，支持长上下文VLM的训练，并实现了一个五阶段训练流程。实验表明，LongVILA在VideoMME和长视频字幕任务上的性能有所提高，其模型在处理大量上下文时表现优越，例如在1024帧上训练的模型在274k个token的上下文长度上达到99.5%的准确率。此外，MM-SP系统能有效扩展上下文长度至200万个token，且在处理长序列时比其他方法更快。",
    "user_summary": "研究人员推出了LongVILA，这是一个全栈解决方案，用于训练和部署长上下文视觉语言模型（VLM）。LongVILA包括系统设计、模型训练策略和数据集构建，旨在处理长文档和视频。研究中，他们建立了一个名为多模态序列并行（MM-SP）的高效框架，支持长上下文VLM的训练，并实现了一个五阶段训练流程。实验表明，LongVILA在VideoMME和长视频字幕任务上的性能有所提高，其模型在处理大量上下文时表现优越，例如在1024帧上训练的模型在274k个token的上下文长度上达到99.5%的准确率。此外，MM-SP系统能有效扩展上下文长度至200万个token，且在处理长序列时比其他方法更快。",
    "keywords": [
        "LongVILA",
        "视觉语言模型",
        "VLM",
        "长上下文",
        "系统设计",
        "模型训练",
        "数据集",
        "多模态序列并行",
        "MM-SP",
        "长文档",
        "视频",
        "性能",
        "提高",
        "VideoMME",
        "五阶段训练流程",
        "准确率",
        "上下文长度",
        "1024帧",
        "274k个token",
        "200万个token",
        "有效扩展",
        "快速"
    ],
    "timestamp": "2024-10-27T07:17:59.210027"
}