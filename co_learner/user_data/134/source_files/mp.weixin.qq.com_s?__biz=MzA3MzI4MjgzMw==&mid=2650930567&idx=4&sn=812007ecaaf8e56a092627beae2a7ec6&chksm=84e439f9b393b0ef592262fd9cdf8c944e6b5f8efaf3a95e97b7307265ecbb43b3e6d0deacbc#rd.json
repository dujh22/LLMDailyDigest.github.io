{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930567&idx=4&sn=812007ecaaf8e56a092627beae2a7ec6&chksm=84e439f9b393b0ef592262fd9cdf8c944e6b5f8efaf3a95e97b7307265ecbb43b3e6d0deacbc#rd",
    "title": "大神Karpathy：我给大模型「SQL注入」攻击，简直不要太轻松",
    "summary": "AI大牛Andrej Karpathy指出，大型语言模型（LLM）存在类似SQL注入的安全风险。攻击者可以利用LLM的分词器将恶意特殊token插入输入，导致模型执行意外操作。在SQL注入中，攻击者通过恶意SQL语句访问或修改数据库。在LLM中，不良代码可能导致模型混淆输入，产生未定义的输出。Karpathy建议在处理特殊token时禁用`add_special_tokens=False`和`split_special_tokens=True`，并使用编程方式显式添加，以提高安全性。他还警告，大约50%的代码可能因这个问题出现bug，即使是经过严格测试的ChatGPT也存在相关问题。开发人员应以“普通”方式标记字符串，以遵循安全领域的“最小特权”原则。",
    "user_summary": "AI大牛Andrej Karpathy指出，大型语言模型（LLM）存在类似SQL注入的安全风险。攻击者可以利用LLM的分词器将恶意特殊token插入输入，导致模型执行意外操作。在SQL注入中，攻击者通过恶意SQL语句访问或修改数据库。在LLM中，不良代码可能导致模型混淆输入，产生未定义的输出。Karpathy建议在处理特殊token时禁用`add_special_tokens=False`和`split_special_tokens=True`，并使用编程方式显式添加，以提高安全性。他还警告，大约50%的代码可能因这个问题出现bug，即使是经过严格测试的ChatGPT也存在相关问题。开发人员应以“普通”方式标记字符串，以遵循安全领域的“最小特权”原则。",
    "keywords": [
        "AI",
        "大牛",
        "Andrej",
        "Karpathy",
        "大型语言模型",
        "LLM",
        "SQL",
        "注入",
        "安全风险",
        "分词器",
        "恶意",
        "token",
        "输入",
        "执行",
        "意外操作",
        "SQL",
        "注入",
        "数据库",
        "攻击者",
        "代码",
        "模型",
        "混淆",
        "输入",
        "未定义",
        "输出",
        "建议",
        "禁用",
        "`add_special_tokens=False`",
        "`split_special_tokens=True`",
        "显式",
        "添加",
        "编程",
        "安全性",
        "bug",
        "ChatGPT",
        "测试",
        "问题",
        "开发人员",
        "标记",
        "字符串",
        "安全",
        "最小特权",
        "原则"
    ],
    "timestamp": "2024-10-27T07:19:06.952132"
}