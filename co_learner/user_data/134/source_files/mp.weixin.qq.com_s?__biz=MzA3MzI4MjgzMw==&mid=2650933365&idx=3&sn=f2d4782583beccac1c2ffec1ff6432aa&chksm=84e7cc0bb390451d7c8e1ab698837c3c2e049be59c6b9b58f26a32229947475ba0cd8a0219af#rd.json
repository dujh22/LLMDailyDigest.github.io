{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933365&idx=3&sn=f2d4782583beccac1c2ffec1ff6432aa&chksm=84e7cc0bb390451d7c8e1ab698837c3c2e049be59c6b9b58f26a32229947475ba0cd8a0219af#rd",
    "title": "用60%成本干80%的事，DeepSeek分享沉淀多年的高性能深度学习架构",
    "summary": "研究人员提出了一个名为Fire-Flyer AI-HPC的架构，以构建成本高效的深度学习和大语言模型（LLM）训练系统。该架构基于硬件发展的实际情况，针对深度学习的高算力需求，提供了一种使用PCIe A100 GPU的集群设计，与英伟达的DGX-A100系统相比，计算性能达到83%，但成本和能耗分别下降到60%。该集群采用两层Fat-Tree网络拓扑，降低了交换机和连接成本。同时，研究团队还开发了HFReduce软件库，优化了allreduce操作，降低了PCIe带宽消耗和GPU核开销。此外，他们还推出了HaiScale分布式数据并行工具，针对大规模模型训练进行了优化，实现了良好的并行扩展性。整体而言，Fire-Flyer 2 AI-HPC在保持高性能的同时，显著降低了建设和运行成本。",
    "user_summary": "研究人员提出了一个名为Fire-Flyer AI-HPC的架构，以构建成本高效的深度学习和大语言模型（LLM）训练系统。该架构基于硬件发展的实际情况，针对深度学习的高算力需求，提供了一种使用PCIe A100 GPU的集群设计，与英伟达的DGX-A100系统相比，计算性能达到83%，但成本和能耗分别下降到60%。该集群采用两层Fat-Tree网络拓扑，降低了交换机和连接成本。同时，研究团队还开发了HFReduce软件库，优化了allreduce操作，降低了PCIe带宽消耗和GPU核开销。此外，他们还推出了HaiScale分布式数据并行工具，针对大规模模型训练进行了优化，实现了良好的并行扩展性。整体而言，Fire-Flyer 2 AI-HPC在保持高性能的同时，显著降低了建设和运行成本。",
    "keywords": [
        "Fire-Flyer",
        "AI-HPC",
        "深度学习",
        "大语言模型",
        "LLM",
        "PCIe",
        "A100",
        "GPU",
        "集群设计",
        "DGX-A100",
        "计算性能",
        "成本",
        "能耗",
        "Fat-Tree",
        "网络拓扑",
        "HFReduce",
        "allreduce",
        "PCIe带宽",
        "GPU核开销",
        "HaiScale",
        "分布式数据并行",
        "并行扩展性",
        "高性能",
        "建设",
        "运行成本"
    ],
    "timestamp": "2024-10-27T07:14:44.550468"
}