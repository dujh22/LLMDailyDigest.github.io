{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931294&idx=4&sn=aba803c8ac060ca6648de9c96309fe88&chksm=84e7c420b3904d36b057cd12112417fc86cf1cd6de384c4700a87a27a90771b5233384ca8ddd#rd",
    "title": "国内首个自研MoE多模态大模型，揭秘腾讯混元多模态理解",
    "summary": "腾讯混元推出了基于MoE架构的多模态理解大模型，这是国内首个此类模型，旨在解决视觉理解问题，推动人工智能从数字世界向物理世界的跨越。该模型在架构、训练方法和数据处理上进行了创新，提升了性能，能理解最高7K分辨率和任意长宽比的图片。在SuperCLUE-V基准评测中，腾讯混元模型获得国内排名第一，显示出强大的多模态场景理解能力。模型设计遵循简单、可规模化原则，支持原生任意分辨率并采用MLP适配器。它已经在腾讯的AI助手产品腾讯元宝中应用，并通过腾讯云向企业和个人开发者开放。",
    "user_summary": "腾讯混元推出了基于MoE架构的多模态理解大模型，这是国内首个此类模型，旨在解决视觉理解问题，推动人工智能从数字世界向物理世界的跨越。该模型在架构、训练方法和数据处理上进行了创新，提升了性能，能理解最高7K分辨率和任意长宽比的图片。在SuperCLUE-V基准评测中，腾讯混元模型获得国内排名第一，显示出强大的多模态场景理解能力。模型设计遵循简单、可规模化原则，支持原生任意分辨率并采用MLP适配器。它已经在腾讯的AI助手产品腾讯元宝中应用，并通过腾讯云向企业和个人开发者开放。",
    "keywords": [
        "腾讯",
        "混元",
        "MoE",
        "多模态",
        "理解",
        "大模型",
        "国内",
        "首个",
        "视觉理解",
        "人工智能",
        "数字世界",
        "物理世界",
        "创新",
        "架构",
        "训练方法",
        "数据处理",
        "性能",
        "图片",
        "SuperCLUE-V",
        "基准",
        "评测",
        "排名",
        "第一",
        "多模态场景理解",
        "能力",
        "简单",
        "可规模化",
        "原生",
        "分辨率",
        "MLP",
        "适配器",
        "腾讯",
        "元宝",
        "产品",
        "腾讯云",
        "企业",
        "个人",
        "开发者"
    ],
    "timestamp": "2024-10-27T07:17:46.828773"
}