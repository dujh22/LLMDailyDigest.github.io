{
    "link": "http://arxiv.org/abs/2410.18938v1",
    "title": "从随机矩阵理论的角度看学习到的特征谱与渐近泛化能力",
    "summary": "神经网络的一个重要特性是它们在训练过程中对数据的适应性。然而，我们目前对于特征学习及其与泛化的数学理解仍然有限。在这项工作中，我们对全连接的两层神经网络进行了随机矩阵分析，研究了在网络经过一次但剧烈的梯度下降步骤后如何适应目标函数。在大批次限制下，我们严格证明了更新后的特征等同于一个各向同性的突变随机特征模型。对于后者，我们推导出了特征经验协方差矩阵的确定性等价描述，这是通过对某些低维算子的描述来实现的。这使我们能够精确地刻画训练对特征谱的影响，特别是为特征谱尾部如何随训练变化提供了理论依据。确定性等价还给出了精确的渐近泛化误差，揭示了在特征学习存在下泛化性能提升的机制。我们的结果超出了标准的随机矩阵族，因此我们相信它具有独立的技术价值。与以往的工作不同，我们的结果在具有挑战性的最大学习率范式下成立，是完全严格的，并允许有限支持的第二层初始化，这对于研究学习到的特征的功能表达性至关重要。这为两层神经网络的泛化提供了对特征学习影响的精确描述，超越了随机特征和惰性训练阶段。",
    "user_summary": "神经网络的一个重要特性是它们在训练过程中对数据的适应性。然而，我们目前对于特征学习及其与泛化的数学理解仍然有限。在这项工作中，我们对全连接的两层神经网络进行了随机矩阵分析，研究了在网络经过一次但剧烈的梯度下降步骤后如何适应目标函数。在大批次限制下，我们严格证明了更新后的特征等同于一个各向同性的突变随机特征模型。对于后者，我们推导出了特征经验协方差矩阵的确定性等价描述，这是通过对某些低维算子的描述来实现的。这使我们能够精确地刻画训练对特征谱的影响，特别是为特征谱尾部如何随训练变化提供了理论依据。确定性等价还给出了精确的渐近泛化误差，揭示了在特征学习存在下泛化性能提升的机制。我们的结果超出了标准的随机矩阵族，因此我们相信它具有独立的技术价值。与以往的工作不同，我们的结果在具有挑战性的最大学习率范式下成立，是完全严格的，并允许有限支持的第二层初始化，这对于研究学习到的特征的功能表达性至关重要。这为两层神经网络的泛化提供了对特征学习影响的精确描述，超越了随机特征和惰性训练阶段。",
    "keywords": [
        "神经网络",
        "特征学习",
        "泛化",
        "随机矩阵",
        "分析",
        "梯度下降",
        "更新",
        "特征",
        "向同性",
        "突变",
        "随机特征模型",
        "协方差矩阵",
        "算子",
        "训练",
        "影响",
        "谱尾部",
        "渐近",
        "泛化误差",
        "技术价值",
        "学习率",
        "初始",
        "化",
        "功能表达性",
        "泛化",
        "特征学习",
        "影响"
    ],
    "timestamp": "2024-10-27T05:15:13.618942"
}