{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928134&idx=1&sn=7855c453083236c5c5d121d3b4fb955e&chksm=84e43078b393b96ed88a6a5a7ea0aaf950e3257bae24b5cd957041b4f338920d3c84013dfc92#rd",
    "title": "刚刚，Meta开源「分割一切」2.0模型，视频也能分割了",
    "summary": "Meta 在 SIGGRAPH 上发布了 Segment Anything Model 2 (SAM 2)，这是一个统一的模型，能够实时、可提示地处理图像和视频中的对象分割。SAM 2 可以在未见过的对象和视觉域中进行分割，无需自定义适配，适用于各种用例。相比前代，SAM 2 提高了图像分割的准确性，减少了视频分割所需的交互时间，并通过创新的流式内存设计适应实时应用。该模型在实时视频分割方面实现了重大进步，且能够在不依赖数据中心的情况下运行。Meta 还发布了大型带注释的视频数据库 SA-V 以支持训练。SAM 2 的代码和模型权重将开源，并在 Amazon SageMaker 等平台上托管，提供了一个在线演示地址以供体验。该模型有望应用于各种实际场景，如 AR 眼镜中的对象识别和科学研究。尽管 SAM 2 仍面临一些挑战，如处理快速移动对象和长时间遮挡，但它的出现标志着在通用分割模型上的重大进展。",
    "user_summary": "Meta 在 SIGGRAPH 上发布了 Segment Anything Model 2 (SAM 2)，这是一个统一的模型，能够实时、可提示地处理图像和视频中的对象分割。SAM 2 可以在未见过的对象和视觉域中进行分割，无需自定义适配，适用于各种用例。相比前代，SAM 2 提高了图像分割的准确性，减少了视频分割所需的交互时间，并通过创新的流式内存设计适应实时应用。该模型在实时视频分割方面实现了重大进步，且能够在不依赖数据中心的情况下运行。Meta 还发布了大型带注释的视频数据库 SA-V 以支持训练。SAM 2 的代码和模型权重将开源，并在 Amazon SageMaker 等平台上托管，提供了一个在线演示地址以供体验。该模型有望应用于各种实际场景，如 AR 眼镜中的对象识别和科学研究。尽管 SAM 2 仍面临一些挑战，如处理快速移动对象和长时间遮挡，但它的出现标志着在通用分割模型上的重大进展。",
    "keywords": [
        "Meta",
        "SIGGRAPH",
        "SAM",
        "2",
        "实时",
        "对象分割",
        "图像",
        "视频",
        "未见过的对象",
        "自定义适配",
        "高精度",
        "交互时间",
        "实时应用",
        "视频分割",
        "大型带注释的视频数据库",
        "SA-V",
        "开源",
        "Amazon",
        "SageMaker",
        "在线演示",
        "AR",
        "眼镜",
        "对象识别",
        "科学研究",
        "快速移动对象",
        "长时间遮挡",
        "通用分割模型",
        "进展"
    ],
    "timestamp": "2024-10-27T07:22:29.050563"
}