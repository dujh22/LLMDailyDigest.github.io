{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920090&idx=2&sn=2b3bfd6c33f118785f5f506933d7d9b3&chksm=84e410e4b39399f2a1258c10f96dddb4ac170c9604c46a3f7f50513a67784ccc2844e310badb#rd",
    "title": "多模态大模型不够灵活，谷歌DeepMind创新架构Zipper：分开训练再「压缩」",
    "summary": "Google DeepMind的研究人员提出了一种名为Zipper的新型架构，用于融合多种模态的生成任务。Zipper由多个单独预训练的单模态解码器模型组成，可以在预训练后利用交叉注意力将它们“压缩”在一起，通过有限的跨模态数据进行微调，实现多模态生成能力。这种方法比传统的多模态预训练模型更灵活，可以在新的多模态组合中重复使用和再利用预训练的纯解码器模型，而不需要大量对齐的跨模态数据。Zipper在语音到文本和文本到语音任务中的实验展示了其强大的跨模态生成能力，即使使用少量对齐数据也能取得良好效果。",
    "user_summary": "Google DeepMind的研究人员提出了一种名为Zipper的新型架构，用于融合多种模态的生成任务。Zipper由多个单独预训练的单模态解码器模型组成，可以在预训练后利用交叉注意力将它们“压缩”在一起，通过有限的跨模态数据进行微调，实现多模态生成能力。这种方法比传统的多模态预训练模型更灵活，可以在新的多模态组合中重复使用和再利用预训练的纯解码器模型，而不需要大量对齐的跨模态数据。Zipper在语音到文本和文本到语音任务中的实验展示了其强大的跨模态生成能力，即使使用少量对齐数据也能取得良好效果。",
    "keywords": [
        "Google",
        "DeepMind",
        "Zipper",
        "多模态",
        "生成任务",
        "预训练",
        "单模态",
        "解码器模型",
        "跨模态",
        "数据",
        "微调",
        "灵活",
        "重复使用",
        "再利用",
        "对齐",
        "数据",
        "语音到文本",
        "文本到语音",
        "实验",
        "跨模态生成能力"
    ],
    "timestamp": "2024-10-27T07:35:33.629001"
}