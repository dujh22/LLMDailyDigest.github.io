{
    "link": "http://arxiv.org/abs/2410.18860v1",
    "title": "DeCoRe：通过对比检索头来减轻幻觉的解码方法",
    "summary": "大型语言模型（LLMs）经常产生幻觉，即在误解上下文或错误回忆内部知识的情况下，输出不准确或与事实不符的信息。最近的研究已经识别出Transformer架构中的一些特定注意力头，称为检索头，它们负责提取相关上下文信息。我们推测，屏蔽这些检索头可能会引发幻觉，而对比基本LLM和屏蔽LLM的输出可以减少幻觉。为此，我们提出了一个无需训练的解码策略，即对比检索头解码（DeCoRe），它能放大上下文和模型参数中的信息。DeCoRe通过动态对比基本LLM和屏蔽LLM的输出，利用条件熵作为指导，来缓解潜在的幻觉响应。我们的大量实验表明，DeCoRe在需要高度上下文忠实度的任务上，如摘要（XSum提高18.6%）、指令遵循（MemoTrap提高10.9%）和开放式问答（NQ-Open提高2.4%和NQ-Swap提高5.5%）等方面，显著提高了性能。",
    "user_summary": "大型语言模型（LLMs）经常产生幻觉，即在误解上下文或错误回忆内部知识的情况下，输出不准确或与事实不符的信息。最近的研究已经识别出Transformer架构中的一些特定注意力头，称为检索头，它们负责提取相关上下文信息。我们推测，屏蔽这些检索头可能会引发幻觉，而对比基本LLM和屏蔽LLM的输出可以减少幻觉。为此，我们提出了一个无需训练的解码策略，即对比检索头解码（DeCoRe），它能放大上下文和模型参数中的信息。DeCoRe通过动态对比基本LLM和屏蔽LLM的输出，利用条件熵作为指导，来缓解潜在的幻觉响应。我们的大量实验表明，DeCoRe在需要高度上下文忠实度的任务上，如摘要（XSum提高18.6%）、指令遵循（MemoTrap提高10.9%）和开放式问答（NQ-Open提高2.4%和NQ-Swap提高5.5%）等方面，显著提高了性能。",
    "keywords": [
        "大型语言模型",
        "LLMs",
        "幻觉",
        "注意力头",
        "检索头",
        "输出",
        "不准确",
        "事实不符",
        "Transformer",
        "架构",
        "屏蔽",
        "输出",
        "幻觉",
        "解码策略",
        "对比检索头解码",
        "DeCoRe",
        "上下文",
        "信息",
        "参数",
        "放大",
        "条件熵",
        "幻觉响应",
        "实验",
        "性能",
        "提高",
        "摘要",
        "指令遵循",
        "开放式问答"
    ],
    "timestamp": "2024-10-27T05:17:39.056707"
}