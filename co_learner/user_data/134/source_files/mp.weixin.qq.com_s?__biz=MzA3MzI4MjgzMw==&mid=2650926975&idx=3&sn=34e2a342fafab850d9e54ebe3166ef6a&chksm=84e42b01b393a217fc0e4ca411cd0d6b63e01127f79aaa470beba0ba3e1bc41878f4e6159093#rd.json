{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926975&idx=3&sn=34e2a342fafab850d9e54ebe3166ef6a&chksm=84e42b01b393a217fc0e4ca411cd0d6b63e01127f79aaa470beba0ba3e1bc41878f4e6159093#rd",
    "title": "权重、代码、数据集全开源，性能超越Mistral-7B，苹果小模型来了",
    "summary": "苹果公司最近在Hugging Face上发布了开源模型DCLM-7B，该模型在性能上超越了Mistral-7B，并接近其他领先开源模型，如Llama 3和Gemma。DCLM项目旨在创建一个语言模型训练数据的基准，通过使用机器学习模型过滤数据来提升模型性能。DCLM-7B模型在MMLU基准上的5-shot准确率达到64%，与Llama 3 8B相当，但所需计算量仅为Llama 3 8B的1/6。DCLM-7B模型的独特之处在于其不仅开放模型权重，还开放了训练代码和预训练数据集，因此被描述为“真正开源”的模型。",
    "user_summary": "苹果公司最近在Hugging Face上发布了开源模型DCLM-7B，该模型在性能上超越了Mistral-7B，并接近其他领先开源模型，如Llama 3和Gemma。DCLM项目旨在创建一个语言模型训练数据的基准，通过使用机器学习模型过滤数据来提升模型性能。DCLM-7B模型在MMLU基准上的5-shot准确率达到64%，与Llama 3 8B相当，但所需计算量仅为Llama 3 8B的1/6。DCLM-7B模型的独特之处在于其不仅开放模型权重，还开放了训练代码和预训练数据集，因此被描述为“真正开源”的模型。",
    "keywords": [
        "苹果公司",
        "DCLM-7B",
        "Hugging",
        "Face",
        "开源",
        "模型",
        "Mistral-7B",
        "Llama",
        "3",
        "Gemma",
        "语言模型",
        "训练数据",
        "基准",
        "机器学习",
        "模型性能",
        "MMLU",
        "基准",
        "5-shot",
        "准确率",
        "Llama",
        "3",
        "8B",
        "计算量",
        "开放",
        "模型权重",
        "训练代码",
        "预训练数据集",
        "真正开源"
    ],
    "timestamp": "2024-10-27T07:24:40.343241"
}