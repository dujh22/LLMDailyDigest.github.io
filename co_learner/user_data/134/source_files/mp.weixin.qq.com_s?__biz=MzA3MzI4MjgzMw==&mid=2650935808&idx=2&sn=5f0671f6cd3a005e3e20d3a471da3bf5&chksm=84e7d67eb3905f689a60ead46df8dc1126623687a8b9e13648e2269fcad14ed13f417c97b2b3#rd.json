{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935808&idx=2&sn=5f0671f6cd3a005e3e20d3a471da3bf5&chksm=84e7d67eb3905f689a60ead46df8dc1126623687a8b9e13648e2269fcad14ed13f417c97b2b3#rd",
    "title": "LLM仍然不能规划，刷屏的OpenAI o1远未达到饱和",
    "summary": "亚利桑那州立大学研究团队评估了大型语言模型（LLM）在规划能力方面的表现，包括OpenAI的o1模型。尽管o1在多个基准测试中表现出色，但在 PlanBench 基准上，LLM的规划能力仍然有限。即使是最新的o1模型，在解决复杂问题时的性能并不稳定，特别是在Mystery Blocksworld测试中。研究发现，LLM在规划任务中的表现远不如检索任务，而且自然语言提示对它们的影响大于PDDL。虽然o1模型通过结合RL训练和自适应扩展推理程序有所改进，但其性能仍不够稳健，且在处理无法解决的问题时识别率较低。研究强调了LLM在实现真正通用推理能力方面还有很长的路要走。",
    "user_summary": "亚利桑那州立大学研究团队评估了大型语言模型（LLM）在规划能力方面的表现，包括OpenAI的o1模型。尽管o1在多个基准测试中表现出色，但在 PlanBench 基准上，LLM的规划能力仍然有限。即使是最新的o1模型，在解决复杂问题时的性能并不稳定，特别是在Mystery Blocksworld测试中。研究发现，LLM在规划任务中的表现远不如检索任务，而且自然语言提示对它们的影响大于PDDL。虽然o1模型通过结合RL训练和自适应扩展推理程序有所改进，但其性能仍不够稳健，且在处理无法解决的问题时识别率较低。研究强调了LLM在实现真正通用推理能力方面还有很长的路要走。",
    "keywords": [
        "亚利桑那州立大学",
        "LLM",
        "OpenAI",
        "o1模型",
        "PlanBench",
        "规划能力",
        "Mystery",
        "Blocksworld",
        "RL训练",
        "自适应扩展推理程序",
        "通用推理能力"
    ],
    "timestamp": "2024-10-27T07:11:27.968692"
}