{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920390&idx=3&sn=b46c35437f520e90d4b3c5b49186406a&chksm=84e411b8b39398ae4aa54356c2d97d62cea34e5ed94cded431be2086fcfe0d892badc1625c29#rd",
    "title": "Karpathy点赞，这份报告教你如何用 LLaMa 3创建高质量网络数据集",
    "summary": "研究人员构建了一个名为FineWeb的大规模数据集，用于预训练大型语言模型。这个数据集包含15万亿个token，经过过滤和质量评估，旨在提供高质量的教育内容。AI专家Andrej Karpathy推荐了FineWeb-Edu，它是FineWeb的一个子集，专注于教科级内容，经过Llama 3 70B模型的评估，分为1.3万亿和5.4万亿token的两个版本。FineWeb-Edu在教育相关基准测试中表现出色，超过了其他公开可用的网络数据集。数据集的创建涉及对CommonCrawl的处理、重复数据删除和使用LLM进行质量注释等步骤。这是提高大语言模型性能的一个重要步骤，强调了高质量教育内容在训练中的价值。",
    "user_summary": "研究人员构建了一个名为FineWeb的大规模数据集，用于预训练大型语言模型。这个数据集包含15万亿个token，经过过滤和质量评估，旨在提供高质量的教育内容。AI专家Andrej Karpathy推荐了FineWeb-Edu，它是FineWeb的一个子集，专注于教科级内容，经过Llama 3 70B模型的评估，分为1.3万亿和5.4万亿token的两个版本。FineWeb-Edu在教育相关基准测试中表现出色，超过了其他公开可用的网络数据集。数据集的创建涉及对CommonCrawl的处理、重复数据删除和使用LLM进行质量注释等步骤。这是提高大语言模型性能的一个重要步骤，强调了高质量教育内容在训练中的价值。",
    "keywords": [
        "FineWeb",
        "大规模数据集",
        "预训练",
        "语言模型",
        "token",
        "过滤",
        "质量评估",
        "教育内容",
        "Andrej",
        "Karpathy",
        "FineWeb-Edu",
        "教科级内容",
        "Llama",
        "3",
        "70B",
        "模型",
        "评估",
        "1.3万亿",
        "5.4万亿",
        "token",
        "教育相关基准",
        "测试",
        "表现",
        "公开可用",
        "网络数据集",
        "CommonCrawl",
        "处理",
        "重复数据删除",
        "LLM",
        "质量注释",
        "提高",
        "性能",
        "重要步骤",
        "高质量教育内容",
        "训练",
        "价值"
    ],
    "timestamp": "2024-10-27T07:35:04.841319"
}