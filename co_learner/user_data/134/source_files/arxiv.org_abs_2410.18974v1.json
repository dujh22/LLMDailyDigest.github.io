{
    "link": "http://arxiv.org/abs/2410.18974v1",
    "title": "3D-Adapter：用于高质量3D生成的几何一致多视图扩散",
    "summary": "多视图图像扩散模型在开放域3D对象生成方面取得了显著进步。然而，大多数现有模型依赖于缺乏内在3D偏置的2D网络架构，导致几何一致性受损。为解决这一挑战，我们引入了3D-Adapter，这是一个设计用于将3D几何意识注入预训练图像扩散模型的插件模块。我们的方法核心思想是3D反馈增强：在采样循环的每个去噪步骤中，3D-Adapter将中间多视图特征解码为一致的3D表示，然后重新编码渲染的RGBD视图，通过特征添加来增强预训练的基础模型。我们研究了3D-Adapter的两种变体：一种基于高斯散射的快速前向版本，另一种是利用神经场和网格的无需训练的多功能版本。我们的大量实验表明，3D-Adapter不仅显著提高了Instant3D和Zero123++等文本到多视图模型的几何质量，而且还使使用纯文本到图像的Stable Diffusion实现高质量3D生成成为可能。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到头像任务中展示高质量的结果，展示了3D-Adapter的广泛应用潜力。",
    "user_summary": "多视图图像扩散模型在开放域3D对象生成方面取得了显著进步。然而，大多数现有模型依赖于缺乏内在3D偏置的2D网络架构，导致几何一致性受损。为解决这一挑战，我们引入了3D-Adapter，这是一个设计用于将3D几何意识注入预训练图像扩散模型的插件模块。我们的方法核心思想是3D反馈增强：在采样循环的每个去噪步骤中，3D-Adapter将中间多视图特征解码为一致的3D表示，然后重新编码渲染的RGBD视图，通过特征添加来增强预训练的基础模型。我们研究了3D-Adapter的两种变体：一种基于高斯散射的快速前向版本，另一种是利用神经场和网格的无需训练的多功能版本。我们的大量实验表明，3D-Adapter不仅显著提高了Instant3D和Zero123++等文本到多视图模型的几何质量，而且还使使用纯文本到图像的Stable Diffusion实现高质量3D生成成为可能。此外，我们通过在文本到3D、图像到3D、文本到纹理和文本到头像任务中展示高质量的结果，展示了3D-Adapter的广泛应用潜力。",
    "keywords": [
        "3D-Adapter",
        "3D几何意识",
        "2D网络架构",
        "3D反馈增强",
        "采样循环",
        "去噪步骤",
        "中间多视图特征",
        "3D表示",
        "RGBD视图",
        "高斯散射",
        "神经场",
        "网格",
        "训练",
        "文本到多视图模型",
        "几何质量",
        "Instant3D",
        "Zero123++",
        "纯文本到图像",
        "Stable",
        "Diffusion",
        "3D生成",
        "文本到3D",
        "图像到3D",
        "文本到纹理",
        "文本到头像"
    ],
    "timestamp": "2024-10-27T05:13:53.130642"
}