{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924168&idx=4&sn=058fb8291d83ea2fb1c6bfde7576ebb0&chksm=84e420f6b393a9e02d91627fbdbce5e77b89c0bc976bb7cbf649fb4a76aac29d2d0563cbc366#rd",
    "title": "等不来OpenAI的Q*，华为诺亚探索LLM推理的秘密武器MindStar先来了",
    "summary": "华为蒙特利尔诺亚方舟实验室的研究人员提出了一种名为MindStar的新方法，旨在增强预训练大型语言模型（LLMs）在推理时间的数学推理能力。MindStar通过将推理任务视为搜索问题，使用过程监督的奖励模型（PRM）在推理树空间中导航，寻找最优路径。实验结果显示，MindStar在开源模型LLaMA-13B和Mistral-7B上达到了接近GPT-3.5和Grok-1的数学问题解决能力，同时显著减少了计算资源。该方法结合束搜索和Levin树搜索策略，提高了搜索效率。研究发现，LLMs在处理复杂推理任务时，有时会生成正确的推理轨迹，MindStar通过帮助模型选择正确的输出来增强其推理能力。",
    "user_summary": "华为蒙特利尔诺亚方舟实验室的研究人员提出了一种名为MindStar的新方法，旨在增强预训练大型语言模型（LLMs）在推理时间的数学推理能力。MindStar通过将推理任务视为搜索问题，使用过程监督的奖励模型（PRM）在推理树空间中导航，寻找最优路径。实验结果显示，MindStar在开源模型LLaMA-13B和Mistral-7B上达到了接近GPT-3.5和Grok-1的数学问题解决能力，同时显著减少了计算资源。该方法结合束搜索和Levin树搜索策略，提高了搜索效率。研究发现，LLMs在处理复杂推理任务时，有时会生成正确的推理轨迹，MindStar通过帮助模型选择正确的输出来增强其推理能力。",
    "keywords": [
        "华为",
        "蒙特利尔",
        "诺亚方舟实验室",
        "MindStar",
        "大型语言模型",
        "LLMs",
        "推理时间",
        "数学推理",
        "过程监督",
        "奖励模型",
        "PRM",
        "推理树",
        "空间",
        "寻找",
        "最优路径",
        "LLaMA-13B",
        "Mistral-7B",
        "GPT-3.5",
        "Grok-1",
        "计算资源",
        "束搜索",
        "Levin",
        "树搜索",
        "策略",
        "提高",
        "效率",
        "复杂推理任务",
        "正确",
        "推理轨迹",
        "增强"
    ],
    "timestamp": "2024-10-27T07:28:56.021814"
}