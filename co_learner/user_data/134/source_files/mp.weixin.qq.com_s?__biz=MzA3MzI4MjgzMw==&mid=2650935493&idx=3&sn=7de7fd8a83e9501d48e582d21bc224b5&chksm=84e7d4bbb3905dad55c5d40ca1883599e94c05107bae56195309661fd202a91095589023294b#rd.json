{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935493&idx=3&sn=7de7fd8a83e9501d48e582d21bc224b5&chksm=84e7d4bbb3905dad55c5d40ca1883599e94c05107bae56195309661fd202a91095589023294b#rd",
    "title": "仅用4块GPU、不到3天训练出「开源版GPT-4o」，这是国内团队最新研究",
    "summary": "中国科学院计算技术研究所和中国科学院大学的研究者提出了新型模型架构 LLaMA-Omni，实现了与大型语言模型（LLM）的低延迟、高质量语音交互。该模型能同步生成文本和语音响应，延迟仅为226ms，低于GPT-4的平均音频响应延迟。LLaMA-Omni由语音编码器、语音适配器、LLM和流式语音解码器组成，无需先将语音转为文本，能直接从语音指令生成响应。此外，模型使用了InstructS2S-200K数据集进行训练，显著减少了所需的训练数据和计算资源。实验结果显示，LLaMA-Omni在内容、风格和对齐方面优于其他语音-语言模型。",
    "user_summary": "中国科学院计算技术研究所和中国科学院大学的研究者提出了新型模型架构 LLaMA-Omni，实现了与大型语言模型（LLM）的低延迟、高质量语音交互。该模型能同步生成文本和语音响应，延迟仅为226ms，低于GPT-4的平均音频响应延迟。LLaMA-Omni由语音编码器、语音适配器、LLM和流式语音解码器组成，无需先将语音转为文本，能直接从语音指令生成响应。此外，模型使用了InstructS2S-200K数据集进行训练，显著减少了所需的训练数据和计算资源。实验结果显示，LLaMA-Omni在内容、风格和对齐方面优于其他语音-语言模型。",
    "keywords": [
        "中国科学院计算技术研究所",
        "中国科学院大学",
        "LLaMA-Omni",
        "大型语言模型",
        "低延迟",
        "高质量语音交互",
        "文本",
        "语音响应",
        "延迟",
        "GPT-4",
        "语音编码器",
        "语音适配器",
        "LLM",
        "流式语音解码器",
        "语音转文本",
        "响应",
        "InstructS2S-200K",
        "数据集",
        "训练",
        "计算资源",
        "实验结果",
        "内容",
        "风格",
        "对齐",
        "语音-语言模型"
    ],
    "timestamp": "2024-10-27T07:11:37.791920"
}