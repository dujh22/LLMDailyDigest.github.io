{
    "link": "http://arxiv.org/abs/2410.18952v1",
    "title": "早期退出LLM中的动态词汇剪枝",
    "summary": "增大语言模型（LLMs）的规模已被证明可以提升性能。然而，这也会导致推断过程变得更慢、成本更高。早期退出是一种有前景的策略，通过允许在中间层进行下一个词的预测，从而提高LLM推断的效率。但是，现代LLMs的庞大词汇量使得为退出决策所需的置信度估计计算代价高昂，抵消了效率提升。为了解决这个问题，我们提出在测试时针对每个词动态地裁剪词汇表。具体来说，词汇表在初始层之一进行裁剪，然后在后续的前向传播过程中使用更小的词汇表。我们的实验表明，这种事后动态词汇裁剪可以提高早期退出LLM的置信度估计效率，同时保持了竞争力的性能。",
    "user_summary": "增大语言模型（LLMs）的规模已被证明可以提升性能。然而，这也会导致推断过程变得更慢、成本更高。早期退出是一种有前景的策略，通过允许在中间层进行下一个词的预测，从而提高LLM推断的效率。但是，现代LLMs的庞大词汇量使得为退出决策所需的置信度估计计算代价高昂，抵消了效率提升。为了解决这个问题，我们提出在测试时针对每个词动态地裁剪词汇表。具体来说，词汇表在初始层之一进行裁剪，然后在后续的前向传播过程中使用更小的词汇表。我们的实验表明，这种事后动态词汇裁剪可以提高早期退出LLM的置信度估计效率，同时保持了竞争力的性能。",
    "keywords": [
        "语言模型",
        "LLMs",
        "规模",
        "增大",
        "性能",
        "推断",
        "慢",
        "成本",
        "早期退出",
        "预测",
        "中间层",
        "效率",
        "置信度",
        "估计",
        "计算",
        "代价高昂",
        "裁剪",
        "词汇表",
        "动态",
        "考虑",
        "词",
        "初始层",
        "前向传播",
        "过程",
        "竞争力",
        "性能"
    ],
    "timestamp": "2024-10-27T05:14:34.495777"
}