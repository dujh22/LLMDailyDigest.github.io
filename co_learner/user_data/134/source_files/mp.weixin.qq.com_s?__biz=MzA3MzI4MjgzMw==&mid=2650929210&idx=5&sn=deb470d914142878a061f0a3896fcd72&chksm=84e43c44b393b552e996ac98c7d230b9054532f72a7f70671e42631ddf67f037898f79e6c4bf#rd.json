{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929210&idx=5&sn=deb470d914142878a061f0a3896fcd72&chksm=84e43c44b393b552e996ac98c7d230b9054532f72a7f70671e42631ddf67f037898f79e6c4bf#rd",
    "title": "错误率从10%降至0.01%，领英全面分享LLM应用落地经验",
    "summary": "这篇文章分享了LinkedIn团队在构建生成式AI产品时的经验。他们利用大型语言模型（LLM）技术，开发了一个系统，以帮助用户更快地获取信息、连接信息点和提供建议。该系统通过选择合适的AI智能体来处理用户查询，结合内部API和Bing进行信息检索，然后生成连贯的回复。开发过程中，他们面临了如何保持用户体验一致性、评估响应质量、调用内部API的挑战，并通过固定三步pipeline、共享提示模板和构建AI技能来解决这些问题。此外，他们还关注了容量、延迟和成本优化。",
    "user_summary": "这篇文章分享了LinkedIn团队在构建生成式AI产品时的经验。他们利用大型语言模型（LLM）技术，开发了一个系统，以帮助用户更快地获取信息、连接信息点和提供建议。该系统通过选择合适的AI智能体来处理用户查询，结合内部API和Bing进行信息检索，然后生成连贯的回复。开发过程中，他们面临了如何保持用户体验一致性、评估响应质量、调用内部API的挑战，并通过固定三步pipeline、共享提示模板和构建AI技能来解决这些问题。此外，他们还关注了容量、延迟和成本优化。",
    "keywords": [
        "LinkedIn",
        "LLM",
        "大型语言模型",
        "生成式AI",
        "用户体验",
        "信息检索",
        "响应质量",
        "内部API",
        "Bing",
        "AI技能",
        "管道",
        "提示模板",
        "容量",
        "延迟",
        "成本优化"
    ],
    "timestamp": "2024-10-27T07:21:18.749897"
}