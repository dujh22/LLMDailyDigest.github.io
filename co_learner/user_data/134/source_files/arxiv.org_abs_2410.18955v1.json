{
    "link": "http://arxiv.org/abs/2410.18955v1",
    "title": "BioMistral-NLU：通过指令微调实现更泛化的医疗语言理解",
    "summary": "大型语言模型（LLMs）如ChatGPT在遵循指令的大型多样化语料库上进行了微调，能够泛化到新任务。然而，这些经过指令微调的LLMs在需要领域知识、细致文本理解及结构化数据提取的专业医学自然语言理解（NLU）任务中往往表现不佳。为了解决这一问题，我们：（1）提出了一种统一的提示格式，适用于7个重要的NLU任务，包括跨度提取和多选题问答（QA）；（2）编制了一个指令微调数据集MNLU-Instruct，利用了各种现有的开源医学NLU语料库；（3）通过在MNLU-Instruct上微调BioMistral，开发了可泛化的医学NLU模型BioMistral-NLU。我们在六个重要的NLU任务上评估了BioMistral-NLU，这些任务来自两个广泛采用的医学NLU基准：生物医学语言理解评估（BLUE）和生物医学语言理解与推理基准（BLURB）。实验结果显示，我们的BioMistral-NLU超越了原始的BioMistral，以及专有的LLMs——ChatGPT和GPT-4。我们的数据集无关提示策略和在多样化NLU任务上的指令微调提升了LLMs在广泛医学NLU任务中的泛化能力。我们的消融实验表明，即使总的训练实例数量保持不变，但在更广泛的任务上进行指令微调也能增强下游零样本泛化能力。",
    "user_summary": "大型语言模型（LLMs）如ChatGPT在遵循指令的大型多样化语料库上进行了微调，能够泛化到新任务。然而，这些经过指令微调的LLMs在需要领域知识、细致文本理解及结构化数据提取的专业医学自然语言理解（NLU）任务中往往表现不佳。为了解决这一问题，我们：（1）提出了一种统一的提示格式，适用于7个重要的NLU任务，包括跨度提取和多选题问答（QA）；（2）编制了一个指令微调数据集MNLU-Instruct，利用了各种现有的开源医学NLU语料库；（3）通过在MNLU-Instruct上微调BioMistral，开发了可泛化的医学NLU模型BioMistral-NLU。我们在六个重要的NLU任务上评估了BioMistral-NLU，这些任务来自两个广泛采用的医学NLU基准：生物医学语言理解评估（BLUE）和生物医学语言理解与推理基准（BLURB）。实验结果显示，我们的BioMistral-NLU超越了原始的BioMistral，以及专有的LLMs——ChatGPT和GPT-4。我们的数据集无关提示策略和在多样化NLU任务上的指令微调提升了LLMs在广泛医学NLU任务中的泛化能力。我们的消融实验表明，即使总的训练实例数量保持不变，但在更广泛的任务上进行指令微调也能增强下游零样本泛化能力。",
    "keywords": [
        "大型语言模型",
        "LLMs",
        "医学自然语言理解",
        "NLU",
        "指令微调",
        "数据集",
        "MNLU-Instruct",
        "BioMistral",
        "医学NLU模型",
        "跨度提取",
        "多选题问答",
        "QA",
        "BLUE",
        "BLURB",
        "泛化能力",
        "消融实验",
        "下游零样本泛化"
    ],
    "timestamp": "2024-10-27T05:14:29.845992"
}