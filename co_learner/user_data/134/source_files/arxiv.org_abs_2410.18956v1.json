{
    "link": "http://arxiv.org/abs/2410.18956v1",
    "title": "大空间模型：端到端的无标定图像到语义3D",
    "summary": "从有限数量的图像中重建和理解3D结构是计算机视觉领域一个成熟的问题。传统的方法通常将这个任务分解成多个子任务，每个子任务都需要在不同的数据表示之间进行复杂的转换。例如，通过运动结构（SfM）进行密集重建，涉及到将图像转换为关键点，优化相机参数，以及估计结构。随后，需要精确的稀疏重建来进行进一步的密集建模，这随后会被输入到特定任务的神经网络中。这个多步骤的过程导致了显著的处理时间和工程复杂性的增加。\n\n在本工作中，我们提出了大型空间模型（LSM），它能直接将未经摆拍的RGB图像处理为语义辐射场。LSM在一个单一的前向操作中同时估计几何形状、外观和语义，并且能够在新颖的视角下通过与语言交互生成多样的标签映射。利用基于Transformer的架构，LSM通过像素对齐的点图整合全局几何信息。为了增强空间属性回归，我们通过多尺度融合引入局部上下文聚合，提高了细小局部细节的准确性。为了解决3D语义标注数据的稀缺性，以及实现自然语言驱动的场景操纵，我们将一个预训练的2D语言基础分割模型整合到一个3D一致的语义特征场中。然后，一个高效的解码器参数化一组语义各向异性高斯分布，从而促进端到端的监督学习。\n\n广泛的实验表明，LSM直接从未经摆拍的图像中统一了多个3D视觉任务，首次实现了实时的语义3D重建。",
    "user_summary": "从有限数量的图像中重建和理解3D结构是计算机视觉领域一个成熟的问题。传统的方法通常将这个任务分解成多个子任务，每个子任务都需要在不同的数据表示之间进行复杂的转换。例如，通过运动结构（SfM）进行密集重建，涉及到将图像转换为关键点，优化相机参数，以及估计结构。随后，需要精确的稀疏重建来进行进一步的密集建模，这随后会被输入到特定任务的神经网络中。这个多步骤的过程导致了显著的处理时间和工程复杂性的增加。\n\n在本工作中，我们提出了大型空间模型（LSM），它能直接将未经摆拍的RGB图像处理为语义辐射场。LSM在一个单一的前向操作中同时估计几何形状、外观和语义，并且能够在新颖的视角下通过与语言交互生成多样的标签映射。利用基于Transformer的架构，LSM通过像素对齐的点图整合全局几何信息。为了增强空间属性回归，我们通过多尺度融合引入局部上下文聚合，提高了细小局部细节的准确性。为了解决3D语义标注数据的稀缺性，以及实现自然语言驱动的场景操纵，我们将一个预训练的2D语言基础分割模型整合到一个3D一致的语义特征场中。然后，一个高效的解码器参数化一组语义各向异性高斯分布，从而促进端到端的监督学习。\n\n广泛的实验表明，LSM直接从未经摆拍的图像中统一了多个3D视觉任务，首次实现了实时的语义3D重建。",
    "keywords": [
        "3D视觉",
        "计算机视觉",
        "SfM",
        "稠密重建",
        "稀疏重建",
        "神经网络",
        "处理时间",
        "工程复杂性",
        "LSM",
        "语义辐射场",
        "几何形状",
        "外观",
        "语义",
        "新颖视角",
        "语言交互",
        "标签映射",
        "Transformer",
        "像素对齐",
        "点图",
        "局部上下文",
        "聚合",
        "细节",
        "准确性",
        "语义标注",
        "数据稀缺性",
        "自然语言",
        "场景操纵",
        "2D语言基础分割模型",
        "3D一致",
        "语义特征场",
        "高斯分布",
        "监督学习",
        "实时",
        "语义3D重建"
    ],
    "timestamp": "2024-10-27T05:14:24.911876"
}