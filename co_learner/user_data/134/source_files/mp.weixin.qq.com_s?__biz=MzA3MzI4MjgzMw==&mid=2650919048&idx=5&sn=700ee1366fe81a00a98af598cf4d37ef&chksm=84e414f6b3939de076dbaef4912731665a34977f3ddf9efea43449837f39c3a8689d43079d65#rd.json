{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919048&idx=5&sn=700ee1366fe81a00a98af598cf4d37ef&chksm=84e414f6b3939de076dbaef4912731665a34977f3ddf9efea43449837f39c3a8689d43079d65#rd",
    "title": "腾讯PCG自研高性能大语言模型推理引擎「一念LLM」正式开源",
    "summary": "一念LLM是腾讯PCG机器学习平台中心自研的高性能大语言模型推理引擎，旨在解决大语言模型推理成本高的问题。相比其他著名开源框架如vLLM和TensorRT-LLM，一念LLM在相同精度下推理单价降低20%+，并且首次同时支持Nvidia GPU和华为NPU，以应对硬件供应问题。该框架通过显存优化、异步调度和计算复用技术提高性能，并已在QQ智能体等业务场景上线。一念LLM的开源代码可在github上获取。",
    "user_summary": "一念LLM是腾讯PCG机器学习平台中心自研的高性能大语言模型推理引擎，旨在解决大语言模型推理成本高的问题。相比其他著名开源框架如vLLM和TensorRT-LLM，一念LLM在相同精度下推理单价降低20%+，并且首次同时支持Nvidia GPU和华为NPU，以应对硬件供应问题。该框架通过显存优化、异步调度和计算复用技术提高性能，并已在QQ智能体等业务场景上线。一念LLM的开源代码可在github上获取。",
    "keywords": [
        "一念LLM",
        "腾讯PCG",
        "机器学习平台",
        "大语言模型",
        "推理引擎",
        "高性能",
        "成本",
        "开源框架",
        "vLLM",
        "TensorRT-LLM",
        "精度",
        "推理单价",
        "GPU",
        "华为NPU",
        "硬件供应",
        "显存优化",
        "异步调度",
        "计算复用",
        "QQ智能体",
        "业务场景",
        "github"
    ],
    "timestamp": "2024-10-27T07:38:29.827081"
}