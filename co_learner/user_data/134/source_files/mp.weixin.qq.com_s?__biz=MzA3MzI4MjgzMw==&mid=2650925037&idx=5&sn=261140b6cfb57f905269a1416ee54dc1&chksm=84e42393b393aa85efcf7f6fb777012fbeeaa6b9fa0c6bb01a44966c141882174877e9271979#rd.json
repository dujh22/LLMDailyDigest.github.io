{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925037&idx=5&sn=261140b6cfb57f905269a1416ee54dc1&chksm=84e42393b393aa85efcf7f6fb777012fbeeaa6b9fa0c6bb01a44966c141882174877e9271979#rd",
    "title": "开源视频版GPT-4o？快速记忆，实时问答，拿下CVPR'24长视频问答竞赛冠军",
    "summary": "字节跳动和清华大学的研究人员联合开发了Flash-VStream，这是首个针对长视频流的在线理解多模态大模型，可以实现高效记忆和实时回答关于长视频的问题。该模型采用STAR记忆机制，包括空间、时间、抽象和检索四种记忆模块，能够融合不同粒度的语义信息。与现有方法相比，Flash-VStream可以在线处理极长的视频流，显存开销和回答延迟几乎不随输入帧数增加，且在多个长视频问答基准上取得最佳性能，包括赢得了CVPR'24长视频问答竞赛的冠军。此外，研究团队还构建了一个名为VStream-QA的在线视频流问答数据集，以支持该领域的模型评估和改进。",
    "user_summary": "字节跳动和清华大学的研究人员联合开发了Flash-VStream，这是首个针对长视频流的在线理解多模态大模型，可以实现高效记忆和实时回答关于长视频的问题。该模型采用STAR记忆机制，包括空间、时间、抽象和检索四种记忆模块，能够融合不同粒度的语义信息。与现有方法相比，Flash-VStream可以在线处理极长的视频流，显存开销和回答延迟几乎不随输入帧数增加，且在多个长视频问答基准上取得最佳性能，包括赢得了CVPR'24长视频问答竞赛的冠军。此外，研究团队还构建了一个名为VStream-QA的在线视频流问答数据集，以支持该领域的模型评估和改进。",
    "keywords": [
        "字节跳动",
        "清华大学",
        "Flash-VStream",
        "长视频流",
        "在线理解",
        "多模态大模型",
        "高效记忆",
        "实时回答",
        "问题",
        "STAR记忆机制",
        "空间",
        "时间",
        "抽象",
        "检索",
        "语义信息",
        "输入帧数",
        "延迟",
        "CVPR'24",
        "长视频问答竞赛",
        "数据集",
        "VStream-QA",
        "模型评估",
        "改进"
    ],
    "timestamp": "2024-10-27T07:27:37.420484"
}