{
    "link": "http://arxiv.org/abs/2410.18923v1",
    "title": "SegLLM：多轮推理分割",
    "summary": "我们推出了SegLLM，这是一种创新的多轮交互式推理分割模型，它通过利用视觉和文本输出的对话记忆来增强基于LLM（大型语言模型）的分割。借助于具备掩码感知的多模态LLM，SegLLM将先前的分割结果重新整合到其输入流中，使其能够理解复杂的用户意图，并根据先前识别的实体（包括位置关系、交互关系和层次关系）来分割对象，这一切都可在多次交互中实现。这种能力使SegLLM能够以聊天式的方式响应视觉和文本查询。在新编纂的MRSeg基准测试中，SegLLM在多轮交互式推理分割任务上的表现超过了现有方法20%以上。此外，我们发现，在多轮推理分割数据上进行训练可以提升标准单轮提及分割和定位任务的性能，导致提及表达分割的cIoU提高了5.5%，提及表达定位的Acc@0.5提高了4.5%。",
    "user_summary": "我们推出了SegLLM，这是一种创新的多轮交互式推理分割模型，它通过利用视觉和文本输出的对话记忆来增强基于LLM（大型语言模型）的分割。借助于具备掩码感知的多模态LLM，SegLLM将先前的分割结果重新整合到其输入流中，使其能够理解复杂的用户意图，并根据先前识别的实体（包括位置关系、交互关系和层次关系）来分割对象，这一切都可在多次交互中实现。这种能力使SegLLM能够以聊天式的方式响应视觉和文本查询。在新编纂的MRSeg基准测试中，SegLLM在多轮交互式推理分割任务上的表现超过了现有方法20%以上。此外，我们发现，在多轮推理分割数据上进行训练可以提升标准单轮提及分割和定位任务的性能，导致提及表达分割的cIoU提高了5.5%，提及表达定位的Acc@0.5提高了4.5%。",
    "keywords": [
        "SegLLM",
        "多轮交互式推理分割",
        "基于LLM",
        "分割",
        "视觉",
        "文本",
        "输出",
        "对话记忆",
        "大型语言模型",
        "掩码感知",
        "多模态LLM",
        "用户意图",
        "实体",
        "位置关系",
        "交互关系",
        "层次关系",
        "对象",
        "聊天式",
        "响应",
        "视觉",
        "文本查询",
        "MRSeg",
        "基准",
        "测试",
        "表现",
        "现有方法",
        "多轮交互式推理分割",
        "任务",
        "提升",
        "标准单轮",
        "提及分割",
        "定位任务",
        "性能",
        "提高",
        "cIoU",
        "Acc@0.5"
    ],
    "timestamp": "2024-10-27T05:15:43.629510"
}