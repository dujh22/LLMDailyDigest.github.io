{
    "link": "http://arxiv.org/abs/2410.18965v1",
    "title": "矩阵分解中初始化的关键作用",
    "summary": "这项工作重新审视了经典的低秩矩阵分解问题，并揭示了初始化在塑造此类非凸且非光滑优化问题的收敛速度方面的重要作用。我们引入了Nyström初始化方法，它显著提高了对称和非对称矩阵分解任务中规模化梯度下降（ScaledGD）的全局收敛性。具体来说，我们证明了带有Nyström初始化的ScaledGD在之前只知道线性收敛率的情况下实现了二次收敛。此外，我们将这种初始化方法扩展到了常用于微调基础模型的低秩适配器（LoRA）。我们的方法，即NoRA（LoRA与Nyström初始化），在大型语言模型和扩散模型中，从10亿到70亿参数的各种下游任务和模型规模上表现出优越的性能。",
    "user_summary": "这项工作重新审视了经典的低秩矩阵分解问题，并揭示了初始化在塑造此类非凸且非光滑优化问题的收敛速度方面的重要作用。我们引入了Nyström初始化方法，它显著提高了对称和非对称矩阵分解任务中规模化梯度下降（ScaledGD）的全局收敛性。具体来说，我们证明了带有Nyström初始化的ScaledGD在之前只知道线性收敛率的情况下实现了二次收敛。此外，我们将这种初始化方法扩展到了常用于微调基础模型的低秩适配器（LoRA）。我们的方法，即NoRA（LoRA与Nyström初始化），在大型语言模型和扩散模型中，从10亿到70亿参数的各种下游任务和模型规模上表现出优越的性能。",
    "keywords": [
        "矩阵分解",
        "优化问题",
        "初始",
        "区间",
        "收敛性",
        "Nyström初始化",
        "ScaledGD",
        "二次收敛",
        "LoRA",
        "NoRA",
        "低秩适配器",
        "大规模语言模型",
        "扩散模型",
        "参数",
        "下游任务"
    ],
    "timestamp": "2024-10-27T05:14:11.701753"
}