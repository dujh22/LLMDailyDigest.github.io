{
    "link": "http://arxiv.org/abs/2410.18912v1",
    "title": "基于图神经动力学模型的动态3D高斯跟踪",
    "summary": "视频中的机器人与物体交互记录了丰富的物体动力学信息。然而，现有的视频预测方法通常并未显式地考虑来自视频的3D信息，如机器人的动作和物体的3D状态，这限制了它们在现实世界机器人应用中的效用。在本工作中，我们提出了一种框架，通过显式考虑机器人的动作轨迹及其对场景动力学的影响，直接从多视角RGB视频中学习物体动力学。我们利用3D高斯积聚（3DGS）的3D高斯表示来训练一个基于图神经网络的粒子动力学模型。该模型在从密集跟踪的3D高斯重建中下采样的稀疏控制粒子上运行。通过在离线机器人交互数据上学习神经动力学模型，我们的方法可以预测在不同初始配置和未见过的机器人动作下的物体运动。通过控制粒子运动的插值，可以推断出高斯体的3D变换，从而实现预测未来物体状态的渲染和条件于动作的视频预测。动力学模型也可应用于基于模型的规划框架，以解决物体操纵任务。我们在包括绳子、衣物和填充玩具在内的各种可变形材料上进行了实验，展示了我们的框架建模复杂形状和动力学的能力。我们的项目页面可在https://gs-dynamics.github.io访问。",
    "user_summary": "视频中的机器人与物体交互记录了丰富的物体动力学信息。然而，现有的视频预测方法通常并未显式地考虑来自视频的3D信息，如机器人的动作和物体的3D状态，这限制了它们在现实世界机器人应用中的效用。在本工作中，我们提出了一种框架，通过显式考虑机器人的动作轨迹及其对场景动力学的影响，直接从多视角RGB视频中学习物体动力学。我们利用3D高斯积聚（3DGS）的3D高斯表示来训练一个基于图神经网络的粒子动力学模型。该模型在从密集跟踪的3D高斯重建中下采样的稀疏控制粒子上运行。通过在离线机器人交互数据上学习神经动力学模型，我们的方法可以预测在不同初始配置和未见过的机器人动作下的物体运动。通过控制粒子运动的插值，可以推断出高斯体的3D变换，从而实现预测未来物体状态的渲染和条件于动作的视频预测。动力学模型也可应用于基于模型的规划框架，以解决物体操纵任务。我们在包括绳子、衣物和填充玩具在内的各种可变形材料上进行了实验，展示了我们的框架建模复杂形状和动力学的能力。我们的项目页面可在https://gs-dynamics.github.io访问。",
    "keywords": [
        "视频预测",
        "3D信息",
        "机器人交互",
        "物体动力学",
        "图神经网络",
        "粒子动力学模型",
        "3D高斯积聚",
        "动力学模型",
        "视频预测",
        "基于模型的规划",
        "可变形材料"
    ],
    "timestamp": "2024-10-27T05:16:04.171824"
}