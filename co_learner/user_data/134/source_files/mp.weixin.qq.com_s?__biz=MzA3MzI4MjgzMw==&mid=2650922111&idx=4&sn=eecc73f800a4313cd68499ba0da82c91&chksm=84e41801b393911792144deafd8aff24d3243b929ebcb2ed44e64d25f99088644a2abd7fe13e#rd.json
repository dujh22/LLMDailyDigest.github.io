{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922111&idx=4&sn=eecc73f800a4313cd68499ba0da82c91&chksm=84e41801b393911792144deafd8aff24d3243b929ebcb2ed44e64d25f99088644a2abd7fe13e#rd",
    "title": "字节豆包、武大提出 CAL：通过视觉相关的 token 增强多模态对齐效果",
    "summary": "武汉大学、字节跳动豆包大模型团队和中国科学院大学的研究人员提出了一种基于对比学习的文本token筛选方法（CAL），用于改进视觉语言模型（VLM）的多模态对齐。当前VLM主要依赖大语言模型（LLM）微调，通过文本自回归进行模态对齐。CAL方法能识别与图像高度相关的文本token，加强它们在训练过程中的权重，从而实现更精确的对齐。该方法无需额外的预训练阶段，且在OCR和Caption benchmarks上表现出显著提升，增强了模型对噪声数据的抵抗力。实验表明，使用CAL的模型在各项基准测试中表现更优，并且具有更好的注意力分布和图像内容映射。",
    "user_summary": "武汉大学、字节跳动豆包大模型团队和中国科学院大学的研究人员提出了一种基于对比学习的文本token筛选方法（CAL），用于改进视觉语言模型（VLM）的多模态对齐。当前VLM主要依赖大语言模型（LLM）微调，通过文本自回归进行模态对齐。CAL方法能识别与图像高度相关的文本token，加强它们在训练过程中的权重，从而实现更精确的对齐。该方法无需额外的预训练阶段，且在OCR和Caption benchmarks上表现出显著提升，增强了模型对噪声数据的抵抗力。实验表明，使用CAL的模型在各项基准测试中表现更优，并且具有更好的注意力分布和图像内容映射。",
    "keywords": [
        "武汉大学",
        "字节跳动豆包大模型团队",
        "中国科学院大学",
        "对比学习",
        "文本token筛选方法",
        "CAL",
        "视觉语言模型",
        "VLM",
        "大语言模型",
        "LLM",
        "微调",
        "模态对齐",
        "图像相关性",
        "OCR",
        "Caption",
        "benchmarks",
        "噪声数据",
        "抵抗力",
        "实验",
        "表现",
        "注意力分布",
        "图像内容映射"
    ],
    "timestamp": "2024-10-27T07:32:00.128506"
}