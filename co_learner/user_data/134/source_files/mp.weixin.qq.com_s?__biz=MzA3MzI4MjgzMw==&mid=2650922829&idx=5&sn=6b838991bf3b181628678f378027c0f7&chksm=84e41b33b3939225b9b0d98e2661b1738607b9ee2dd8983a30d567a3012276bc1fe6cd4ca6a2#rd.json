{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922829&idx=5&sn=6b838991bf3b181628678f378027c0f7&chksm=84e41b33b3939225b9b0d98e2661b1738607b9ee2dd8983a30d567a3012276bc1fe6cd4ca6a2#rd",
    "title": "ShareGPT4V作者团队又一力作！百万高质量视频-字幕数据助力社区提升多模态大模型视频理解及生成能力",
    "summary": "来自中国科学技术大学、北京大学和上海 AI Lab 的研究人员发布了 ShareGPT4Video 系列，旨在提升视频理解和生成能力。该研究基于高质量的 ShareGPT4V 数据集，通过一种称为差分滑窗视频描述 (DiffSW) 的策略，为任意分辨率、宽高比和长度的视频生成高质量描述。研究者们创建了大型“视频-文本描述”数据集 ShareGPT4Video，包含4万条（291小时）由GPT-4V标注的视频数据，以及一个多功能多模态大模型ShareCaptioner-Video，用于视频描述生成。实验表明，ShareGPT4Video 数据集的使用可以显著提高视频理解模型的性能，并且详细的字幕数据对文生视频模型的视频生成质量有显著提升。",
    "user_summary": "来自中国科学技术大学、北京大学和上海 AI Lab 的研究人员发布了 ShareGPT4Video 系列，旨在提升视频理解和生成能力。该研究基于高质量的 ShareGPT4V 数据集，通过一种称为差分滑窗视频描述 (DiffSW) 的策略，为任意分辨率、宽高比和长度的视频生成高质量描述。研究者们创建了大型“视频-文本描述”数据集 ShareGPT4Video，包含4万条（291小时）由GPT-4V标注的视频数据，以及一个多功能多模态大模型ShareCaptioner-Video，用于视频描述生成。实验表明，ShareGPT4Video 数据集的使用可以显著提高视频理解模型的性能，并且详细的字幕数据对文生视频模型的视频生成质量有显著提升。",
    "keywords": [
        "ShareGPT4Video",
        "数据集",
        "视频理解",
        "生成能力",
        "高质量描述",
        "DiffSW",
        "视频-文本描述",
        "GPT-4V",
        "ShareCaptioner-Video",
        "视频生成",
        "实验",
        "表明",
        "性能",
        "提升",
        "字幕",
        "数据",
        "文生视频",
        "模型"
    ],
    "timestamp": "2024-10-27T07:31:23.104151"
}