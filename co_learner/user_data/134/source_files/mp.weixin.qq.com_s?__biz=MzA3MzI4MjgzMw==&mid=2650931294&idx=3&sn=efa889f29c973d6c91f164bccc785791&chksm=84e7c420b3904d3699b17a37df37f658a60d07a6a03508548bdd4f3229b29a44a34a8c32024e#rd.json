{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931294&idx=3&sn=efa889f29c973d6c91f164bccc785791&chksm=84e7c420b3904d3699b17a37df37f658a60d07a6a03508548bdd4f3229b29a44a34a8c32024e#rd",
    "title": "明确了：文本数据中加点代码，训练出的大模型更强、更通用",
    "summary": "这篇论文研究了代码数据对通用大语言模型（LLM）性能的影响。研究者发现，代码数据对非代码任务，如自然语言推理和世界知识任务，也有显著的正向影响。预训练中使用代码可以提升模型的自然语言推理能力8.2%，世界知识理解能力4.2%，代码生成能力提升12倍。代码质量和属性也至关重要，使用高质量的合成代码数据可以进一步提高性能。在预训练的冷却阶段继续使用代码数据，所有任务的性能都会得到改善。这些发现强调了代码在大语言模型泛化能力中的关键作用，并提供了优化模型性能的指导。",
    "user_summary": "这篇论文研究了代码数据对通用大语言模型（LLM）性能的影响。研究者发现，代码数据对非代码任务，如自然语言推理和世界知识任务，也有显著的正向影响。预训练中使用代码可以提升模型的自然语言推理能力8.2%，世界知识理解能力4.2%，代码生成能力提升12倍。代码质量和属性也至关重要，使用高质量的合成代码数据可以进一步提高性能。在预训练的冷却阶段继续使用代码数据，所有任务的性能都会得到改善。这些发现强调了代码在大语言模型泛化能力中的关键作用，并提供了优化模型性能的指导。",
    "keywords": [
        "代码数据",
        "通用大语言模型",
        "LLM",
        "性能",
        "自然语言推理",
        "世界知识任务",
        "提升",
        "预训练",
        "代码生成",
        "高质量",
        "合成代码",
        "数据",
        "泛化能力",
        "模型性能"
    ],
    "timestamp": "2024-10-27T07:17:45.223554"
}