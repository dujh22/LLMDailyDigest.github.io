{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926863&idx=4&sn=2cd49bf5de146bd8afed19675d1ee8cc&chksm=84e42b71b393a26761f12092b12a6e39ab4ac9f752cc975ffdabaad4aef401ec9879ad81b098#rd",
    "title": "华为GTS LocMoE+：高可扩展性亲和度 MoE 架构，低开销实现主动路由",
    "summary": "华为GTS AI计算Lab的研究团队提出了一种新的MoE（Mixture of Experts）架构，名为LocMoE+，旨在提高大语言模型的训练效率。LocMoE+结合了传统的被动路由与低开销的主动路由策略，通过定义和量化专家与token之间的亲和性，实现更有效的token分派，从而提升训练效率。论文表明，这种自适应的双向路由分派机制可以在不牺牲模型效果的情况下，减少每个专家处理的token数量，提高训练效率，并减少显存占用。实验结果在昇腾910B3 NPU集群上得出，LocMoE+在不同规模的集群中平均提高了5.4%至46.6%的训练效率，并在通用知识和领域知识的评测集中展现出良好的性能提升。",
    "user_summary": "华为GTS AI计算Lab的研究团队提出了一种新的MoE（Mixture of Experts）架构，名为LocMoE+，旨在提高大语言模型的训练效率。LocMoE+结合了传统的被动路由与低开销的主动路由策略，通过定义和量化专家与token之间的亲和性，实现更有效的token分派，从而提升训练效率。论文表明，这种自适应的双向路由分派机制可以在不牺牲模型效果的情况下，减少每个专家处理的token数量，提高训练效率，并减少显存占用。实验结果在昇腾910B3 NPU集群上得出，LocMoE+在不同规模的集群中平均提高了5.4%至46.6%的训练效率，并在通用知识和领域知识的评测集中展现出良好的性能提升。",
    "keywords": [
        "华为",
        "GTS",
        "AI",
        "计算Lab",
        "MoE",
        "LocMoE+",
        "大语言模型",
        "训练效率",
        "路由",
        "主动路由",
        "专家",
        "token",
        "亲和性",
        "分派",
        "训练效率",
        "显存占用",
        "实验",
        "昇腾910B3",
        "NPU",
        "集群",
        "效率",
        "提升",
        "性能"
    ],
    "timestamp": "2024-10-27T07:24:56.588400"
}