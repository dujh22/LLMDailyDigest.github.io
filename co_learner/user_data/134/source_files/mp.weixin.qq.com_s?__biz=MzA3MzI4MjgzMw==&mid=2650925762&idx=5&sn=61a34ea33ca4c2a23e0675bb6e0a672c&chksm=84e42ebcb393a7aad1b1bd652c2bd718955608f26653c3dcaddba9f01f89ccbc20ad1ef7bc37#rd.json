{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925762&idx=5&sn=61a34ea33ca4c2a23e0675bb6e0a672c&chksm=84e42ebcb393a7aad1b1bd652c2bd718955608f26653c3dcaddba9f01f89ccbc20ad1ef7bc37#rd",
    "title": "CVPR'24 Highlight｜一个框架搞定人物动作生成，精细到手部运动",
    "summary": "北京大学和北京通用人工智能研究院的研究人员提出了一种使用自回归条件扩散模型的动作生成框架，该框架能生成符合场景约束、具有语义的真实人物动作。研究中还发布了大规模人物-场景交互数据集TRUMANS，包含15小时的动作数据和详细的场景与动作标注。这一方法考虑了场景和动作类别作为条件，解决了现有工作对场景约束处理不足的问题。通过空间占有网格和局部场景感知器，模型能生成符合路径和物体交互要求的动作。实验表明，这种方法在生成多样性和场景适应性方面表现出色。",
    "user_summary": "北京大学和北京通用人工智能研究院的研究人员提出了一种使用自回归条件扩散模型的动作生成框架，该框架能生成符合场景约束、具有语义的真实人物动作。研究中还发布了大规模人物-场景交互数据集TRUMANS，包含15小时的动作数据和详细的场景与动作标注。这一方法考虑了场景和动作类别作为条件，解决了现有工作对场景约束处理不足的问题。通过空间占有网格和局部场景感知器，模型能生成符合路径和物体交互要求的动作。实验表明，这种方法在生成多样性和场景适应性方面表现出色。",
    "keywords": [
        "北京大学",
        "北京通用人工智能研究院",
        "动作生成",
        "自回归条件扩散模型",
        "场景约束",
        "语义",
        "实际人物",
        "动作",
        "数据集",
        "TRUMANS",
        "大规模",
        "人物-场景",
        "交互",
        "15小时",
        "动作数据",
        "场景",
        "动作标注",
        "现有工作",
        "场景约束",
        "处理",
        "不足",
        "空间",
        "占有",
        "网格",
        "局部",
        "场景",
        "感知器",
        "模型",
        "路径",
        "物体",
        "交互",
        "生成",
        "多样性",
        "场景适应性"
    ],
    "timestamp": "2024-10-27T07:26:47.942524"
}