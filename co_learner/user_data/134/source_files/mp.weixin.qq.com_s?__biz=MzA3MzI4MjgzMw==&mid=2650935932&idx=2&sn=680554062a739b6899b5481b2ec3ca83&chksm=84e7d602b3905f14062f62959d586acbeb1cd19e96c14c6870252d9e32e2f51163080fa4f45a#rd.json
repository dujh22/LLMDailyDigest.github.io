{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935932&idx=2&sn=680554062a739b6899b5481b2ec3ca83&chksm=84e7d602b3905f14062f62959d586acbeb1cd19e96c14c6870252d9e32e2f51163080fa4f45a#rd",
    "title": "斯坦福新作：无指令调优的指令遵循",
    "summary": "斯坦福大学的研究者发现，通过对模型的响应进行微调（响应调优）而不是显式地进行指令调优，也可以实现指令跟随。响应调优模型在AlpacaEval 2上的评估显示，与指令调优模型相比，有43%的胜率。此外，仅对单任务、窄域数据进行微调，如诗歌生成或Python代码生成，也能产生广泛的指令遵循行为。这些发现表明，即使适应方法不是专门设计来实现指令跟随，也可能隐式地产生这种行为。",
    "user_summary": "斯坦福大学的研究者发现，通过对模型的响应进行微调（响应调优）而不是显式地进行指令调优，也可以实现指令跟随。响应调优模型在AlpacaEval 2上的评估显示，与指令调优模型相比，有43%的胜率。此外，仅对单任务、窄域数据进行微调，如诗歌生成或Python代码生成，也能产生广泛的指令遵循行为。这些发现表明，即使适应方法不是专门设计来实现指令跟随，也可能隐式地产生这种行为。",
    "keywords": [
        "斯坦福大学",
        "研究者",
        "模型",
        "响应调优",
        "指令调优",
        "AlpacaEval",
        "2",
        "胜率",
        "诗歌生成",
        "Python代码生成",
        "指令跟随",
        "适应方法"
    ],
    "timestamp": "2024-10-27T07:11:08.736413"
}