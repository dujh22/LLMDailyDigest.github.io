{
    "link": "http://arxiv.org/abs/2410.18824v1",
    "title": "PSY：基于后验采样的大型语言模型隐私增强器",
    "summary": "大型语言模型（LLMs）的隐私漏洞，如因记忆而产生的信息泄露，一直被不断发现，因此已经提出了各种缓解措施。LoRA通常用于LLMs的微调，是插入隐私增强模块的良好入口。在这一持续进行的研究中，我们引入了基于后验采样的隐私增强器PSY，它可以与LoRA一起使用。我们提出了一种简单但有效的PSY实现方法，即使用后验采样，它能有效防止中间信息的隐私泄露，从而保护数据所有者的隐私。我们评估了结合PSY的LoRA对抗最先进的成员推理攻击和数据提取攻击。实验在使用LoRA微调的三个不同的LLM架构和三个数据集上进行。与常用的差分隐私方法相比，我们发现我们的提议修改一致地降低了攻击成功率。同时，我们的方法几乎对模型微调或最终性能没有负面影响。最重要的是，PSY为利用潜在空间扩展增强隐私提供了一条有前途的途径。",
    "user_summary": "大型语言模型（LLMs）的隐私漏洞，如因记忆而产生的信息泄露，一直被不断发现，因此已经提出了各种缓解措施。LoRA通常用于LLMs的微调，是插入隐私增强模块的良好入口。在这一持续进行的研究中，我们引入了基于后验采样的隐私增强器PSY，它可以与LoRA一起使用。我们提出了一种简单但有效的PSY实现方法，即使用后验采样，它能有效防止中间信息的隐私泄露，从而保护数据所有者的隐私。我们评估了结合PSY的LoRA对抗最先进的成员推理攻击和数据提取攻击。实验在使用LoRA微调的三个不同的LLM架构和三个数据集上进行。与常用的差分隐私方法相比，我们发现我们的提议修改一致地降低了攻击成功率。同时，我们的方法几乎对模型微调或最终性能没有负面影响。最重要的是，PSY为利用潜在空间扩展增强隐私提供了一条有前途的途径。",
    "keywords": [
        "LLMs",
        "大型语言模型",
        "LoRA",
        "隐私漏洞",
        "信息泄露",
        "隐私增强模块",
        "后验采样",
        "PSY",
        "微调",
        "成员推理攻击",
        "数据提取攻击",
        "差分隐私",
        "方法",
        "实验",
        "架构",
        "数据集",
        "性能",
        "潜在空间",
        "扩展"
    ],
    "timestamp": "2024-10-27T05:18:38.425510"
}