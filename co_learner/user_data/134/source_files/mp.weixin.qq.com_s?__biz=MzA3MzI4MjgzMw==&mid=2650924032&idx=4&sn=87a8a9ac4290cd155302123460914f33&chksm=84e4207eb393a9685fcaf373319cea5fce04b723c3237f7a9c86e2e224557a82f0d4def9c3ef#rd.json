{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924032&idx=4&sn=87a8a9ac4290cd155302123460914f33&chksm=84e4207eb393a9685fcaf373319cea5fce04b723c3237f7a9c86e2e224557a82f0d4def9c3ef#rd",
    "title": "ICML 2024｜Transformer究竟如何推理？基于样例还是基于规则",
    "summary": "这篇论文来自北京大学的研究团队，研究了Transformer模型在处理数学推理问题时采用的推理机制，是基于规则（rule-based reasoning）还是基于样例（case-based reasoning）。研究发现，Transformer模型在解决数学问题时倾向于使用case-based reasoning，依赖于训练数据中的相似样例，而难以实现系统性的泛化。通过Leave-Square-Out方法的实验，证明了模型在没有见过的相似样例时性能下降。此外，尽管使用Scratchpad可以部分改善模型的推理行为，但模型仍未能完全转向rule-based reasoning。为此，研究者提出了Rule-Following Fine-Tuning（RFFT）方法，旨在教Transformer进行rule-based reasoning，实验表明RFFT在增强模型的长度泛化能力方面表现出色。",
    "user_summary": "这篇论文来自北京大学的研究团队，研究了Transformer模型在处理数学推理问题时采用的推理机制，是基于规则（rule-based reasoning）还是基于样例（case-based reasoning）。研究发现，Transformer模型在解决数学问题时倾向于使用case-based reasoning，依赖于训练数据中的相似样例，而难以实现系统性的泛化。通过Leave-Square-Out方法的实验，证明了模型在没有见过的相似样例时性能下降。此外，尽管使用Scratchpad可以部分改善模型的推理行为，但模型仍未能完全转向rule-based reasoning。为此，研究者提出了Rule-Following Fine-Tuning（RFFT）方法，旨在教Transformer进行rule-based reasoning，实验表明RFFT在增强模型的长度泛化能力方面表现出色。",
    "keywords": [
        "Transformer",
        "研究团队",
        "北京大学",
        "数学推理",
        "rule-based",
        "reasoning",
        "case-based",
        "reasoning",
        "模型",
        "训练数据",
        "相似样例",
        "系统性",
        "泛化",
        "Leave-Square-Out",
        "方法",
        "性能",
        "下降",
        "Scratchpad",
        "推理行为",
        "rule-based",
        "reasoning",
        "Rule-Following",
        "Fine-Tuning",
        "(RFFT)",
        "长度泛化能力"
    ],
    "timestamp": "2024-10-27T07:29:22.662266"
}