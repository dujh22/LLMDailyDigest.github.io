{
    "link": "http://arxiv.org/abs/2410.18889v1",
    "title": "LLMs是否比报告的更好？检测标签错误并减轻其对模型性能的影响",
    "summary": "自然语言处理（NLP）基准依赖于标准化的数据集来训练和评估模型，这对于推动该领域的发展至关重要。传统上，专家注解确保了高质量的标签，但专家注解的成本并不随着现代模型所需更大规模数据集需求的增长而良好扩展。虽然众包提供了一种更可扩展的解决方案，但它常常以牺牲注解的精确度和一致性为代价。近年来，大型语言模型（LLMs）的进步为增强注解过程，特别是检测现有数据集中标签错误提供了新的机会。在这项工作中，我们考虑了最近的LLM-as-a-judge方法，利用LLM的集合来标记可能被错误标记的示例。通过TRUE基准中的四个涵盖不同任务和领域的数据集的案例研究，我们实证分析了现有数据集的标签质量，并在一致性和标签质量以及效率方面比较了专家、众包和我们基于LLM的注解，展示了每种注解方法的优点和局限性。我们的发现揭示了大量的标签错误，当这些错误被纠正后，会导致报告的模型性能显著提升。这表明，许多LLM所谓的错误实际上是由标签错误引起的，而不是真正的模型失效。此外，我们讨论了错误标签数据的影响，并提出在训练中缓解这些错误的方法以提高模型性能。",
    "user_summary": "自然语言处理（NLP）基准依赖于标准化的数据集来训练和评估模型，这对于推动该领域的发展至关重要。传统上，专家注解确保了高质量的标签，但专家注解的成本并不随着现代模型所需更大规模数据集需求的增长而良好扩展。虽然众包提供了一种更可扩展的解决方案，但它常常以牺牲注解的精确度和一致性为代价。近年来，大型语言模型（LLMs）的进步为增强注解过程，特别是检测现有数据集中标签错误提供了新的机会。在这项工作中，我们考虑了最近的LLM-as-a-judge方法，利用LLM的集合来标记可能被错误标记的示例。通过TRUE基准中的四个涵盖不同任务和领域的数据集的案例研究，我们实证分析了现有数据集的标签质量，并在一致性和标签质量以及效率方面比较了专家、众包和我们基于LLM的注解，展示了每种注解方法的优点和局限性。我们的发现揭示了大量的标签错误，当这些错误被纠正后，会导致报告的模型性能显著提升。这表明，许多LLM所谓的错误实际上是由标签错误引起的，而不是真正的模型失效。此外，我们讨论了错误标签数据的影响，并提出在训练中缓解这些错误的方法以提高模型性能。",
    "keywords": [
        "自然语言处理",
        "NLP",
        "基准",
        "数据集",
        "标签",
        "专家",
        "注解",
        "众包",
        "大规模",
        "数据集",
        "进展",
        "模型",
        "LLMs",
        "语言模型",
        "错误检测",
        "TRUE",
        "任务",
        "领域",
        "标签质量",
        "一致",
        "性",
        "效率",
        "专家",
        "众包",
        "LLM",
        "注解",
        "模型性能",
        "错误",
        "纠正",
        "性能",
        "提升",
        "模型",
        "失效",
        "错误标签",
        "数据",
        "训练",
        "改进",
        "性能"
    ],
    "timestamp": "2024-10-27T05:16:38.924392"
}