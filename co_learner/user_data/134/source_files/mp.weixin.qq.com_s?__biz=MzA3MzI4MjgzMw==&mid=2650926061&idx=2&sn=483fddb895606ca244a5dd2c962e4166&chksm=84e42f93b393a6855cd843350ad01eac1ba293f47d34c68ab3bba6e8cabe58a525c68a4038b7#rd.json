{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926061&idx=2&sn=483fddb895606ca244a5dd2c962e4166&chksm=84e42f93b393a6855cd843350ad01eac1ba293f47d34c68ab3bba6e8cabe58a525c68a4038b7#rd",
    "title": "OpenAI Lilian Weng万字长文解读LLM幻觉：从理解到克服",
    "summary": "这篇博文介绍了大型语言模型（LLM）在生成内容时可能出现的“幻觉”问题，即模型生成不真实、虚构或不一致的信息。幻觉分为上下文幻觉和外源性幻觉。文章探讨了幻觉产生的原因，包括预训练数据的问题和微调阶段引入的新知识，以及检测和克服幻觉的方法，如检索增强式评估、事实性检测、采样方法等。此外，文章还提到了针对模型进行校准和微调以减少幻觉的方法，如RAG、编辑和归因动作链等。最后，文中列举了一些相关的评估基准，用于衡量模型的事实性和幻觉行为。",
    "user_summary": "这篇博文介绍了大型语言模型（LLM）在生成内容时可能出现的“幻觉”问题，即模型生成不真实、虚构或不一致的信息。幻觉分为上下文幻觉和外源性幻觉。文章探讨了幻觉产生的原因，包括预训练数据的问题和微调阶段引入的新知识，以及检测和克服幻觉的方法，如检索增强式评估、事实性检测、采样方法等。此外，文章还提到了针对模型进行校准和微调以减少幻觉的方法，如RAG、编辑和归因动作链等。最后，文中列举了一些相关的评估基准，用于衡量模型的事实性和幻觉行为。",
    "keywords": [
        "大型语言模型",
        "LLM",
        "幻觉问题",
        "上下文幻觉",
        "外源性幻觉",
        "预训练数据",
        "微调",
        "事实性检测",
        "采样方法",
        "检索增强式评估",
        "校准",
        "微调",
        "RAG",
        "编辑",
        "归因动作链",
        "评估基准",
        "事实性",
        "幻觉行为"
    ],
    "timestamp": "2024-10-27T07:26:12.480184"
}