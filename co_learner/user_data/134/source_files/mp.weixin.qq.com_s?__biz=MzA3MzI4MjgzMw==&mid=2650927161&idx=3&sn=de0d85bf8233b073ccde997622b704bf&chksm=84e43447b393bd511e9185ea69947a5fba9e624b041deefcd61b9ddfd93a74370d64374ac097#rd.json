{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927161&idx=3&sn=de0d85bf8233b073ccde997622b704bf&chksm=84e43447b393bd511e9185ea69947a5fba9e624b041deefcd61b9ddfd93a74370d64374ac097#rd",
    "title": "真相了！大模型解数学题和人类真不一样：死记硬背、知识欠缺明显，GPT-4o表现最佳",
    "summary": "本文介绍了We-Math，一个用于评估大型多模态模型（LMMs）在数学推理任务中的新基准。We-Math包含6.5k个多模态小学数学问题和一个基于67个原子知识点的知识体系。研究人员通过拆分复杂问题为子问题来研究模型的推理过程，并引入了四维度量标准（知识掌握不足、泛化能力不足、完全掌握和死记硬背）来评估模型性能。实验表明，LMMs在涉及多个知识点的问题中表现较差，且存在“知识掌握不足”和“死记硬背”的问题，而GPT-4o在这些方面表现相对较好。此外，研究还提出了KCA策略来缓解模型的某些问题。",
    "user_summary": "本文介绍了We-Math，一个用于评估大型多模态模型（LMMs）在数学推理任务中的新基准。We-Math包含6.5k个多模态小学数学问题和一个基于67个原子知识点的知识体系。研究人员通过拆分复杂问题为子问题来研究模型的推理过程，并引入了四维度量标准（知识掌握不足、泛化能力不足、完全掌握和死记硬背）来评估模型性能。实验表明，LMMs在涉及多个知识点的问题中表现较差，且存在“知识掌握不足”和“死记硬背”的问题，而GPT-4o在这些方面表现相对较好。此外，研究还提出了KCA策略来缓解模型的某些问题。",
    "keywords": [
        "We-Math",
        "LMMs",
        "数学推理",
        "基准",
        "多模态",
        "小学数学",
        "问题",
        "知识体系",
        "原子知识点",
        "推理过程",
        "四维度量",
        "标准",
        "知识掌握",
        "泛化",
        "完全掌握",
        "死记硬背",
        "GPT-4o",
        "KCA",
        "策略"
    ],
    "timestamp": "2024-10-27T07:24:05.171320"
}