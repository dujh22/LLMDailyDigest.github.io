{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919048&idx=4&sn=7a2966b882bf11c1bce687a541712741&chksm=84e414f6b3939de0fcf8797efce7f42630af0bc1f20692b8a51e0d0d6cea070ea34a9a4dd30f#rd",
    "title": "从80个模型中构建Scaling Law：华人博士生新作，思维链提出者力荐",
    "summary": "研究人员提出了一种新的方法，称为可观察的扩展定律（Observational Scaling Laws），用于理解语言模型（LM）的性能如何随规模变化，而无需从头开始构建扩展法则。这一方法利用大约 80 个公开可用的模型，建立起 LM 功能与下游性能之间的关系，绕过了模型训练的计算资源限制。研究发现，LM 的性能可以表示为低维度能力空间的函数，不同模型系列在将训练计算转换为能力的效率上有所差异。通过这种方法，研究者能够预测模型的涌现能力、智能体性能和后训练干预措施的效果，例如思维链（Chain-of-Thought）。这种方法成本低且预测准确，有助于扩展研究，并预注册了对未来模型的预测以验证其有效性。",
    "user_summary": "研究人员提出了一种新的方法，称为可观察的扩展定律（Observational Scaling Laws），用于理解语言模型（LM）的性能如何随规模变化，而无需从头开始构建扩展法则。这一方法利用大约 80 个公开可用的模型，建立起 LM 功能与下游性能之间的关系，绕过了模型训练的计算资源限制。研究发现，LM 的性能可以表示为低维度能力空间的函数，不同模型系列在将训练计算转换为能力的效率上有所差异。通过这种方法，研究者能够预测模型的涌现能力、智能体性能和后训练干预措施的效果，例如思维链（Chain-of-Thought）。这种方法成本低且预测准确，有助于扩展研究，并预注册了对未来模型的预测以验证其有效性。",
    "keywords": [
        "语言模型",
        "可观察的扩展定律",
        "规模",
        "性能",
        "下游任务",
        "计算资源",
        "低维度能力空间",
        "模型系列",
        "思维链",
        "预测",
        "研究"
    ],
    "timestamp": "2024-10-27T07:38:27.188084"
}