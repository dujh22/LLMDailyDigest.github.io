{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926719&idx=5&sn=25ffef042b1b5b8578ee903cb41e4362&chksm=84e42a01b393a317f45ffa1bbbb8785ba1738464bf4981e555d4a3812d590aa018cef7235bdb#rd",
    "title": "ACL 2024 | 对25个开闭源模型数学评测，GPT-3.5-Turbo才勉强及格",
    "summary": "研究人员设计了一个新的基准测试GSM-Plus，用于评估大型语言模型（LLMs）在解决基础数学应用题时的鲁棒性。尽管LLMs在一些数学推理基准测试中表现出色，但GSM-Plus的实验结果显示，即使是在GSM8K上表现优秀的GPT-3.5-Turbo，在GSM-Plus上的准确率也大幅下降。这项工作揭示了LLMs在处理数学问题时的局限性，尤其是在面对数值变化、算术变化和干扰项插入等扰动时。研究表明，尽管任务特定的优化可以提高准确性，但模型的鲁棒性更多地取决于基础模型和微调数据集的选择。现有的提示技术对于增强鲁棒性的效果有限，且LLMs在解决需要批判性思维的问题时表现较弱。",
    "user_summary": "研究人员设计了一个新的基准测试GSM-Plus，用于评估大型语言模型（LLMs）在解决基础数学应用题时的鲁棒性。尽管LLMs在一些数学推理基准测试中表现出色，但GSM-Plus的实验结果显示，即使是在GSM8K上表现优秀的GPT-3.5-Turbo，在GSM-Plus上的准确率也大幅下降。这项工作揭示了LLMs在处理数学问题时的局限性，尤其是在面对数值变化、算术变化和干扰项插入等扰动时。研究表明，尽管任务特定的优化可以提高准确性，但模型的鲁棒性更多地取决于基础模型和微调数据集的选择。现有的提示技术对于增强鲁棒性的效果有限，且LLMs在解决需要批判性思维的问题时表现较弱。",
    "keywords": [
        "GSM-Plus",
        "LLMs",
        "大型语言模型",
        "数学应用题",
        "鲁棒性",
        "GSM8K",
        "GPT-3.5-Turbo",
        "准确率",
        "数值变化",
        "算术变化",
        "干扰项",
        "插入",
        "任务特定优化",
        "基础模型",
        "微调数据集",
        "提示技术",
        "批判性思维"
    ],
    "timestamp": "2024-10-27T07:25:13.896380"
}