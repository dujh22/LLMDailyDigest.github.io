{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927761&idx=3&sn=bf9644c00fddfa2ea8e937465ced73c7&chksm=84e436efb393bff9dedc77a68970c57c020a120cbea5d5ff7d204e2bfad19f309e3cb9d21c60#rd",
    "title": "贾扬清点赞：3K star量的SGLang上新，加速Llama 405B推理秒杀vLLM、TensorRT-LLM",
    "summary": "LMSYS Org 团队推出了 SGLang Runtime v0.2，这是一个用于大型语言模型和视觉语言模型的通用服务引擎，旨在提高推理速度和效率。该引擎在运行 Llama 3.1 405B 模型时，表现优于 vLLM 和 TensorRT-LLM，在某些情况下吞吐量可达到 TensorRT-LLM 的 2.1 倍，vLLM 的 3.8 倍。SGLang 由纯 Python 编写，完全开源，并且具有高效的批处理调度器。该团队通过运营 Chatbot Arena 平台的经验，不断优化底层服务系统，SGLang Runtime 在处理不同大小的 Llama 模型和不同 GPU 上的表现均展现出优秀性能。",
    "user_summary": "LMSYS Org 团队推出了 SGLang Runtime v0.2，这是一个用于大型语言模型和视觉语言模型的通用服务引擎，旨在提高推理速度和效率。该引擎在运行 Llama 3.1 405B 模型时，表现优于 vLLM 和 TensorRT-LLM，在某些情况下吞吐量可达到 TensorRT-LLM 的 2.1 倍，vLLM 的 3.8 倍。SGLang 由纯 Python 编写，完全开源，并且具有高效的批处理调度器。该团队通过运营 Chatbot Arena 平台的经验，不断优化底层服务系统，SGLang Runtime 在处理不同大小的 Llama 模型和不同 GPU 上的表现均展现出优秀性能。",
    "keywords": [
        "LMSYS",
        "Org",
        "SGLang",
        "Runtime",
        "v0.2",
        "大型语言模型",
        "视觉语言模型",
        "推理速度",
        "效率",
        "Llama",
        "3.1",
        "405B",
        "vLLM",
        "TensorRT-LLM",
        "吞吐量",
        "Python",
        "开源",
        "批处理调度器",
        "Chatbot",
        "Arena",
        "平台",
        "Llama",
        "模型",
        "GPU",
        "性能"
    ],
    "timestamp": "2024-10-27T07:23:11.437126"
}