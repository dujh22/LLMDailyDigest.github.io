{
    "link": "http://arxiv.org/abs/2410.18870v1",
    "title": "基于语言的用户画像的端到端推荐系统训练",
    "summary": "许多在线平台为了个性化服务会维护用户的个人资料。然而，这些资料通常对用户来说不透明，也不易于修改。为了解决这一问题，我们探索了基于自然语言的用户资料，因为它们有望提高推荐系统的透明度和可审查性。尽管已有研究表明，使用标准语言大模型构建的语言资料可以有效，但这些通用的大模型可能并不适用于此任务。在本文中，我们提出了LangPTune，这是第一个端到端的学习方法，用于训练语言大模型生成优化推荐效果的语言用户资料。通过对LangPTune在不同训练配置和基准测试上的全面评估，我们证明了我们的方法显著优于现有的基于资料的方法。此外，它在性能上接近最先进的、不那么透明的推荐系统，为传统系统提供了一种稳健且可解释的替代方案。最后，我们通过众包用户研究和GPT-4为基础的评估，验证了这些基于语言的用户资料的相对可解释性。LangPTune的实现可以在https://github.com/ZhaolinGao/LangPTune找到。",
    "user_summary": "许多在线平台为了个性化服务会维护用户的个人资料。然而，这些资料通常对用户来说不透明，也不易于修改。为了解决这一问题，我们探索了基于自然语言的用户资料，因为它们有望提高推荐系统的透明度和可审查性。尽管已有研究表明，使用标准语言大模型构建的语言资料可以有效，但这些通用的大模型可能并不适用于此任务。在本文中，我们提出了LangPTune，这是第一个端到端的学习方法，用于训练语言大模型生成优化推荐效果的语言用户资料。通过对LangPTune在不同训练配置和基准测试上的全面评估，我们证明了我们的方法显著优于现有的基于资料的方法。此外，它在性能上接近最先进的、不那么透明的推荐系统，为传统系统提供了一种稳健且可解释的替代方案。最后，我们通过众包用户研究和GPT-4为基础的评估，验证了这些基于语言的用户资料的相对可解释性。LangPTune的实现可以在https://github.com/ZhaolinGao/LangPTune找到。",
    "keywords": [
        "用户资料",
        "透明度",
        "可审查性",
        "自然语言",
        "大模型",
        "优化",
        "推荐系统",
        "LangPTune",
        "终端",
        "学习方法",
        "评估",
        "性能",
        "可解释性",
        "众包",
        "研究",
        "GPT-4",
        "实现"
    ],
    "timestamp": "2024-10-27T05:17:14.629682"
}