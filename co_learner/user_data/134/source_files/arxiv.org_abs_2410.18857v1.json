{
    "link": "http://arxiv.org/abs/2410.18857v1",
    "title": "概率性语言-图像预训练",
    "summary": "视觉语言模型（VLMs）将对齐的图像-文本对嵌入到一个联合空间中，但通常依赖于确定性的嵌入，假设图像和文本之间存在一对一的对应关系。这过于简化了现实世界中固有的多对多关系，即一张图像可以用多个标题描述，反之亦然。我们引入了概率语言-图像预训练（ProLIP），这是第一个仅使用概率目标在十亿规模的图像-文本数据集上预训练的概率VLM，实现了强大的零样本能力（例如，ViT-B/16在ImageNet上的零样本准确率为74.6%）。ProLIP通过一个“不确定性标记”有效地估计不确定性，而无需额外参数。我们还提出了一种新颖的包含损失，以强制执行图像-文本对之间以及原始和被遮罩输入之间的分布包含关系。实验表明，通过利用不确定性估计，ProLIP使下游任务受益，并且与直观的不确定性概念对齐，例如，较短的文本具有更高的不确定性，更通用的输入包括特定的输入。利用文本不确定性，我们在ImageNet上的准确性从74.6%提高到75.8%（在少量样本设置下），这证明了我们概率方法的实际优势。代码可在https://github.com/naver-ai/prolip获取。",
    "user_summary": "视觉语言模型（VLMs）将对齐的图像-文本对嵌入到一个联合空间中，但通常依赖于确定性的嵌入，假设图像和文本之间存在一对一的对应关系。这过于简化了现实世界中固有的多对多关系，即一张图像可以用多个标题描述，反之亦然。我们引入了概率语言-图像预训练（ProLIP），这是第一个仅使用概率目标在十亿规模的图像-文本数据集上预训练的概率VLM，实现了强大的零样本能力（例如，ViT-B/16在ImageNet上的零样本准确率为74.6%）。ProLIP通过一个“不确定性标记”有效地估计不确定性，而无需额外参数。我们还提出了一种新颖的包含损失，以强制执行图像-文本对之间以及原始和被遮罩输入之间的分布包含关系。实验表明，通过利用不确定性估计，ProLIP使下游任务受益，并且与直观的不确定性概念对齐，例如，较短的文本具有更高的不确定性，更通用的输入包括特定的输入。利用文本不确定性，我们在ImageNet上的准确性从74.6%提高到75.8%（在少量样本设置下），这证明了我们概率方法的实际优势。代码可在https://github.com/naver-ai/prolip获取。",
    "keywords": [
        "概率语言-图像预训练",
        "ProLIP",
        "VLMs",
        "图像-文本",
        "对应关系",
        "一对一",
        "多对多",
        "零样本能力",
        "ImageNet",
        "准确率",
        "不确定性标记",
        "包含损失",
        "下游任务",
        "文本不确定性",
        "代码"
    ],
    "timestamp": "2024-10-27T05:17:45.313714"
}