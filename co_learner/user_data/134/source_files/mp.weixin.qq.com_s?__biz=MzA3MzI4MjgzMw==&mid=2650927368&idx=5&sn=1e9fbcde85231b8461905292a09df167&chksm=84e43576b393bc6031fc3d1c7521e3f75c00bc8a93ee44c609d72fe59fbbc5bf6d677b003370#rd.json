{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927368&idx=5&sn=1e9fbcde85231b8461905292a09df167&chksm=84e43576b393bc6031fc3d1c7521e3f75c00bc8a93ee44c609d72fe59fbbc5bf6d677b003370#rd",
    "title": "清华领衔发布多模态评估MultiTrust：GPT-4可信度有几何？",
    "summary": "这篇论文介绍了一个名为MultiTrust的综合基准，该基准首次全面评估了主流多模态大语言模型的可信度。由清华大学等机构的研究人员联合撰写的这篇百页长文，提出了五个可信评价维度：事实性、安全性、鲁棒性、公平性和隐私保护，并进一步构建了32个评估任务。研究发现，尽管多模态大模型在各种任务中表现出色，但它们存在安全风险，如对抗攻击、幻觉、偏见和隐私泄漏。文中还提到，闭源商用模型在安全可靠性上通常优于开源模型，但仍然存在脆弱性。此外，多模态训练可能会削弱大语言模型的安全对齐机制。该基准的发布旨在促进对多模态大模型可信性的深入理解和改进。",
    "user_summary": "这篇论文介绍了一个名为MultiTrust的综合基准，该基准首次全面评估了主流多模态大语言模型的可信度。由清华大学等机构的研究人员联合撰写的这篇百页长文，提出了五个可信评价维度：事实性、安全性、鲁棒性、公平性和隐私保护，并进一步构建了32个评估任务。研究发现，尽管多模态大模型在各种任务中表现出色，但它们存在安全风险，如对抗攻击、幻觉、偏见和隐私泄漏。文中还提到，闭源商用模型在安全可靠性上通常优于开源模型，但仍然存在脆弱性。此外，多模态训练可能会削弱大语言模型的安全对齐机制。该基准的发布旨在促进对多模态大模型可信性的深入理解和改进。",
    "keywords": [
        "MultiTrust",
        "清华大学",
        "多模态大语言模型",
        "可信度",
        "事实性",
        "安全性",
        "鲁棒性",
        "公平性",
        "隐私保护",
        "评估任务",
        "对抗攻击",
        "幻觉",
        "偏见",
        "隐私泄漏",
        "闭源商用模型",
        "开源模型",
        "安全可靠性",
        "多模态训练",
        "安全对齐机制"
    ],
    "timestamp": "2024-10-27T07:23:56.338112"
}