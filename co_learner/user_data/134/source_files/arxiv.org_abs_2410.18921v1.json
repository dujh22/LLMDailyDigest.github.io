{
    "link": "http://arxiv.org/abs/2410.18921v1",
    "title": "从盲目解题者到逻辑思考者：在错误数学问题上的大模型逻辑完整性基准测试",
    "summary": "思考一道数学题：“莉莉昨天从她最好的朋友那里收到了3块饼干，然后早餐吃了5块。今天，她的朋友又给了她3块饼干。现在莉莉有多少块饼干？”许多先前研究中的大型语言模型（LLMs）会通过计算“3 - 5 + 3”得出答案“1”。但是，从人的角度来看，我们能识别出这个问题的内在错误：如果莉莉最初只有3块饼干，她是不可能吃掉5块的。这个矛盾提出了一个关键问题：当前的LLMs仅仅是盲目解题器，只会应用数学运算而没有深入推理，还是它们能作为逻辑思考者，识别出逻辑不一致性？\n\n为了探究这个问题，我们提出了一个基准数据集，叫做FaultyMath，它包含了丰富多样性的错误数学问题：i) 多种数学类别，如代数、几何、数论等，ii) 不同难度级别，iii) 不同的错误来源——从违反常识和模糊陈述到数学矛盾等。我们使用FaultyMath从三个方面评估了广泛的LLMs，包括开源、闭源和专门针对数学的模型：(i) 模型在没有明确提示的情况下能多准确地检测出错误的数学问题？(ii) 当提供问题正确性或误导性的线索时，LLMs在多大程度上能转变为可靠的逻辑思考者？(iii) 当LLMs识别出数学问题有误时，它们生成的解释有多可信？通过广泛的实验和详细分析，我们的结果表明，现有的LLMs主要作为盲目解题器运作，缺乏作为逻辑思考者所需的推理能力。",
    "user_summary": "思考一道数学题：“莉莉昨天从她最好的朋友那里收到了3块饼干，然后早餐吃了5块。今天，她的朋友又给了她3块饼干。现在莉莉有多少块饼干？”许多先前研究中的大型语言模型（LLMs）会通过计算“3 - 5 + 3”得出答案“1”。但是，从人的角度来看，我们能识别出这个问题的内在错误：如果莉莉最初只有3块饼干，她是不可能吃掉5块的。这个矛盾提出了一个关键问题：当前的LLMs仅仅是盲目解题器，只会应用数学运算而没有深入推理，还是它们能作为逻辑思考者，识别出逻辑不一致性？\n\n为了探究这个问题，我们提出了一个基准数据集，叫做FaultyMath，它包含了丰富多样性的错误数学问题：i) 多种数学类别，如代数、几何、数论等，ii) 不同难度级别，iii) 不同的错误来源——从违反常识和模糊陈述到数学矛盾等。我们使用FaultyMath从三个方面评估了广泛的LLMs，包括开源、闭源和专门针对数学的模型：(i) 模型在没有明确提示的情况下能多准确地检测出错误的数学问题？(ii) 当提供问题正确性或误导性的线索时，LLMs在多大程度上能转变为可靠的逻辑思考者？(iii) 当LLMs识别出数学问题有误时，它们生成的解释有多可信？通过广泛的实验和详细分析，我们的结果表明，现有的LLMs主要作为盲目解题器运作，缺乏作为逻辑思考者所需的推理能力。",
    "keywords": [
        "",
        "FaultyMath",
        "LLMs",
        "数学问题",
        "逻辑不一致性",
        "错误检测",
        "常识",
        "迷糊陈述",
        "数学矛盾",
        "代数",
        "几何",
        "数论",
        "开源",
        "闭源",
        "误导性线索",
        "可靠的逻辑思考者",
        "解题器",
        "推理能力"
    ],
    "timestamp": "2024-10-27T05:15:49.575611"
}