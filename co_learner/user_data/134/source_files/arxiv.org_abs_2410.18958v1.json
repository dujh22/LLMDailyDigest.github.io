{
    "link": "http://arxiv.org/abs/2410.18958v1",
    "title": "稳定一致性调优：理解和提升一致性模型",
    "summary": "扩散模型在生成质量上表现出色，但因去噪的迭代特性而速度较慢。相比之下，一致性模型这一新兴的生成模型家族以显著更快的采样速度达到了竞争力的性能。这些模型可以通过一致性蒸馏（利用预训练的扩散模型）或直接从原始数据进行一致性训练/微调进行训练。在这项工作中，我们提出了一种新的框架，通过将扩散模型的去噪过程建模为马尔科夫决策过程（MDP）并将一致性模型训练表述为通过时间差分（TD）学习的价值估计，来理解一致性模型。更重要的是，这一框架使我们能够分析当前一致性训练/微调策略的局限性。基于简单的一致性微调（ECT），我们提出了稳定一致性微调（SCT），它利用得分恒等性引入了方差减少学习。SCT在CIFAR-10和ImageNet-64等基准测试中带来了显著的性能提升。在ImageNet-64上，SCT实现了1步FID 2.42和2步FID 1.55，这是一致性模型的新SOTA（State-of-the-Art）。",
    "user_summary": "扩散模型在生成质量上表现出色，但因去噪的迭代特性而速度较慢。相比之下，一致性模型这一新兴的生成模型家族以显著更快的采样速度达到了竞争力的性能。这些模型可以通过一致性蒸馏（利用预训练的扩散模型）或直接从原始数据进行一致性训练/微调进行训练。在这项工作中，我们提出了一种新的框架，通过将扩散模型的去噪过程建模为马尔科夫决策过程（MDP）并将一致性模型训练表述为通过时间差分（TD）学习的价值估计，来理解一致性模型。更重要的是，这一框架使我们能够分析当前一致性训练/微调策略的局限性。基于简单的一致性微调（ECT），我们提出了稳定一致性微调（SCT），它利用得分恒等性引入了方差减少学习。SCT在CIFAR-10和ImageNet-64等基准测试中带来了显著的性能提升。在ImageNet-64上，SCT实现了1步FID 2.42和2步FID 1.55，这是一致性模型的新SOTA（State-of-the-Art）。",
    "keywords": [
        "扩散模型",
        "一致性模型",
        "采样速度",
        "去噪",
        "迭代",
        "马尔科夫决策过程",
        "MDP",
        "价值估计",
        "一致性训练",
        "微调",
        "TD学习",
        "限制",
        "ECT",
        "SCT",
        "方差减少",
        "学习",
        "CIFAR-10",
        "ImageNet-64",
        "FID",
        "SOTA"
    ],
    "timestamp": "2024-10-27T05:14:20.227471"
}