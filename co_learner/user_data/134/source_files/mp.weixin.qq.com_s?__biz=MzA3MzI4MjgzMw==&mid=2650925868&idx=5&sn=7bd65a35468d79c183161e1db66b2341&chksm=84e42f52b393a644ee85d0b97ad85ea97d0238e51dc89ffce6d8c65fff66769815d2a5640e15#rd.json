{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925868&idx=5&sn=7bd65a35468d79c183161e1db66b2341&chksm=84e42f52b393a644ee85d0b97ad85ea97d0238e51dc89ffce6d8c65fff66769815d2a5640e15#rd",
    "title": "首个视频思维链推理框架Video-of-Thought来了：像人一样从感知到认知全面推理视频",
    "summary": "新加坡国立大学、南洋理工大学和哈工深的研究人员提出了一种新的视频推理框架，名为视频思维链（Video-of-Thought，VoT），该框架显著提升了视频多模态大语言模型在复杂视频理解与推理的能力。这一工作被ICML 2024录用为Oral paper。VoT受到人类理解视频方式的启发，强调了像素理解的感知能力和语义理解的认知能力，将视频推理分解为一系列子问题，通过时空场景图（Spatial-Temporal Scene Graph, STSG）辅助推理。实验结果显示，VoT在多个复杂VideoQA数据集上超越了当前所有传统视频MLLM以及CoT方法的表现，并在零样本设置下展现出更强的性能。此外， VoT的推理过程可解释性强，错误率较低，能适应复杂的视频理解和推理任务。",
    "user_summary": "新加坡国立大学、南洋理工大学和哈工深的研究人员提出了一种新的视频推理框架，名为视频思维链（Video-of-Thought，VoT），该框架显著提升了视频多模态大语言模型在复杂视频理解与推理的能力。这一工作被ICML 2024录用为Oral paper。VoT受到人类理解视频方式的启发，强调了像素理解的感知能力和语义理解的认知能力，将视频推理分解为一系列子问题，通过时空场景图（Spatial-Temporal Scene Graph, STSG）辅助推理。实验结果显示，VoT在多个复杂VideoQA数据集上超越了当前所有传统视频MLLM以及CoT方法的表现，并在零样本设置下展现出更强的性能。此外， VoT的推理过程可解释性强，错误率较低，能适应复杂的视频理解和推理任务。",
    "keywords": [
        "视频推理",
        "帧",
        "视频思维链",
        "VoT",
        "ICML",
        "2024",
        "口头报告",
        "像素理解",
        "语义理解",
        "时空场景图",
        "STSG",
        "VideoQA",
        "数据集",
        "可解释性",
        "错误率",
        "复杂任务"
    ],
    "timestamp": "2024-10-27T07:26:33.366493"
}