{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927761&idx=4&sn=5885e14205808b9593ef833fe5079a72&chksm=84e436efb393bff95bf805fdda70420dd76db8d8a45f70a2b21b65c965dcd14697beeb9c61c0#rd",
    "title": "万亿token！史上最大多模态数据集诞生",
    "summary": "研究人员构建了一个名为MINT-1T的开源多模态数据集，包含一万亿文本token和三十亿张图像，源自HTML、PDF和ArXiv等多种来源，是目前最大的开源多模态数据集。此前，最大的开源数据集OBELICS包含1150亿文本token和3.53亿张图像。MINT-1T的构建过程中执行了文本质量、图像、安全性和重复内容的过滤。实验表明，在MINT-1T上训练的多模态模型在视觉问答任务上表现出色，但在某些视觉描述任务上可能不如在OBELICS上训练的模型。这个大规模数据集的发布将可能促进开源多模态大模型的发展。",
    "user_summary": "研究人员构建了一个名为MINT-1T的开源多模态数据集，包含一万亿文本token和三十亿张图像，源自HTML、PDF和ArXiv等多种来源，是目前最大的开源多模态数据集。此前，最大的开源数据集OBELICS包含1150亿文本token和3.53亿张图像。MINT-1T的构建过程中执行了文本质量、图像、安全性和重复内容的过滤。实验表明，在MINT-1T上训练的多模态模型在视觉问答任务上表现出色，但在某些视觉描述任务上可能不如在OBELICS上训练的模型。这个大规模数据集的发布将可能促进开源多模态大模型的发展。",
    "keywords": [
        "MINT-1T",
        "数据集",
        "多模态",
        "开源",
        "文本",
        "token",
        "图像",
        "HTML",
        "PDF",
        "ArXiv",
        "OBELICS",
        "视觉问答",
        "任务",
        "训练",
        "模型",
        "发展"
    ],
    "timestamp": "2024-10-27T07:23:13.946103"
}