{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924319&idx=4&sn=b960170f9de3efbd4e1030325cb17058&chksm=84e42161b393a87784ff90b5c8d45e77d8a8b8b491d4b9a7cf65c643e5e724ee01320e7e844d#rd",
    "title": "神经网络可能不再需要激活函数？Layer Normalization也具有非线性表达！",
    "summary": "北京航空航天大学黄雷副教授团队的最新研究发现，层标准化（Layer Normalization, LN）和其计算退化版本RMSNorm具有非线性表达能力。这项研究打破了人们认为标准化层不能提升模型表达能力的观念。团队在ICML 2024上发表的论文《On the Nonlinearity of Layer Normalization》中提出，仅含线性层和LN的简单神经网络LN-Net在足够深的情况下，理论上可以任意分类给定的样本和样本类别。这一发现对于神经网络架构设计具有开创性意义，特别是在LN广泛应用于Transformer模型的背景下。论文证明了LN的非线性主要存在于尺度缩放操作中，并提出了分组层标准化技术（LN-G），在实验中展示了增强LN非线性对于提升模型性能的效果。",
    "user_summary": "北京航空航天大学黄雷副教授团队的最新研究发现，层标准化（Layer Normalization, LN）和其计算退化版本RMSNorm具有非线性表达能力。这项研究打破了人们认为标准化层不能提升模型表达能力的观念。团队在ICML 2024上发表的论文《On the Nonlinearity of Layer Normalization》中提出，仅含线性层和LN的简单神经网络LN-Net在足够深的情况下，理论上可以任意分类给定的样本和样本类别。这一发现对于神经网络架构设计具有开创性意义，特别是在LN广泛应用于Transformer模型的背景下。论文证明了LN的非线性主要存在于尺度缩放操作中，并提出了分组层标准化技术（LN-G），在实验中展示了增强LN非线性对于提升模型性能的效果。",
    "keywords": [
        "北京航空航天大学",
        "黄雷",
        "副教授",
        "研究团队",
        "层标准化",
        "LN",
        "RMSNorm",
        "非线性表达能力",
        "模型",
        "表达能力",
        "ICML",
        "2024",
        "论文",
        "LN-Net",
        "神经网络",
        "分类",
        "样本",
        "样本类别",
        "标准化层",
        "线性层",
        "LN",
        "开创性意义",
        "Transformer",
        "模型",
        "非线性",
        "层标准化技术",
        "LN-G",
        "模型性能"
    ],
    "timestamp": "2024-10-27T07:28:40.398026"
}