{
    "link": "http://arxiv.org/abs/2410.18861v1",
    "title": "可验证鲁棒的开源语言模型水印",
    "summary": "最近高质量的语言模型的爆发式增长促使我们开发新的方法来识别人工智能生成的文本。水印技术作为一种前沿解决方案，可能在生成式人工智能时代成为至关重要的工具。现有的方法在推理过程中嵌入水印，并且严重依赖大型语言模型（LLM）的规格和参数保密，这使得它们不适用于开源环境。在本工作中，我们首次提出了一个针对开源LLM的水印方案。我们的方案通过修改模型参数来实现，但仅通过模型的输出就可以检测到水印。令人惊讶的是，我们证明了在对攻击者知识的某些假设下，我们的水印是不可移除的。为了展示我们的构造在具体参数实例下的行为，我们使用OPT-6.7B和OPT-1.3B展示了实验结果。我们证明了水印对令牌替换和模型参数扰动两种攻击具有鲁棒性。我们发现，较强烈的攻击，即模型参数扰动攻击，需要将质量评分降低到0分（满分100）才能将检测率降低到50%。",
    "user_summary": "最近高质量的语言模型的爆发式增长促使我们开发新的方法来识别人工智能生成的文本。水印技术作为一种前沿解决方案，可能在生成式人工智能时代成为至关重要的工具。现有的方法在推理过程中嵌入水印，并且严重依赖大型语言模型（LLM）的规格和参数保密，这使得它们不适用于开源环境。在本工作中，我们首次提出了一个针对开源LLM的水印方案。我们的方案通过修改模型参数来实现，但仅通过模型的输出就可以检测到水印。令人惊讶的是，我们证明了在对攻击者知识的某些假设下，我们的水印是不可移除的。为了展示我们的构造在具体参数实例下的行为，我们使用OPT-6.7B和OPT-1.3B展示了实验结果。我们证明了水印对令牌替换和模型参数扰动两种攻击具有鲁棒性。我们发现，较强烈的攻击，即模型参数扰动攻击，需要将质量评分降低到0分（满分100）才能将检测率降低到50%。",
    "keywords": [
        "水印",
        "AI",
        "生成文本",
        "识别",
        "开源",
        "LLM",
        "模型",
        "参数",
        "修改",
        "输出",
        "检测",
        "不可移除",
        "令牌",
        "替换",
        "参数",
        "扰动",
        "攻击",
        "鲁棒性",
        "质量",
        "评分"
    ],
    "timestamp": "2024-10-27T05:17:36.448478"
}