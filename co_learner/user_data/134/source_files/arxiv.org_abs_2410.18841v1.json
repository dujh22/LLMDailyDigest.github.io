{
    "link": "http://arxiv.org/abs/2410.18841v1",
    "title": "从效率到公平：评估偏好学习中的公正性",
    "summary": "随着人工智能系统，尤其是生成模型，越来越多地影响决策过程，确保它们能够公平地反映人类多样化的偏好变得至关重要。这篇论文提出了一种新的框架，用于评估偏好学习模型中的认识论公平性，这一框架受到了经济不平等理论和罗尔斯正义理论的启发。我们借鉴了基尼系数、阿特金森指数和库兹涅茨比率来提出量化这些模型公平性的指标。我们使用两个数据集验证了我们的方法：一个定制的视觉偏好数据集（AI-EDI-Space）和Jester笑话数据集。我们的分析揭示了用户间模型性能的差异，突显出潜在的认识论不公正。我们探索了预处理和处理技术来缓解这些不平等，展示了模型效率和公平性之间复杂的平衡关系。这项工作通过提供一个评估和改进偏好学习模型中认识论公平性的框架，为AI伦理做出了贡献，为在重视多样人类偏好的情境中开发更具包容性的AI系统提供了见解。",
    "user_summary": "随着人工智能系统，尤其是生成模型，越来越多地影响决策过程，确保它们能够公平地反映人类多样化的偏好变得至关重要。这篇论文提出了一种新的框架，用于评估偏好学习模型中的认识论公平性，这一框架受到了经济不平等理论和罗尔斯正义理论的启发。我们借鉴了基尼系数、阿特金森指数和库兹涅茨比率来提出量化这些模型公平性的指标。我们使用两个数据集验证了我们的方法：一个定制的视觉偏好数据集（AI-EDI-Space）和Jester笑话数据集。我们的分析揭示了用户间模型性能的差异，突显出潜在的认识论不公正。我们探索了预处理和处理技术来缓解这些不平等，展示了模型效率和公平性之间复杂的平衡关系。这项工作通过提供一个评估和改进偏好学习模型中认识论公平性的框架，为AI伦理做出了贡献，为在重视多样人类偏好的情境中开发更具包容性的AI系统提供了见解。",
    "keywords": [
        "人工智能",
        "系统",
        "决策过程",
        "公平性",
        "偏好学习",
        "模型",
        "认识论公平性",
        "经济不平等",
        "罗尔斯正义理论",
        "基尼系数",
        "阿特金森指数",
        "库兹涅茨比率",
        "数据集",
        "AI-EDI-Space",
        "Jester",
        "笑话",
        "用户性能",
        "差异",
        "不公平性",
        "预处理",
        "技术",
        "不平等",
        "公平性",
        "平衡",
        "关系",
        "AI伦理",
        "多样性",
        "人类偏好",
        "包容性",
        "模型框架"
    ],
    "timestamp": "2024-10-27T05:18:08.141626"
}