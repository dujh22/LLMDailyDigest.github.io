{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936710&idx=1&sn=dbbd17956166684cee4eb73e75e41111&chksm=84e7d1f8b39058ee0eb5fda8a56d4ba9a6650d178b7e26e2d78fe617dc937e5fc0353e45e1db#rd",
    "title": "给机器人装上「虫脑」？非Transformer液态神经网络终于来了！MIT CSAIL负责人创业成果",
    "summary": "Liquid AI公司推出了一种名为Liquid Foundation Models（LFM）的新一代多模态AI模型，该模型在各种规模上均能实现SOTA性能，同时保持较低的内存占用和高效的推理。LFM的核心优势在于它们在超越基于Transformer的模型的同时，需要更少的内存。LFM系列包含1B、3B和40B三种不同尺寸的模型，分别适用于不同环境和任务。在基准测试中，LFM在性能和内存效率方面优于一些基于Transformer的模型，例如Meta的Llama和微软的Phi模型。此外，LFM的高效内存管理允许在边缘设备上处理长上下文任务，为各种应用场景提供了新的可能性。 Liquid AI的LFM模型受到了线虫神经结构的启发，采用液态神经网络架构，提供了一种不同于Transformer的替代方案。公司计划在2024年10月23日举行发布会，并鼓励用户进行测试和反馈以改进产品。",
    "user_summary": "Liquid AI公司推出了一种名为Liquid Foundation Models（LFM）的新一代多模态AI模型，该模型在各种规模上均能实现SOTA性能，同时保持较低的内存占用和高效的推理。LFM的核心优势在于它们在超越基于Transformer的模型的同时，需要更少的内存。LFM系列包含1B、3B和40B三种不同尺寸的模型，分别适用于不同环境和任务。在基准测试中，LFM在性能和内存效率方面优于一些基于Transformer的模型，例如Meta的Llama和微软的Phi模型。此外，LFM的高效内存管理允许在边缘设备上处理长上下文任务，为各种应用场景提供了新的可能性。 Liquid AI的LFM模型受到了线虫神经结构的启发，采用液态神经网络架构，提供了一种不同于Transformer的替代方案。公司计划在2024年10月23日举行发布会，并鼓励用户进行测试和反馈以改进产品。",
    "keywords": [
        "Liquid",
        "AI",
        "Liquid",
        "Foundation",
        "Models",
        "LFM",
        "Transformer",
        "SOTA",
        "内存占用",
        "推理",
        "基准测试",
        "Llama",
        "Phi",
        "模型",
        "边缘设备",
        "长上下文任务",
        "线虫神经结构",
        "液态神经网络",
        "架构",
        "发布会",
        "测试",
        "反馈",
        "产品改进"
    ],
    "timestamp": "2024-10-27T07:10:17.735460"
}