{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924168&idx=5&sn=a9e3c2ce66eb327acca5306c82a947dc&chksm=84e420f6b393a9e06a4cd38b2dbd927437c5c30bd49a8ec36341a78db6516c4de5e1d8547526#rd",
    "title": "ICML 2024 Spotlight | 在解码中重新对齐，让语言模型更少幻觉、更符合人类偏好",
    "summary": "这篇论文介绍了一种名为Decoding-time Realignment (DeRa)的方法，用于在语言模型对齐研究中平衡人类偏好奖励和正则化。DeRa允许在生成回答时动态调整这两个因素的比重，而无需重新训练模型，从而节省计算资源。它基于两个模型在原始输出（logits）空间的插值，实现简单且灵活，可以针对不同需求调整对齐强度。通过解码时的重新对齐，DeRa可以在不牺牲模型流畅性的情况下，有效控制语言模型的对齐程度。实验结果表明，DeRa在多项任务中表现出色，包括调整生成内容的长度、提高摘要任务的效率以及减少大模型中的幻觉生成。",
    "user_summary": "这篇论文介绍了一种名为Decoding-time Realignment (DeRa)的方法，用于在语言模型对齐研究中平衡人类偏好奖励和正则化。DeRa允许在生成回答时动态调整这两个因素的比重，而无需重新训练模型，从而节省计算资源。它基于两个模型在原始输出（logits）空间的插值，实现简单且灵活，可以针对不同需求调整对齐强度。通过解码时的重新对齐，DeRa可以在不牺牲模型流畅性的情况下，有效控制语言模型的对齐程度。实验结果表明，DeRa在多项任务中表现出色，包括调整生成内容的长度、提高摘要任务的效率以及减少大模型中的幻觉生成。",
    "keywords": [
        "Decoding-time",
        "Realignment",
        "DeRa",
        "语言模型",
        "对齐",
        "人类偏好",
        "奖励",
        "正则化",
        "动态调整",
        "无需重训练",
        "计算资源",
        "logits",
        "空间",
        "插值",
        "灵活",
        "对齐强度",
        "解码",
        "重新对齐",
        "流畅性",
        "控制",
        "对齐程度",
        "实验",
        "任务",
        "长度",
        "调整",
        "摘要",
        "任务",
        "效率",
        "幻觉",
        "生成"
    ],
    "timestamp": "2024-10-27T07:28:59.603891"
}