{
    "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923417&idx=6&sn=b4035dfd33e4e788611744007554a777&chksm=84e425e7b393acf1384c81363e9466f772f9e29257218798ba2bc2055f975aa4034b49e65761#rd",
    "title": "太全了！苹果上新视觉模型4M-21，搞定21种模态",
    "summary": "来自洛桑联邦理工学院（EPFL）和苹果的研究者联合开发了一个任意到任意模态单一模型，该模型在数十种高度多样化的模态上进行训练，并对大规模多模态数据集和文本语料库进行协同训练。该研究展示了训练单一模型也能完成现有模型至少3倍多的任务/模态，且不会损失性能，实现了更细粒度和更可控的多模态生成能力。模型能处理21种不同模态，包括跨模态检索、可控生成和强大的开箱即用性能。研究通过使用特定于模态的离散分词器进行编码，扩展了现有模型的功能，支持更多结构化数据，如人体姿态、元数据等，并在多个数据集上进行联合训练。",
    "user_summary": "来自洛桑联邦理工学院（EPFL）和苹果的研究者联合开发了一个任意到任意模态单一模型，该模型在数十种高度多样化的模态上进行训练，并对大规模多模态数据集和文本语料库进行协同训练。该研究展示了训练单一模型也能完成现有模型至少3倍多的任务/模态，且不会损失性能，实现了更细粒度和更可控的多模态生成能力。模型能处理21种不同模态，包括跨模态检索、可控生成和强大的开箱即用性能。研究通过使用特定于模态的离散分词器进行编码，扩展了现有模型的功能，支持更多结构化数据，如人体姿态、元数据等，并在多个数据集上进行联合训练。",
    "keywords": [
        "EPFL",
        "苹果",
        "单一模型",
        "多模态",
        "训练",
        "大规模",
        "数据集",
        "语料库",
        "任务",
        "模态",
        "性能",
        "生成",
        "跨模态检索",
        "可控",
        "生成",
        "结构化数据",
        "人体姿态",
        "元数据",
        "数据集"
    ],
    "timestamp": "2024-10-27T07:30:16.459025"
}