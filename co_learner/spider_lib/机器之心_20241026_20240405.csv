标题,URL,日期,摘要
UCL博士生创业一年，造出最强AI「ML工程师」，OpenAI盖戳认证,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940508&idx=1&sn=1483718d500bc76557d5397827638c7f&chksm=84e7e022b3906934994976f420e96f5aaf6a7d87bd799d96b354e167253833e2f445186d5cad#rd,2024-10-26 12:18:18,OpenAI推出新基准测试MLE-bench，评估大型语言模型在机器学习工程中的表现。研究发现，GPT-4o与AIDE框架的组合在75个Kaggle竞赛中的平均奖牌数量优于其他开源框架。当模型升级到OpenAI的o1-preview时，表现翻倍，约16.9%的比赛中达到Kaggle铜牌以上水平。AIDE是一个机器学习代码生成Agent，专注于代码优化，其设计范式有助于提升大模型的能力。AIDE在处理机器学习任务时展现出优于通用框架的能力，特别是在代码优化方面。WecoAI的CEO蒋铮尧表示，一个好的Agent框架对前沿模型的能力提升至关重要。
控制电脑手机的智能体人人都能造，微软开源OmniParser,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940508&idx=2&sn=e80aa4b0b65e715882b8d7226fe25259&chksm=84e7e022b3906934cacc911117c249d6b452d76a1e00493bfcda4fa4cb4c49e5496cc59ddf60#rd,2024-10-26 12:18:18,这篇文章介绍了最近在大模型控制计算机领域的进展，包括 Anthropic 的新版 Claude 3.5 Sonnet、荣耀 MagicOS 9.0 的全局智能体、智谱的 AutoGLM 以及华为的 LiMAC 研究。苹果发布了 Ferret-UI 的两个版本，这是一个让 AI 理解手机屏幕的技术，而微软开源了 OmniParser，这是一个基于大模型的屏幕解析工具，可以将 UI 截图转换为结构化的元素，并能理解并执行用户任务。OmniParser 展示了其在处理各种用户任务时的强大解析和执行能力。这些发展表明，让 AI 操控计算机的技术正在不断进步，并可能成为未来的趋势。
Waymo获得56亿美元融资，有史以来最大一轮,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940508&idx=3&sn=b0cf3f30184a29b41f8258523a19e900&chksm=84e7e022b39069341bd0f9ab57cf0d1c35e4eac385c283297eee49d95ee61a1e2bcc48e6202d#rd,2024-10-26 12:18:18,Waymo，Alphabet 旗下的自动驾驶子公司，已完成一轮 56 亿美元的超额认购 C 轮融资，旨在扩展其无人驾驶出租车服务。这笔资金是该公司有史以来最大的一轮融资，由 Alphabet 领投，包括 Andreessen Horowitz、Fidelity 在内的多家投资机构参与。Waymo 表示将利用这笔资金扩张到新城市并提升其自动驾驶技术。目前，Waymo 在旧金山、洛杉矶、菲尼克斯等地提供商业自动驾驶出租车服务，并计划扩展到奥斯汀和亚特兰大。该公司每周为超过 10 万名客户提供服务，并已推出了针对成本和功能优化的第六代 Waymo Driver。此次融资显示了 Waymo 在自动驾驶汽车行业的领先地位及其重塑城市交通的雄心。
手搓迪士尼同款机器人，总花费不到1500美元,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940508&idx=4&sn=b2d0d667a3c6980e0167205084f5715b&chksm=84e7e022b3906934d589314f054df0e6fe500e7082a5696d8d65addf69ccfa98034c6de417c3#rd,2024-10-26 12:18:18,还记得迪士尼那个会跳舞的双足机器人BDX吗？现在，你可以在家自己动手做一个迷你版的了。开源项目Open Duck Mini提供了制作教程，虽然走起路来还有点摇摇晃晃，但它的平衡性不错，能抵御一定的外界干扰。不过，目前的版本（alpha）组装不易，作者建议大家等待问题更少的v2版本。想要打造自己的迪士尼机器人？可以先收藏这个项目，准备迎接未来的教程。
无需训练即可创建数字人，字节PersonaTalk视频口型编辑超SOTA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940508&idx=5&sn=33555596caeea4a7f80814b712c81f46&chksm=84e7e022b3906934a3b18f507089bdc67169911b8ba97d26c0ef09b23a6a0b4663a7f2631f9c#rd,2024-10-26 12:18:18,字节跳动的一项名为 PersonaTalk 的技术入选了 SIGGRAPH Asia 2024-Conference Track，该技术能以高效便捷的方式使用语音修改视频中人物的口型，实现高质量视频编辑。PersonaTalk 通过一个基于注意力机制的双阶段框架，结合了定制化训练和 zero-shot 技术的优点，能够在不需要额外训练或微调的情况下生成逼真的视频。该技术能够用于视频翻译、虚拟教师、AIGC 创作等多个场景，提高了视频内容个性化和智能化的可能性。同时，技术团队在实验中展示了 PersonaTalk 在唇动同步、视觉质量和个性化特征保留方面的优势。
刚刚，我们感受了一波最「像人」的国产AI，模型还是开源的,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940454&idx=1&sn=5e956a7c118a8ab015916965a49df3fa&chksm=84e7e058b390694ef18b7f45e388626b124afe87c8a7a6178d092ba87e0e3278aa2c1e68145b#rd,2024-10-25 17:29:05,这篇文章介绍了智谱清言推出的情感语音通话功能，该功能提供类似GPT-4的实时语音交互体验，允许用户随时打断并感知用户情绪。这一功能是免费开放的，且其背后的情感语音模型GLM-4-Voice已开源。GLM-4-Voice是一个端到端的语音模型，能够理解情感、表达情绪、支持多语言和方言，并具有低延迟和可打断的特点。此外，智谱还发布了AutoGLM，使得AI能够自动操作电脑和手机，执行各种任务。智谱在追求人工智能（AGI）的道路上规划了技术路线图，目标是打造统一多模态模型，并具有安全可控的能力。目前，智谱正逐步实现不同级别的AI能力，包括工具使用和环境感知等。
让AI像人类一样操作手机，华为也做出来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940454&idx=2&sn=5cbb1046bbfe18f27760d54044ccb9c3&chksm=84e7e058b390694eb5699677ccb89811aa8372fdcb435c38dfb372be35d9220022bbeb3836a2#rd,2024-10-25 17:29:05,"这篇文章的摘要可以是：

AI 大模型正在发展出操作计算机的能力，微软发布了商业智能体， Anthropic 的大模型 Claude 3.5 Sonnet 可以根据用户指令执行计算机操作，甚至有人利用它破解了 CAPTCHA 验证码。荣耀推出了MagicOS 9，通过 AI 实现了“自动驾驶”手机模式。华为诺亚方舟实验室和伦敦大学学院的团队提出了轻量级多模态应用控制（LiMAC）架构，结合 Transformer 和小型微调版 VLM，实现更高效、准确的手机控制，降低了计算需求和响应时间。LiMAC 框架使用预训练嵌入和 Transformer 进行动作类型预测，通过对比学习方法进行点击定位，适用于计算能力有限的设备。未来的研究将探索如何通过在线学习技术提高模型在更复杂任务上的性能。"
稚晖君来填坑：开源灵犀X1全套图纸+代码，复刻搞起来,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940454&idx=3&sn=e31c29887d6f0a2f7f549b439dd73005&chksm=84e7e058b390694e38bc291384f09169e542c8acaac3d7f8bbd796c834e968a1911eda28f031#rd,2024-10-25 17:29:05,机器人研发公司智元将灵犀X1人形机器人的全套设计图纸和代码开源，包括本体设计、软件框架、中间件源码和运控算法等，提供一站式软硬件技术资源。这一开源行动受到网友的赞赏，被认为是推动国内机器人领域发展的重要举措。稚晖君，即彭志辉，是一位知名B站UP主，曾任职于OPPO和华为，目前创业专注于机器人研发。他的团队在不到3个月内开发出灵犀X1，该机器人具有创新设计，如模块化关节和稳定性技术。全套资料已上传至百度云盘和谷歌云盘，供有兴趣的读者研究和复刻。
与OpenAI o1技术理念相似，TDPO-R算法有效缓解奖励过优化问题,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940454&idx=4&sn=6c3b8104b3c3f754012fc47c93a087ca&chksm=84e7e058b390694ef9d7d6631cb2c5cd80ecc27ced8d79f2d64b3f91348b74a7787194883a0c#rd,2024-10-25 17:29:05,"本文介绍了由武汉大学、悉尼大学、京东探索研究院和南洋理工大学的研究人员在ICML 2024上发表的研究，该研究提出了一种名为TDPO-R的强化学习算法，用于解决扩散模型对齐中的奖励过优化问题。研究中，作者包括陶大程、文勇刚、张森、詹忆冰和罗勇等。他们发现细粒度奖励机制对于改善模型性能和防止奖励过优化至关重要，这一点与OpenAI的o1模型有相似之处。

扩散模型在图像生成任务中表现出色，但在奖励驱动的对齐过程中可能出现奖励过优化，导致生成图像的多样性和质量下降。TDPO-R通过引入时间差分奖励机制，对扩散模型的每一步生成过程提供即时反馈，缓解了这一问题。该算法使用一个时间差分评判器来估计每个时间步的奖励，允许模型在每一步都能进行策略更新，提高训练效率并减少延迟。

此外，研究者还发现神经元的首要偏置（Primacy Bias）可能导致奖励过优化，并提出神经元重置机制来打破这种偏置，通过定期重置活跃神经元并激活休眠神经元，提升模型的泛化能力。实验结果表明，TDPO-R在跨奖励泛化度量上表现优于其他方法，生成的图像既具有视觉质量又保持了多样性。

总的来说，这项研究为解决扩散模型对齐中的奖励过优化问题提供了一个有效方案，并强调了细粒度奖励机制和神经元管理在强化学习中的重要性。"
他们掰开神经元，终于让大模型9.8大于9.11了：神秘创业公司，开源AI「洗脑」工具,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940174&idx=1&sn=2accc1bd4b05ed08d2bab349dbed4606&chksm=84e7e770b3906e66804f11cf893e16a25d6a89cb1c7be7c13cfb95e7d78449556195fd47f335#rd,2024-10-24 12:59:30,AI研究实验室Transluce开发了一个名为Monitor的交互界面，帮助人们观察和理解语言模型的内部计算。该工具通过分析神经元来揭示模型出错的原因，例如在9.8和9.11大小比较的问题上，模型错误地认为9.11更大。Monitor能够显示模型预测错误的位置和概率，并找出影响错误预测的神经元。通过调整这些神经元的激活状态，可以引导模型给出更准确的答案。该工具的目的是提高对AI模型的理解，促进可信赖AI的发展。Transluce是一个致力于创建理解AI系统工具的非营利性研究实验室，其目标是构建开源、可扩展的技术。
100%英伟达的错：黄仁勋确认Blackwell缺陷修复，明年初出货,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940174&idx=2&sn=939f170904c18aae74bae5167bd0879d&chksm=84e7e770b3906e66d19467281ea4a297daf9474940370e32a549740aae594df2d93b2435dd0d#rd,2024-10-24 12:59:30,英伟达CEO黄仁勋承认，公司的Blackwell AI芯片存在设计缺陷，导致良率低下，但该问题已修复。他表示，这个缺陷是英伟达的错，并已得到台积电的帮助。Blackwell芯片由于其新架构和高效率备受期待，但最初出现的报道暗示台积电应承担责任，黄仁勋否认了这一说法。英伟达已对设计进行修改，并计划在第四季度开始量产修复后的GPU，预计将于2025年初开始发货。主要客户包括AWS、谷歌、Meta和微软。
Nature专业户DeepMind又登封面，开源水印技术SynthID-Text，Gemini已经用上了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940174&idx=3&sn=16010aae051b03aa6599d9b665c9fb0c&chksm=84e7e770b3906e66016c0502861d3aa550bd6e1b7a39ff60989e649f42e99d886e66f66177bc#rd,2024-10-24 12:59:30,谷歌的SynthID文本水印技术登上了最新一期Nature杂志封面，这是一种用于识别人工智能生成文本的工具。该技术可以在不明显影响文本质量的情况下添加水印，实现高检测精度，并且水印检测计算效率高，无需使用底层大型语言模型（LLM）。SynthID-Text建立在新型的Tournament采样算法上，可以配置为非失真或失真模式，提供更高的检测率。通过大规模用户反馈评估，证明了SynthID-Text可以用于现实世界的生产系统。然而，目前该技术主要适用于短文本，对于修改、重写或翻译的内容处理较困难。谷歌强调，SynthID并非识别AI内容的万能解决方案，但对开发更可靠的AI识别工具至关重要。
​哪个模型擅长调用工具？这个7B模型跻身工具调用综合榜单第一,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940174&idx=4&sn=ed1d8426641f7ec9aba146b5b9c1ec92&chksm=84e7e770b3906e663748743a2081699b5b557a038e0b52675281c83a4197d1188523830a1907#rd,2024-10-24 12:59:30,OPPO 研究院和上海交通大学的研究团队提出函数掩码（Function Masking）方法，构建了具备强大泛化能力的轻量化工具调用系列模型：Hammer，并开源了完整技术栈。Hammer 系列模型在工具调用典型评测基准上展现出出色性能，特别是 Hammer-7B 模型，综合效果仅次于 GPT-4，在工具调用模型中排名第一，具备新场景和新工具泛化能力。函数掩码技术有助于减少模型对函数名称和参数名称的依赖，增强数据集则帮助模型在无适用函数时正确判断。实验表明，函数掩码对不同模型架构有显著优化效果。
荣耀MagicOS 9.0来了个全局智能体，AI手机方向变了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940077&idx=1&sn=57c5e6170f52fac563ad96833ffcb8f1&chksm=84e7e6d3b3906fc5d968cb3d21ebf6e55c3b7b5c94e9ca1b50f65de6c1b1a1488beb8fd98e0d#rd,2024-10-23 20:20:45,荣耀发布新一代操作系统MagicOS 9.0，这是业内首个搭载智能体的个人化全场景AI操作系统。该系统让智能终端进入“自动驾驶”时代，通过AI智能体，用户可以实现语音命令控制手机自动完成任务，如点咖啡，且能识别AI换脸技术。MagicOS 9.0引入了语言、图像、语音和多模态大模型家族矩阵，提供更快的加载速度和出词速度，同时优化功耗和内存占用。此外，系统升级了场景感知、用户理解和意图决策的能力，实现更深入的意图理解和个性化服务。荣耀Magic7系列将是首发搭载MagicOS 9.0的手机，预计在10月30日发布。
朱玉可团队新作：看一眼就能模仿，大模型让机器人轻松学会撒盐,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940077&idx=2&sn=cb9353cf957897cc68951b0d40a3e217&chksm=84e7e6d3b3906fc5f513ab014ca9af5d15aa8cd9cecd41a11ee98b223802215c807f6b3e2a7f#rd,2024-10-23 20:20:45,德克萨斯大学奥斯汀分校和NVIDIA Research的团队提出了一种名为OKAMI的新方法，让人形机器人可以通过观看单个RGB-D视频来学习和模仿操作技能。OKAMI是一种物体感知型动力学重定向方法，能让人形机器人基于单个视频进行操作规划并执行策略。通过识别视频中的相关物体、重建人类运动并进行物体感知型重定向，机器人可以学会包括装东西、撒盐、放置物品等任务。该方法使用了视觉-语言模型GPT-4V进行物体识别，并依赖于改进的SLAHMR算法来重建和重定向运动。实验表明，OKAMI在各种任务中表现出色，可以有效泛化到不同的视觉和空间条件。未来的工作将扩展到全身运动重定向和使用网络视频，以及提高对物体形状变化的适应性。
魔法填充+无限扩图，Ideogram推出AI画板工具Canvas,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940077&idx=3&sn=94afe61e92090151fe4c32cf9874f706&chksm=84e7e6d3b3906fc5b4818a409f137095a5bdb1cf3a4cda3cbc55dc445e7dceaea7fbf6353f60#rd,2024-10-23 20:20:45,这篇文章介绍了一款名为Ideogram Canvas的AI创意画板服务，该服务允许用户组织、生成、编辑和组合图像。利用AI的Magic Fill功能，它可以围绕用户选定的部分生成各种视觉风格的内容，实现物体替换、文本添加、缺陷修复和背景更换等。此外，Canvas还具有扩图功能，可以扩展图片边界并调整结构，以及将两张图像无缝融合。Ideogram Canvas在处理图中文本方面表现出色，可以添加风格一致的文字。尽管目前基础功能免费，但一些高级功能如上传图像和魔法填充需要付费。值得注意的是，这款工具目前专注于图像生成，缺少一些传统画板工具的绘图和元素链接功能。Ideogram Canvas鼓励用户发挥想象力，探索无限可能。
NeurIPS 2024 | 解锁大模型知识记忆编辑的新路径，浙大用「WISE」对抗幻觉,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650940077&idx=4&sn=99010fe2518f7d6178435d1dbdf8f293&chksm=84e7e6d3b3906fc52fa571196aaa8d1206ee8257b752448229bbce414382a8d230b646ca454d#rd,2024-10-23 20:20:45,本文介绍了一种名为WISE的新型大模型知识编辑方法，该方法受到人类记忆机制的启发，旨在解决大语言模型中的知识记忆灵活性和可控性问题。WISE通过双重记忆机制——主记忆和侧记忆，实现了知识的持续更新和精确编辑，同时保持模型的通用能力和避免对非编辑知识的干扰。这种方法通过知识分片和自适应门控策略，保证了编辑的可靠性、泛化性和局部性，适用于大模型的终身知识编辑。实验结果表明，WISE在长期编辑任务中表现出色，具有良好的稳定性和扩展性。该工作已被 NeurIPS 会议接收。
大模型是否有推理能力？DeepMind数月前的论文让AI社区吵起来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939760&idx=1&sn=edeb27005b521d8742ec09899c2b67e8&chksm=84e7e50eb3906c18df884f950e2308ac7b4ca57dc038f8b0f6d00364c2206876e859db3fc4b0#rd,2024-10-22 13:01:24,DeepMind的一项研究显示，一个2.7亿参数的Transformer模型可以通过标准的监督学习，无需依赖搜索算法就能达到国际象棋的特级大师水平，优于AlphaZero和GPT-3.5-turbo-instruct。这一结果被一些人解读为Transformer模型可能具有推理和规划能力，但也有争议。Meta FAIR的田渊栋指出，评估方法“blitz”可能存在局限，可能并不足以测试模型的推理能力。纽约大学的Gary Marcus则认为模型的泛化能力存在问题。该模型的训练是基于Stockfish 16注释的大量棋局，通过预测棋盘的动作-值来决策，表明大型transformer可能可以作为算法近似的强大技术。
骁龙8至尊版登场：CPU牙膏挤爆，AI生成速度创纪录，奥特曼也来助阵,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939760&idx=2&sn=ccb63a21887d0fd6450a26ee9eac6d85&chksm=84e7e50eb3906c182efac85b5d822017c43694c644d79db0ea405bbb3d73fd4bfa5301f9147f#rd,2024-10-22 13:01:24,高通在2024骁龙峰会上发布了新一代旗舰移动平台“骁龙8至尊版”，这是全球速度最快的移动端系统级芯片。该平台首次采用第二代定制的高通Oryon CPU、高通Adreno GPU和增强的高通Hexagon NPU，带来性能的颠覆性提升。Oryon CPU由两个4.32 GHz的“超级内核”和六个3.53 GHz的“性能内核”组成，集成X80 5G调制解调器。Adreno GPU性能提升40%，能效提升42%。Hexagon NPU增强了AI运算性能，支持多模态生成任务。此外，骁龙8至尊版还提升了图像处理能力，包括语义分割技术和视频中移除对象的功能。网络连接方面，搭载Snapdragon X80 5G调制解调器，下载速度峰值可达10 Gbps。多款手机厂商计划在未来几周内推出搭载骁龙8至尊版的机型。
DeepSeek新作Janus：解耦视觉编码，引领多模态理解与生成统一新范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939760&idx=3&sn=2f425cc6b13728af7e0a28b1b45c2e48&chksm=84e7e50eb3906c18ce0e6af039362951502c62b61f19f1a2630e798f7cacb65dd813ce9f27ab#rd,2024-10-22 13:01:24,Janus 是一种新型的多模态理解和生成统一模型，其特点是将理解和生成任务的视觉编码解耦，以提高模型灵活性并缓解单一视觉编码的冲突和性能瓶颈。该模型在理解和生成方面都展现出与纯理解或纯生成模型相当或更好的性能。Janus 的设计允许研究人员轻松地将最新的编码技术应用于模型，具有扩展性。通过实验，Janus 超越了现有的统一模型，并在多模态理解基准测试中达到或超过了最先进的性能。该模型的名称来源于罗马神话中的双面神 Janus，象征其在理解和生成任务中的双重能力。Janus 的设计为多模态统一模型的研究开辟了新方向，展示了在理解和生成任务之间平衡的潜力。
自动化、可复现，基于大语言模型群体智能的多维评估基准Decentralized Arena来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939760&idx=4&sn=cddfd0aee2c9b51c155a7705279fa35e&chksm=84e7e50eb3906c18e0af738cb2ca19138b27cea91c701520821e07e4c555fc97570e79f7ad87#rd,2024-10-22 13:01:24,Maitrix.org，一个由多所学术机构学者组成的开源组织，发布了Decentralized Arena，这是一个用于大语言模型（LLM）评估的新平台。该平台旨在解决大规模、精细化的LLM性能基准测试的挑战，提供自动化、去中心化和可扩展的评估方法。Decentralized Arena利用LLM之间的相互评估，减少了对单一评委模型的依赖，提高了排名的稳健性和公平性。与其他基准测试相比，如Chatbot Arena，Decentralized Arena在评估的自动化、速度、可扩展性和定制化方面具有优势，可以评估模型在不同领域的特定能力，如数学、推理、编程和科学知识。该平台还允许创建自定义维度以针对特定问题集进行基准测试。随着更多模型的参与，评估将变得更加准确和稳定。
视频、图像、文本，只需基于下一个Token预测：智源Emu3发布，验证多模态模型新范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939676&idx=1&sn=d8a55a8e14f0f48d705e7274be6e773a&chksm=84e7e562b3906c7421c3348ed7e36e254f04d20866d93c550935b2b97551fc5820f2e7a11479#rd,2024-10-21 12:02:06,智源研究院发布了原生多模态世界模型 Emu3，该模型仅基于下一个 token 预测，无需扩散模型或组合方法，就能完成文本、图像、视频三种模态数据的理解和生成。Emu3 在图像生成、视频生成和视觉语言理解等任务上超过了现有的知名开源模型，如 SDXL、LLaVA 和 OpenSora，且仅通过预测下一个 token 实现这一成就。这一研究证明了下一个 token 预测可以作为多模态模型的强大范式，为构建多模态 AGI 提供了一条新路径。Emu3 已开源，其统一的架构和高效的性能在社区中引起了广泛关注和积极评价。
苹果内部员工自揭其短：生成式AI研发竟已落后两年多,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939676&idx=2&sn=b158dbd290cdb95b3f277782c7938c5c&chksm=84e7e562b3906c74c1951d81a8563c1b6bf241e353fb61f84a86721a1cc6cfe979827709080b#rd,2024-10-21 12:02:06,苹果内部员工认为公司在AI技术上落后行业领先者两年以上，根据内部研究，OpenAI的ChatGPT在准确性和可回答问题数量上超过苹果的Siri。尽管苹果拥有大量资源，但其在AI领域的进展和公众曝光度相比其他科技巨头如谷歌、Meta和微软较少。不过，苹果计划将其AI功能推广到更多设备，并在下一代家居设备中集成AI能力。未来苹果是否会加大AI投入并追赶竞争对手还有待观察。
突破视频多模态大模型瓶颈！「合成数据」立大功，项目已开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939676&idx=3&sn=b46f7433c2ab7976a4fbea3fcf20745a&chksm=84e7e562b3906c74a3ac7337f9ef2c109bc95673095312f05e3b243db484a36bec808e952f90#rd,2024-10-21 12:02:06,研究人员提出了一个名为 LLaVA-Video-178K 的高质量合成视频数据集，旨在解决视频多模态大模型发展中的数据获取难题。该数据集包含详细的视频描述、开放式问答和多项选择题，用于视频指令跟随任务。通过在 LLaVA-Video-178K 和现有数据上训练模型，他们推出了视频 LMM——LLaVA-Video，该模型在多个视频基准上表现出色。数据集的创建重点在于视频内容和语言注释的丰富性和多样性，通过自动生成详细描述和问答对，以提高模型的视频理解和推理能力。实验表明，LLaVA-Video 数据集的有效性。
NeurIPS 2024 | 标签噪声下图神经网络有了首个综合基准库，还开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939676&idx=4&sn=87ff79fa50dba3426da3f9d6f2992a75&chksm=84e7e562b3906c74e4e5ee12a6d92cc1a15fb8b4830329262aa230a2a4575c5e0ba8b0957724#rd,2024-10-21 12:02:06,浙江大学周晟老师团队与阿里安全交互内容安全团队合作的研究成果被 NeurIPS 2024 Datasets and Benchmarks Track 收录。他们提出了 NoisyGL，这是第一个针对标签噪声下图神经网络的综合基准，用于在不同性质的图数据上公平比较和多角度分析不同方法的抗噪性能。NoisyGL 旨在填补现有研究中缺乏综合基准的空白，提供了一个统一的实验设置和接口，并且是可扩展和易用的框架，便于后续研究。该研究通过大量实验提出了标签噪声下图神经网络的重要见解，并为未来研究指明了发展方向。
132年未解开的李雅普诺夫函数谜题，被Symbolic Transformer攻克了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939537&idx=1&sn=462e22217cdcbaadf5039f25336263b6&chksm=84e7e4efb3906df9e4bef47505185ddb83af7d9166d7f7e819bd365b48bae1a0d07ae2c44d96#rd,2024-10-20 12:32:42,Meta和巴黎理工学院的研究人员使用序列到序列Transformer模型解决了困扰数学界132年的李雅普诺夫函数问题。李雅普诺夫函数用于判断动力系统的稳定性，但通常难以推导。研究者通过生成训练数据集并训练Transformer，使其在测试集上达到高准确率，甚至在分布外测试中也表现出色。这种方法表明AI模型可能有助于解决数学中的开放问题，为数学研究提供新的工具。该论文已被NeurIPS 2024接收。
视频生成模型变身智能体：斯坦福Percy Liang等提出VideoAgent，竟能自我优化,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939537&idx=2&sn=f821253cee51f68a8af55bb7bac9df82&chksm=84e7e4efb3906df92e49904ac863564633ea02ceedf719dbab58d95e59a325b389f8bed713ea#rd,2024-10-20 12:32:42,研究人员提出了一种名为VideoAgent的视频生成模型，该模型可以通过来自视觉-语言模型（VLM）的AI反馈和真实世界执行反馈实现自我提升。VideoAgent在训练中利用自我调节一致性优化视频生成，通过VLM引导的视频生成进行推理，并通过在线微调进行自我改进。实验表明，VideoAgent在多个数据集上的端到端任务成功率超过基线模型，并能提高真实机器人操作视频的质量。该研究为文本生视频模型的改进提供了新途径。
OpenAI发布MLE-Bench：是AGI奇点的先兆还是炒作？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939537&idx=3&sn=83496bb204f2cc5357111718594401d0&chksm=84e7e4efb3906df9f38fa1a90f2930aaef92597fcce99b70735d5becc13403fdd19594be6a7c#rd,2024-10-20 12:32:42,OpenAI最近发布了MLE-Bench，一个评估机器学习代理在机器学习工程中能力的基准测试。这个基准测试由75个来自Kaggle的机器学习任务组成，旨在模拟实际工程师的日常挑战。OpenAI表示，能够成功解决大部分MLE-bench任务的模型可能具有执行多种开放式机器学习任务的能力，这可能对AGI（人工智能）的准备度产生重大影响。然而，实验结果显示，尽管AI智能体在某些任务中表现良好，但它们的性能并未随着硬件资源的增加而显著提高，且尚未达到人类水平。关于OpenAI的观点，即能够自主执行机器学习研究的AI可能会加速科学进步并导致经济转型，这一说法在Reddit上引发了关于AGI奇点的讨论。
NeurIPS 2024 Oral | 小参数，大作为！揭秘非对称 LoRA 架构的高效性能,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939537&idx=4&sn=7877746d75c910589fbd84131f878b26&chksm=84e7e4efb3906df92270ce90f5a7d21fb7bc5b1fb7df1be71a7b715767d949fa8a7a0d6851bb#rd,2024-10-20 12:32:42,这篇文章介绍了一项新的AI研究，提出了名为HydraLoRA的非对称LoRA架构，用于大型语言模型的高效微调。现有的参数高效微调方法，如LoRA，在处理复杂任务时效果有限，而HydraLoRA通过引入共享的A矩阵和多个独立的B矩阵来解决这一问题，每个B矩阵专注于不同的任务，减少任务间的干扰。这种方法提高了任务适应性和性能，同时优化了资源消耗。实验结果表明，HydraLoRA在单任务和多任务场景中均表现出优越性能，且在系统效率方面具有优势，降低了训练能耗和延迟。该研究由澳门大学、德克萨斯大学奥斯汀分校和剑桥大学的研究者合作完成，论文已被NeurIPS Oral接收。
OpenAI若造出AGI，就能从微软独立：股权争夺战开打，两边都找好了投行,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939511&idx=1&sn=52b1f1fc24245ea9f7806127f89c28ea&chksm=84e7e409b3906d1f672b1abe3baf68ac51569583018aaf1cefdd1399adc7a719709f0f49df84#rd,2024-10-19 13:08:48,OpenAI，知名的AI研究实验室，最近与微软的关系出现紧张。OpenAI在寻求更多资金和独立性，而微软对于继续巨额投资持谨慎态度，尤其是在OpenAI预计今年可能亏损50亿美元的情况下。尽管微软是OpenAI的主要投资者，但据报道，微软已经在寻找其他AI合作伙伴，例如挖走了OpenAI竞争对手Inflection的前CEO。OpenAI曾试图重新谈判与微软的独家协议，以减少成本并扩大计算资源来源。最近，微软同意让OpenAI从Oracle购买额外的计算资源。OpenAI正在扩大投资者基础，包括苹果、英伟达和MGX等，并在最新一轮融资中筹集了66亿美元。然而，两家公司的合作关系的未来仍然存在不确定性，特别是合同中的一项条款规定，一旦OpenAI开发出通用人工智能（AGI），微软可能会失去对其技术的使用权。目前，微软和OpenAI正在就股权和治理权进行谈判。
SAM 2.1上新、Lingua代码库发布，一大波Meta开源工具来袭,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939511&idx=2&sn=ea4e0c596e8276abedf5d2d89cfaa05c&chksm=84e7e409b3906d1fe280e9654f971a4013a3ac943cea0242eee4580d613e6f6810f4799f22d3#rd,2024-10-19 13:08:48,Meta发布了一系列支持其高级机器智能（AMI）目标的研究和模型，强调了感知、语音和语言、推理、具身智能和对齐等领域。其中包括性能增强的SAM 2.1模型，用于视觉和语音无缝集成的开源多模态语言模型Spirit LM，加速大型语言模型推理的Layer Skip技术，以及用于大规模语言模型训练的Lingua代码库。此外，Meta还介绍了跨语言句子编码器MEXMA和自学习评估器，后者无需人工标注即可训练奖励模型。这些工作体现了Meta对开放科学和可复现性的承诺。
又快又准，即插即用！清华8比特量化Attention，两倍加速于FlashAttention2，各端到端任务均不掉点！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939511&idx=3&sn=dabddded9914c9219df01f93576b1930&chksm=84e7e409b3906d1fb9a8aaa0c9a15728843ee54a848039841ff183967c9ce9d6105dd7c55d45#rd,2024-10-19 13:08:48,清华大学陈键飞团队提出了SageAttention，这是一种8位（INT8）注意力机制，旨在加速大模型中的注意力运算，解决长序列处理中的效率瓶颈。SageAttention在保持端到端精度的同时，实现了比现有最佳方法FlashAttention2和xformers快2到2.7倍的推理加速。该方法通过对矩阵K进行平滑处理，对Q和K进行分块INT8量化，以及对P和V使用FP16矩阵乘法累加器来提高效率。实验结果显示，SageAttention在不同模型和任务上都表现出高效率和无精度损失的性能。
Jurgen、曼宁等大佬新作：MoE重塑6年前的Universal Transformer，高效升级,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939511&idx=4&sn=3512aa98e60840a5287609be806931ba&chksm=84e7e409b3906d1f01593d58f1584ab2d4a3c96e8192c37f7fb901bc9afbdf99d82d9a3081cc#rd,2024-10-19 13:08:48,谷歌在2017年提出了Transformer，2019年推出了Universal Transformer（UT），它通过跨层共享参数实现深度循环，提升了组合泛化能力。然而，UT的计算效率低于标准Transformer，不适用于大规模任务。近期，包括LSTM之父Jürgen Schmidhuber和斯坦福大学教授Christopher Manning在内的一组研究者提出了Mixture-of-Experts Universal Transformers（MoEUT），这是一种混合专家架构，通过layer grouping和peri-layernorm方案，解决了UT的基础计算参数比问题，实现了计算和内存效率更高的UT模型。MoEUT在多个语言建模和代码生成任务上展现出优越性能，同时在下游任务中也有良好表现，验证了循环对于模型性能的重要性。
大模型步入「推理Scaling」时代，SambaNova如何挑战英伟达的霸主地位？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939405&idx=1&sn=47a2fef868e9131289999e5b5d4f9437&chksm=84e7e473b3906d656ff2bca6081cda7b31612ede23274fca5d0357bbb43135b0c0b9a607039f#rd,2024-10-18 12:06:55,"OpenAI的o1模型展示了强大的通用推理能力，无需专门训练就能解决复杂问题，甚至在数学奥赛和博士级别科学问答中超越人类。这一成就标志着大模型训练范式的转变，即通过更多强化学习和推理，模型性能可随计算资源增加而提升。这一转变促使业界重新考虑计算资源分配和硬件选择，强调推理阶段的计算资源投入和硬件优化。GPU虽然适合训练大模型，但在大规模推理上表现不佳，延迟和功耗成为问题。

SambaNova的RDU（Reconfigurable Dataflow Unit）芯片采用动态可重构数据流架构，优化了推理性能和效率，相比GPU具有2-4倍的性能优势。RDU通过极致的算子融合和高HBM利用率实现高效推理，成为大模型推理的有力竞争者。数据流架构因其并行处理能力而受到关注，与GPU相比，它能更好地支持大模型的快速推理需求。SambaNova的RDU芯片在处理速度和效率上的优势，使得它在AI推理领域展现出巨大潜力，可能开启AI硬件市场的新篇章。"
DenseNet共一作者刘壮官宣新去向，将任普林斯顿大学助理教授,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939405&idx=2&sn=9d32562767ad288569f6f223dbfd5799&chksm=84e7e473b3906d655ff50d11fa70254924d5ef69810082c7cc0bba0426030675555e7f161999#rd,2024-10-18 12:06:55,DenseNet和ConvNeXt的开发者之一，刘壮，将于2025年9月加入普林斯顿大学，担任计算机科学系助理教授。刘壮在深度学习和计算机视觉领域有重要贡献，他的工作对神经网络架构产生了深远影响。在入职学术界之前，他将继续在Meta AI Fair担任研究科学家。刘壮的DenseNet论文在CVPR 2017上获得了最佳论文奖，目前被广泛引用。他在加州大学伯克利分校获得博士学位，并在Meta、康奈尔大学等机构有研究经历。最近，他和团队发布的ConvNeXt展示了纯CNN模型可以达到与Transformer模型相似的性能。刘壮的研究经常挑战现有观念，未来在学术界有望带来新的创新。
以图灵机为师：通过微调训练让大语言模型懂执行计算过程,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939405&idx=3&sn=6bd41627e87d10c5056491c315eb8601&chksm=84e7e473b3906d658a0948be8eebc8a1cb1c6112bd077580f37c71d47faa8613900d2db169bb#rd,2024-10-18 12:06:55,南京大学的研究团队提出了一种名为可组装算术执行框架（CAEF）的方法，旨在帮助大型语言模型（LLM）理解并执行算术逻辑。当前，尽管LLM在许多自然语言处理任务中表现出色，但在处理算术问题时依赖记忆而非真正理解计算逻辑。CAEF通过模仿图灵机的工作方式，使LLM能够分步执行计算任务，从而掌握运算符的计算逻辑，并具有组合运算符的能力。实验结果显示，结合CAEF的LLaMA 3.1-8B模型在七个常见运算符上的准确率接近100%，且能处理100位操作数的计算，超越了GPT-4o的性能。该框架为LLM在解决复杂计算问题上提供了新的途径。
卷起来！让智能体评估智能体，Meta发布Agent-as-a-Judge,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939405&idx=4&sn=2736186eaef5f3338a6da25f28a01f1f&chksm=84e7e473b3906d651e7b4a9988cdf0a9f96408843e9eec9d1c26975e905d408fa6655586d637#rd,2024-10-18 12:06:55,Meta AI研究团队提出了一种新的智能体评估方法，称为Agent-as-a-Judge，该框架使用智能体来评估其他智能体的性能，提高了评估的自动化和灵活性。传统评估方法通常仅关注最终结果，而Agent-as-a-Judge则引入了中间反馈机制，能够精确评估任务的每个环节，更接近人类的评估方式。实验显示，该框架的评估结果与人类专家的对齐率高达90.44%，并且在效率上显著优于人类评估，节省了大量时间和成本。此外，研究团队还发布了DevAI，一个包含55个现实AI开发任务的新基准，用于测试和优化智能体。这个数据集强调任务的中间反馈和多阶段评估，以更好地反映智能体在实际问题中的表现。该研究为AI评估提供了高性价比和潜力，有望推动智能体技术的进一步发展。
从威尔・史密斯鬼畜吃面到「Her」，这些幕后技术正在推动AI视频时代的到来,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939341&idx=1&sn=9da5e728d69773d442d66dfc03a4683b&chksm=84e7dbb3b39052a529297a41f25115ee6bfcf2098473435f0e8e493d73ffb5c827e610910772#rd,2024-10-17 17:29:15,这篇文章讲述了AI视频生成技术的快速发展，特别是字节跳动的豆包·视频生成模型，该模型能够生成高质量、电影级别的视频，引发国内外网友的关注。文章指出，AI视频生成技术的进步带来了计算资源需求的增加和编解码技术的挑战。为应对这些挑战，火山引擎在算力层研发了视频转码专用芯片，提高了效率并降低了成本；在编解码层，他们推出了BVC2智能混合编解码方案；在框架层，他们基于BMF构建的解决方案帮助处理大量视频数据。此外， BMF-lite移动端后处理解决方案的开源降低了企业研发成本。随着视频技术的不断进步，视频正逐渐成为人类的第二语言，将广泛应用于各个领域。
英伟达开源最新大模型Nemotron 70B后，只有OpenAI o1一个对手了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939341&idx=2&sn=691c451038d55fdece07407ad71e1e99&chksm=84e7dbb3b39052a5d68c1401554b305151fd8cfb47731d283d7d4bb164d94f3cb4ad5c9ec9c6#rd,2024-10-17 17:29:15,英伟达开源了性能强大的语言模型Llama-3.1-Nemotron-70B-Instruct，该模型在多个基准测试中击败了包括OpenAI的GPT-4o和Anthropic的Claude-3.5 Sonnet在内的其他模型。Llama-3.1-Nemotron-70B-Instruct在通用领域的性能表现优秀，但尚未针对数学等专业领域进行优化。模型基于Llama-3.1-70B，并使用RLHF技术进行训练。此外，英伟达还提供了训练数据集HelpSteer2和另一个模型Llama-3.1-Nemotron-70B-Reward。用户可以在线体验该模型，但部署该模型需要特定的硬件资源。
全模态对齐框架align-anything来了：实现跨模态指令跟随,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939341&idx=3&sn=41d7f300f53e6f79875c2c6f757f86dc&chksm=84e7dbb3b39052a5c7f8deb57f083e8e6321c40a2458148609251f58a9292a4fcb6a8bf838ee#rd,2024-10-17 17:29:15,北京大学的研究团队开发了全球首个全模态对齐框架「Align Anything」，用于强化学习方法和大模型的后训练对齐技术。该框架支持文本、图像、音频、视频等多种模态的输入和输出对齐，填补了现有框架的空白。团队还发布了全模态人类偏好数据集 Align-Anything，以促进模型的多模态理解和对齐。通过Align Anything框架，研究人员可以提高模型的训练和评估效率，微调大模型以提升特定任务性能。此外，团队基于Llama-3.2-Vision模型进行了后训练对齐微调，得到Beaver-Vision-11B，展现出比Meta微调版本更强的对齐性和指令跟随性。该框架的开源将推动全模态大模型与人类意图对齐的研究。
NeurIPS 2024 | FaceChain团队新作，开源拓扑对齐人脸表征模型TopoFR,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650939341&idx=4&sn=23a3b9b552b7cffd3e769afb7063f809&chksm=84e7dbb3b39052a5f5ad5ca11a2b9efa323bd22265b35528b40e0b78017f58b450ea9ba7aa5b#rd,2024-10-17 17:29:15,FaceChain团队在人脸表征学习领域取得新进展，其论文“TopoFR: A Closer Look at Topology Alignment on Face Recognition”被NeurIPS 2024接收。该研究关注如何利用大规模人脸数据集中的结构信息来提升人脸识别模型的泛化能力。研究发现，随着数据量增加，输入空间的拓扑结构变得复杂，而输入空间与隐层空间的拓扑结构差异增大。为解决这个问题，团队提出了扰动引导的拓扑结构对齐策略（PTSA），包括随机结构扰动（RSP）和不变性结构对齐（ISA）机制，以及结构破坏性估计（SDE）策略，以保留和对齐数据的结构信息。实验表明，TopoFR模型在人脸识别任务中展现出优秀的性能和泛化能力。
AI 蛋白质夺诺奖，清华聂再清：大模型解码生物语言 | 智者访谈,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938891&idx=1&sn=538c2917cb0f1b7e846aa875b53343d0&chksm=84e7da75b39053637aa0e465be0b6fae1b592e020cc9be6fd512f5d38cf63b1fe35add4f27a4#rd,2024-10-16 12:32:20,清华大学聂再清教授在访谈中讨论了人工智能在药物研发中的应用，特别是基于大模型的对话式药物研发助手的创新实践。他指出，当前药物研发存在“干湿实验”不结合的问题，即基于数据的预测模型效果在实验室验证时可能不理想。聂教授的团队正在构建生物医药领域的基座大模型，以整合不同尺度和模态的数据，建立生物语言与自然语言之间的桥梁。他们研发的ChatDD是一个能够通过自然语言与专家交互的药物研发助手，目标是提升药物研发效率和成功率。该模型不仅可以用于药物设计，还可以帮助进行立项分析和临床试验等环节，有望成为生物医药行业的重要入口。目前，ChatDD已经在实际应用中取得积极反馈，未来有望通过服务订阅、云部署、私有化部署以及提供行业应用商店等多种商业模式实现盈利。
ChatGPT确实会看人下菜！OpenAI官方报告揭示大模型的刻板印象,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938891&idx=2&sn=8c88b79759ca019296135e9a9396391c&chksm=84e7da75b39053638e8113a8b758c95a3a790a775ae69118c59c467e9778b146395ab32485e6#rd,2024-10-16 12:32:20,OpenAI的一项新研究发现，其聊天机器人ChatGPT的响应可能受到用户身份线索的影响，显示出对性别和种族的刻板印象。研究中，OpenAI分析了用户姓名如何影响ChatGPT的响应，发现虽然大多数响应在总体质量上没有显著差异，但约有1%的差异反映了有害的刻板印象。例如，对于同样的问题，ChatGPT可能会根据用户的名字给出不同答案，这些差异可能基于性别、种族或文化的关联。OpenAI使用一种名为“语言模型研究助理”（LMRA）的方法来检测这些偏见，并计划通过持续的努力来降低模型中的偏见。
补齐Transformer规划短板又不放弃快速思考，田渊栋团队的Dualformer融合System 1和2双重优势,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938891&idx=3&sn=e992d114462a6ef9c1a8c8175035e7b3&chksm=84e7da75b3905363ac684f5f585b19ce03528013081b0c5b8a1cbbf25b36d40b96e128b8f626#rd,2024-10-16 12:32:20,Meta FAIR 的田渊栋团队受人类认知理论启发，提出了一种名为 Dualformer 的新型 Transformer 架构，它可以控制模型在推理过程中使用快速或慢速模式。该研究基于人类的 System 1（快速直觉）和 System 2（慢速深思熟虑）思考系统，允许模型在解决推理任务时动态配置这两种模式。Dualformer 在训练时使用随机化的推理轨迹丢弃策略，模仿人类在决策时使用捷径的行为，从而在保持推理能力的同时减少了计算成本。在实验中，Dualformer 展示了在快速和慢速模式下优于基线模型的性能，并且能够生成更短的推理轨迹和更多样化的解决方案。此外，研究还表明，结构化的轨迹丢弃技术可以应用于大规模语言模型的训练，提高解决数学问题的效率和效果。
实测13个类Sora视频生成模型，8000多个案例，一次看个够,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938891&idx=4&sn=e578dab362a5a039221f5dfc1870d691&chksm=84e7da75b3905363816d41f13acd3342c7fc4983ddae0edfe6f1ab42103a79b3735b30663717#rd,2024-10-16 12:32:20,腾讯AI Lab和中科大联合发布了一份针对类SORA视频生成模型的测评报告，评估了13个主流模型（包括10个闭源和3个开源模型），生成了超过8000个视频案例。报告强调了人眼观感的重要性，通过700多个生成提示词和图片，从多个维度测试了模型在文生视频、图生视频和视频到视频生成等方面的能力。视频生成的测评涵盖了垂类场景、客观评价角度、应用和落地能力等多个方面。开源模型的性能目前仍落后于闭源模型，主要差距在于训练资源、模型规模、数据质量和数量。报告提出了视频生成领域的挑战和未来研究方向，如复杂动作理解与生成、多模态视频生成等。所有生成结果已公开，供社区进行深入研究。
AI智能体引擎加持：天玑9400让「完全体」AI手机提前问世了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938690&idx=1&sn=bf375654bd21c5958ba76693f42287b9&chksm=84e7d93cb390502ac4621605760f824ff1e601487a0313146b168f1d38b8847005f3dbf6f173#rd,2024-10-15 14:39:38,联发科推出了新一代旗舰5G智慧体AI芯片天玑9400，该芯片在AI算力和能效上取得了显著提升，成为2024年旗舰手机芯片的标杆。在AI Benchmark最新榜单中，天玑9400以6773分的成绩排名第一，是上一代的1.4倍，而且在进行AI计算任务时平均功耗降低了35%。该芯片支持端侧高画质视频生成、AI训练、多模态大模型推理等功能，实现了AI应用生态的全面承载。此外，天玑9400还首发了“AI智能体化引擎”，支持端侧智能体级硬件加速，推动AI手机从“智能”到“智慧”的转变。天玑9400将首先应用在vivo X200系列手机上，其他品牌也将陆续推出搭载该芯片的产品。
追逐AGI！微软AI副总裁、Phi小模型领导者Bubeck将加入OpenAI,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938690&idx=2&sn=119410b0725105b35e4255908c440e82&chksm=84e7d93cb390502a21bcc0dbc97b06a8922d5eb954fd02fb2879568f19ee1d56bf27360e36da#rd,2024-10-15 14:39:38,微软人工智能副总裁和杰出科学家Sebastien Bubeck宣布离职，他将加入最近人事变动频繁的OpenAI。Bubeck在微软工作了近十年，领导开发了包括Phi-3在内的高效语言模型。微软发言人表示，他们感谢Bubeck的贡献，并期待与他在OpenAI的工作中保持合作。Bubeck的研究领域包括凸优化、在线算法和对抗稳健性，他在这些领域获得了多项最佳论文奖。他的工作现在集中在理解智能如何在大语言模型中出现，以及如何通过这种方法来提升模型智能，可能朝着构建AGI（人工通用智能）的方向发展。此前，他的一篇关于GPT-4的论文引起了广泛关注，认为GPT-4可能是AGI系统的早期版本。
北大林宙辰团队全新混合序列建模架构MixCon：性能远超Mamba,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938690&idx=3&sn=52e98eaf0211aa5bffd68a5b516c1fb2&chksm=84e7d93cb390502a0a1c04336fbf2f8250b0c3094ac30afe1a5b9d5eba4e5856aafd2534de2f#rd,2024-10-15 14:39:38,北京大学的研究人员提出了一种名为MixCon的新混合序列建模架构，旨在解决现有模型在捕捉长程依赖和高效建模序列方面的挑战。MixCon结合了线性注意力Transformer、线性RNN和MoE模型的优点，通过创新的Conba模型架构和自适应控制机制，提高了处理长序列的效率和适应性。实验结果显示，MixCon在性能和吞吐量上优于同类模型，如Mixtral、Mamba和Jamba，并在多任务基准测试中表现出色。该论文已发表在European Conference on Artificial Intelligence (ECAI) 2024上。
大模型合成数据机理分析，人大刘勇团队：信息增益影响泛化能力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938690&idx=4&sn=1c8a9420fa799e2d8074d7e9fb0bf9c8&chksm=84e7d93cb390502ab9d44a9d0c058618f1efa9b8c66f2fa1491d2cb7928dd943c1df8c783451#rd,2024-10-15 14:39:38,研究人员探索了大语言模型（LLMs）后训练阶段中合成数据的理论理解，证明了模型的泛化能力取决于生成模型带来的信息增益。他们提出了互信息泛化增益（GGMI）的概念，阐述了信息增益与泛化能力之间的关系。合成数据在缺乏高质量特定领域数据时成为重要的训练资源，本文为合成数据在模型训练中的应用提供了理论基础，有助于优化合成数据生成技术并提升模型性能。
扩散模型训练方法一直错了！谢赛宁：Representation matters,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938369&idx=1&sn=7a3b65aba8a1eff4dc8a2f4f89f95b84&chksm=84e7d87fb3905169531db6e7b5fad75b382e415566b36bba12dc096a4746d28276185702679d#rd,2024-10-14 12:10:51,研究人员发现，使用错误的方法训练扩散模型可能会导致性能下降。纽约大学的研究者提出了一种名为REPA（表征对齐）的技术，该技术能简化扩散Transformer的训练过程并提高其性能。REPA通过将预训练的自监督视觉表征与扩散模型的内部表征对齐，提升了模型的训练效率和生成质量。这种方法显著提高了模型的收敛速度，例如，相比于原生模型，REPA能将收敛速度提升17.5倍以上，并在无分类器引导下实现了当前最佳的FID分数（1.42）。这项研究强调了在生成模型中使用有意义的表征的重要性，并表明表征对齐对于优化扩散模型的性能至关重要。
首个o1复现开源RL框架OpenR来了，UCL、上交等高校联合团队发布,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938369&idx=2&sn=30b2101be17d656c6d29b1234e521d3e&chksm=84e7d87fb3905169da0f3d10a617a698faba58b732f18786b366be3801aa102af48ea81bce8d#rd,2024-10-14 12:10:51,伦敦大学学院、上海交通大学、利物浦大学、香港科技大学（广州）和西湖大学的研究团队联合开源了首个类o1全链条训练框架OpenR，旨在增强大型语言模型的复杂推理能力。OpenR是一个集过程奖励模型（PRM）训练、强化学习和多种搜索框架于一体的开源代码库，受到了OpenAI的o1模型启发，采用基于模型的方法超越传统自回归方法。研究团队通过在MATH数据集上的实验展示了OpenR的有效性，开源了包括代码、模型和数据集在内的整个框架，以促进推理领域的开源社区发展。
图灵奖得主Yoshua Bengio新作：Were RNNs All We Needed?,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938369&idx=3&sn=c0fc8dd15e96a254baaec4d834e75ca3&chksm=84e7d87fb390516902ad6a0722eda2745ba58adf07d9f507dabfe67779729867e9693d0e700e#rd,2024-10-14 12:10:51,这篇文章介绍了Yoshua Bengio团队的研究，他们发现简化版的LSTM和GRU模型在去掉隐藏状态依赖后，性能可以与Transformer相媲美。通过去掉输出范围的限制，创建了minLSTM和minGRU，这些简化模型不仅训练参数显著减少，而且可以并行训练，例如在上下文长度为512的情况下，速度提升了175倍。这些发现挑战了Transformer在自然语言处理中的主导地位，并重新燃起了对循环序列模型的兴趣。研究者还通过实验比较了minLSTM、minGRU与传统RNN和最新序列模型的效率，显示了简化RNN的潜力。
Evaluation is All You Need！首个开源多模态大模型通用评测器LLaVA-Critic,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938369&idx=4&sn=ee475dc1e7f2180a303d8a09e4cdaa23&chksm=84e7d87fb3905169c8a1168dd72b75d7fb410959d99f0ca657332ca2c0059202b42a4c9aae51#rd,2024-10-14 12:10:51,来自字节跳动和马里兰大学的研究团队发布了首个用于多任务评测的开源多模态大模型 LLaVA-Critic，旨在启发社区开发通用大模型评测器。研究团队构建了一个涵盖了多样化评测场景和评分标准的评测指令遵循数据集，并在这一数据集上训练 LLaVA-Critic，使其能对模型回复给出评分和理由。LLaVA-Critic 在多个多模态评测任务中与 GPT-4o 的打分一致性进行了验证，表现出了高一致性，并在偏好学习中作为奖励信号提升模型性能。该模型的发布为自动评测多模态大模型的开放式回复提供了一个可行的开源替代方案。
长文本、语音、视觉、结构化数据全覆盖，中国移动九天善智多模态大模型震撼发布,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938248&idx=1&sn=3d1cef17c3a1d34b27b3fd634649104f&chksm=84e7dff6b39056e0e79b8763ef92ca0c300791b850298f5a7b32ba71782a5b3f97e55a85bee7#rd,2024-10-13 17:46:25,中国移动在全球合作伙伴大会上发布了九天善智多模态基座大模型，这是其全栈国产化、复杂系统智能化的最新AI成果。该模型强调平衡技术卓越与社会责任，能处理长文本、实现全双工语音交互、处理图像和视频以及结构化数据。模型在多项国际竞赛中取得优异成绩，并在文本理解、语音交互、视频生成和结构化数据分析等方面展现技术突破。中国移动致力于打造行业领先的AI生态，并通过“九天揽月”合作计划与业界共同推进大模型技术的发展和行业应用。
除了Ilya，刚拿诺奖的Hinton还教出了这些AI博士,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938248&idx=2&sn=0ba5c1e6a446febdff62598a218391ae&chksm=84e7dff6b39056e0448aa870e6e66bdb62dc95a68e82fb8f6fd62f5fdea40a36d9641e1aca15#rd,2024-10-13 17:46:25,这篇文章是关于人工智能领域的先驱Geoffrey Hinton的一些最新动态和他的学生们的成就。Hinton是2022年诺贝尔物理学奖得主，他在AI领域的研究产生了深远影响。他在谷歌担任首席科学家，并培养了40位博士生，其中包括知名AI专家Ilya Sutskever和Ruslan Salakhutdinov。在一次演讲中，Hinton表达了对学生成就的自豪，并呼吁关注AI安全和基础研究。文章还列举了自1987年以来Hinton指导的博士生的名单，他们在各自领域做出了重要贡献。
解锁具身 Scaling Law 需要先搞定异构数据吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938248&idx=3&sn=4d788c8a2f47ffb29f4d37cb4a409852&chksm=84e7dff6b39056e0f7d2ac3652407ca59e3ed601d5251ddba433675afd08b480f827c8a7b1d6#rd,2024-10-13 17:46:25,这篇文章探讨了具身智能和AI基础设施领域的三个关键议题。首先，文章指出处理异构数据是解锁具身智能Scaling Law的必要条件之一，但并非充分条件。具身智能面临着异构数据集和任务的挑战，需要解决不同机器人和环境的数据差异。其次，OpenAI和科技巨头们在建设AI数据中心和多数据中心分布式训练方面进行了竞争，以提升AI基础设施能力，其中微软和OpenAI可能已经实现了多数据中心训练。最后，Scale AI的创始人Alexandr Wang强调数据是新一代AI发展的核心，高质量的数据对于语言模型训练至关重要。本期通讯还包含了其他AI和Robotics领域的29项重要动态。
陶哲轩众包数学项目完成度99.99%：仍未看到AI工具的重大贡献,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938248&idx=4&sn=2808623a96e4904656f2a4de4132da60&chksm=84e7dff6b39056e015fc15b8f4904a78374225074b8e972e224035da9fa7f9dd8c3e540876bc#rd,2024-10-13 17:46:25,著名数学家陶哲轩发起的众包数学研究项目接近完成，目标是确定4694条magma方程定律之间的蕴含关系。该项目利用专业和业余数学家、自动定理证明器、AI工具和证明辅助语言Lean进行合作。目前，99.9963%的蕴含关系已被证明为真或假，只剩下极少数待解决。参与者使用各种工具，包括 Lean 和自动定理证明器，发现新的证明技术和代数结构。虽然现代AI在项目中起到辅助作用，但旧式自动定理证明器在解决核心任务上更为有效。项目已取得显著进展，但仍有一些复杂蕴含未解决，期待AI在解决这些难题上发挥更大作用。
AI作曲缺数据，浙大GTSinger数据集上线：适配所有歌声任务、带有真实乐谱,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938248&idx=5&sn=a2c668cb6118ad5213e018c0f3f08267&chksm=84e7dff6b39056e0090b462d82bde49486e2708ac6ad93a4d4c5e01b33c7adbb8a6e5cb86564#rd,2024-10-13 17:46:25,浙江大学的研究团队推出了一个名为GTSinger的全球化、多技巧的大型开源高质量歌声数据集，旨在促进歌声合成、技巧识别、歌声风格迁移和语音到歌声转换等任务的发展。GTSinger包含80.59小时的专业歌手录制的歌声，涉及九种语言和多种歌唱技巧，提供真实乐谱、人工音素对齐和全局风格标签。这个数据集解决了现有开源数据集在质量、多样性和任务适用性上的局限，并在多个歌声任务上提供了基准测试。GTSinger已在NeurIPS 2024 Datasets and Benchmarks Track被接收为Spotlight，并已开源数据集和相关代码。
特斯拉机器人真这么丝滑？科技博主在线「打假」：远程操控的,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938248&idx=6&sn=139bba465109e820c9ad9f312b285ee1&chksm=84e7dff6b39056e00b5175c3f4c151345f72da52ab339f4281fc39e608bca65f6df7390ba5d3#rd,2024-10-13 17:46:25,特斯拉在发布会上展示了新一代人形机器人Optimus，马斯克宣称这款机器人能执行各种任务，如照顾孩子、做家务、调酒等，并有望以2万到3万美元的价格出售。社交媒体上出现了Optimus的视频，展示其调酒、唱歌和对话的能力。然而，科技博主质疑Optimus的自主性，指出其可能需要远程协助，并在与机器人的对话中得到了含糊的回应。有报道称，Optimus的某些展示可能是通过远程控制和动作捕捉技术实现的，而不是完全自主的人工智能。特斯拉此前曾被发现篡改Optimus的演示视频，显示出人类操作的痕迹。目前，Optimus的自主执行能力仍存在疑问。
六年、六届学生接力，共铸上交大图像合成工具箱libcom,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938125&idx=1&sn=ca109a7d527b1749c4e9471b3230ff4f&chksm=84e7df73b3905665b00b6338061f241beb7883787b676a25ba3a6ba7689455c39a57d35822c8#rd,2024-10-12 12:01:10,上海交通大学牛力团队持续四年更新的图像合成综述报告已进入第5个版本，论文详细介绍了图像合成领域的子任务、数据集、传统和深度学习方法。团队还研发了图像合成工具箱libcom，经过六年研发，已更新至1.2万次下载。libcom提供了包括图像融合、合理性评估、颜色迁移、图像和谐化、阴影生成等十几项功能，涵盖了图像合成的多个方面。团队现诚邀对图像合成感兴趣的人士合作，共同改进和扩展libcom项目。
OpenAI今天Open了一下：开源多智能体框架Swarm,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938125&idx=2&sn=8285b16c33c7a34a3bac158ed7961c9e&chksm=84e7df73b39056656dafaea05ae387f4a3c327bac4cd2aa4bc0f99b4c2edca021aef96644e13#rd,2024-10-12 12:01:10,OpenAI 开源了一个实验性的多智能体编排框架 Swarm，主打工效和轻量级特性。Swarm 通过智能体和交接两种原语抽象来实现多智能体的协作和执行，适合处理大量独立功能和指令的情况。它由 Chat Completions API 提供支持，无状态，适合需要高度透明度和细粒度控制的场景。Swarm 的核心组件包括客户端、智能体和函数，支持智能体间的交接和上下文变量更新。项目已在 GitHub 上开源，引起热议，被认为能简化多智能体用例的工作流程。
李飞飞：不要数字孪生，要数字表兄弟，一张照片生成机器人训练场景,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938125&idx=3&sn=211ee6420a93f571599e766197f3e8a9&chksm=84e7df73b39056659b370c9c00aeec8670a9204a0776bb56d0dafb60d8c58d8b968775a6db96#rd,2024-10-12 12:01:10,斯坦福大学李飞飞团队提出了“数字表亲”（digital cousin）的概念，以解决真实数据到模拟数据转换中的问题。数字表亲不是真实物体的精确虚拟复制品，而是具有相似几何和语义特征的模拟版本。这种方法能降低生成虚拟环境的成本，同时提升机器人的跨域泛化能力。团队提出了自动数字表亲创建（ACDC）方法，能从RGB图像中提取信息，匹配并生成模拟场景。实验表明，基于数字表亲训练的机器人策略在零样本虚拟到真实迁移条件下，成功率超过基于数字孪生的策略。ACDC能保留输入场景的语义和空间细节，并实现模拟到真实世界的策略迁移。
NeurIPS 2024 | Transformer长度外推，全新位置编码DAPE大幅提升模型性能,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650938125&idx=4&sn=557e3449fd6925f204f431765abae339&chksm=84e7df73b390566578db474b880f8c0515db112aa7b7e2cccd56d7cdecf9cc132bff5ec89b24#rd,2024-10-12 12:01:10,这篇论文介绍了一种新的位置编码方法，称为Data-Adaptive Positional Encoding（DAPE），用于改善Transformer模型处理长文本的性能。传统的绝对位置编码和相对位置编码在处理超长文本时存在局限性，而DAPE通过动态调整位置编码，使其能根据输入上下文自适应地调整。这一方法在模型训练长度和长度泛化方面表现出显著的性能提升，特别是在处理超出训练长度的文本时。论文已被NeurIPS 2024接收，相关代码已开源。实验结果显示，DAPE在不同长度和模型规模上均优于现有的位置编码技术，表明其在长文本处理中的优越性和适应性。
VBench评测第一，5周访问量暴增8倍多! 这款国产AI视频生成器「压番」Runway,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937808&idx=1&sn=5e2f1edc5e0ac749774b16e4cb556392&chksm=84e7ddaeb39054b8fcdf31f90ddf0a1528e940e14e429aa5a9d4c73ed3871b20e447f164bb59#rd,2024-10-11 12:39:13,海螺AI近期推出了新功能“图生视频”（I2V），该功能在AI视频生成领域引发了关注。海螺AI的视频模型abab-video-1上线后，其网页版视频创作入口吸引了大量专业人士，包括电影导演和数字艺术家等。在AI产品榜单上，海螺AI网页版的访问量在过去一个月内增长了8倍，成为全球和国内增速最快的AI产品。用户使用海螺AI创建了各种风格的视频，包括超现实、科幻和动漫等，其在人物运动和情绪表达上的表现受到好评。海螺AI在视频生成的流畅性、细节和连贯性上表现出色，被认为在某些方面甚至超越了其他领先视频生成器。此外，海螺AI的新手友好性也得到了认可，使得更多人能够轻松创作高质量的AI视频。目前，海螺AI的视频模型在VBench评测中排名第一，并在VideoGen-Eval项目中被肯定了其在文本控制方面的强大能力。海螺AI的“图生视频”功能可以准确识别图片并理解复杂的文本指令，为用户提供了广阔的创作空间。
国产模型首开Hugging Face月度下载全球第一，智源BGE累计下载逾亿,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937808&idx=2&sn=984e16490f78fd6ad45d567b2102de74&chksm=84e7ddaeb39054b8d0b948f11870eacc6b51a2f8181d9338dce28d801c7697d7a1a3f838f194#rd,2024-10-11 12:39:13,北京智源人工智能研究院的BGE模型在Hugging Face月度榜单上登顶，成为中国首个获得该荣誉的AI模型。BGE下载量超过数亿次，是下载量最多的国产AI系列模型，提供多场景、多语言、多功能和多模态的技术支持。该模型在BEIR、MTEB、C-MTEB等评测中表现优秀，且开源开放。BGE在检索增强（RAG）技术中发挥关键作用，为大语言模型提供信息检索服务，支持多种任务和语言。智源研究院通过开发通用向量模型解决RAG技术的检索环节挑战，BGE v1和BGE M3等迭代模型在综合性能和多语言支持上取得显著成果。BGE系列模型的开源和社区应用促进了相关技术的发展和商业价值，未来目标是构建通用搜索智能，将大模型与检索工具深度融合。
一文看懂LLM推理，UCL汪军教授解读OpenAI ο1的相关方法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937808&idx=3&sn=755bef63911a07ab9644cc9eb357b1cf&chksm=84e7ddaeb39054b8ec3aa38898c9fce3389a47f9dabb03932faaa7858841e3bd4a2686422d12#rd,2024-10-11 12:39:13,伦敦大学学院（UCL）人工智能中心的汪军教授撰写了关于OpenAI的o1模型的“LLM推理教程”，该模型通过强化学习和原生“思维链”（NCoT）技术，展现出强大的推理能力，特别是在数学和编程任务上的表现远超前代模型ChatGPT。o1模型能够进行深度思考，允许在推理过程中花费更多时间。其推理能力的增强类似于人类的系统2思维，即深思熟虑和计算性的推理过程。汪军教授将在RLChina 2024大会上分享相关研究，并发布开源框架以促进o1模型的进一步发展。o1模型的创新可能为整合人类价值观和提高AI安全性提供新途径。尽管存在挑战，如计算复杂性和需要更高级的计算架构，但LLM的推理能力正逐步接近人类的深度思考模式。
AMD发布最强AI芯片，对标英伟达Blackwell，2025年上市,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937808&idx=4&sn=7e69a58bf9854f11bd432c9c03d5ef16&chksm=84e7ddaeb39054b86cb7afe2bc29bcc227853aad66ce87c841799977a32429ce09678f6358ea#rd,2024-10-11 12:39:13,AMD在一场活动中发布了新一代Ryzen AI Pro CPU、Instinct AI计算卡和EPYC AI芯片等产品，致力于覆盖从PC到服务器的AI计算。新款Ryzen AI Pro 300系列CPU采用4nm工艺，结合GPU和NPU，提供高达55 TOPS的AI算力，支持微软的Copilot+功能，以实现更高效的协作和本地AI处理。此外，AMD还推出了Instinct MI325X和MI355X加速卡，对标英伟达的AI芯片，提供更高的内存容量和带宽，以及增强的推理性能。AMD的下一代AI网络互联技术，如Pensando Salina DPU和Pollara 400 NIC，旨在提升数据中心的性能和效率。最后，AMD还展示了第五代EPYC“Turin”处理器，用于企业、AI和云服务，最高端型号为192核的EPYC 9965。
NeurIPS 2024 | 大模型的词表大小，同样适用于Scaling Law,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937808&idx=5&sn=3d7b552cddae4bcb449f682cf24f7504&chksm=84e7ddaeb39054b8fadf4d1a4dbe543b2cb2bce6deda0cd57a018df976a21f535f5ba3046c11#rd,2024-10-11 12:39:13,这篇论文探讨了大型语言模型（LLMs）的词表大小对其性能的影响。以往的研究主要关注模型参数和训练数据量，而忽略了词表大小。研究者通过训练不同词表配置的模型，提出了三种方法预测最优词表大小：基于FLOPs的、基于导数的和基于损失函数参数拟合的。结果表明，更大的模型需要更大的词表，并且存在一个计算预算下的最优词表大小上限。论文中提出的预测方法在实践中有效，使用预测的最优词表大小可以提高模型在多个下游任务的性能。这为优化LLMs的效率和性能提供了新的视角。
不出所料！Jürgen又站出来反对Hinton得诺奖，Nature也炮轰提名过程不透明,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937457&idx=1&sn=4d4b7fac1d38cfcc322a8438160763c2&chksm=84e7dc0fb3905519591526e8e1c10a78a450e89d27a0d8bc208c803d3485bb91fe8b532dede5#rd,2024-10-10 12:33:28,这篇文章讨论了2024年诺贝尔物理学奖被授予John J. Hopfield和Geoffrey E. Hinton两位AI研究者后引发的争议。一些人质疑Hinton与物理学的关系，以及AI科学家为何能获得物理学奖。其中，LSTM之父Jürgen Schmidhuber在社交媒体上指控Hopfield和Hinton的工作存在剽窃和错误归属，特别是关于Hopfield网络和玻尔兹曼机的贡献。他列举了Amari等人的工作被忽视或未得到适当引用的例子。然而，一些网友指出，学术界存在不同的术语和独立发现，并且 Hopfield 网络的贡献归功可能有历史复杂性。文章还提到了Nature杂志对诺贝尔奖提名过程的批评，认为需要更多透明度和包容性。
开源软件Gradio上新5大功能，几行Python代码，构建Web应用程序,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937457&idx=2&sn=350505e18f2456a7f3e4c0a9e24e7797&chksm=84e7dc0fb390551917d5b6f08709480e9fcc33f73ce43c84319a986c6eb5ec30d6d1afa16bff#rd,2024-10-10 12:33:28,Gradio 5，一个开源Python软件包，用于快速构建机器学习模型和Python函数的Web应用程序，已由Hugging Face发布稳定版本。Gradio使开发人员无需JavaScript、CSS或Web托管经验即可创建演示，并具有内置的共享功能。新版本Gradio 5注重企业级安全，经过独立审计并修复了所有安全问题。它提供了性能改进，包括服务器端渲染以实现快速加载，更新了界面和核心组件，支持实时应用和流媒体，增加了新的内置主题，并加强了安全性。此外，Gradio 5还引入了一个AI Playground，允许开发人员使用自然语言提示生成和预览Gradio应用。这个工具简化了AI驱动的Web应用程序的构建过程，并可能对企业人工智能开发产生影响。
CMU副教授：在多智能体流行的当下，不要忽视单智能体系统,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937457&idx=3&sn=a5613781443fff0fb203c78a575556f5&chksm=84e7dc0fb3905519ff4f7de0b831ec1735ce6a813c755cb83f6a8dfbb894441e00b2a3edb9c2#rd,2024-10-10 12:33:28,卡内基梅隆大学的副教授 Graham Neubig 在文章《Don't Sleep on Single-agent Systems》中指出，尽管多智能体系统是当前人工智能领域的热门研究方向，但单智能体系统也不应被忽视。他讨论了构建智能体的三个关键元素：大语言模型、提示和动作空间，并通过举例说明了多智能体系统可能存在的问题，如结构匹配、上下文信息传递和可维护性。Neubig 提倡考虑建立强大的单智能体系统，使用单一的大语言模型、动作空间和提示工程技术，以提高系统的简单性和维护性。文章还提到了一些解决这些问题的方法，如提示词连接和检索增强式提示。
NeurIPS 2024｜SparseLLM：突破性全局剪枝技术，大语言模型稀疏化革命,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937457&idx=4&sn=3d462fd03d6038ddb9182b816937cc83&chksm=84e7dc0fb390551909cee9fb910b08170276669591f11d73aac5f1fa2afb13ee7a5d42e8d96e#rd,2024-10-10 12:33:28,这篇文章介绍了一种名为SparseLLM的新方法，它旨在提高预训练语言模型的效率，特别是针对大语言模型的全局剪枝。当前，大模型的压缩通常采用局部剪枝，但由于忽略了层间的相互依赖，这可能导致次优性能。SparseLLM通过引入辅助输入和输出，将全局剪枝问题分解为可管理的子问题，从而在高稀疏度下实现高效优化，同时保持模型性能。这种方法在内存消耗较低的情况下实现全局剪枝，超越了现有的剪枝技术。该研究由埃默里大学和美国阿贡国家实验室的研究人员合作完成，并已被NeurIPS 2024接收。实验表明，SparseLLM在不同规模的预训练语言模型上，尤其是在高稀疏度条件下，表现出色。
GR-2登场！ByteDance Research提出机器人大模型，具备世界建模和强大泛化能力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937291&idx=1&sn=276b0a20021e1214c99e2b96435e0eed&chksm=84e7d3b5b3905aa3e0bad9f1967188ae0587e1a530c1bef0d5eb8c2db743478e97ff7885bad5#rd,2024-10-09 14:07:34,ByteDance Research推出第二代机器人大模型GR-2，该模型在3800万个互联网视频片段上进行生成式训练，具有强大的泛化能力和多任务通用性。GR-2通过预训练和微调过程学习，能预测动作轨迹并生成视频，平均成功率高达97.7%。模型规模的增加显著提升其性能，能处理复杂的任务和未知场景，展现出在多任务学习和环境适应方面的优秀能力。此外，GR-2还能与大语言模型结合，完成与人类的互动任务。尽管仍有进步空间，GR-2预示着机器人大模型技术的巨大潜力。
这篇论文非常火！差分Transformer竟能消除注意力噪声，犹如降噪耳机,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937291&idx=2&sn=d3781b4720aedd1410ca317c3e304836&chksm=84e7d3b5b3905aa3ecb74fe17827d4dd9fc2eb58af7385af905ea864c7b5d9c4669c0fa2def6#rd,2024-10-09 14:07:34,这篇文章介绍了微软研究院和清华大学的研究人员提出的一种新型Transformer架构，称为差分Transformer（Diff Transformer）。Transformer模型在处理序列建模时有时会过度关注不相关的上下文，产生注意力噪声。差分Transformer通过引入差分注意力机制来解决这一问题，该机制可以放大对答案范围的注意力并消除噪声，提高上下文建模能力。文章详细描述了差分Transformer的架构，包括差分注意力模块和多头差分注意力机制，并与常规Transformer进行了对比。实验结果显示，差分Transformer在语言建模、可扩展性、长上下文处理、关键信息检索等方面表现出优越性能，且能减少上下文幻觉和激活异常值，有利于模型量化。
综合RLHF、DPO、KTO优势，统一对齐框架UNA来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937291&idx=3&sn=346e42d7121fddb38ace5ff2b1228a19&chksm=84e7d3b5b3905aa39c90a292cd4ee21f4f2f15c260cafa88cec6d34b72975287dbcaf9f86a1b#rd,2024-10-09 14:07:34,来自Salesforce和厦门大学的研究团队提出了一种名为UNA的新方法，旨在统一大规模语言模型（LLM）的对齐技术。RLHF、DPO和KTO等方法虽然有助于优化LLM的输出，但仍存在如内存占用高、训练不稳定和处理反馈类型有限等问题。UNA通过一个通用的隐式奖励函数将这些方法集成到一个监督学习框架中，简化了训练流程，提高了性能、稳定性和效率。实验表明，UNA在多个语言理解和生成任务中优于传统方法，且训练速度快、内存消耗低。这项工作为LLM对齐提供了一个更灵活和适应性强的解决方案。
1万Star量，最火AI证件照项目怎么训的？西电博士手把手在线教学,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937291&idx=4&sn=5c9b902eb7255f8026551c751b4e58a8&chksm=84e7d3b5b3905aa317f8a81f8e7b27ace3b54f8436ae5a3782e206562ab2317cd8912bf97201#rd,2024-10-09 14:07:34,HivisionIDPhotos是一个开源的AI证件照项目，它提供了面部定位、背景去除、尺寸裁剪和美颜等功能，帮助用户轻松制作标准证件照。该项目在Github上获得了超过10.7千的星标，因其简单操作和出色效果受到欢迎。开发者可以使用Gradio、API接口或Docker等多种方式来利用这个工具。该项目的作者、SwanLab联合创始人林泽毅将在机器之心的线上分享中介绍HivisionIDPhotos的开源历程，并指导如何训练AI抠图模型。分享包括项目介绍、成功因素以及在线教学内容，并提供相关代码、数据集和教程。直播将在10月12日19:00-20:00进行。
潞晨Video Ocean震撼发布，打开了「任意角色、任意风格」的视频魔盒,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937076&idx=1&sn=177e9797990d68619d585ed4ae6c9c67&chksm=84e7d28ab3905b9ca2aca0def6244c19ca0af9c93e5ed7cbbb69a6bbc034774a38aa1d6077c6#rd,2024-10-08 14:03:49,潞晨Video Ocean推出了全新升级的模型，提供了文生视频、图生视频和角色生视频三大突破性功能，可以创建任意角色和风格的逼真或超现实短视频内容。用户可以通过这个平台打造电影级视觉体验，例如让熊猫拉小提琴、让橘猫扮演海盗等。新模型在视频质感和功能上都有显著提升，还引入了图生视频功能，可以从图片中创造动态场景。此外，角色生视频功能允许用户自定义角色并生成个性化视频。体验地址：https://video.luchentech.com/zh-CN。
陈丹琦等人组织的COLM奖项公布：被ICLR拒稿的Mamba入选杰出论文,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937076&idx=2&sn=bbeb2245f04fc34876543557ccd31ae4&chksm=84e7d28ab3905b9ca6bfb0f1d6729e37c8b5ce2c29de19c1717139e5f9fd7c859d857255cbbe#rd,2024-10-08 14:03:49,很抱歉，您还未提供具体的文章内容。请您提供一篇文章，我将为您生成摘要。
微调大模型，AMD MI300X就够了！跟着这篇博客微调Llama 3.1 405B，效果媲美H100,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937076&idx=3&sn=d8622d9ae94a83d1d857ab9455faf77d&chksm=84e7d28ab3905b9cb3e3c2ffb8b5ff5036a73da81439e59d6376d6af39eb180319104c000c43#rd,2024-10-08 14:03:49,创业公司Felafax致力于简化AI训练集群的搭建，目标是降低机器学习的训练成本。该公司认为AMD的GPU，特别是MI300X系列，提供了比英伟达更高的性价比。Felafax的联合创始人Nikhil Sonti分享了如何使用8张AMD MI300X GPU和JAX库微调开源大模型LLaMA 3.1 405B，所有代码已开源。JAX库在多硬件并行支持、独立于底层硬件和高度适应性方面具有优势，使其成为在非英伟达硬件上训练AI模型的合适选择。在8张AMD MI300X GPU上，LLaMA 405B模型的训练速度达到35 tokens/秒，内存效率稳定在约70%。
TPAMI | 安全强化学习方法、理论与应用综述，慕工大、同济、伯克利等深度解析,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650937076&idx=4&sn=7e466e2c9bcf65060c8202f7118dc93c&chksm=84e7d28ab3905b9c84fe31920c4f38d766e62c84c0659ffc8aa26ffcf2d4a9027033b5733db7#rd,2024-10-08 14:03:49,本文介绍了安全强化学习（Safe RL）的重要性，它在AI应用如自动驾驶、机器人和推荐系统中确保系统的安全性。文章概述了一篇被IEEE TPAMI接收的综述论文，该论文由来自慕尼黑工业大学、同济大学、加州大学伯克利分校等机构的研究人员合作完成。安全强化学习旨在在优化奖励的同时满足安全约束，解决了如何保证策略安全、需要多少训练数据、应用进展、评估基准以及未来挑战等问题。文章还讨论了基于模型和无模型的安全强化学习方法、理论分析以及基准测试环境，并指出了未来的研究方向，包括与博弈论和信息论的结合。
Cursor创始团队最新访谈：如果Github整合o1，Cursor可能要倒闭了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936991&idx=1&sn=b1ef163dcd6eae74dfdea1ada2604336&chksm=84e7d2e1b3905bf75c1f0517845aa1db4e46dcadcb0bad1a3befdfda6e8881a0ede5447198cb#rd,2024-10-07 12:59:01,Cursor是一款基于VS Code的AI编程工具，它利用AI辅助编程并提供多种强大功能，如代码编辑和自动完成功能，受到了编程和人工智能领域的广泛关注。Cursor的团队成员在与Lex Fridman的对话中透露，他们提前获得了GPT-IV的使用权，这促使他们开始构建更广泛的应用愿景。Cursor的一个亮点是其代码差异功能，它能够以红色和绿色显示代码修改，并通过diff接口呈现给用户。团队正在不断优化这一功能，以处理多个文件和提供更好的用户体验。此外，Cursor还利用定制模型和前沿模型的集成，实现更智能的代码修改和自动应用。在机器学习细节方面，Cursor使用微调过的模型来优化代码建议和应用，同时通过投机编辑（speculative edits）提高处理速度。关于模型的比较，Cursor团队认为没有一个模型在所有方面都是最好的，Sonnet目前在处理代码编辑和速度上表现优越。团队强调了提示词设计、上下文管理和模型智能等方面的重要性，并致力于不断优化Cursor的功能和用户体验。
机械手「成精」了，能从手臂上溜走，拿完够不到的东西，还能爬回来自动合体,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936991&idx=2&sn=fd4c1f492c3e63c7bb86e4e2771833d9&chksm=84e7d2e1b3905bf7dfb72755e29a8119114896c1b5db36999cc9f780ae6ada39623b6d340dee#rd,2024-10-07 12:59:01,来自瑞士洛桑联邦理工学院和麻省理工学院的研究团队开发了一种“手脚并用”的机器人，这款机器人可以从手臂脱离，爬行到原本够不到的地方，识别并抓取物体，然后调整姿势爬回来，再与手臂重新接合。这款机器人能够自我移动，避免不必要的碰撞，同时通过反转手指实现正反手抓取，解决了传统机械臂在抓取和移动物体时的局限性。设计中，团队采用遗传算法优化了机械手的抓握和爬行能力，并在现实世界中测试了其抓握力和脱离、附着功能。虽然目前的演示仍需手动操作，但团队正在测试自动化版本。
ECCV 2024 | 新梦幻场景生成方法，高质量、视角一致、可编辑3D场景,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936991&idx=3&sn=e21943c20196116203e0668f626c9ccb&chksm=84e7d2e1b3905bf725db1008a6980f7482551f3f6ee23bbb728e468e51e7ad833aec56e028cd#rd,2024-10-07 12:59:01,来自中国科学技术大学、香港科技大学、香港理工大学和奥胡斯大学的研究者提出了一种新的3D场景生成方法DreamScene，该方法仅需文本描述就能生成高质量、视角一致且可编辑的3D场景。现有的文本生成3D场景方法存在低效、视角不一致和编辑性有限等问题。DreamScene通过形成模式采样和相机采样解决了这些问题，能高效生成高质量3D场景并保持视角一致性，同时支持对单个物体的编辑。实验结果表明，DreamScene在3D一致性、生成质量和编辑性方面优于现有方法。
AI博士如何做出有影响力的研究？斯隆奖得主弟子亲身讲述经验,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936977&idx=1&sn=b70f895dca1dc31aa524d95e72c338b8&chksm=84e7d2efb3905bf96d13f0923f1333196f212eeff1df80923db810fb94c3ccabe093f1c11775#rd,2024-10-06 13:02:52,本文是斯坦福大学NLP组博士生Omar Khattab关于如何在人工智能领域做有影响力研究的思考。他提出，应着眼于项目而非论文，选择有潜力、前沿且具有发展空间的问题，并提前两步思考问题。他还强调了快速迭代、将工作公之于众、发展开源研究和通过新论文继续投资项目的重要性。Khattab建议，发布开源研究成果时，要使其可用、有用、易懂，并建立社区，通过不同里程碑逐步提高影响力。开源研究需要平衡好研究质量和开源成果的有效性，而发布和持续发布是关键。
Sebastian Raschka最新博客：从头开始，用Llama 2构建Llama 3.2,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936977&idx=2&sn=fdb30176c232829dd16ced695e4f4294&chksm=84e7d2efb3905bf946d0b00e556e670aedc0530747552266a40e19db8bd1b7c5284a516893ab#rd,2024-10-06 13:02:52,本文介绍了如何将Meta的Llama 2架构模型逐步转换为Llama 3.2。Llama 3.2是一个轻量级的文本模型，可以在边缘和移动设备上运行，支持多语言文本生成和工具调用。与Llama 2相比，Llama 3.2具有更高的上下文长度和改进的RoPE（旋转位置嵌入）实现，以及分组查询注意力机制，以提高计算和参数效率。此外，文章还提供了转换模型的代码示例，并展示了如何加载预训练权重和tokenizer，以及如何使用模型生成文本。
Python程序到计算图一键转化，详解清华开源深度学习编译器MagPy,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936977&idx=3&sn=47d5d4bc2a4075c9ddc71f91a7d8d925&chksm=84e7d2efb3905bf9d37047643440f20aafeb4e9ee38b69cdc6ae63551004f63d3bbb43516086#rd,2024-10-06 13:02:52,清华大学计算机系PACMAN实验室开源了深度学习编译器MagPy，它能一键编译用户用Python编写的深度学习程序，自动将其转化为计算图表示，从而实现模型的自动加速。MagPy直接面向Python+PyTorch程序，避免了手动转换计算图的不便，旨在提供易用性和效率的双重提升。该工作由博士生张晨作为第一作者，翟季冬教授为通讯作者，相关研究在USENIX ATC'24会议上发表。MagPy旨在解决深度学习模型的性能优化问题，为非专业程序员提供更方便的模型开发加速工具。
告别CUDA无需Triton！Mirage零门槛生成PyTorch算子，人均GPU编程大师？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936977&idx=4&sn=2c267f731fa462fc48f8e2b37d7a964e&chksm=84e7d2efb3905bf99766e6cfb55187b75b877791614854ab1216824e788583046346fbc28be5#rd,2024-10-06 13:02:52,CMU的Catalyst Group团队发布了一款名为Mirage的PyTorch算子编译器，该工具允许用户在无需编写CUDA或Triton代码的情况下自动生成GPU内核，以实现更好的性能。随着GPU在AI领域的广泛应用，尤其是大语言模型的兴起，优化GPU计算效率成为重要任务。Mirage使用SuperOptimization技术，用户只需用Python描述计算过程，它将自动搜索并生成高效的GPU内核。相较于手动实现，如在Triton中编写FlashAttention内核，Mirage简化了编程过程，提高了生产力，并且在多个基准测试中，生成的内核性能提高了1.2到2.5倍。此外，Mirage还利用形式化验证确保生成内核的正确性。
Meta又给OpenAI一记重击，视频生成Movie Gen震撼登场，甚至可以配音、编辑,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936903&idx=1&sn=ce6d9d9b862c95a11fcfbc45ef0c7483&chksm=84e7d239b3905b2fc62f64be47bbd94b903a079b388d41ff31fbacd3c66458bf9351b740e267#rd,2024-10-05 09:01:57,Meta首次公开展示了他们的“突破性生成式AI研究”——Movie Gen，这是一个能够生成视频和音频的模型，可用于媒体制作和日常分享。Movie Gen的功能包括文本生成视频、编辑现有视频和图片生成视频，其在这些任务上的表现超过了行业内类似模型。该模型能够生成高质量的视频，包括人物动作、表情和背景细节，还能自动生成匹配的音乐和音效。Meta表示，Movie Gen结合了他们之前在图像、音频和视频生成的研究，并提供了用户更多的细粒度控制。虽然目前只是初次展示，但Meta的这一进展展示了视频生成技术的显著进步。
号称击败Claude 3.5 Sonnet，媲美GPT-4o，开源多模态模型Molmo挑战Scaling law,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936903&idx=2&sn=316f42606cfd78b61ff4fafb06ca96e4&chksm=84e7d239b3905b2fd9adf4b72e3e9350b415411f29cf5cdc244b3a9d350ab431baaecd42e6f2#rd,2024-10-05 09:01:57,创业公司Ai2发布了一款名为Molmo的开源多模态人工智能模型，该模型在视频中展示了强大的功能，如识别和描述物体，以及执行在线购物任务。Molmo在人类测评和一系列测试集中表现优秀，击败了多个顶尖模型，包括Claude 3.5 Sonnet和GPT4V，其性能可媲美GPT4o，但参数量更小。关键在于Ai2使用高质量的人工标注图像描述数据集进行训练，而非依赖大规模的合成数据。Molmo的模型架构简单，由预处理器、图像编码器、连接器和仅解码器Transformer LLM组成。此外，Molmo还引入了独特的二维“指向”数据，使其能以非语言方式回答问题和执行任务。Molmo的某些权重、推理代码和一个演示模型已经开源，未来还将发布更多相关资源。
ECCV 2024 | 像ChatGPT一样，聊聊天就能实现三维场景编辑,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936903&idx=3&sn=10c686d92dafed56a10eb9f3113fb18d&chksm=84e7d239b3905b2f82c8d949c1c7b564983ab5ea8692693e862b43410535dcb9cc0481027fc1#rd,2024-10-05 09:01:57,这篇文章介绍了Chat Edit 3D，这是一个由大语言模型驱动的交互式3D场景编辑框架，可以处理任意数量的视觉模型，允许用户通过文本指令进行复杂的3D场景编辑。传统方法通常限制了文本输入形式和编辑能力，而Chat Edit 3D通过Hash-Atlas网络将3D场景转换为2D图集编辑，从而实现更多样化和灵活的编辑操作。这种方法利用大规模语言模型解析用户输入，调用相应的视觉模型完成编辑任务，支持多轮对话和多种编辑功能，如对象移除、风格迁移、深度图预测等。Chat Edit 3D的代码已开源，为3D场景编辑提供了新的可能性和扩展性。
刚刚，OpenAI重磅发布交互界面canvas，让ChatGPT成为写作和编程利器,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936851&idx=1&sn=1186ceaa011198f68e537a877f93024a&chksm=84e7d26db3905b7b5d6623641a1b4f70cef66418c9be70b38718c156ba254826108fd28fe287#rd,2024-10-04 08:24:54,OpenAI发布了ChatGPT的新应用canvas，这是一个使用ChatGPT进行写作和编程的平台，类似于 Anthropic 的 Artifacts。canvas支持文本文件、代码、网页、SVG等多种输出格式，提供了一种新的交互方式，用户可以通过高亮和直接编辑与ChatGPT协作完成更复杂的任务。该功能由GPT-4o支持，目前处于Beta阶段，仅对ChatGPT Plus和团队用户开放，企业及教育用户将在下周获得访问权限，免费用户需等待正式发布。canvas旨在解决在对话式界面中进行内容修改的难题，提供了代码审查、日志添加、注释和错误修复等功能，并能支持多种编程语言。OpenAI对GPT-4o进行了训练，使其能作为协作伙伴进行目标性编辑和重写文档。canvas目前仍早期测试，未来功能将不断优化和扩展。
Noam Brown早已预示o1强大推理能力，演讲深度解析AI推理研究脉络,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936851&idx=2&sn=26f3fe5de73ea5686c2f1c8f467be7f8&chksm=84e7d26db3905b7bef3edf0e996c5647d4cef0d3f609ee2eaf9e6af37e438553eea77ae4d375#rd,2024-10-04 08:24:54,OpenAI的研究科学家Noam Brown在一次演讲中介绍了AI在游戏领域的研究突破，特别是搜索/规划算法在这些成就中的关键作用。他的研究涵盖了扑克、围棋和外交等游戏，强调了搜索/规划在改进机器学习模型的潜力。演讲中，Brown提到了2015年人脑与AI扑克竞赛中，AI虽然训练量大，但在决策速度上远超人类，这促使他认识到搜索策略的重要性。之后，他展示了搜索策略在扑克游戏AI中的显著效果，表明其带来的提升远超模型规模的增大。此外，他还讨论了搜索和规划对其他游戏任务的贡献，如围棋和合作策略游戏Hanabi。最后，Brown提到了外交游戏Diplomacy中达到人类水平的AI Cicero，它结合了规划和自然语言处理。他强调了规划在提升AI性能方面的重要性，并对未来研究方向提出了建议，包括通用性模型和外部验证器的研究。
5秒内快速生成、直出工业级PBR资产，三维扩散模型3DTopia-XL开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936851&idx=3&sn=685328498e6968bbdae490fa4b735594&chksm=84e7d26db3905b7b364a3fdb7a573da1575fd72c17f6f04afa47a17e69d4904c584ee239bba2#rd,2024-10-04 08:24:54,上海人工智能实验室和南洋理工大学推出了3DTopia-XL，这是一个能够从图像或文本直接生成具有物理渲染材质的高质量三维模型的系统。该模型使用了全新的三维表征PrimX和基于DiT的生成架构，拥有10亿参数，能在5秒内完成超写实三维模型的生成，生成的GLB格式资产可无缝导入到主流游戏引擎和工业设计软件。3DTopia-XL的代码、预训练模型和技术报告已开源，未来还将提供多模态输入的预训练模型。该模型在用户评测中在多个维度上超越了基于重建的主流方法，展现了在三维内容创作的潜力。
奥特曼赢家通吃！OpenAI再揽66亿美元新融资，还不忘「狙击」一把老同事Ilya,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936827&idx=1&sn=4bc64211ef6415a72b27d9c7a79d9b5d&chksm=84e7d185b39058933a51b80070fb6ae0408a57cb8336a9bba3d7e9f4c10fb29427c1af1ce634#rd,2024-10-03 12:23:05,OpenAI，一家知名的人工智能研究实验室，最近宣布完成了一笔66亿美元的巨额融资，使其估值达到1570亿美元，短短9个月内估值翻倍。这轮融资由Thrive Capital领投，参与者包括微软、英伟达、软银等。然而，OpenAI设置了一些不寻常的条件，要求投资者不得资助其竞争对手，如Anthropic、xAI和创始人Ilya Sutskever的新公司Safe Superintelligence (SSI)。此外，OpenAI正面临从非营利组织向营利性公司的转变，这一转变引发了争议。此次融资还涉及一些宫斗传闻，包括OpenAI前CEO Sam Altman的离职与回归，以及与苹果公司可能的投资谈判失败。
一张人脸照片，Meta眼镜识别全部个人信息，两位哈佛开发者：只为警醒世人,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936827&idx=2&sn=dbfa0fca8ac0648111a7c7e158132e25&chksm=84e7d185b390589311081826b851a822a6a8eca024d1865bc340c6ece54fef8f93f98718c7b4#rd,2024-10-03 12:23:05,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
Windows 竞技场：面向下一代AI Agent的测试集,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936827&idx=3&sn=ac385343bb3fbcf2a02d1d07e58e614b&chksm=84e7d185b3905893c8eba8788b2563ea079f50d057796ac4ba3680738cc41c665ea5c2ea3c7d#rd,2024-10-03 12:23:05,这篇文章介绍了微软开发的Windows Agent Arena (WAA)，这是一个基于Windows操作系统的AI Agent测试集，用于评估多模态操作系统代理执行任务的能力。WAA包含154个日常Windows任务，旨在帮助研究人员测试和比较不同AI Computer Agent的性能。目前，最先进的Agent在WAA上的成功率约为19.5%，而人类不借助外部帮助的得分是74.5%。文章还提到了当前Agent存在的缺陷和未来的发展方向，强调了在开发过程中重视隐私、安全和伦理规范的重要性。
单目三维检测实时泛化，纯视觉自动驾驶鲁棒感知方法入选ECCV 2024,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936827&idx=4&sn=262b4dcee75158ee7d248464fc34f25c&chksm=84e7d185b3905893d379e612c7ebca8c6327b05da01f707f85ff6e17159b337b863fd46d8ec8#rd,2024-10-03 12:23:05,来自香港中文大学（深圳）等机构的学者提出了一种名为 MonoTTA 的单目三维检测模型的实时测试时自适应方法，旨在提升纯视觉自动驾驶系统在未知测试分布上的表现。 MonoTTA 在测试阶段进行快速无监督学习，通过挖掘高置信度物体和缓解伪标签噪音减少漏检和误检。方法针对分布偏移问题，特别是自动驾驶中遇到的天气变化、图像模糊等挑战，通过实时适应和负标签优化缓解这些影响。实验结果显示，MonoTTA 能显著提高模型性能，平均提升了 137% 和 244%。该方法已在 KITTI 和 nuScenes 数据集上验证，并开源了代码。
Pika 1.5王者归来！将一切压扁、膨胀、融化、爆炸，化身为了超强特效利器,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936793&idx=1&sn=b6226727a5ce8111b8d5b4224e63c66b&chksm=84e7d1a7b39058b1bb65906ef98f5bcf35102d5f519f9fb59a9941a0026a13c617a29f62a7d3#rd,2024-10-02 10:20:48,视频生成模型Pika在去年引起轰动后，最近发布了新版本Pika 1.5，该版本带来了令人惊叹的镜头效果、更长的剪辑和复杂动作。Pika 1.5的特色包括虚幻的“Pikaffects”，能够实现如爆炸、融化、粉碎和膨胀等各种特效，以及大屏幕镜头效果和新的动作功能，如跑步、滑板和飞行。用户通过简单的提示词就能生成各种创意视频，例如将物体充气、膨胀或压扁，引发网友赞叹，称其为特效制作利器。Pika 1.5的发布再次巩固了它在视频模型领域的竞争力。
乏善可陈的第二届OpenAI开发者大会，果然没有掀起太大波澜,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936793&idx=2&sn=a76df871c5a190c35cc1671d0023dd5f&chksm=84e7d1a7b39058b145b2af06fa80dc991edb05ecfd74ddf43f670ea48552cc7417165382807a#rd,2024-10-02 10:20:48,OpenAI 在第二届 DevDay 开发者大会上发布了四个新功能：视觉微调、实时 API、模型蒸馏和提示缓存。这些更新主要针对现有 AI 工具和 API 的改进，体现了 OpenAI 从直接竞争终端用户应用转向增强开发者生态系统的战略转变。实时 API 提供了低延迟的语音到语音体验，允许开发者在应用中集成 ChatGPT 的语音控制。视觉微调功能使得 GPT-4o 模型能够通过图像和文本进行微调，增强视觉理解能力。提示缓存功能降低了使用相同上下文的 API 调用成本，最高可节省 50%。模型蒸馏让小型模型能够通过高级模型的输出提升性能，降低了计算成本。此外，Sam Altman 表示，OpenAI 的成本已大幅降低，通往 AGI 的道路更加清晰。
mini-GPT4o来了? 能看、能听、会说，还情感丰富的多模态全能助手EMOVA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936793&idx=3&sn=55e737d060d80fed7c3f69797403dcf3&chksm=84e7d1a7b39058b1f1f0f53fd73dbefef7b63c31599e5260f58487bc87c9614be1f8c1179c9d#rd,2024-10-02 10:20:48,这篇论文介绍了EMOVA，一个全模态的语音助手，能够处理图像、文本和语音信息，并具有情感控制功能，实现更人性化的交流。EMOVA结合了连续的视觉编码器和离散的语音分词器，通过文本模态进行全模态对齐训练，无需依赖稀缺的三模态数据。模型在视觉理解和语音任务中表现出色，能生成情感丰富、自然流畅的语音。这一研究为AI的情感交互提供了新的方法。
ECCV2024 Oral | 第一视角下的动作图像生成，Meta等提出LEGO模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936793&idx=4&sn=64a9a139bd28655f37461030c6755a5f&chksm=84e7d1a7b39058b177b91a1d837ececf4133404c2cec0a236f824b3de717ea8d935b7d448b5b#rd,2024-10-02 10:20:48,Meta和佐治亚理工大学的研究人员提出了一种名为LEGO的新方法，该方法可以根据用户的问题和当前场景照片，生成同一场景下的第一视角动作图像，以更准确地指导用户执行任务。这一技术通过微调大语言模型并使用扩散模型生成图像，解决了现有数据集中动作描述不详细和训练数据与任务之间的domain gap问题。LEGO在两个大型第一视角动作数据集上的实验结果显示，它在多个指标上超过了其他图生成模型，并在人工评测中获得了高评价。这一研究为提高人们学习新技能的效率提供了新的可能性。
给机器人装上「虫脑」？非Transformer液态神经网络终于来了！MIT CSAIL负责人创业成果,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936710&idx=1&sn=dbbd17956166684cee4eb73e75e41111&chksm=84e7d1f8b39058ee0eb5fda8a56d4ba9a6650d178b7e26e2d78fe617dc937e5fc0353e45e1db#rd,2024-10-01 12:37:50,Liquid AI公司推出了一种名为Liquid Foundation Models（LFM）的新一代多模态AI模型，该模型在各种规模上均能实现SOTA性能，同时保持较低的内存占用和高效的推理。LFM的核心优势在于它们在超越基于Transformer的模型的同时，需要更少的内存。LFM系列包含1B、3B和40B三种不同尺寸的模型，分别适用于不同环境和任务。在基准测试中，LFM在性能和内存效率方面优于一些基于Transformer的模型，例如Meta的Llama和微软的Phi模型。此外，LFM的高效内存管理允许在边缘设备上处理长上下文任务，为各种应用场景提供了新的可能性。 Liquid AI的LFM模型受到了线虫神经结构的启发，采用液态神经网络架构，提供了一种不同于Transformer的替代方案。公司计划在2024年10月23日举行发布会，并鼓励用户进行测试和反馈以改进产品。
手把手教你部署端侧大模型，10月26日相约上海,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936710&idx=2&sn=2e3415222c0cf120a8a27cef872a31b9&chksm=84e7d1f8b39058ee0a13fe9f99cdb0f5b3733ee581edd77e17c167b57fb2c03f8384fa06d80d#rd,2024-10-01 12:37:50,这篇文章预告了一场名为“端侧 AI 大模型开发与应用实践”的技术论坛，该论坛将于10月26日在上海举行。论坛聚焦于端侧大模型的研发与应用，探讨如何在有限计算资源和电池续航能力下优化模型性能和能效。会议将涵盖端侧模型的压缩与量化技术、端侧推理引擎、手机端侧部署、多模态大模型、端侧芯片能效优化以及车载场景应用等议题。论坛旨在通过技术研讨、案例分享和实操教程，帮助参会者掌握端侧 AI 技术并了解其在不同行业的应用。适合参会的人群包括研发工程师、企业家、研究员和学生。文章还介绍了部分主讲人的背景和成就，并提及了早鸟票优惠信息。
280页PDF，全方位评估OpenAI o1，Leetcode刷题准确率竟这么高,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936710&idx=3&sn=48ebe942af8e4e11e22a0d2198bc28e9&chksm=84e7d1f8b39058ee15f2dedcfb70004adcb41a4ce943ce2fd51f4f2edfde8fe854bc2a70ee2c#rd,2024-10-01 12:37:50,这篇论文对OpenAI的o1-preview模型进行了全面的系统评估，测试了它在多个领域的复杂推理任务中的性能，包括计算机科学、数学、自然科学、医学、语言学和社会科学。研究发现，o1在编程挑战中的成功率达到了83.3%，在高中数学推理中取得了100%的准确性，自然语言推理能力也表现出色，特别是在编程、放射学报告生成和高中数学方面超过了其他模型。然而，o1在处理某些高度专业和复杂的问题时仍有局限性。论文为o1的潜力提供了见解，并指出了未来发展的关键领域，如多模态集成和伦理考虑。
一手训练，多手应用：国防科大提出灵巧手抓取策略迁移新方案,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936710&idx=4&sn=4e5e77a9cdfce49c68cb9f87547cdde1&chksm=84e7d1f8b39058eed1917b7332098f9e56f7e92cc71a068ad45bddfdfa096ab8df92996f99b6#rd,2024-10-01 12:37:50,国防科技大学和深圳大学的研究者提出了一种新的策略学习方法，旨在解决复杂灵巧手（多指机械手）的抓取策略跨手转移问题。当前基于学习的抓取方法在提高对不同物体的泛化能力方面取得了进展，但不同灵巧手之间的泛化能力仍是一项挑战。研究团队通过设计一个运动和控制分离的层次化框架，以及手无关的状态和动作表示，实现了抓取策略在不同灵巧手之间的有效迁移。这种方法使用Transformer网络结构，通过注意力机制整合信息，适用于不同手指数量的灵巧手。实验表明，这种方法提高了抓取策略的泛化能力和在不同机械手上的适应性。
北大陈宝权教授：从图形计算到世界模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936623&idx=1&sn=e3536cdf6e16106dea5a74989c3e24d3&chksm=84e7d151b39058477bd0b9331224b0f47c49ffdf0d778db822700a8ae7cbb03c6a35293eb9b1#rd,2024-09-30 13:07:34,北京大学陈宝权教授在第九届计算机图形学与混合现实研讨会上分享了从图形仿真角度对世界模型的思考。世界模型是当前AI领域的热点话题，能够基于当前信息预测未来状态并做出决策。大模型如Sora通过视频生成模型展示了世界模型的特征。世界模型的构建可以从数据丰富性、训练模式、监督机制增强等角度进行，其中，图形计算和模拟（simulation）起着关键作用，能够生成大量高质量、带标签的数据以扩展数据集规模并支持模型训练。通过“模拟到现实”（sim-to-real）和“现实到模拟”（real-to-sim）的双向转换，模拟技术可以为强化学习提供训练环境，促进智能体的决策推理能力。此外，可微分模拟的发展为优化策略学习过程提供了新途径。图形仿真在构建更精准的世界模型中具有巨大潜力，可应用于自动驾驶、数字人、机器人等领域。未来，图形计算和仿真技术将继续推动世界模型的优化和发展。
SB 1047尘埃落定！州长否决，李飞飞等人有了新使命,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936623&idx=2&sn=4a1739f42db9f05b63afbd38e92497c0&chksm=84e7d151b3905847451e5866c23f6f3f47048fda765a4c96d2798e4ba542fe8f8dc417cec204#rd,2024-09-30 13:07:34,加州州长Gavin Newsom否决了《前沿人工智能模型安全创新法案》(SB 1047)，该法案旨在为高风险AI模型建立安全标准，防止其滥用。该法案因可能对大型模型产生广泛限制和对开源模型发布产生负面影响而备受争议。李飞飞、Yann LeCun、吴恩达等知名人士曾表示反对，而马斯克等人则表示支持。Newsom在否决声明中指出该法案可能给AI公司带来负担，且监管门槛不适当。他强调加州将在AI安全问题上采取其他措施，并邀请李飞飞等专家协助制定生成式AI的防护措施。在过去30天里，Newsom已签署了十多项针对AI具体风险的监管法案。
LeCun批评o1根本不像研究，Noam Brown回怼：已发表的研究都是废话,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936623&idx=3&sn=857b8d3cc59cd4cea266098f1efb36d0&chksm=84e7d151b3905847aab41def70ccfeda9572ee7784f2920c78f29e82d6638434b100dd6b57a4#rd,2024-09-30 13:07:34,图灵奖得主Yann LeCun与OpenAI的研究员Noam Brown展开争论，焦点在于OpenAI的闭源策略。LeCun批评OpenAI只发布博客而缺少技术论文，认为这无法达到研究的透明度和可复现性标准。Brown则反驳，表示OpenAI在博客和演讲中分享了大量信息，并称实际应用的检验比单纯发表论文更重要。争论中，哈佛大学教授Boaz Barak认为OpenAI的工作具有创新性，但同意公开更多细节会更有利于科学进步。OpenAI的闭源策略引发了一些评论，网友对其每年发表的论文数量和研究的开放性表示质疑。
端到端优化所有能力，字节跳动提出强化学习LLM Agent框架AGILE,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936623&idx=4&sn=3c6959f5f349e915efdde582fa526d04&chksm=84e7d151b39058479c08dc21b6b6269157c36c2a855595c1fc0a6e15c8345dd0e5de00f49c49#rd,2024-09-30 13:07:34,字节跳动的研究人员提出了一种名为AGILE的强化学习框架，用于构建具有多种能力的大语言模型（LLM）Agent，包括记忆、工具使用、规划、反思和与环境交互等。AGILE允许Agent在不自信时向人类专家求助，提高了处理复杂问题的准确性和泛化能力。在ProductQA和MedMCQA任务上，经过RL训练的AGILE Agent在性能上超越了GPT-4 Agent。该框架为LLM Agent的统一优化提供了一个端到端的解决方案。
终于拿到内测！豆包-PixelDance真是字节视频生成大杀器,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936521&idx=1&sn=faa2d620e02d3d2058e1ad5072e025cc&chksm=84e7d0b7b39059a1ceaefa252cdb23e22e12956d43aaf568cf059273cb9936498d768afd2a0e#rd,2024-09-29 12:06:50,字节跳动在“2024 火山引擎 AI 创新巡展”上发布了两个新的豆包视频生成模型：PixelDance 和 Seaweed，这两个模型基于 DiT（扩散 Transformer）架构，能够生成连贯一致、具有多种运镜技术的高质量视频。 PixelDance 和 Seaweed 支持复杂动作和多主体交互，能够在镜头切换时保持一致性，同时提供多样化的风格和宽高比选择。此外，字节跳动还推出了豆包音乐模型和同声传译模型，音乐模型能根据文本或图片生成音乐，同声传译模型则实现了低延迟、高准确度的同声传译。已有的通用语言模型、文生图模型和语音模型也进行了升级，提升了效率和性能。火山引擎的这些新模型和升级将为视频、音频和文本处理提供更强大的工具。
OpenAI创始成员Andrej Karpathy：这才是技术之美,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936521&idx=2&sn=9d509d69a1439a46e49ead579daa6c0c&chksm=84e7d0b7b39059a16a791bc6184a65467dc53c321eb089cb6f722fca91980522978614576606#rd,2024-09-29 12:06:50,知名 AI 领域学者 Andrej Karpathy 近日表达了他对优秀产品设计的看法，他认为技术应该是“不打扰人”的，像计算器一样简单而实用。Karpathy 指出，计算器是一个独立的物理产品，无需互联网连接、蓝牙权限，不会收集用户数据，不强制订阅或更新，是大脑的算术扩展，体现了完美的产品哲学。他对比了现代技术产品的复杂性和依赖性，质疑了当前行业实践中过度优化股东价值而牺牲用户体验的现象。作为消费者和开发者，我们都应关注并推动更人性化、注重隐私的技术发展。
LLM 之后，AI 的下个关键词会是 LWM 吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936521&idx=3&sn=71c840b38ebe3ef13b818dc176baea34&chksm=84e7d0b7b39059a1a27776b11dab10812e1a0339dd9ffdfe922b1a19ea71c7dd46469ea81cd1#rd,2024-09-29 12:06:50,这篇文章提到了AI领域的三个重要议题。首先，LLM（大型语言模型）之后，World Labs公司正在探索LWM（大世界模型），目标是开发3D空间智能，让AI能理解和生成3D世界。创始人李飞飞认为空间智能是AI的一个重要挑战，未来AI的底层表示可能会转向三维形式。其次，人形机器人成为关注点，越来越多的公司投入研发，但人形是否是通用机器人最合适的形态尚存争议，Scaling Laws被指出是通用机器人面临的真正难点。最后，Sundar Pichai在演讲中谈到AI平台的变革，他认为AI不会取代程序员，而会与程序员合作，AI的发展将继续依赖于人类的创新和指导。
迈向多语言医疗大模型：大规模预训练语料、开源模型与全面基准测试,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936521&idx=4&sn=41fb8fa51647c0f0995eeadeb3a5cca0&chksm=84e7d0b7b39059a16bec4706a177cdec48ab2ba08e1d57d30f60bd4f90fab2869bf7ad0d0805#rd,2024-09-29 12:06:50,上海交通大学和上海人工智能实验室的研究团队构建了一个多语言医疗语料库 MMedC，包含255亿个tokens，并开发了多语言医疗问答评测标准 MMedBench，覆盖6种语言和21种医学子课题。团队还推出了8B参数的MMed-Llama 3模型，在多项基准测试中超越现有开源模型。该工作旨在克服医疗领域大模型处理非英语问题的挑战，所有数据、代码和模型已开源。研究团队通过全面的基准测试评估了模型的性能，并展示了多语言模型在医疗领域的重要应用价值，如解决语言障碍和理解文化差异。
苹果反水：OpenAI的1500亿「史上最大」融资轮，难了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936472&idx=1&sn=29b0e8cd0d0810572a8f86c79e28e046&chksm=84e7d0e6b39059f02b9e063b98209ddb348deb4cc0d711db0aac4df2cfa6bc7929fcf0bac63c#rd,2024-09-28 13:32:49,OpenAI，知名人工智能实验室，近期遭遇高层动荡，首席技术官Mira Murati、首席研究官Bob McGrew和Post Training研究副总裁Barret Zoph相继宣布辞职。这一变化发生在OpenAI准备完成高达65亿美元融资的同一周，苹果公司决定不再参与此轮融资。此前，OpenAI已转变公司结构，计划成为营利性企业，但这一过程可能并不顺利。员工离职和组织变革引发了对其研究文化和财务可持续性的担忧。尽管OpenAI的ChatGPT等产品取得了显著的商业成功，但也有批评指出其产品开发可能过于仓促，失去了对竞争对手的技术领先优势。OpenAI正面临来自 Anthropic 和其他公司的激烈竞争，以及内部权力斗争的挑战。尽管预计年收入将达到数十亿美元，但今年仍可能亏损50亿美元。面对未来，OpenAI需要平衡产品开发和研究使命，以维持其在人工智能领域的领导地位。
《Python机器学习》作者科普长文：从头构建类GPT文本分类器，代码开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936472&idx=2&sn=5616c0564cf163838280f7a7868798b4&chksm=84e7d0e6b39059f08d228f8887d7a9e09764c6eab347ca2a9da306af9a131c37cf14fbe73c9d#rd,2024-09-28 13:32:49,本文是《Python 机器学习》作者 Sebastian Raschka 的一篇文章，介绍了如何将预训练的大型语言模型（LLM）转化为文本分类器。文章解答了7个问题，包括是否需要训练所有层、为何微调最后一个 token、BERT 与 GPT 的性能比较、是否应禁用因果掩码等。作者强调，预训练模型的微调是入门 LLM 知识的有效方式，并提供了相关代码示例。文章还讨论了指令微调和分类微调的区别，并展示了如何修改预训练模型的架构以适应特定的分类任务。通过微调模型的最后几层，可以提高模型在分类任务上的性能。
从数据增强的隐藏作用出发，揭示视觉强化学习可塑性损失的独特机制,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936472&idx=3&sn=38abbd8a61b84552c5d119ccc6e3b7a5&chksm=84e7d0e6b39059f0d60f80ae9daa3923e03cc93e25bcb88712866f94d32dfab02ca903ccaecb#rd,2024-09-28 13:32:49,来自清华大学、悉尼大学、华盛顿大学、京东探索研究院和南洋理工大学的研究人员针对深度强化学习中的“可塑性损失”问题进行了深入研究，发现深度神经网络在持续学习环境中表现不如浅层网络，尤其是在面对非平稳训练目标时。研究指出，深度强化学习中的关键瓶颈是评价者网络（Critic）的可塑性损失，而非编码器（Encoder）的视觉表征能力。此外，数据增强对于缓解可塑性损失、提高视觉强化学习的样本利用效率具有显著效果。研究还揭示了训练早期对Critic网络可塑性的干预至关重要，早期的可塑性损失可能导致后期无法逆转的性能下降。研究人员提出了一种创新的训练方法——自适应回放比例，动态调整回放比例以根据Critic网络的可塑性水平优化学习效果。
长短大小样样精通！原始分辨率、超长视频输入：更灵活的全开源多模态架构Oryx,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936472&idx=4&sn=fd27d437f9200f80d1cc5208c032442b&chksm=84e7d0e6b39059f03067af43d637f5937db6c78fa813573540fac12441028ef34ca3d515291a#rd,2024-09-28 13:32:49,来自清华大学、腾讯和南洋理工大学的研究者提出了多模态模型Oryx，它能处理图像、视频和多视角3D场景，支持按需处理任意空间大小和时间长度的视觉输入。Oryx包含一个预训练的OryxViT模型，用于将任意原始分辨率的图像编码为视觉token，以及一个动态压缩模块，可实现1到16倍的视觉token压缩。这种设计提高了处理不同任务时的效率和精度。Oryx在多个多模态理解任务上表现出色，包括视频理解、长视频理解、图像理解和3D空间理解。其代码、论文和演示已公开。
与其造神，不如依靠群体的力量：这家公司走出了一条不同于OpenAI的AGI路线,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936264&idx=1&sn=0caf29b222e6af5c78faa730a7c0b036&chksm=84e7d7b6b3905ea0fe689d4776da60ed97d9459a3b7c9bdddbba252fd76a9bc9619b32d550ca#rd,2024-09-27 12:04:54,RockAI，一家AI初创公司，正在探索群体智能的可能性，通过将他们自研的非Attention机制Yan架构通用大模型部署到手机、PC、无人机、机器人等端侧设备上，以实现设备的自主学习和智能进化。公司目标是形成能够协作的智能单元，共享数据和任务，从而实现群体智能。RockAI认为，生成式AI的发展提高了个体智能水平，为群体智能的实现提供了可能。与依赖大型中央模型的路径不同，RockAI强调个体智能的自主学习能力，指出模型在端侧的自主学习和协作是关键。Yan 1.3是RockAI的最新进展，这是一个多模态模型，可以在多种设备上运行，并具有高效的计算性能。RockAI致力于实现模型在推理时的实时学习和知识更新，以形成独特的知识体系，并通过去中心化的动态系统实现设备间的协作。
Layout工程师危，谷歌自动芯片设计AlphaChip问世，开放权重可外部定制,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936264&idx=2&sn=8c56d2bfd6ef1185a551c235a02518ff&chksm=84e7d7b6b3905ea0cfdf4df5166c2aad02e96f9c8df0efe8e9c8f41a15349eebb2ff335fba96#rd,2024-09-27 12:04:54,谷歌发表在Nature上的论文介绍了其使用深度强化学习设计芯片布局的方法，称为AlphaChip。该方法已经用于设计谷歌自定义AI加速器TPU的三代芯片布局，并且谷歌开放了一个在20个TPU模块上预训练的检查点，以便外部用户可以使用AlphaChip进行芯片设计。这种方法只需数小时就能完成与人类相当或更好的芯片布局，大大加速了设计过程。AlphaChip不仅用于设计AI加速器，还应用于Alphabet的其他芯片设计，如Google Axion处理器，并在业界得到采用，如联发科在旗舰5G芯片开发中的应用。谷歌将继续开发AlphaChip，以优化芯片设计的各个环节。
英伟达RTX 5090功耗高达600W，32G显存，核心比5080多一倍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936264&idx=3&sn=ac31e3a7d1bbe29c3998b8cda3545923&chksm=84e7d7b6b3905ea01465fc7fd07aa3e847ca41c8887d5fd59a3b17b1434b84e07542c7f9b6f7#rd,2024-09-27 12:04:54,"这篇文章的摘要可以是：

海外知名爆料者 Kopite7kimi 曝光了英伟达（Nvidia）GeForce RTX 5080 和 RTX 5090 显卡的初步规格。据称，RTX 5090 将是一款拥有 600W 额定功率的高端GPU，基于 GB202 图形处理器，配备 21760 个 CUDA 核心和 32GB GDDR7 内存。相比之下，RTX 5080 将配备 10752 个 CUDA 核心，16GB GDDR7 显存，额定功率为 400W。这两款显卡预计将在性能上远超前代产品，但RTX 5090 和 RTX 5080 之间存在显著的性能差距。目前，这些信息尚未得到官方确认，RTX 50 系列的发布日期也存在不确定性。"
形式化定理证明新突破：SubgoalXL框架让大模型在Isabelle中性能暴涨,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650936264&idx=4&sn=545350a1be4b3cb0d28ef85d89d5c807&chksm=84e7d7b6b3905ea0f081ab370de7f7531699b8342d1f2cb399613cd16db7cad42320a01f074e#rd,2024-09-27 12:04:54,来自香港大学和SambaNova Systems的研究团队提出了一种名为SubgoalXL的新框架，用于解决大语言模型在形式化定理证明中的挑战。现有的问题包括形式化证明数据的稀缺性和多步骤推理的复杂性。SubgoalXL通过子目标证明策略将证明过程分解为多个子任务，以简化复杂推理，并采用专家学习框架进行迭代优化，提高模型在多步骤推理中的准确性和效率。实验结果显示，SubgoalXL在标准miniF2F数据集上取得了最优性能，超过了其他基线方法。这项工作为大语言模型在形式化定理证明中的应用开辟了新路径，为未来在数学和科学领域的深入研究奠定了基础。
突发！OpenAI CTO Mira Murati离职，高层动荡继续,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935932&idx=1&sn=d41ffe16b77703c20ce1dc83e0799d47&chksm=84e7d602b3905f14a6d6772843b57411c9bac2ce0446936f007e030b35b764860eb53eae5ed4#rd,2024-09-26 07:05:33,OpenAI的首席技术官Mira Murati宣布离职，结束了她在该公司六年的任期。Murati在公开信中表达了对OpenAI团队的感谢，并表示她的离职是为了进行个人探索。OpenAI的首席执行官Sam Altman对Murati的贡献表示了感激，并提到将会讨论过渡计划。此前，OpenAI的联合创始人Ilya Sutskever和John Schulman也已离职，总裁Greg Brockman正在长期休假。这些高层变动引发了外界对OpenAI领导层稳定性的关注。同时，有消息称OpenAI正在寻求新一轮融资，估值可能超过1500亿美元。
斯坦福新作：无指令调优的指令遵循,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935932&idx=2&sn=680554062a739b6899b5481b2ec3ca83&chksm=84e7d602b3905f14062f62959d586acbeb1cd19e96c14c6870252d9e32e2f51163080fa4f45a#rd,2024-09-26 07:05:33,斯坦福大学的研究者发现，通过对模型的响应进行微调（响应调优）而不是显式地进行指令调优，也可以实现指令跟随。响应调优模型在AlpacaEval 2上的评估显示，与指令调优模型相比，有43%的胜率。此外，仅对单任务、窄域数据进行微调，如诗歌生成或Python代码生成，也能产生广泛的指令遵循行为。这些发现表明，即使适应方法不是专门设计来实现指令跟随，也可能隐式地产生这种行为。
调研219篇文献，全面了解GenAI在自适应系统中的现状与研究路线图,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935932&idx=3&sn=c2347e392259d83b13b6a1ef7d93812f&chksm=84e7d602b3905f14d24aefeb6f8c58e00edacd4ff8a12698106a4cd34c9b6b7c7d34945a4aca#rd,2024-09-26 07:05:33,这篇论文综述了生成式人工智能（GenAI）在自适应系统中的应用现状和未来研究方向。自适应系统广泛应用于动态环境，如自动驾驶和网络安全，通过自我调整以适应变化。GenAI，特别是大型语言模型（LLMs），能增强自适应系统在监控、分析、规划和执行等方面的能力。论文分析了219篇相关研究，探讨了GenAI在增强自主性、改善人机交互、异常检测、决策规划和执行等方面的作用。同时，也指出了现有研究的不足，如设计时与运行时的转换、LLM服务的集成、多模态数据处理、责任归属和评估方法等，并提出了未来的发展方向，包括伦理责任、自我测试和自我进化等。
当大模型Scaling Law继续，万卡集群算力释放在「百舸」这里找到一条通途,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935865&idx=1&sn=95fb1a3870a0602a332e17e17cb0cb6f&chksm=84e7d647b3905f51898627cf76313ccabc0bfa786990594361a324c40d6dd6cb062bdf6ff739#rd,2024-09-25 13:11:06,"随着人工智能行业的进步，算力成为了最宝贵的资源，特别是随着AI模型规模的扩大，对训练和推理算力的需求呈爆炸式增长。文章提到OpenAI的研究表明，AI模型训练算力需求每3.5个月翻一番，远超摩尔定律。为了应对这一需求，大规模GPU算力集群成为趋势，企业纷纷构建万卡甚至十万卡集群。然而，大规模集群面临多类型芯片混合训练、电力消耗、网络通信和负载等问题，需要在系统、框架和算法层面进行技术突破。

百度的AI异构计算平台「百舸」针对这些问题进行了优化，实现了高算力利用率和多芯混合训练。百舸4.0版本进一步提升了集群的性能，包括提高整体算力利用率至90%，万卡规模任务的有效训练时长达到99.5%，并支持多类型AI芯片的混合训练。此外，该平台还通过大模型加速套件AIAK提升了训练和推理效率，降低了成本。通过技术优化，百舸4.0在大模型训练和推理方面提供了更快、更省的解决方案，为AI基础设施的发展奠定了基础。"
终于来了！OpenAI开放GPT-4o高级语音，还用中文说「对不起」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935865&idx=2&sn=a3ec786cf9c53d4f7758758556d93f53&chksm=84e7d647b3905f51f8f52f230e4081a35c83f9a3c36d89491f67d746cfd2a2ccc88b14618d17#rd,2024-09-25 13:11:06,OpenAI宣布其高级语音功能正式开放，面向Plus和Team用户推出。这一功能新增了自定义指令、记忆、五种新声音和改进的口音，支持50多种语言。Plus用户将在秋末前获得访问权限，而免费用户目前无法使用。新声音包括Arbor、Maple、Sol、Spruce和Vale，由专业配音演员制作。此外，OpenAI还发布了多语言大规模多任务语言理解数据集MMMLU。高级语音功能尚未在某些欧盟国家和北欧国家推出。
文档处理效能飙升！浩鲸科技“文档大模型”核心技术揭秘！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935865&idx=3&sn=5ec11d3802e1bddccd81bfd034a4070a&chksm=84e7d647b3905f5163b5317d5657643b1b34fcbf7d31b82e2cd4c0864e8f455e15836ba1afb2#rd,2024-09-25 13:11:06,浩鲸科技在云栖大会上发布了“鲸智文档大模型”，这是专为企业文档场景构建的垂直领域模型，旨在帮助企业实现文档知识的抽取、融合和推理。该模型包括标题提取、表格提取和版面分析等功能，以提升知识提取的效率和质量。此外，鲸智文档大模型还提供了多模态文档工具链DocChain和软硬件一体机，以支持全流程的知识管理。通过这种端到端的解决方案，企业可以更有效地管理和利用其知识资产。浩鲸科技在电信、政务、电力等领域拥有丰富的数据治理和知识沉淀经验，此次发布的文档大模型是其技术积累的体现。
自动化机器学习研究MLR-Copilot：利用大型语言模型进行研究加速,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935865&idx=4&sn=10167f5ae616ae167111548b4070e3b9&chksm=84e7d647b3905f51e3f472fb67c2d8d5c21a4f3530a5d9913cefc4a199299549b13d9f9e9b7c#rd,2024-09-25 13:11:06,德克萨斯大学达拉斯分校的研究团队开发了一个名为MLR-Copilot的自动化机器学习研究平台，利用大型语言模型（LLM）来加速和自动化科研过程。该框架分为研究思路生成、实验实现和实验执行三个阶段，能从研究论文中提取任务定义，生成研究假设和实验计划，并自动化执行实验以获得结果。实验表明，MLR-Copilot在研究思路的有效性和实验实现的成功率方面表现出色，有助于提高研究效率和结果可靠性。该框架的源代码和论文已在GitHub和arXiv上发布。
解码瓴羊：一群最懂数据的人如何让AI真正无处不在？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935808&idx=1&sn=176b4bcc3e3d248a40cfcc3b2c7cda4d&chksm=84e7d67eb3905f688f620653241919590a27e20bfa0fece10fe742a29c2622ff48b3e7c26530#rd,2024-09-24 20:42:37,这篇文章主要介绍了瓴羊智能科技在2024云栖大会上提出的“Data×AI”企业服务智能化理念，强调AI与具体场景深度融合的重要性。瓴羊专注于数据要素服务，提供五大产品矩阵，包括分析、营销和客服等方面，通过大模型与业务场景结合，提升企业效率和价值。文章提到，瓴羊的Quick BI、Quick Audience和Quick Service三款产品分别在数据分析、营销和客服场景中应用AI技术，以解决实际业务痛点。此外，瓴羊的数据治理产品Dataphin和数据流通平台瓴羊港也分别在数据治理和数据流通方面提供解决方案，促进企业数据资产的高效利用。文章最后指出，AI真正落地需要快速、深入理解行业并获得客户认可。
LLM仍然不能规划，刷屏的OpenAI o1远未达到饱和,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935808&idx=2&sn=5f0671f6cd3a005e3e20d3a471da3bf5&chksm=84e7d67eb3905f689a60ead46df8dc1126623687a8b9e13648e2269fcad14ed13f417c97b2b3#rd,2024-09-24 20:42:37,亚利桑那州立大学研究团队评估了大型语言模型（LLM）在规划能力方面的表现，包括OpenAI的o1模型。尽管o1在多个基准测试中表现出色，但在 PlanBench 基准上，LLM的规划能力仍然有限。即使是最新的o1模型，在解决复杂问题时的性能并不稳定，特别是在Mystery Blocksworld测试中。研究发现，LLM在规划任务中的表现远不如检索任务，而且自然语言提示对它们的影响大于PDDL。虽然o1模型通过结合RL训练和自适应扩展推理程序有所改进，但其性能仍不够稳健，且在处理无法解决的问题时识别率较低。研究强调了LLM在实现真正通用推理能力方面还有很长的路要走。
伯克利MemGPT团队创业，要做开源的OpenAI，Jeff Dean也投了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935808&idx=3&sn=355a891bfa933980ca9e82fbaf3d3f94&chksm=84e7d67eb3905f688ed50f2b438ad6797dc2b548b2512ba636aeee460e7ebc32011c1687f789#rd,2024-09-24 20:42:37,Letta，一家由加州大学伯克利分校实验室创业工厂孵化的AI初创公司，获得了1000万美元的种子资金，估值达7000万美元。该公司专注于帮助AI模型记住用户和对话，其技术可能重塑人工智能行业。Letta得到了包括谷歌的Jeff Dean和Hugging Face的Clem Delangue等知名投资者的支持。公司由Sarah Wooders和Charles Packer创立，其项目MemGPT是一个开源项目，旨在解决大语言模型无状态的问题，使AI能够存储历史数据。MemGPT在发布前意外走红，吸引了大量关注。Letta计划提供托管代理服务和开发人员工具，以支持有状态智能体的构建和运行。尽管存在LangChain和OpenAI等竞争对手，Letta强调其开源和模型兼容性的优势。
ACM TOG｜仅通过手机拍照就可以对透明物体进行三维重建,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935808&idx=4&sn=f3e20f5144102508c919a192e0f16c28&chksm=84e7d67eb3905f6826554ba4dfe057d16a2c253dd789cf8accc0dfb37948ece1634c350e3172#rd,2024-09-24 20:42:37,中国科学院计算技术研究所、加州大学圣芭芭拉分校和KIRI Innovations的研究人员合作提出了一种名为NU-NeRF的新方法，能够无需额外输入和特殊捕捉环境，对嵌套透明物体进行三维重建。这种方法解决了现有方法在重建具有折射或透明材质、特别是嵌套物体时的难题。NU-NeRF通过分开建模透明表面的反射和折射来处理折射的二义性，并通过显式外层几何重建和内层几何重建的两步过程来实现嵌套物体的重建。该研究已被ACM TOG录用，并将在SIGGRAPH Asia 2024上报告。实验结果显示，NU-NeRF在合成和实拍场景的重建上均表现出色，能够准确地重建内外几何结构。
李飞飞创业之后首个专访：视觉空间智能与语言一样根本,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935493&idx=1&sn=7e33fb802b6ab3aca2aaa5f9d0a0edd7&chksm=84e7d4bbb3905dad84cc335b4832f3925ee43bddacad14898271560bffd684f6a589961990cf#rd,2024-09-23 14:17:41,李飞飞教授和Justin Johnson共同创立的空间智能公司World Labs在近期的a16z访谈中被讨论，李飞飞强调空间智能是AI研究的新前沿，它与语言一样基础。她回顾了ImageNet对计算机视觉的贡献，并讨论了计算和数据在AI发展中的作用。AI的终极目标与空间智能密切相关，World Labs团队致力于发展和度量空间智能的进展。访谈中还提到了计算能力的飞速增长、数据的重要性以及从监督学习到生成式AI的转变。World Labs现在关注空间智能，目标是解锁其潜力，应用可能包括游戏、教育和增强现实等领域。
AI会「说谎」，RLHF竟是帮凶,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935493&idx=2&sn=3751eb9a7c402165f12f75e8e777eb75&chksm=84e7d4bbb3905dad432c274d6c9fd71bb06734b15626da26f8b9129e6f0cdf1a6dae0631ba4d#rd,2024-09-23 14:17:41,很抱歉，您还未提供具体的文章内容。请您提供一篇文章，我将为您生成摘要。
仅用4块GPU、不到3天训练出「开源版GPT-4o」，这是国内团队最新研究,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935493&idx=3&sn=7de7fd8a83e9501d48e582d21bc224b5&chksm=84e7d4bbb3905dad55c5d40ca1883599e94c05107bae56195309661fd202a91095589023294b#rd,2024-09-23 14:17:41,中国科学院计算技术研究所和中国科学院大学的研究者提出了新型模型架构 LLaMA-Omni，实现了与大型语言模型（LLM）的低延迟、高质量语音交互。该模型能同步生成文本和语音响应，延迟仅为226ms，低于GPT-4的平均音频响应延迟。LLaMA-Omni由语音编码器、语音适配器、LLM和流式语音解码器组成，无需先将语音转为文本，能直接从语音指令生成响应。此外，模型使用了InstructS2S-200K数据集进行训练，显著减少了所需的训练数据和计算资源。实验结果显示，LLaMA-Omni在内容、风格和对齐方面优于其他语音-语言模型。
开源！上海AI Lab视频生成大模型书生·筑梦 2.0来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935493&idx=4&sn=ee966a4e3bb0b8d3d8af06d3fb6e6656&chksm=84e7d4bbb3905dad084298b0df7819af8094ac20be56f84614c0b5cfe8f9a2d51ced8c44ed75#rd,2024-09-23 14:17:41,上海人工智能实验室推出了新一代视频生成大模型“书生・筑梦 2.0”(Vchitect 2.0)，该模型支持文生视频、图生视频、插帧超分和训练系统一体化，能够生成长达20秒、分辨率达到720x480的视频，并兼容多种视频格式。筑梦 2.0 的核心亮点包括：支持更长的视频生成、配备了视频增强算法VEnhancer，以及全球首个支持长视频生成评测的框架VBench。模型采用扩散式Transformer网络架构，并开源了训练和推理框架LiteGen，后者通过Activation Offload和Sequence Parallel技术优化了显存使用和序列长度。书生・筑梦团队由上海人工智能实验室和新加坡南洋理工大学成员组成，专注于视频生成技术的研发。
Jeff Dean回忆谷歌趣事：吴恩达激励自己继续研究，Hinton曾是最强「实习生」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935359&idx=1&sn=a505ec362c0a7903f71fdc39da18862d&chksm=84e7d441b3905d57d47b1b7984f120d9adadb1e05ae2ea9c575acb0a5eeb0723d9be4d7e29df#rd,2024-09-22 12:38:44,谷歌的AI负责人Jeff Dean在最近的访谈中分享了他的AI发展历程，包括他在1999年加入谷歌，2011年参与创建Google Brain团队，以及对大规模神经网络的兴趣始于与吴恩达的交谈。2023年，谷歌宣布将Google Brain和DeepMind合并为Google DeepMind，Dean成为首席科学家。在这次访谈中，Dean讲述了谷歌收购DeepMind的经过，这个提议最初是由深度学习先驱Hinton提出的。他还讨论了Transformer模型的重要性，这种模型革新了自然语言处理，通过并行处理大幅度提高了性能。Dean强调了多模态模型的潜力，这些模型能够整合视觉、听觉等多种信息，以更全面的方式理解和生成内容。
o1 研发团队完整采访：Ilya早期曾参与，灵感源于AlphaGo,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935359&idx=2&sn=3b768bbbd4cde566ef020e29744c986f&chksm=84e7d441b3905d57ef001ea7dbc32dfe4e61d37cfb583c7f2cf85640fcc69a558e24a8acec38#rd,2024-09-22 12:38:44,OpenAI 的新模型 o1 自发布以来，以其强大的推理能力引起了广泛关注。这款模型在数学竞赛和高难度的科学问答中展现了出色的表现。在最近发布的访谈中，OpenAI 团队揭示了 o1 的研发过程和背后的关键人物。Jakub Pachocki、Łukasz Kaiser 和 Ilya Sutskever 等人在早期探索中发挥了重要作用，Jerry Tworek 则在整合和推进项目中起到关键作用。团队将强化学习和监督学习相结合，经历了多次突破和挑战。o1 的研发过程中有许多“aha moments”，比如通过强化学习训练模型生成自己的思维链，效果优于人类编写思维过程。此外，团队面临了大规模模型训练的困难，包括验证模型的正确性和资源限制等问题。o1 项目也衍生出了 o1 Mini，这是一个更小、更快、专注于推理的模型，旨在降低成本并让更多用户能够体验到 o1 的优势。
TLDR，o1 技术细节推测汇总了解一下？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935359&idx=3&sn=f9c02f968408cf8265a61d6678748772&chksm=84e7d441b3905d57a304be2f3005627107a0aa73a17ce65706fdb899f1ac02e84afe0f816108#rd,2024-09-22 12:38:44,这篇文章是关于人工智能和机器人行业的一份通讯摘要。主要讨论了OpenAI的最新模型o1（可能指的是ChatGPT-1）的细节、影响和潜在的技术路径。虽然OpenAI没有发布详细论文，但社区对其进行了深入分析。一些观点认为o1在逻辑推理和解决复杂问题方面的能力提升，为AGI（人工智能）研究开辟了新方向。文章提到了可能影响Scaling Law的探讨，以及o1可能通过强化学习和搜索技术来增强模型的推理过程。此外，通讯中还讨论了OpenAI计划提高模型使用费用的商业模式，以及对GenAI（生成式人工智能）热潮的分析，指出GenAI在降本增效方面的潜力，但同时也存在风险。通讯涵盖了多个专题和行业动态，包括技术进展、国内外新闻和企业部署情况。
ECCV 2024 oral | 首次基于深度聚类的多模态融合，上交、伯克利提出双向结构对齐的融合网络新SOTA！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935359&idx=4&sn=8ceb0928dc784ed1c0aa792e27bfc1ad&chksm=84e7d441b3905d5769d03a9a13e88594dc813d9e34bd096a47eb9551c36cbc44632731c36062#rd,2024-09-22 12:38:44,上海交通大学和加州伯克利大学的研究团队提出了一种新型的局部到全局融合网络（DVLO）用于多模态里程计，解决了以往方法中数据结构错位的问题。该网络采用双向结构对齐，通过将图像视为伪点与激光雷达点进行局部融合，并将点云转换为伪图像进行全局自适应融合。这种方法在Kitti里程计数据集上的实验中表现出色，超越了近期的深度激光雷达、视觉和视觉激光雷达融合里程计方法。此外，DVLO的融合策略还成功应用于场景流估计任务，超过了当前的SOTA方法。
最强卷王3个月进化9次！可灵AI上新1.5模型，国外网友：太疯狂,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935336&idx=1&sn=2aa93461d4a1558510709b5e6d673fc7&chksm=84e7d456b3905d4030d265f6a4c0721439cddbc4338e38ec363d3175a49ca35285b6daa410c1#rd,2024-09-21 14:50:30,可灵AI推出了新模型1.5，该模型显著提升了生成视频的画质，现在可以在高品质模式下直出1080p视频，同时增强了画面主体的运动幅度、质量及文本响应度。与1.0模型相比，1.5模型在内部评测中整体效果提升95%。新模型还引入了“运动笔刷”功能，以增强对视频生成的精准控制。尽管功能升级，但生成价格不变，保持在35个灵感值生成一则高品质模式视频。新功能发布后，吸引了大量用户尝试，甚至一度导致服务器拥塞。可灵AI自今年6月发布以来，已迭代9次，目前服务超过260万用户。
强化学习让大模型自动纠错，数学、编程性能暴涨，DeepMind新作,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935336&idx=2&sn=47546c9b9decbcb45f8f291267c9d20f&chksm=84e7d456b3905d40e3b9b258d4642e52d38b13d54c4c430de33b05322fa88c50a3ca55d3a0fd#rd,2024-09-21 14:50:30,Google DeepMind的研究者开发了一种名为SCoRe（Self-Correction via Reinforcement Learning）的方法，使大语言模型（LLM）能够自我纠正错误，无需依赖外部反馈或额外模型。SCoRe通过强化学习让模型在自生成的数据上训练，以实现自我纠正能力。这种方法在MATH推理问题上提高了15.6%的准确性，在HumanEval编码问题上提高了9.1%的性能。SCoRe分为两个阶段，首先训练模型初始化以防止崩溃，然后进行带有奖励的多轮强化学习。实验结果表明，SCoRe在数学和代码生成任务上表现出显著的改进。
OpenAI前研究者发布提示词工程框架ell，升级版LangChain，支持版本控制和多模态,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935336&idx=3&sn=baf231c998a7dd28871b87c836423f6f&chksm=84e7d456b3905d406356a95b68dd436ae584226653eeb248d4a91025b931617efd816e6109e5#rd,2024-09-21 14:50:30,前OpenAI研究科学家William H. Guss发布了名为ell的工具，声称它是“提示词工程的未来”。ell是一个轻量级的函数式语言模型编程库，专注于提示词的自动化版本控制、跟踪和多模态数据支持。这个项目在GitHub上获得了大量关注，被称赞为构建AI软件栈的重要部分。ell将提示词视为程序，认为它们是发送给语言模型的代码，并通过将LMP视为函数，提供优化工具。此外，Ell Studio是一个用于提示词版本控制、监控和可视化的本地开源工具，旨在使提示词工程过程更具可追溯性和科学性。ell还支持多模态输入和输出，简化了使用LLM处理非文本数据的复杂性。
首个Mamba+Transformer混合架构多模态大模型来了，实现单卡千图推理,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935336&idx=4&sn=1d0f7c1abd46f072741e563050151045&chksm=84e7d456b3905d40bba652e3ca595a148df10d464dd3c1f70df1b9cc89f96385acdc784cabc5#rd,2024-09-21 14:50:30,这篇文章介绍了香港中文大学深圳和深圳大数据研究院的研究团队提出的一种新的多模态大语言模型，称为LongLLaVA。这个模型旨在扩展大语言模型处理多图像和长上下文的能力，对于视频理解、高分辨率图像处理和多模态智能体有重要意义。研究团队采用混合架构，结合了Mamba和Transformer，通过2D池化减少计算成本，同时设计了考虑时间和空间依赖性的数据构建方法，并实施了渐进式训练策略。LongLLaVA在多个基准测试中展现出强劲的性能，可以处理大量图像，同时保持高吞吐量和低显存消耗。该模型的开源将促进相关领域的进一步研究和应用。
真·AI程序员来了，阿里云「通义灵码」全面进化，全流程开发仅用几分钟,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935056&idx=1&sn=75aabe71ebd52ab77d9856f64d9604b8&chksm=84e7cb6eb3904278a9547adb5baaf5dbfeccd6c194ed6e4517388c062de1f586489d72d3d75a#rd,2024-09-20 12:39:46,阿里云发布了通义灵码的升级版“AI程序员”，这是一个能够独立完成软件研发任务的AI智能体。AI程序员可以在Web端完成需求分析、开发、测试等全过程，速度最快可达分钟级，大大提高了开发效率。它预置了缺陷修复、需求实现和研发问答三个场景，并支持与阿里云一站式DevOps平台云效和GitHub集成。在云栖大会上，AI程序员展示了快速修复《魂斗罗》游戏代码和自动开发Python倒计时网页的能力。此外，AI程序员可以理解自然语言描述的需求，降低了编程的门槛。
o1带火的CoT到底行不行？新论文引发了论战,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935056&idx=2&sn=25a4d6445aaae181db9f38047847f62c&chksm=84e7cb6eb39042785b2143823c17294aab67780356f38fa902b832f524d1c799ff6686acf6d4#rd,2024-09-20 12:39:46,"这篇论文探讨了思维链（Chain-of-thought, CoT）在大型语言模型（LLM）中的效用，发现CoT在数学和符号推理任务中能显著提升模型性能，但在其他任务上的效果不明显，甚至可能降低模型表现。研究者通过分析文献和实验，指出很多使用CoT的问题实际上可以使用更高效的方法解决，且在某些任务上，使用外部工具比CoT更优。论文建议，需要更复杂的方法来改进CoT，如基于搜索或交互式智能体的方法。实验表明，CoT在涉及常识、语言理解和阅读理解的任务上提升不大，而在需要逻辑规则的应用中表现较好。此外，回答格式和知识、软推理及常识推理方面的提升并不显著，CoT的优势主要在于形式推理任务。"
别Cursor了，集成o1的GitHub Copilot让网友直呼要回归,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935056&idx=3&sn=fa02b4fe51277c2bac8bc73d56449635&chksm=84e7cb6eb3904278bfe00135f5f046e16760de11107fae6deb2df3f020ecf082f6484412cb79#rd,2024-09-20 12:39:46,GitHub 宣布在 VSCode 中为 GitHub Copilot Chat 开放 OpenAI 最新 o1-series 模型的早期访问权，包括 o1-preview 和 o1-mini。o1 系列模型具有强大的推理和编程能力，能更好地理解代码约束并生成高效、高质量的结果。GitHub 团队发现该模型在处理复杂编码挑战时表现出色。用户现在可以选择使用 o1-models 以替代默认的 GPT-4o，体验更先进的代码辅助功能。感兴趣的用户可以加入 waitlist 以尝试这一新功能。
从架构、工艺到能效表现，全面了解LLM硬件加速，这篇综述就够了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650935056&idx=4&sn=ff20461efc284a44c8000794fca8e523&chksm=84e7cb6eb390427869a3b7a87df38e03f843de15b81df788dcee7813fcbb0b7da626b41b8d43#rd,2024-09-20 12:39:46,本文对使用 FPGA、ASIC 等硬件加速器对大型语言模型（LLM）的性能和能效进行了全面调查。深度学习中的Transformer模型在语言建模中发挥了重要作用，而硬件加速对于提升其效率至关重要。研究者详细列举和比较了使用 FPGA 的多项研究，如 FTRANS、多头注意力加速器等，以及基于 CPU 和 GPU 的加速器如 TurboTransformer 和 Softmax 重组技术。此外，还探讨了 ASIC 加速器如 A3、ELSA 和 SpAtten，以及内存硬件加速器如 ATT 和 ReTransformer。文章提供了各项加速器的性能和能效定量比较，展示了不同技术在不同工艺下的表现。
字节音乐大模型炸场！Seed-Music发布，支持一键生成高质量歌曲、片段编辑等,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934937&idx=1&sn=6e56859c8d151a69abbc3b3613a3a40c&chksm=84e7cae7b39043f12cc44f1e3ac32b33918eafd80ffd3ae1a387791e3e834cb8043be4c9c022#rd,2024-09-19 12:45:34,字节跳动发布了音乐大模型Seed-Music，这是一个具有灵活控制能力的音乐生成系统，包含四大核心功能，涵盖十种创作任务。该模型可以生成高质量音乐，并支持通过领谱进行音乐编辑，满足不同用户群体的音乐创作需求。Seed-Music的创新之处在于将语言模型和扩散模型结合，并融入符号音乐处理，提供高灵活度的编辑功能，包括歌词和旋律的调整，以及跨语种人声克隆。该模型的发布在海外引起了关注，被认为在AI音乐生成领域提高了标准。
硕博招生将启！AI排名跻身前15，全球首所人工智能大学MBZUAI实力大增,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934937&idx=2&sn=907e04b2791fc6357d36b50bdf1875dc&chksm=84e7cae7b39043f170f427873cc725464b967faae3c31526b3cc87d9898d19e0fb694d4f4956#rd,2024-09-19 12:45:34,全球首个人工智能大学MBZUAI（穆罕默德·本·扎耶德人工智能大学）在成立四年多以来，已取得显著的学术成果和国际声誉。在AI研究领域，MBZUAI建立了Foundation Models研究所，开发了领先的K2开源模型，并在生命大模型、人脑控制机器人和虚拟现实世界模型等前沿项目上取得进展。根据最新排名，MBZUAI在多个AI专业的全球排名中位列前15，自然语言处理专业更是进入全球前11。学校吸引了来自世界各地的顶尖学者加入教师团队，包括慕尼黑工业大学的Sami Haddadin、前Google用户体验总监Elizabeth Churchill等。目前，MBZUAI的faculty团队有81人，发表超过2200篇论文，2024年度发表论文数量接近1000篇。此外，MBZUAI的生源也日益国际化，2024秋季学期迎来了197名来自34个国家的新生。学校提供优厚的待遇和全面的生活支持，毕业生就业前景广阔，主要集中在AI相关领域。MBZUAI还通过创新创业中心支持学生创业，资助多个项目并建立与行业合作伙伴的关系。目前，MBZUAI正准备开启2025秋季学期的招生工作，计划在全球多地举办宣讲会。
KAN结合Transformer，真有团队搞出了解决扩展缺陷的KAT,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934937&idx=3&sn=ab1575b8c37ab189fe7a5f40920070bc&chksm=84e7cae7b39043f18cead045f9d8cea477f6b07e39e25c9d895861788cea268a1f0f9a28a872#rd,2024-09-19 12:45:34,新加坡国立大学的研究者提出了Kolmogorov–Arnold Transformer (KAT)，它使用Kolmogorov-Arnold Network (KAN)层取代传统Transformer中的多层感知器（MLP）层，以增强模型的表达能力和性能。KAN层在准确性和可解释性方面表现优越，但面临着基函数选择、参数和计算效率低下以及权重初始化的挑战。研究者通过引入有理基础、Group KAN和Variance-preserving初始化解决这些挑战，提出了Group-Rational KAN (GR-KAN)。实验结果显示，KAT在图像识别、目标检测和语义分割等视觉任务上表现出优于基于MLP的Transformer的性能，同时具有更高的计算效率。
时序＝图像？无需微调，视觉MAE跨界比肩最强时序预测大模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934937&idx=4&sn=ce8587ace1e257745950bb586f71a481&chksm=84e7cae7b39043f1ded8e7019621603339bb7158436a80197bf73b7e4c1a327af30599206e32#rd,2024-09-19 12:45:34,研究人员发现，图像模型可以有效地迁移到时序预测领域。他们提出的VisionTS时序预测框架，基于何恺明的MAE模型，仅从自然图像预训练，无需时间序列微调，就能在零样本情况下比肩甚至超越专门的时序预测基础模型。这一工作表明计算机视觉和时间序列之间可能存在密切联系，并提出了一种新的预训练模型用于通用时间序列预测的方法。VisionTS在多个基准数据集上展现出优秀的预测性能。
保守派中间派原生派，谁将主导搜索引擎未来三十年？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934904&idx=1&sn=341ece1d85e2bdb433173dbee7d2c91b&chksm=84e7ca06b39043107f84a3200338b2b267225a4e92cbb6bd9044b9af0d1745673e5e598883d5#rd,2024-09-18 19:52:48,AI正在改变搜索引擎的格局，从传统搜索引擎到AI原生的“知识引擎”，不同流派的AI搜索方式展现出不同的特性和效果。保守派在现有搜索引擎上添加AI功能，中间派如New Bing深入改造但保留传统架构，而原生派如Perplexity、360AI搜索则构建全新的AI系统。原生派的“知识引擎”通过智能索引库、专属知识库和混合大模型智能调度系统，提供结构化、高质量的回答，尤其在处理复杂问题时表现更优。尽管AI原生搜索的成本高，但其效果和用户行为的改变（如更高的信息搜索需求和停留时间）显示潜力。360AI搜索作为AI原生引擎的代表，已实现商业闭环并快速增长。随着技术发展和推理成本的下降，AI搜索可能逐渐取代传统搜索引擎，成为用户获取知识的主要工具。
OpenAI押注的「1X」训出专用世界模型，首证机器人Scaling Law,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934904&idx=2&sn=676dfce39431a93eef9c5e42f6378063&chksm=84e7ca06b39043103685b065a06162c154d1307da318f2a84da0ee8dad84cc7bbc01e9082615#rd,2024-09-18 19:52:48,挪威人形机器人公司1X推出了双足人形机器人NEO Beta，并训练出一个世界模型作为机器人的虚拟模拟器。这个世界模型能够理解物理世界，生成高保真视频，让机器人可以在神经空间中进行规划、评估和模拟操作。模型可以预测物体交互、掉落影响、部分可观测性等问题，但尚未实现自我认知，如镜子实验中未能识别镜中的自己。1X认为世界模型是机器人技术扩展定律的重要一步，对于解决机器人评估的挑战具有重要意义。
Sigmoid注意力一样强，苹果开始重新审视注意力机制,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934904&idx=3&sn=baaf619eaf6f9f23e0109e3ba765189d&chksm=84e7ca06b39043102fa0a72b256343056615164b0eee91099bd590206cc1509e97e3dd41f9d5#rd,2024-09-18 19:52:48,苹果的研究者对Transformer架构中的注意力机制进行了探索，重新审视了sigmoid注意力并进行了深入的理论和实验分析。他们证明了sigmoid注意力的Transformer是通用函数逼近器，并且由于改进的正则化而受益。研究中提出了一种硬件感知且内存高效的sigmoid注意力实现——FLASHSIGMOID，它在H100 GPU上的推理速度比之前的方法提高了17%。实验表明，sigmoid注意力在各种任务和规模上的性能与softmax注意力相当，同时提供了训练和推理的加速。该研究还强调了sigmoid注意力在没有偏置的视觉任务中的有效性，并提出了如何在语言建模和自动语音识别任务中调整初始化以匹配softmax注意力的性能。
ECCV 2024 | 探索离散Token视觉生成中的自适应推理策略,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934904&idx=4&sn=d6df835c9eaaa5011edbb0ea72c0a800&chksm=84e7ca06b39043106f88f2bfcf141b301516c35c9a336454063c89285acf9aed20d5486aca87#rd,2024-09-18 19:52:48,这篇文章介绍了清华大学自动化系倪赞林等人发表的论文Ada NAT，该论文提出了一种自适应的策略网络，用于优化基于离散token的图像生成模型，特别是非自回归Transformer（NAT）。NAT在图像生成中显示出了高效的计算效率和生成质量，但其并行解码过程中的策略选择是一个挑战。Ada NAT通过引入可学习的策略网络，根据每个样本的特性自适应地配置生成策略，解决了这一问题。由于离散token生成过程的不可微性，研究者将问题形式化为马尔可夫决策过程，并使用强化学习进行训练。实验结果显示，Ada NAT在多个基准数据集上实现了高效的生成质量和多样性，同时降低了推理开销。
强化学习成为OpenAI o1灵魂，速来学习下Self-play增强大模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934904&idx=5&sn=52507c3eef0b80d312b85e9e6ba8a798&chksm=84e7ca06b390431093dc30a4729a0490b55cac1f80242cf2dd7a2a9b78cf940105009a2da9b8#rd,2024-09-18 19:52:48,这篇文章除了介绍自我博弈在强化学习中的重要性，特别是通过AlphaGo的例子，还提到了OpenAI的o1模型如何利用自我博弈策略实现通用推理能力的突破。加州大学洛杉矶分校（UCLA）顾全全教授的团队在2024年提出了两种自我博弈的大语言模型增强方法：自我博弈微调（SPIN）和自我博弈偏好优化（SPPO）。这些方法通过模型与自身历史版本的对抗学习，提升了模型性能，无需额外的人工标注数据。SPIN和SPPO在多个基准测试上表现出显著的性能提升。文章还宣布了一次线上分享活动，由顾全全教授及其团队成员详细解读自我博弈如何增强大语言模型。
OpenAI o1要跟，怎么跟？这个GitHub项目把解读、博客、相关论文一网打尽,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934677&idx=1&sn=0608865c95899e1063b627e7e3dd5352&chksm=84e7c9ebb39040fd1226fa431df641ee9c089376fb643a4eb10964a46456d0b20a43fb599ec1#rd,2024-09-17 13:02:37,这篇文章提到了一个 GitHub 项目，该项目汇总了关于 OpenAI o1 模型的高质量技术解读博客和相关论文。OpenAI o1 是一个重要的 AI 模型，引发了许多研究和讨论。文章列举了几个关键的博客和论文，包括 OpenAI 官方发布的关于模型训练方法、o1-mini 模型、使用 GPT-4 挑错的 CriticGPT 以及关于推理 scaling law 的研究。此外，还提到了一些论文，如训练验证器解决数学问题、使用大型语言模型进行自动定理证明以及通过批评性评论协助人类评估的模型。这些资源为理解 OpenAI o1 的工作原理和强化学习的最新进展提供了帮助。
OpenAI o1式思维链，开源模型也可以有，成功案例来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934677&idx=2&sn=9d8e02194368147c04020f15581dd2d2&chksm=84e7c9ebb39040fd85bca8179d86acfa0926af6c4689fda5c79714eab66dbc7125ad076caa89#rd,2024-09-17 13:02:37,"这篇文章的摘要可以是：

OpenAI 最近发布的 ο1 模型因其强大的推理性能引起关注，各路研究者尝试复现其技术。不久后，已经有研究者宣布成功开发出类似 ο1 的推理技术。其中，Martin Bowling 创建的 Llamaberry 通过思维链（CoT）实现推理，采用多轮推理系统，让 AI 进行更深入的思考。Llamaberry 的核心是让 AI 在解决问题时展示其思维过程，并通过多轮迭代不断改进。另一项目 g1 由 Benjamin Klieger 开发，它使用角色扮演、思维链提示等策略，也实现了类似 ο1 的推理能力，且开源。这两个项目表明，通过提示词工程和多轮推理，可以显著提升大模型的推理性能。"
昂贵LLM的救星？Nature新研究提出新型忆阻器，比Haswell CPU高效460倍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934677&idx=3&sn=78db7d2fbb66a0729dc25bef120fa91c&chksm=84e7c9ebb39040fdf10efcd97bb5db1c7ef391506da178bd852d16a96c65decbeb4f6adb0113#rd,2024-09-17 13:02:37,研究人员正在探索使用忆阻器来降低大语言模型（LLM）的使用成本，忆阻器是一种能记忆电荷量并能进行高效模拟计算的电子元件。最近，Nature上发表的一篇论文介绍了线性对称的自选择式14位动力学分子忆阻器，它能实现超过73分贝的信噪比和14位模拟计算精度，比现有电子器件效率更高且能耗低460倍。这种分子忆阻器的发明有望解决神经形态计算中的精度和功耗问题，为实现更高效、低成本的LLM硬件提供可能。
COLM 24 | 从正确中学习？大模型的自我纠正新视角,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934677&idx=4&sn=a08f8b05fc138fa3ba43fc6d076a3076&chksm=84e7c9ebb39040fd237d6b70739c19121d6691fce5822e618194fd546a5fcaae75b3a92b15b1#rd,2024-09-17 13:02:37,本文介绍了香港城市大学和华为诺亚方舟实验室的研究成果，提出了一种名为Learning from Correctness（LeCo）的新方法，用于改进大型语言模型的自我纠正能力。现有的自我纠正方法通常依赖复杂的prompt工程、人类反馈或外部工具，而LeCo则无需这些，它通过模型自己生成的推理步骤进行自我纠正。该方法计算每个推理步骤的置信度分数，识别并纠正低分步骤，逐步逼近正确答案。LeCo在逻辑推理、常识推理和数学推理等任务上表现出性能和效率的提升，同时减少了令牌消耗和迭代次数。研究发现，LeCo可以相对较准确地识别正确和错误的推理步骤，为大型语言模型的改进提供了一种新途径。
刚刚，CVPR 2025新规来了：审稿进入「半实名制」，不负责任的审稿人将被标记并拒稿,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934649&idx=1&sn=c6ad1cf2378eb92600f4422219d5dc8b&chksm=84e7c907b3904011f8fe650ce09ae14be9a2666f9057efa7d23838991f02ca4a66bebbc6ec55#rd,2024-09-16 13:16:02,计算机视觉领域顶级会议CVPR因投稿数量急剧增加和审稿质量下降，宣布对审稿制度进行重大调整。新规定包括：所有作者（除非在CVPR 2025组织中担任其他角色）有义务担任审稿人，审稿数量按作者资历决定；审稿人若被标记为“高度不负责任”，其提交的论文可能会被直接拒绝；每位作者最多可提交25篇论文，超出会被直接拒绝；禁止使用大型语言模型撰写审稿意见；审稿人的名字在OpenReview上对其他审稿人可见；投稿者需填写完整OpenReview个人资料，否则论文将被拒绝；CVPR 2025的审稿数据将分享给未来相关会议以评估审稿质量。这一系列措施旨在改善审稿质量，但引起了关于投稿篇数上限和审稿人责任的讨论。
OpenAI o1智商120，还是被陶哲轩称为「平庸的研究生」，但实力究竟如何？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934649&idx=2&sn=bc5360ff59010b92689429d5ce4f0ada&chksm=84e7c907b3904011237f66077a2aefb1a683aab7a7f27f55aa1e8f08cfc41c495b2948c7ebe8#rd,2024-09-16 13:16:02,OpenAI 的新模型 o1 引发了广泛关注和一系列测试。有人使用门萨智商测试题评估 o1，得到智商分数高达 120，但也有测试得到的分数为 100。数学家陶哲轩认为 o1 相当于一个平庸但不无能的研究生，能解决一些数学问题，但在复杂任务上仍有不足。在 ARC Prize 测试中，o1 的表现未达预期，与几个月前的模型得分相当。此外，有研究者通过逆向工程试图解析 o1 的架构。尽管 o1 显示出一定的能力，但 OpenAI 对其在化学、生物和风险领域评为“中等”，并警告其潜在危险，包括策略性伪装对齐和“奖励黑客行为”。
ECCV 2024 | 一眼临摹：瞥一眼就能模仿笔迹的AI,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934649&idx=3&sn=bdc55abc44abe48e85d37526fbbc6280&chksm=84e7c907b390401150f48ab8485554974d830653eebaf3490ac4c34348c6bbae4d6a329587ed#rd,2024-09-16 13:16:02,来自华南理工大学、新加坡国立大学、昆仑万维和琶洲实验室的研究者们提出了一种新的风格化手写文字生成方法，名为One-DM（One-Shot Diffusion Mimicker），该方法仅需单张参考样本即可模仿用户的书写风格，支持英文、中文和日文。这一方法解决了现有方法需要多张样本作为输入的繁琐问题，提高了效率和便利性。研究者发现，通过高低频分离，可以从单张样本的高频成分中提取清晰的书写风格，并使用拉普拉斯风格增强模块和自适应门控机制来增强风格提取和过滤背景噪声。One-DM在多个数据集上的实验表明，它在风格临摹性能上超过了需要十几张样本的现有SOTA方法。论文和代码已开源。
打开AI黑匣子，「三段式」AI用于化学研究，优化分子同时产生新化学知识，登Nature,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934649&idx=4&sn=108825e6783ec01b378ee3babf81f5fc&chksm=84e7c907b3904011fa9d745703364ba1be6a156afe4685d4fc60acfe008a927543649c524b2a#rd,2024-09-16 13:16:02,"研究人员通过结合AI与自动化学合成和实验验证，揭示了AI在优化分子过程中的工作原理，特别是在提高用于收集太阳能的分子的光稳定性方面。他们提出了一种称为“闭环转移”（Closed-loop Transfer, CLT）的方法，该方法在优化目标函数的同时产生了化学见解。研究发现，高能三重态（Tn, n>1）是分子光稳定性的关键因素，这一发现有助于解决有机光伏电池的稳定性问题，这些电池在暴露于光线下时会降解。通过五轮闭环实验，研究团队成功提高了分子的光稳定性高达四倍，并为分子设计提供了新的物理描述。这种方法有望加速新材料的发现，并为其他材料系统提供解决方案。"
北大对齐团队独家解读：OpenAI o1开启「后训练」时代强化学习新范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934580&idx=1&sn=41c727eb05b277ea855f03962bf7e5a0&chksm=84e7c94ab390405c71972e79b15858cb5270cb8058782d607112edbeedd3c7f23780c8bcf757#rd,2024-09-15 13:06:51,OpenAI 推出的 o1 模型在数学、代码和长程规划等复杂问题上取得显著进步，这得益于后训练阶段（Post-Training Stage）中强化学习训练和推理阶段思考计算量的增加。关键技术创新包括运用强化学习的搜索与学习机制，基于LLM的推理能力，通过迭代式Bootstrap生成合理推理过程（Rationales），并将这些Rationales融入训练中，让模型学会推理。此外，通过增加测试推理阶段的思考时间，模型性能进一步提升。这一发展表明了Post-Training Scaling Laws的重要性，即在训练后阶段提升模型能力的新趋势。模型在数学问题上表现优秀，例如在Codeforces竞赛中排名靠前，在AIME资格赛中达到美国顶尖学生水平，并在GPQA基准测试中超过人类博士水平。OpenAI o1 的成功在于合理使用强化学习进行探索，通过构建逻辑数据集和类似AlphaGo的MCTS方法，但不局限于直接搜索，而是通过学习和优化内部推理过程提高性能。模型通过动态引入Reasoning Token进行“思考”，并在推理时间上实现新的扩展维度。OpenAI o1 的技术路线与STaR和Quiet-STaR类似，但更进一步，通过强化学习优化隐式思维链，增强了模型的推理能力。未来，强化学习和模型推理能力的提升将成为大模型发展的重要方向，同时，强化学习在训练和推理阶段的作用，以及如何平衡推理能力和指令跟随能力，也将是研究的关键问题。
DeepMind又损大将，AI总监Nando de Freitas离职，曾领导开发Gato、Genie,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934580&idx=2&sn=dd00fc29ef15b5c736ef620eec65a305&chksm=84e7c94ab390405c92ec0c555fad89c386bf4b4fb1ee1b08a1315d6fad117ded7d615e1c7120#rd,2024-09-15 13:06:51,谷歌DeepMind的高级AI总监Nando de Freitas宣布离职，结束他在该公司10年的任职。Nando de Freitas是DeepMind众多知名大模型项目如Imagen、Gato的共同领导者。他在推特上感谢了DeepMind的团队和同事，并表示离开是为了成长和进步。他在DeepMind期间对机器学习领域做出了重要贡献，他的离职引发了同事们的惋惜和祝福。Nando de Freitas在人工智能研究方面有着显著的成就，他的论文被广泛引用，且在教育和研究方面有着丰富的经验。
「LLM」这个名字不好，Karpathy认为不准确、马斯克怒批太愚蠢,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934580&idx=3&sn=7746b10bf4947ea9a3230e315ee29b8d&chksm=84e7c94ab390405c643852f9055b161c2e2d38cd645b0498341ae739c5134759338591ace128#rd,2024-09-15 13:06:51,AI专家Andrej Karpathy提出，大型语言模型（LLM）的名字具有误导性，因为它们并不仅仅与语言相关，而是一种统计建模的通用技术。他建议更准确的名称应为自回归Transformer，因为这些模型可以处理各种离散token，而不仅仅是文本。这个观点引发了大量的讨论，有人支持改名，认为“语言”一词限制了人们对LLM潜力的理解，而有人则认为从广义上讲，所有可转化为token流的事物都可以视为一种语言。马斯克和一些研究员表达了赞同，但也有人指出，即使专注LLM，深度学习框架的通用性仍有其必要性，以适应不断发展的模型需求。
华为诺亚联合中科大发布工具调用模型ToolACE，效果持平GPT-4获开源第一,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934580&idx=4&sn=cd8335a678dd042f72b541e90c907995&chksm=84e7c94ab390405c5d8f166e352850cdf2b5e2fbaaf4f277688bc84cf7674e041eb1dbb95c14#rd,2024-09-15 13:06:51,"华为诺亚方舟实验室和中国科学技术大学等机构的研究人员提出了一种名为ToolACE的统一工具调用数据合成框架，旨在增强大语言模型的工具调用能力。ToolACE通过自进化过程生成包含26,507个API的库，并使用多智能体交互来合成多样化的工具调用对话。该框架还包括一个双层数据质检流程以确保数据的准确性和可靠性。通过对LLaMA-3.1-8B-Instruct模型进行微调，ToolACE在加州大学伯克利分校的BFCL工具调用测试榜单上表现优秀，击败了包括GPT-4在内的其他模型，获得开源模型的第一名。此外，实验表明ToolACE在提升工具调用能力的同时，保持了良好的通用任务处理能力。"
超越AlphaFold3，OpenAI投资的AI生物初创发布Chai-1，分子结构预测新SOTA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934580&idx=5&sn=7daaea6e59baf97901ba6834ec123d9c&chksm=84e7c94ab390405c187a3f48fdc627f94b67c7288c4ba8cecc1abcf6f6346d1db5fa8e3b2495#rd,2024-09-15 13:06:51,AI生物技术公司Chai Discovery发布了新模型Chai-1，该模型能预测蛋白质、小分子、DNA、RNA等多种分子结构，并在药物发现相关任务中达到SOTA水平，与AlphaFold等模型相比在某些基准测试上表现出色。Chai-1提供Web界面免费试用，并开放模型权重和推理代码供非商业使用。Chai Discovery的目标是通过AI技术加速药物研发和生物工程，公司已获得包括OpenAI在内的投资。
李飞飞任CEO，空间智能公司World Labs亮相，全明星阵容曝光,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934463&idx=1&sn=aaecfca83e6249bf23aa15aec04fa162&chksm=84e7c8c1b39041d79808ea9eff7867923d96f4abd8f466ded5e33800bc46a1e8fdeaac29c9d8#rd,2024-09-14 12:09:58,AI领域的标志性学者、ImageNet创始人李飞飞宣布创办AI初创公司World Labs，旨在教授人工智能系统物理现实知识，聚焦空间智能技术。李飞飞认为空间智能是AI领域尚未解决的难题，有潜力应用于创作、设计、AR/VR和机器人等领域。World Labs已获得2.3亿美元投资，估值达10亿美元。该公司的目标是打造对三维性、物理性和时空有深刻理解的AI模型，初期将支持增强现实技术，未来可能进入机器人领域。公司预计在2025年推出产品。World Labs的团队成员包括多位知名AI研究者，如Justin Johnson、Christoph Lassner和Ben Mildenhall，获得了包括Andreessen Horowitz在内的多家投资机构和知名天使投资人的支持。
张俊林：OpenAI o1的价值意义及强化学习的Scaling Law,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934463&idx=2&sn=641e7849ea6e8b207d010c709166d78a&chksm=84e7c8c1b39041d7a21b578a3cdeb620d783c50004c0e138e3e784a584d837f8b5a585b48658#rd,2024-09-14 12:09:58,本文是新浪新技术研发负责人张俊林对OpenAI的最新模型o1的分析，他认为o1是大模型发展的重要里程碑，特别是在增强逻辑推理能力方面，比GPT 4o更重要。o1通过自动化COT（对话操作语法）提升了模型解决复杂逻辑问题的能力，这将有助于改进多模态模型如GPT 4o。文章指出，o1的发展意味着Prompt工程将逐渐被淘汰，因为模型能够自动生成解决复杂问题的步骤。尽管o1对简单和中等复杂度的Agent任务有所提升，但在复杂的多步骤任务中仍有不足。此外，作者讨论了预训练模型的Scaling law，强调逻辑推理能力的提升是当前大模型发展的重要挑战。o1在强化学习（RL）上的Scaling law表明，通过增加计算力可以进一步提高模型的性能。作者认为，o1所指明的方向值得业界关注和跟进，预训练数据中逻辑推理内容的增加将是提升模型能力的关键。
o1 改变了 Scaling 范式？Self-Play 还值得 All In 吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934463&idx=3&sn=ebcb6468cfdac5f21cdb1dd7ac4f8601&chksm=84e7c8c1b39041d706333a7a13368770348eebf6f70d2b0d43986829a7d645e815f8416215e2#rd,2024-09-14 12:09:58,本周的AI & Robotics业内要事包括OpenAI发布的o1模型在数学和理科推理上的突破，这可能改变Scaling Law的范式。o1模型通过强化学习和内部思维链进行复杂推理，展现出在编程和科学知识方面超越前代模型的能力。此外，AI情感陪伴类应用的市场增长迅速，但技术缺陷和盈利前景尚不明朗。Businessinsider评选出2024年最有前途的44家AI创企，这些公司主要集中在不同领域，具有不同的业务模式和融资情况。本期通讯还提供了其他AI和机器人领域的26项重要动态。
首次！用合成人脸数据集训练的识别模型，性能高于真实数据集,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934463&idx=4&sn=edc272afeeae950e81d3c64868470b01&chksm=84e7c8c1b39041d7a1ac11e260c8bbdcd01bc5e99d5df2656bc1198558ba06136fd24cdf7677#rd,2024-09-14 12:09:58,研究人员提出了一种名为Vec2Face的模型，该模型能够从特征向量生成逼真的人脸图像，并在生成过程中控制身份（Inter-class separability）和类内变化（Intra-class variation）。Vec2Face解决了现有方法在实现高分离度和变化度之间的平衡问题，不需要额外的模型即可实现。此外，通过Attribute Operation算法，Vec2Face可以定向生成具有特定属性的人脸。论文结果显示，使用Vec2Face生成的HSFace10k训练的人脸识别模型在多个测试集上表现出色，甚至在某些情况下超越了真实数据集的性能。该模型可以无限生成不同身份的图像，且在扩大数据集规模时，性能持续提高。与现有方法相比，Vec2Face在模型大小、推理速度和FID方面具有优势。
电力、芯片制造、数据和延迟成四大限制因素，Scaling Law能续到2030年吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934463&idx=5&sn=cabe5236376a83c2930c266154ba3313&chksm=84e7c8c1b39041d7006221021d81facab9b0cd7e20c0f346be8f0e9a97e09348b430e7eb6680#rd,2024-09-14 12:09:58,这篇报告分析了人工智能训练规模的快速增长，指出计算资源的增加在人工智能性能提升中起着重要作用。训练计算量以每年约4倍的速度增长，超过了某些技术扩张的峰值增长率。报告探讨了到2030年前，这种扩展是否在技术上可行，考虑了电源可用性、芯片制造能力、数据稀缺性和延迟墙四个关键因素。研究发现，到2030年，训练规模超过当前GPT-4的模型是可能的。然而，这需要克服电力、芯片制造、数据限制和延迟问题。尽管存在不确定性，但报告显示，如果投资数千亿美元，人工智能可能会实现巨大进步。报告还提及了延迟墙作为未来需要克服的障碍，并讨论了扩大规模的潜在经济回报。
刚刚，OpenAI震撼发布o1大模型！强化学习突破LLM推理极限,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934313&idx=1&sn=3e89923751621fed57602ffe4ba751f4&chksm=84e7c857b3904141d5ef61e834efeb469e7982498aca47cfe92cadcf3912908754e752793c2a#rd,2024-09-13 04:00:46,OpenAI发布了全新的AI大模型系列，旨在解决复杂推理问题。这个系列中的首个模型称为o1-preview，拥有通用推理能力，在数学、科学和代码等高难度基准测试中表现出色，超越了之前的GPT-4o。o1模型在某些测试中甚至达到了人类专家的水平，例如在国际数学奥林匹克资格考试中正确解答了83%的问题。与GPT-4o相比，o1在需要复杂思考的任务上有了显著提升。OpenAI表示，该模型通过强化学习训练，能够产生内部思维链，在回答问题前进行深入思考。此外，o1还展示了在编程任务上的优秀能力，例如在国际信息学奥林匹克竞赛中达到了前49%的水平。OpenAI计划不断迭代该模型，期望这些推理能力能增强模型与人类价值观和原则的结合。目前，ChatGPT已经开始使用o1模型，用户可以体验到更高级别的推理能力。
当代版木牛流马？国外网友造出「会走路的桌子」，引百万人围观,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934313&idx=2&sn=f096ee1224f5e25a28ce11557d43d915&chksm=84e7c857b3904141b07e7a39f609f4856fb310dd8c89c052ef3d515a3ada2fc3064d727a8135#rd,2024-09-13 04:00:46,这篇文章介绍了一个独特的发明——Carpentopod，一个拥有12条腿的智能桌子，能够通过内置电机自动向用户移动。这个创意结合了木工、电子和编程技术，腿部设计经过软件模拟进化，以实现平稳行走。作者使用数控机床加工竹板部件，并通过Arduino系统控制电机，让桌子能够移动。设计过程中，腿部连杆的优化是通过虚拟环境中的进化算法实现的，最终选择了最佳的腿部结构。作者表示，这个项目是对他早期编程软件和近年来掌握的木工、电子技能的结合应用。Carpentopod在网上获得了广泛关注，作者计划在活动中进一步展示。整个制作过程包括设计、材料选择、加工和装配，作者分享了详细的制作过程和设计思路。
面向软件工程的AI智能体最新进展，复旦、南洋理工、UIUC联合发布全面综述,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934313&idx=3&sn=8c7cc748fe2d37aff813f349c4e008cb&chksm=84e7c857b3904141556a2b590a6186e6736c8145ed136be7ff434bb5f653e0adadc79ed013eb#rd,2024-09-13 04:00:46,复旦大学CodeWisdom团队与南洋理工大学、UIUC的研究人员联合发表了一篇综述，探讨了AI智能体在软件工程领域的应用。这些AI智能体，基于大模型，通过增强推理、记忆、规划和工具使用能力，提升了处理复杂软件开发和维护任务的效率。文章总结了智能体在软件开发全周期中的应用，包括端到端开发和维护，并列出了相关研究文献。此外，还分析了智能体的基础架构、多智能体设计和人机协同模式。论文展望了未来的研究方向，如建立更全面的评测基准，探索人机协同新范式，以及将AI智能体应用于更多软件工程任务中。
边缘智能的新时代：端侧大模型的研究进展综述,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934313&idx=4&sn=7cb65e74f5ecf228bdd2f58bb770ffc2&chksm=84e7c857b390414165615578aad9eae9fc8d698cd07e003cbf9736980510657d83afeef513fb#rd,2024-09-13 04:00:46,这篇综述文章关注的是将大型语言模型（LLMs）部署到边缘设备上的技术进展和挑战。随着AI技术的发展，端侧AI市场增长迅速，边缘设备上部署LLMs可以提供更快的响应速度和更好的隐私保护。文章分析了模型压缩、能效计算、轻量级模型架构、硬件加速和边缘-云协同部署等策略，并介绍了如Meta的LLaMA、Microsoft的Phi系列、Nexa AI的Octopus系列等端侧LLM的发展。此外，文章还讨论了模型压缩技术，如量化、剪枝、知识蒸馏和低秩分解，并提到了硬件加速器如GPU和TPU在提升端侧LLMs效率中的作用。最后，文章探讨了端侧LLMs在不同应用领域的实例，如即时消息、翻译、医疗、科研等，并展望了未来边缘计算在隐私保护、多模态学习、资源效率和个性化AI体验方面的挑战和机遇。
谢尔盖布林：谷歌不敢用Transformer，作者剩一人了，现在我每天都在写代码,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934126&idx=1&sn=1ed0d5ea016e467e4568d86adb54dc50&chksm=84e7cf10b3904606c8040778ef5699e07f6ca876a6e8a800a62c5b546a9d758c9f2dfb3fe750#rd,2024-09-12 12:46:09,谷歌的联合创始人谢尔盖·布林在ChatGPT的影响下重返一线，亲自参与AI技术开发，他认为AI领域的进展令人兴奋，作为计算机科学家不想错过这一波浪潮。布林表示，AI技术将带来广泛的变革，而不仅仅是搜索的延伸。他更看好通用模型，而不是专精于某个领域的专家模型，并指出谷歌已经在形式证明模型中融合知识到通用语言模型。布林还提到，虽然AI的错误需要应对，但过于保守可能会阻碍创新，他认为及时发布AI技术并接受错误是必要的。谷歌在AI领域面临竞争，布林认为这是一件好事，但公司需要关注大模型的排行榜并不断进步。此外，他指出生物学是AI技术应用的一个成功领域，而机器人技术尚未达到日常可用的水平。
音频驱动人像视频模型：字节Loopy、CyberHost研究成果揭秘,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934126&idx=2&sn=6a03156a218ba6745a0e6bb88155bb31&chksm=84e7cf10b3904606ec423e6d71d7112a88b897f44f849315e6d9ec2b0b46e1a3540a561440cf#rd,2024-09-12 12:46:09,字节跳动的视频生成模型Loopy近日引发关注，该模型能通过一张图片和音频生成逼真的肖像视频，准确实现音频和口型同步，还能生成细腻的表情动作。Loopy采用Diffusion视频生成框架，通过inter/intra-clip temporal layers模块捕捉人物运动信息，并通过Temporal Segment Module学习长时运动信息。此外，audio to latents（A2L）模块增强了音频与头部运动的关联，帮助生成生动的表情。Loopy在不同场景下与近期方法对比表现出优势。团队还推出了CyberHost模型，能纯音频驱动半身视频生成，包括同步的手部动作，这在技术上是一个突破。
蚂蚁自研知识增强大模型服务框架KAG，可显著提升知识推理准确率,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934126&idx=3&sn=1f887632c467091afe785b7734d0f41b&chksm=84e7cf10b3904606ff83d20bbf961ee8b32f5759177378d7f4597617711ef6fe574c237e7109#rd,2024-09-12 12:46:09,蚂蚁集团在2024 Inclusion・外滩大会上分享了其在知识图谱与大模型结合的最新成果——知识增强大模型服务框架 KAG。KAG 通过图谱逻辑符号引导和信息检索，提高了垂直领域决策的精准性和逻辑性，并能补全知识图谱的不足。该框架已在支付宝的“支小宝”App中应用，提升了政务问答和医疗问答的准确率。KAG 框架将在开源框架 OpenSPG 中原生支持，并开放给社区共建。此外，蚂蚁集团与浙江大学成立了知识图谱联合实验室，推动知识图谱与大语言模型的融合。
与「李白」赏图赋诗，同「猴哥」直面天命，人大高瓴提出MMRole多模态角色扮演,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934126&idx=4&sn=e3ebe46ce47683aee042e91a65691774&chksm=84e7cf10b39046069b34dd4ea8e22cf0242514db71f61b776f3587ff39ebc5aed4935a614f74#rd,2024-09-12 12:46:09,中国人民大学高瓴人工智能学院的研究团队提出了多模态角色扮演智能体（MRPAs）的概念，并推出了MMRole框架，包括大规模多模态角色扮演数据集MMRole-Data和评测方法MMRole-Eval。MMRole-Data包含85个角色、11K张图像和14K段多模态对话，旨在训练和评估MRPAs的性能。MMRole-Agent是首个MRPA，展示出优秀的多模态理解和角色扮演能力。该框架的提出扩展了角色扮演智能体的应用场景，为AI交互带来了更沉浸的体验。
检索总结能力超博士后，首个大模型科研智能体PaperQA2开源了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650934126&idx=5&sn=a10dcd5172c28bda49ce326b64d4fe98&chksm=84e7cf10b39046063d97ae79f5269351af1d4df3e20ffe8ffbdcc4dbfe29eb4187a4e369fbdb#rd,2024-09-12 12:46:09,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
Scaling Law瓶颈，Cursor编程为什么这么强？团队参与新研究掏出秘密武器,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933875&idx=1&sn=c11817d2f2d2b6a6f56ac287fd51c5c6&chksm=84e7ce0db390471b0f5a7f77b99e1a187ee51fc7e2bd4c5bc6c0afdcf4d6e4b8fb23408e875f#rd,2024-09-11 12:36:50,研究人员提出了一种名为PlanSearch的新方法，旨在通过搜索自然语言的规划来增强大型语言模型（如Claude 3.5 Sonnet）的代码生成能力。该方法由Scale AI的研究人员主导，论文表明在大模型中增加搜索策略能有效提升代码生成的性能。目前，大模型在生成多样性答案方面存在挑战，这影响了搜索效果。PlanSearch通过生成和组合观察来搜索解决问题的正确思路，从而生成更丰富的代码解决方案。实验结果显示，规划搜索在多个编程基准上优于标准的重复采样方法，特别是在LiveCodeBench基准上，使用规划搜索的Claude 3.5 Sonnet在pass@200指标上取得了最佳性能。
召唤100多位学者打分，斯坦福新研究：「AI科学家」创新确实强,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933875&idx=2&sn=ea124b81eab11720cc0fd5ec8d02ff37&chksm=84e7ce0db390471b4eb1996e92180869c6a454343846099cffa47523655579199c6eb1222d49#rd,2024-09-11 12:36:50,斯坦福大学的研究发现，大型语言模型（LLM）生成的研究想法在新颖性和激动人心程度上超过了专家级人类研究者。研究团队通过让LLM生成科研思路，然后让人类专家进行盲测，结果表明LLM的想法在某些方面显著优于人类。不过，在可行性和有效性方面，AI生成的思路与人类的差距不大。这项研究也指出了一些局限性，如样本量小和主观评价。尽管如此，它证明了AI在科学研究中的潜力，尤其是在创新思维方面。目前，已有研究团队开始开发利用LLM生成创新想法的AI工具。
OpenAI「草莓」两周内发布？网传不是多模态，反应慢了10多秒,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933875&idx=3&sn=686fee131279ec7ce8834884cf20635d&chksm=84e7ce0db390471b49fd2b3d8309cc7c6df116dcbb49d8a3fb5e39a138eb4076db310ca98540#rd,2024-09-11 12:36:50,OpenAI计划在未来两周内发布名为“草莓”的新AI模型，该模型将作为ChatGPT服务的一部分，但也是一个独立的产品。与ChatGPT不同，“草莓”在响应之前会有10到20秒的“思考”阶段，以提供更全面和精准的答案。它主要在数学问题、编码和商业策略等任务上表现出色。然而，目前的原型在某些情况下可能会思考过久，且可能不总是能准确记住并整合之前的聊天内容。关于定价，据悉“草莓”可能会限制用户每小时发送消息的数量并提供不同价格等级，以加快响应速度。尽管存在一些问题，但随着更多爆料，OpenAI的“草莓”似乎越来越接近发布。
iPhone16跑分泄露，8G内存，A18多核不敌上上代A16，网友：假的吧,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933875&idx=4&sn=0fbd40a73c9aa0770b2c71373f501e85&chksm=84e7ce0db390471b60413f6ec655548cc0e289a534d08075438ebb35802d1748a3bac816e9dd#rd,2024-09-11 12:36:50,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我将尽力为您提取关键信息。
ACL杰出论文奖｜GPT-4V暴露致命缺陷？JHU等发布首个多模态ToM 测试集，全面提升大模型心智能力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933875&idx=5&sn=fae88183d526dbc2faa566ea8232ac18&chksm=84e7ce0db390471b91ebb620a733b19330deb8b481588b9e0640512a7d6c3f120241c8c34c36#rd,2024-09-11 12:36:50,研究人员开发了第一个多模态的心智能力测试基准MMToM-QA，用于评估AI模型理解人类思维的能力。该基准通过视频和文本描述测试模型的信念和目标理解。实验显示，现有的多模态模型和大模型如GPT-4V在MMToM-QA上的表现远不及人类，存在系统性缺陷。为解决这一问题，研究团队提出了BIP-ALM方法，通过融合符号表示和逆向规划来推断心理状态，表现出比GPT-4V更好的结果。后续工作MuMA-ToM进一步扩展到多智能体的多模态心智模型领域。
刚刚，苹果首款AI手机发布！A18芯片，新增拍照按钮，AirPods变助听器,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933734&idx=1&sn=6b788a7fb34003b7e709f222840ea5ff&chksm=84e7cd98b390448eafb0fda38dd166d08cb3c92bfec22ad57cf0e74fe8614a9c44dfd90f5fb3#rd,2024-09-10 06:50:44,苹果发布了新一代iPhone 16系列，包括iPhone 16、iPhone 16 Plus、iPhone 16 Pro和iPhone 16 Pro Max。新款iPhone增加了两个按钮，相机控制按钮和动作按钮，颜色更加丰富。硬件产品将于9月13日开启预售，9月20日发售。AI成为本次发布会的关键，所有产品都配置了智能能力。iPhone 16标准版保持60Hz屏幕刷新率，配备4800万像素主摄，支持26毫米焦距和8GB运行内存。新功能包括相机控制，用户可以通过滑动侧面按钮调整相机设置。iPhone 16 Pro版屏幕尺寸升级，最高支持120Hz刷新率，搭载了更强的A18 Pro芯片，性能提升。相机系统也进行了升级，配备三个摄像头，支持多种拍摄模式。此外，发布了新一代AirPods和Apple Watch，Apple Watch支持睡眠呼吸暂停检测和更快的充电速度。Apple Intelligence智能系统将向用户推送，提供更个性化的智能体验。
还在人工炼丹？自动提示工程指南来了，还带从头实现,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933734&idx=2&sn=e28de494c79c1ae581bd51fbea8853e7&chksm=84e7cd98b390448e860d2061d9bf0b4f352705bf399cf5b715b0b97ea394087566a99a820b91#rd,2024-09-10 06:50:44,"谷歌研究者 Heiko Hotz 发表了一篇关于自动提示词工程（Automatic Prompt Engineering, APE）的文章，详细介绍了如何自动生成和优化用于语言模型（LLM）的提示词，以提升模型在特定任务上的性能。APE 类似于传统机器学习中的自动超参数优化，通过自动化生成和测试提示词，避免了手动设计带来的耗时和局限性。文章提供了从零开始编写 APE 程序的指导，包括原理、策略和实现方法，并强调了 APE 的重要性，因为它可以释放 LLM 的潜力，特别是在处理多个模型和大量任务时。作者还分享了代码实现，并提到了一些现有的 APE 框架。通过 APE，可以使用 LLM 生成和优化提示词，从而提高模型在任务上的准确性和效率。"
表格增强生成TAG登场：解锁AI自然语言与数据库的完美结合,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933734&idx=3&sn=2f8c1fd41e9827e2d40a8c3de6f92974&chksm=84e7cd98b390448eea5c4424c8e0ad32b6acef5a7142e23d4090fafacaf858ec69b5986a0b29#rd,2024-09-10 06:50:44,UC 伯克利和斯坦福大学的研究人员提出了一种名为表格增强生成（TAG）的新方法，旨在解决自然语言查询数据库时的复杂性问题。TAG 是一种统一的范式，它结合了语言模型和数据库的功能，以更全面地处理用户查询。与仅关注 SQL 查询或点查找的现有方法不同，TAG 包含查询合成、查询执行和答案生成三个步骤，能够处理更复杂的查询需求，包括领域知识、世界知识和语义推理。实验表明，TAG 在准确率和效率上优于标准基线，尤其在需要推理的查询上表现突出。
还在死磕AI咒语？北大-百川搞了个自动提示工程系统PAS,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933734&idx=4&sn=b3009b146e589fb79be58be47449843b&chksm=84e7cd98b390448e8e3eed275074f09c472731c7e7bd1d61ea8a57d9e888d75b6a062b890789#rd,2024-09-10 06:50:44,北京大学和百川智能AI系统联合实验室的研究人员开发了一种名为PAS的自动提示工程系统，该系统能有效地为大语言模型生成高质量的提示词，从而提高模型在特定任务上的性能和适应性。PAS通过设计自动提示数据集、对GPT模型进行少样本学习和数据筛选，以及自动构建精简高效的提示数据集来实现这一目标。在多个基准测试中，PAS的表现优于现有最佳模型，并且所需数据量更少。这一创新成果不仅推动了提示词工程领域的发展，也为大语言模型在更广泛的应用中提供了支持。论文地址：https://arxiv.org/abs/2407.06027。
清华、北大等发布Self-Play强化学习最新综述,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933734&idx=5&sn=5a5ff3dddf42a5654c57068aaef170c4&chksm=84e7cd98b390448e78eec4a0621ba914dea2ee82bf1ce57b8cb45f7f75770f8339e8735c10df#rd,2024-09-10 06:50:44,这篇综述文章由清华大学、北京大学、第四范式、腾讯和清华-伯克利深圳学院的研究人员合作完成，梳理了自博弈（self-play）在强化学习中的应用和方法。自博弈是智能体通过与自身或历史版本对战来演化策略的方法，近年来在强化学习领域取得显著成果。文章介绍了自博弈的基本概念，包括多智能体强化学习和博弈论背景，并提出一个统一的自博弈算法框架，对现有算法进行分类和比较。此外，文章还探讨了自博弈在棋类游戏、牌类游戏和电子游戏等场景的应用，以及面临的挑战和未来研究方向。
从腾讯大模型的「实用」路线，我们看到了企业应用AI的新方向,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933579&idx=1&sn=f04a98c990ea1b391d8bef55e21d43d2&chksm=84e7cd35b39044231243ec21989de71329094c689a2ce13f0e5ed632399cc51c69fec4c1c6f9#rd,2024-09-09 12:13:23,"这篇文章的摘要可以这样写：

在AI逐渐融入各行业产品的背景下，企业引入AI是否能提高利润成为关注点。Cohere CEO Aidan Gomez认为，随着AI成本的下降，企业在提升客户体验的同时维持产品价格不变，可以扩大用户基数。腾讯混元大模型通过技术创新，实现了训练和推理效率的提升以及推理成本的降低，其新模型混元 Turbo在性能上表现出色，且性价比得到提高。除了模型优化，腾讯还围绕大模型开发了一系列实用工具链和产品，如知识引擎、图像创作引擎等，以解决实际应用场景中的问题。例如，在医疗领域，腾讯与迈瑞医疗合作打造的重症大模型有助于减轻医生的工作负担。企业引入AI不仅可以提升用户体验，随着成本的下降，也有望实现经济效益。"
任意论文一键变播客，谷歌正式发布Illuminate，它能重构研究者的学习方式吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933579&idx=2&sn=1807d7c490558092a312b5481560c983&chksm=84e7cd35b3904423161204d453bfce8512727c09e3d95c0526090248b2b0a749bb8fff8221df#rd,2024-09-09 12:13:23,谷歌推出Illuminate项目，可以将学术论文转化为人工智能生成的音频讨论，用播客的形式介绍论文核心内容。这项服务由谷歌的大模型LLM Gemini生成摘要和问答，通过男性和女性AI声音进行对话呈现。用户可以在运动或开车时听取论文摘要，目前专注于计算机科学领域的已发表论文。用户需要申请才能使用，生成的音频内容支持调整语速和分享，但目前仅提供英文版，且不支持音频下载和字幕。
TPAMI 2024 | 计算机视觉中基于图神经网络和图Transformers的方法和最新进展,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933579&idx=3&sn=fea5f9c2e2775f947edcbe5b2f64786f&chksm=84e7cd35b3904423e6240a8612d16e78373bba3c0c64982d50d06929ac1bfba9be34e4a2f84b#rd,2024-09-09 12:13:23,这篇文章是关于图神经网络（GNN）在计算机视觉领域的综述，已被《IEEE 模式分析与机器智能汇刊》接收。作者来自香港大学、香港中文大学（深圳）和上海科技大学。GNN 在处理非网格数据和图表示学习中的优势使其在多个领域得到广泛应用，包括社交网络分析、目标检测、点云处理和关系提取等。当前的综述文章在全面性或时效性上存在不足，这篇综述则以任务为导向，详细调研了GNN在自然图像、视频、视觉+语言、三维数据和医学影像等领域的应用。文章还介绍了GNN的发展历程，包括循环GNN、图卷积等方法，并探讨了各种视觉任务的统一数学表达和关键挑战。通过系统总结，作者希望为未来的研究提供指导。
Anthropic安全负责人：在超级AI「毁灭」人类之前，我们可以做这些准备,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933579&idx=4&sn=1a6f9b1e665a25279a734227f806f265&chksm=84e7cd35b3904423b96532de329a47d8aa4b12f050346d042061e7ba7460043a4c68395da622#rd,2024-09-09 12:13:23,AI公司Anthropic发布了负责任扩展策略（RSP），以管理越来越强大的AI系统开发中的风险。RSP关注AI系统可能直接造成的灾难性风险，比如故意滥用和自主行动导致的破坏。它还引入了AI安全等级（ASL）框架，分为多个级别，随着级别的提高，安全性验证变得更加严格。当前的大型语言模型被认为是ASL-2级别。Anthropic的安全研究部门负责人讨论了在不同阶段确保AI安全所需的技术工作，强调了准备阶段的技术跟踪、对齐问题的解决和制定合适的RSP的重要性。随着AI能力的增强，安全挑战也日益增大，需要在技术、组织和决策层面采取相应措施。
北大王立威：理论视角看大模型，为什么AI既聪明又愚蠢 | 智者访谈,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933510&idx=1&sn=119ca1a2ddfb58bfa4f0193f37397993&chksm=84e7cd78b390446e5c01890ec0038f613f0134353a167260d1b454eb37cf75a06524f6573031#rd,2024-09-08 12:08:12,"这篇访谈主要讨论了人工智能（AI）大模型的能力边界和理论研究的重要性。北京大学智能学院教授王立威指出，AI 的表现既聪明又愚蠢，这与模型的类型和应用领域有关。他强调，不同的AI系统适用于不同的任务，如语言大模型在逻辑推理方面相对较弱，而专门设计的系统如AlphaGeometry在解决特定数学问题上表现出色。王立威教授认为，大模型并非AI的全部，理论研究需要更深入，寻找能够指导未来的“AI领域的能量守恒定律”。

访谈中提到，使用机器学习解决数学和科学问题具有潜力，但目前还无法完全替代人类。大模型的能力界限在于其表达能力和学习能力，而思维链（Chain of Thought）等方法可以提升模型的推理能力。王立威教授指出，大模型的“涌现”能力并不意味着突然的质变，而是渐进的过程，且存在幻觉现象，这是基于统计而非逻辑的结果。

此外，访谈还探讨了模型的泛化能力、可解释性和Scaling Law。王立威教授提出，未来的理论研究应关注更深层次的问题，鼓励青年学者勇于探索，因为理论研究在AI发展中的作用至关重要。"
这就翻车了？Reflection 70B遭质疑基模为Llama 3，作者：重新训练,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933510&idx=2&sn=0e94275570461f005b688c5ebda7e22f&chksm=84e7cd78b390446e2bf2be9550ba35d6d318782005985b8eef860997b00b4d8c6ccbc78ff870#rd,2024-09-08 12:08:12,开源大模型新秀Reflection 70B被宣称在多项基准测试中超越GPT-4o和Llama 3.1，被誉为新王。该模型由HyperWrite和Glaive AI的开发者在3周内完成。然而，AI模型独立分析机构Artificial Analysis的评估显示，Reflection 70B在MMLU和科学推理基准测试上的表现并不如Llama 3.1 70B。Reddit上的帖子和代码比较揭示，Reflection 70B可能是基于Llama 3而非Llama 3.1进行的调整。开发者Matt Shumer回应称，Hugging Face上的权重有问题，并已重新训练模型以解决这些问题。对于围绕模型基础和性能的质疑，Shumer也做出了解释。
用Test Time换Training Time能让LLM更强吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933510&idx=3&sn=5e3708ea72d684723e6231b0c142da28&chksm=84e7cd78b390446effb416be59703d0621eb9f49af969365e5427051cd6ee1b83d766ce2ff45#rd,2024-09-08 12:08:12,"这篇文章探讨了人工智能和机器学习领域的一些最新发展趋势。首先，文章提出了一种新的思考方向，即通过增加推理时间（Test-Time Compute）而非训练时间来提升大型语言模型（LLMs）的性能。研究人员发现，投入额外的计算资源在推理阶段可以有效提高LLMs的能力，特别是在处理简单到中等难度的问题上。然而，对于最复杂的问题，预训练阶段的计算扩展仍然更有效。

其次，文章提到了法律AI的应用，指出目前最专业的法律AI准确率最高也只能达到65%，并讨论了法律AI在不同场景下的可靠性，以及其在市场和实际工作场景中的应用情况。

最后，文章引用投资人Josh Wolfe的观点，讨论了AI公司的高估值现象，以及风投市场可能面临的损失。Wolfe认为人形机器人和生物科学将是未来的投资风口。

整体来看，这篇文章涵盖了LLM性能优化、法律AI的应用现状以及AI投资趋势等三个方面的重要议题。"
英伟达市值一周蒸发4060亿美元，AI时代「卖铲人」怎么就不香了？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933510&idx=4&sn=97b3ab6c0d68244f316087304de5e1de&chksm=84e7cd78b390446eb90416d7ef842bee45dd6e7445ecf2a576ea902c91b25dea8381f81b0d9b#rd,2024-09-08 12:08:12,这篇文章主要讲述了英伟达（Nvidia）在发布强劲的2024年第二季度财报后，其股价反而大幅下跌的情况。尽管收入和净利润同比增长显著，但公司对第三季度的业绩预测不如市场预期，仅增长79%，引发了投资者对AI增长放缓和芯片需求可持续性的担忧。此外，英伟达Blackwell芯片的量产延迟以及面临的反垄断调查也是股价下跌的原因。尽管今年英伟达的股价总体上涨超过100%，但近期的下跌导致市值显著缩水。一些投资者认为，这可能为长期投资者提供买入机会。
大模型边推理边纠错，有可能做到吗？这是ICML爆火的演讲,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933510&idx=5&sn=cfc4084dfbf8e24124aa7eb14a725193&chksm=84e7cd78b390446ee47b4c94e5382fde681d0a069c9d348724884f65260fffe6c2db4c567d4d#rd,2024-09-08 12:08:12,来自Meta FAIR、CMU和MBZUAI的研究团队在最新arXiv论文中探索了让语言模型“边推理边纠错”的可能性。他们通过在预训练中加入大量“错误的推理”和“错误的纠正”，展示了这种方法可以提高语言模型的推理准确性，无需提示词或多轮对话。研究发现，模型在犯错后内部参数往往显示出“后悔”状态，但简单的错误检测和重试方法效果有限。相反，将错误和纠正的样本加入预训练数据能有效提升模型的推理正确率，且错误比例在合理范围内越高，效果越好。然而，这种纠正能力无法通过少量参数微调现有模型来实现，需要在预训练阶段就包含相关数据。此外，论文还讨论了如何在实际中制备“错误和纠正”数据。
外滩大会上，我们看到了人工智能五年后的样子,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933474&idx=1&sn=53a44f548a54272127dbb64ee9325208&chksm=84e7cc9cb390458a852b94b9503493839898bcc4a430f483a33472fd26f9752e86bcfd39d16a#rd,2024-09-07 12:08:24,这篇文章讨论了人工智能（AI）的发展现状和未来预期。文章指出，尽管ChatGPT等生成式AI引发了热潮，但实际应用层面的变革尚未明显，技术上也面临大模型能力问题和“幻觉问题”。悲观者认为AI并未显著改变世界，而乐观者则相信需要时间让技术落地。在外滩大会上，人们看到了AI在算力竞赛、数据服务和小模型应用等方面的发展趋势。算力竞赛带来了高昂的训练成本，但异构计算有望提升效率和降低成本。小模型在特定任务上表现优越，更可能实现大规模应用。此外，端侧模型（如手机智能）和未来的AI Agent是AI发展的重要方向。文章强调，尽管技术爆发，但AI真正融入日常生活还需要时间，未来五年可能是关键的落地阶段。
不好用不收钱，这家AI公司破天荒按结果收费，要卷死同行？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933474&idx=2&sn=a2e5af3c5140702219efb297089c7ddb&chksm=84e7cc9cb390458ad244b8b713fc71351ad526d0ba4fac9edae77db8dc71e05cb759d6af8847#rd,2024-09-07 12:08:24,这篇文章讨论了一种新的人工智能商业模式，其中AI公司开始按照服务的效果而非使用频率来收费。美国旧金山的AI公司Zendesk改变了其产品定价模式，现在只有当聊天机器人独立完成任务且无需员工介入时才会向企业收费。这种方式注重结果，旨在提供更有价值的服务。其他公司如Intercom和Forethought也在采用类似的基于结果的定价策略。然而，这种模式可能带来收入的不确定性，并非所有软件公司都支持，一些高管对其持保留态度。随着AI自动化的发展，软件行业的定价模式可能面临更多变革。
名场面来了，李云龙、徐江、王多鱼同台飙戏，背后是小红书的AI,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933474&idx=3&sn=0629657cb4d4f3fd169133a165f3b40a&chksm=84e7cc9cb390458ab29833c6a503f4e44a9486dfd4e2677156b3a56beade671430b57d632739#rd,2024-09-07 12:08:24,小红书的技术团队FireRed推出了基于大语言模型的FireRedTTS语音合成系统，该系统能够模仿任意音色和说话风格，只需文本和几秒参考音频，无需训练。FireRedTTS能够生成多风格、高表现力的音频，包括中英混杂的片段和模仿影视剧角色的对话。此外，它在自然对话领域也表现出色，可以创造真实、个性化的语音交流体验。团队已开源模型权重和推理代码，供用户体验尝试。FireRedTTS采用基座语音合成框架，由数据处理、基座系统和下游应用三部分组成，通过语言模型将文本转换为自然的语音序列。该系统支持流式解码和多种微调方法，适用于配音和自然对话等多种应用场景。
突破传统：AI如何应对心电图中的长尾挑战？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933474&idx=4&sn=40641f18b4b8550a3d3cff3c86a54181&chksm=84e7cc9cb390458a05a91b636dcefcbc62e974e83f8cac22a941d3fe8bb96701a9d56cf05e0e#rd,2024-09-07 12:08:24,上海交通大学、上海人工智能实验室和上海交通大学附属瑞金医院的研究团队提出了一种基于异常检测预训练的心电长尾诊断模型，旨在提升对罕见心脏疾病诊断的准确性。该模型通过自监督异常检测预训练，提高了对常见及稀有心电图异常的识别能力。研究团队在一个包含超过一百万份心电图样本的大型临床数据集上验证了模型性能，显示在处理稀有心电类型时具有高准确率、灵敏度和特异性。此外，模型在前瞻性临床验证中也表现出提高心脏病医生诊断准确率、完整性和效率的效果。这项工作为解决心电诊断中的长尾数据分布问题提供了新的方法。
DeepMind Alpha家族新成员：AlphaProteo蛋白质设计成功率破纪录,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933474&idx=5&sn=5079e4eccf87f22b1fd7e89659534b72&chksm=84e7cc9cb390458abd048ebdd91377fbafc487d764063bd756e01d71ce8b4777a56f31ae5ab1#rd,2024-09-07 12:08:24,DeepMind推出了一个名为AlphaProteo的人工智能系统，该系统能够设计出与目标分子结合更紧密的新型蛋白质。在测试的7种靶蛋白上，AlphaProteo的实验成功率高，9%到88%的候选分子成功结合，相比其他方法提高了5到100倍。此外，其结合亲和力比现有最佳方法强3到300倍。这个系统可以生成适用于多种应用的即用型结合剂，有助于科学家更好地理解生物系统，节省研究时间和推动药物设计。DeepMind的团队在2024年9月5日发布了相关论文，展示了AlphaProteo在蛋白质设计上的优势和潜力。
4800个大模型团队竞逐「产业真题」，这场金融科技大赛火出圈了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933365&idx=1&sn=270e798b1ff716687a88dae2ac631d6e&chksm=84e7cc0bb390451dcdc93618d7c9bd1cab2bac5e2df5cdbebe5ca04b0a1911a7ddb01291218e#rd,2024-09-06 17:35:11,这篇文章是关于全球大模型发展趋势的，特别关注了中国在大模型领域的进展和应用。中国和美国是大模型领域的两个主要玩家，中国在大模型的技术层面已经进入全球第一梯队。文章提到，国内大模型的发展路线分为性能竞赛和应用探索两派，中国丰富的产业场景为大模型的落地提供了广阔空间。文章以AFAC 金融智能创新大赛为例，展示了大模型如何在金融等领域中解决实际问题，促进技术创新和人才培养。比赛吸引了数千个团队参与，推动了大模型在金融场景的深入应用。通过这样的赛事，期待能发掘和培养出中国的大模型人才，推动行业创新和发展。
Andrej Karpathy最新激进观点：Transformer将超越人脑,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933365&idx=2&sn=bdc17f786ed219a49463c6e0404f6330&chksm=84e7cc0bb390451d3833714d6d18d83f8bd18ca33efd3484fb3ec5b22ecfcc913e0c3ca13af1#rd,2024-09-06 17:35:11,知名人工智能研究者Andrej Karpathy在最近的采访中分享了他对AI未来的看法，他表示在自动驾驶领域已经实现了有限的AGI，并认为特斯拉在自动驾驶技术上可能领先于Waymo。Karpathy认为Transformer模型可能会在性能上超越人类大脑，并提出AI未来可能会与人类融合，形成一种新的大脑皮层。他还谈到了他在AI教育领域的创业公司Eureka Labs，旨在打造一个全面的AI课程，利用AI实现个性化的教学。此外，他指出大模型目前参数过剩，但通过蒸馏可以得到更小、更高效的模型。
用60%成本干80%的事，DeepSeek分享沉淀多年的高性能深度学习架构,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933365&idx=3&sn=f2d4782583beccac1c2ffec1ff6432aa&chksm=84e7cc0bb390451d7c8e1ab698837c3c2e049be59c6b9b58f26a32229947475ba0cd8a0219af#rd,2024-09-06 17:35:11,研究人员提出了一个名为Fire-Flyer AI-HPC的架构，以构建成本高效的深度学习和大语言模型（LLM）训练系统。该架构基于硬件发展的实际情况，针对深度学习的高算力需求，提供了一种使用PCIe A100 GPU的集群设计，与英伟达的DGX-A100系统相比，计算性能达到83%，但成本和能耗分别下降到60%。该集群采用两层Fat-Tree网络拓扑，降低了交换机和连接成本。同时，研究团队还开发了HFReduce软件库，优化了allreduce操作，降低了PCIe带宽消耗和GPU核开销。此外，他们还推出了HaiScale分布式数据并行工具，针对大规模模型训练进行了优化，实现了良好的并行扩展性。整体而言，Fire-Flyer 2 AI-HPC在保持高性能的同时，显著降低了建设和运行成本。
让大模型能听会说，国内机构开源全球首个端到端语音对话模型Mini-Omni,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933365&idx=4&sn=0bc5997aaf0590dab0897940f519d795&chksm=84e7cc0bb390451d8833e23d5fca8415ec855a82de1a6c9f5d4c51ce2930beb3ad1af062e761#rd,2024-09-06 17:35:11,这篇文章介绍了启元世界多模态算法组的研究成果，即Mini-Omni，这是第一个开源的端到端实时语音多模态模型，支持语音输入和流式语音输出的交互能力。该模型通过文本-语音同时生成的方案，降低了直接推理语音内容的难度，并减少了等待生成完整文本答案的时间消耗，从而解决了实时性问题。Mini-Omni采用了一种多阶段的训练方案，允许任意语言模型通过少量数据获得语音交互能力。实验结果显示，即使在使用0.5B的小模型和少量数据的情况下，Mini-Omni在实时语音问答和语音识别方面也表现出良好的性能。论文、代码和更多实验细节可在提供的链接中获取。
支付宝突然推出新App，竟想用AI让日常生活开挂,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933188&idx=1&sn=855c8ee9df8fee21b3e1f75bb8be0c27&chksm=84e7c3bab3904aac405db24a656db057af3e0fa7a403f6e6d15fbe5ba602527de10ceaf6b6a4#rd,2024-09-05 21:17:56,这篇文章介绍了支付宝新推出的AI原生应用“支小宝”，它是一个办事型AI生活管家，能够通过自然语言处理理解用户需求并采取实际行动，如购票、订咖啡、叫车等。与传统应用不同，“支小宝”采用ACT（Transformer for actions）技术，拥有屏幕感知与仿真执行能力，可以模拟人类交互操作。此外，支付宝通过优化技术，如多模态数据采集和仿真执行能力，提升了大模型的行动力，并计划通过智能体生态开放计划，与行业合作伙伴共创更多服务。支小宝的目标是将AI技术融入日常生活，为用户提供更便捷的服务体验。
你有没思考过，如何加入这场大模型浪潮？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933188&idx=2&sn=d6520894f69e53ede27ff2ab840719aa&chksm=84e7c3bab3904aacf2f7a21a65e82978f48d85d5f9d8162ebd44871e586423b441cbec555cec#rd,2024-09-05 21:17:56,这篇文章提到的活动是一个关于技术、行业和职场跃迁的讨论，邀请了三位具有阿里技术背景的大咖分享他们的经验。活动将探讨如何在快速变化的技术环境中保持竞争力，尤其是面对技术人员的“优化”压力。在AI与金融融合的趋势下，如何成为复合型人才也是讨论的重点。活动将于9月8日晚在上海交通大学上海高级金融学院举行，嘉宾包括飞猪旅行的企业发展部总经理施焱旻、中华财险数据中台部负责人杨威和东方财富创新业务部智能创作平台负责人李彬。主持人是高金在职MBA2018级校友张永昌。
北大领衔，多智能体强化学习研究登上Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933188&idx=3&sn=177d69d48062da4011b830f67ab5f3e9&chksm=84e7c3bab3904aacdcb51edef09b58951a1b077282fd5e2866a7a5f202f22bc138243eb70ecb#rd,2024-09-05 21:17:56,北京大学人工智能研究院杨耀东课题组在Nature Machine Intelligence上发表研究成果，实现了大规模多智能体系统的高效强化学习。该研究首次在大规模多智能体系统中实现去中心化协同训练和决策，提升了模型的扩展性和适用性。研究团队通过智能体动力学特性的解耦和网络化系统模型，设计了一种基于模型的去中心化策略优化方法，允许在有限数据和通信约束下进行高效决策。这种方法在智能交通控制和智能电网场景中的应用展示了其可扩展性和高效性。该成果对于开发适用于大规模真实世界系统的决策范式具有重要意义。
原生集成GitHub，让AI成为协作者，Claude企业版馋哭个人开发者,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933188&idx=4&sn=aa7b48d2c624a345841381031aa97a1d&chksm=84e7c3bab3904aac68ddd4b316e3a4cd940314676f28e69ee7cd90adc36bf120e04ef3e0500a#rd,2024-09-05 21:17:56, Anthropic公司推出了Claude企业版，这是一款升级的聊天机器人，具有原生集成GitHub和500K的上下文长度等优势。GitHub集成允许用户将代码库同步到Claude，以进行代码测试、调试和培训。该功能被视作游戏规则改变者，但目前仅限企业版用户。此外，企业版还提供了更长的上下文长度和文档上传支持，以及更高的使用量和企业级安全特性。Anthropic承诺不使用用户数据训练Claude。多家公司如GitLab已采用Claude企业版。 Anthropic的快速发展和生成式AI市场的巨大潜力预示着更多企业级AI服务将出现。
ECCV 2024 | 比基准高30%，媲美Gemini 1.5 Pro，基于记忆的视频理解智能体来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650933188&idx=5&sn=57409daa0fafe276eb3093ceeddbd048&chksm=84e7c3bab3904aac9018761a628211d809fbb921bd6df610009fc4e5a78e9cf474e3fc445f1d#rd,2024-09-05 21:17:56,研究人员提出了VideoAgent，这是一个基于记忆和工具使用的智能体，用于视频理解，能与先进的Gemini 1.5 Pro相媲美。VideoAgent通过构建时间记忆（存储每2秒视频片段的事件）和物体记忆（存储视频中出现的人和物体信息）来处理视频。模型使用大语言模型推理并从记忆中提取关键信息来回答视频相关问题。这种方法解决了长视频处理时的内存消耗问题，并且VideoAgent可以在实时性要求的场景中使用。在EgoSchema、WorldQA和NExT-QA等数据集上，VideoAgent表现出比多模态大语言模型更好的性能。
真把自己「当个人」的AI，扫去了我的社交贫困,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932881&idx=1&sn=47cc10a04a9df7335de0f2786253a826&chksm=84e7c2efb3904bf9cc546e485e8c16fd87d4798ba0acc582bb6e9375c0602d9111097155b6aa#rd,2024-09-04 19:47:00,快手推出了一款名为“飞船”的虚拟社交App，其中的智能体采用“超拟人策略”，能够与用户进行自然的交流。这些智能体不仅可以回复文本，还能主动发送图像和语音消息，模拟真实的社交体验。用户可以根据需求创建不同的AI智能体，这些角色具备时间概念、身份适应性，并能进行多轮深入的对话。智能体的交互能力得益于快手的快意大模型和可图大模型的技术支持，提供了AI图片生成和多模态交互的功能。这款App旨在为用户提供虚拟陪伴，满足不同群体的社交需求，构建第二虚拟社交网络空间。
超级Prompt：几行乱码让大模型获得科学思维，这个神奇的提示词突然火了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932881&idx=2&sn=753b0c4d5166a01645a6654f908b95f7&chksm=84e7c2efb3904bf9b02ea59628fcf29bc686639a6d3f5393095d882816bd2bf1a5ec22513f17#rd,2024-09-04 19:47:00,一个名为 Super Prompt 的 GitHub 项目在短短几天内获得了 2000 多个星标，该项目由两个 Markdown 文件组成，其中一个包含流程图，另一个是主要由大模型提示词（prompt）组成的 Readme 文件。这个特殊的 prompt 由 Twitter 用户 @BLUECOW009 创建，他自称“提示词之神”。Super Prompt 被设计用于帮助研究复杂的科学问题和定理，能够引导大模型构想新颖的想法，尤其是对于复杂的数学和算法任务。项目作者展示了如何使用这个 prompt 让模型执行任务，如编写《量子迷宫探险者》游戏。一些用户在尝试后表示得到了有趣的结果，但也有人遇到了失败的情况。目前，Super Prompt 在科学和数学领域的具体应用还未知，但作者计划将来会写一篇文章来解释其工作原理。
AMD的GPU跑AI模型终于Yes了？PK英伟达H100不带怕的,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932881&idx=3&sn=9af40ed1840496ba7302fbd468cc5d84&chksm=84e7c2efb3904bf92934ba775eadd17fde18b9b764d24fc370c4dca9b0e458cd0d924e8680a9#rd,2024-09-04 19:47:00,科技媒体The Information进行的对比评测报告显示，在AI推理基准上，AMD的MI300X GPU与英伟达的H100 GPU表现相当，而且在成本估计上，MI300X可能更具性价比。然而，测试仅基于Meta的Llama 2 70B模型，未来需要更多模型的测试来验证结果。AMD的MI300X在内存和带宽方面与英伟达的H200相比仍有所不足。预计英伟达的Blackwell B100和B200 GPU在价格上将与AMD的MI300X竞争，而AMD可能在晚些时候推出的MI325X GPU将需要更大的内存、带宽和更具竞争力的价格来保持竞争力。在AI训练方面的数据，AMD可能会在秋季发布。
大模型走向物理世界，TeleAI 发布大模型驱动的具身智能综述，覆盖300篇文献,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932881&idx=4&sn=a46c2c0f5819c7146da40a7c333543d8&chksm=84e7c2efb3904bf960bad82cd0e9f073be19ae112f2df2a4a0aaa5bc34314cd3a8e78f95c3ee#rd,2024-09-04 19:47:00,这篇文章是关于人工智能领域中大模型和具身智能的综述。大模型在AI领域带来了革命性变化，而具身智能则是下一波浪潮，指的是能理解并互动于物理世界的智能系统。中国电信人工智能研究院的李学龙教授团队撰写了《大模型驱动的具身智能：发展与挑战》一文，详述了大模型如何增强具身智能，包括环境感知、任务规划、基础策略、奖励函数和数据生成等方面。文章分析了相关技术、挑战和未来展望，旨在推动具身智能领域的发展。
自动接人，手机开车，特斯拉纯视觉无人召唤终于来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932881&idx=5&sn=94f4146c7c519b286febaf6ea55cff04&chksm=84e7c2efb3904bf9604e74d79c6902e6c63b7aeb8475a935734f1e68aea77a9dc93d2c51026e#rd,2024-09-04 19:47:00,特斯拉即将向普通用户推出纯视觉的“真智能召唤”（Actually Smart Summon，ASS）功能，该功能允许车主通过手机将车辆从停车位召唤到附近特定位置。此更新适用于大多数特斯拉车型。用户可以在特斯拉App中使用Summon选项卡监控车辆行程，通过“COME TO ME”按钮召唤车辆或使用“GO TO TARGET”设置车辆行驶目的地。特斯拉强调在使用过程中，车主应对车辆负责，并随时注意周围环境。该功能目前仅限于停车场或小区车道使用。此前，国内已有新能源汽车品牌如蔚来、比亚迪等提供了类似智能召唤功能。特斯拉的ASS功能曾因一些问题引发讨论，但作为一项实用的自动功能，它仍受到车主欢迎。该功能的推出表明特斯拉在自动驾驶技术上的发展。
8岁小孩哥上手用AI制作游戏，全程2小时，引来50多万人围观,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932654&idx=1&sn=1a61713b92caf3a314af88ee32545b90&chksm=84e7c1d0b39048c6fb2d774db5133ff56b168fc4d3a764fcf1a87a2a8fb87792f40604576f92#rd,2024-09-03 12:52:22,这篇文章讲述了8岁男孩在没有任何编程经验的情况下，利用名为Claude AI的工具建立了一个Three.js网站，包括创建了游戏、绘图应用、动画应用和AI聊天应用。他的父亲Meng To在社交平台上分享了这一消息，并表示现在编程正变得越来越简单，甚至可能不再需要人工编写代码。男孩通过自然语言与Claude AI交互，AI自动生成相应的代码。这个故事引起了公众的关注，有人对此表示怀疑，但男孩的编程项目和他在其他编程工具上的经验证明了他的能力。此外，文章还提到了一款名为Cursor的AI编程软件，它能根据开发者的指令自动生成代码，被一些开发者称赞为“程序员的Google Docs”。Cursor提供了免费和付费的订阅模式，允许用户快速构建功能性代码。
李飞飞团队提出ReKep，让机器人具备空间智能，还能整合GPT-4o,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932654&idx=2&sn=459ecdfdb4b4e611e03929795230e641&chksm=84e7c1d0b39048c6db011ecc3b78b9817fb9097de1438b96c009159ee3f70430b0770eefb895#rd,2024-09-03 12:52:22,李飞飞团队近日提出了关系关键点约束（ReKep）方法，将任务表示为关系关键点序列，用于机器人操作任务的空间和时间推理。该框架能与多模态大模型（如GPT-4o）结合，实现机器人与环境复杂交互的精妙控制。ReKep通过将任务分解为多个阶段并定义子目标和路径约束，解决了现实世界中构建约束的挑战。实验显示，这种方法在倒茶、摆放物品、叠衣服等任务中表现出色，具有较好的泛化能力和应对新策略的能力。该工作展示了视觉与机器人学习的深度融合，对空间智能领域具有潜力。
最强笔记软件Obsidian中也能使用LLM，让它成为你的智慧第二大脑,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932654&idx=3&sn=1d9aa7a8797378e6f7380ea62acbd536&chksm=84e7c1d0b39048c6e199ade30e7bfbfdfdd5cfdd2f21194abbf70acd7e5fd646c42154fa5229#rd,2024-09-03 12:52:22,本文介绍了如何在知识管理软件Obsidian中使用AI工具，包括Ollama和两个Obsidian插件BMO Chatbot和Ollama，以提升学习和工作效率。Obsidian是一个流行的笔记工具，支持Markdown、丰富的插件生态和本地存储。Ollama是用于本地部署LLM（大型语言模型）的工具，而BMO Chatbot则将LLM整合到Obsidian中，能进行问答、文档总结和标题建议。通过Ollama插件，用户可以预配置命令来生成代码或续写内容。本地部署LLM保证了数据隐私和安全。这些工具的结合使用能帮助用户进行更高效和创新的知识管理和内容创作。
北大李戈团队提出大模型单测生成新方法，显著提升代码测试覆盖率,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932654&idx=4&sn=1d012f08563e4950cfa037ede4443a38&chksm=84e7c1d0b39048c62c492a391835488b2232a67ac38c891e9dad29525c70ccc778669ce84e0d#rd,2024-09-03 12:52:22,北京大学李戈教授团队的研究提出了一种名为HITS的新方法，利用程序分片（Method Slicing）提升大模型生成的单元测试代码覆盖率。单元测试是软件开发中的关键步骤，确保代码片段按预期工作。HITS通过将复杂函数分解为简单片段，使大模型能更有效地为每个片段生成测试样例，从而提高整体测试覆盖率。该方法在大模型学习过和未学习过的Java项目中进行了实验，显示了较其他方法的性能提升。HITS有望在实际开发中帮助发现和修复错误，提高软件质量。相关论文被ASE 2024顶会接受。
黑洞热力学第三定律已死，霍金错了，极端黑洞可能存在,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932654&idx=5&sn=1bb28e363deea78b585d3b80e84b4cc9&chksm=84e7c1d0b39048c64adfe591e0b5859e69084cb144db9608bb41e6eba287c25f43897829d0d7#rd,2024-09-03 12:52:22,两位数学家最近证明，极端黑洞在理论上是可能形成的，推翻了1973年物理学家霍金等人的猜想。极端黑洞是电荷量或自转速度达到极限的黑洞，其边界处的表面引力为零。之前认为，根据黑洞热力学第三定律，黑洞的表面引力不能在有限时间内降至零，因此不可能形成极端黑洞。然而，新的数学证明表明，通过向黑洞添加电荷或能量，可以在有限时间内将其转化为极端黑洞，且不会导致裸奇点的出现。这一发现为理论物理学提供了新的研究方向，尽管极端黑洞的实际存在性仍有待进一步观察和验证。
用最直观的动画，讲解LLM如何存储事实，3Blue1Brown的这个视频又火了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932527&idx=1&sn=976d86a8f1ad67e5d86c43a7ef1a56a6&chksm=84e7c151b39048474d19750ea31660854be069312c0e3b2f2f8a26090900ba7ef7435d2a4483#rd,2024-09-02 12:39:16,这篇文本是关于大型语言模型（LLM）如何存储和处理信息的解释。3Blue1Brown 的《深度学习》课程第 7 课通过动画展示了 LLM 中的事实存储，其中提到事实主要保存在多层感知器（MLP）中。视频以“迈克尔·乔丹从事的体育运动是…”的例子说明，LLM 可以通过内部的向量编码和处理来预测篮球，这涉及向量的注意力机制和多层感知器的运算。MLP 通过矩阵乘法和激活函数（如 ReLU）来处理信息，将输入向量转换为具有相关上下文的输出向量。视频还介绍了 GPT-3 等大模型的参数数量和计算过程。整个演示旨在帮助观众理解 LLM 内部的工作原理。
专注AI+制造：创新奇智大模型工业落地初显成效，探索工业智能机器人新方向,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932527&idx=2&sn=100ef21cf99d02bcf3bb9258ff8d4723&chksm=84e7c151b3904847ca4a590a2aec9bc717463174c38ed0aa6c6a3c5b6e0fbe6da93d83dbce34#rd,2024-09-02 12:39:16,这篇文章提到了OpenAI的一系列动作，表明大模型正朝着实用化方向发展，OpenAI的ChatGPT每周活跃用户量达到两亿。同时，创新奇智这家公司在国内大模型的工业化落地方面取得进展，尤其是在工业领域。创新奇智利用大模型打造的设备维护智能体，如ChatBI和ChatDoc，帮助中加特电气实现生产设备的智能化维护，减少了维修成本和提高生产效率。此外，大模型也在平安资管的数据分析和决策中发挥作用，提升了数据处理和响应速度。创新奇智还推出了工业大模型技术平台和相关产品，如奇智孔明AInnoGC，以及一系列面向制造业的解决方案，包括ChatVision、ChatCAD和ChatRobot Pro，其中ChatRobot Pro探索了端到端的VLA策略模型在工业机器人中的应用。创新奇智在技术和产品创新上的投入，预示着AI2.0时代的到来，即更智能、跨领域的AI应用。
之江实验室、Science/AAAS联合举办，第四届智能计算创新会议开启注册,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932527&idx=3&sn=bbace31610e5359b8afa3e2e84f199ce&chksm=84e7c151b3904847e3cb47540628e4a3f3a20cba75bf2ba666e93bf85115ab488813e2d54035#rd,2024-09-02 12:39:16,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我将很乐意帮助您生成摘要。
机器人把握好手上的力道，安全地做家务有多难？1X人工智能副总裁撰文详解,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932527&idx=4&sn=e395e72d09ec7d20dc5c258c3d3dfb8f&chksm=84e7c151b3904847fd23bf1a91ebf4b5fa43d2601e80bba9bf450f0e808de466aa5a71c36302#rd,2024-09-02 12:39:16,这篇文章介绍了一家名为1X的创业公司，该公司开发了一款名为NEO的人形机器人，该机器人能够在操作时保持安静和实用，避免了传统机器人关节运动时的噪音。NEO能够安全地与人互动，比如轻柔地递给视频中的女生书包，而这得益于其背后的高效电机和驱动系统设计。文章的作者，1X Technologies的AI副总裁Eric Jang解释了电机惯量和齿轮系统在机器人设计中的重要性，指出轻质高扭矩电机对于打造通用机器人至关重要。传统的机器人由于齿轮系统的动能转换效率低，导致噪音大，而NEO通过优化设计，提高了安全性和效率。此外，文章还讨论了如何利用真人视频来训练机器人，以推动通用机器人技术的发展。
鬼手操控着你的手机？大模型GUI智能体易遭受环境劫持,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932527&idx=5&sn=bd332be5a5fe69e09d59554b8b5673e1&chksm=84e7c151b3904847571c05cce618d793722a9791d3abc74f4219724c0dba37daf5ca6081e03f#rd,2024-09-02 12:39:16,本文研究了多模态GUI智能代理在复杂环境中的忠实性问题，发现在现实世界部署时，智能代理可能因环境干扰而偏离用户预设目标，甚至导致安全风险。研究团队通过模拟四种场景（弹框、搜索、推荐和聊天）构建数据集，测试了多种多模态大模型，发现即使强大如GPT-4的模型也易受干扰，降低行动正确率。此外，增强环境感知并不一定能提高忠实性，反而可能增加干扰风险。环境注入的攻击方法展示了恶意利用这一弱点的可能。研究团队呼吁关注多模态代理的忠实性问题，并提出了未来研究的方向。
Claude也变懒了！网友：学会给自己放假了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932434&idx=1&sn=ec2f9524834271b7e62cf194dbadf8ba&chksm=84e7c0acb39049bac5ea1e4a136dbc7fdb1578fa3b62b6da8277db0697dc1c48dec4ba0c85bc#rd,2024-09-01 12:43:42,Reddit 上的用户抱怨AI模型Claude的表现下降，输出变短且常常停顿。模型开发者Anthropic的首席信息安全官Jason Clinton回应称模型没有变化，可能是用户感知上的问题。有独立AI研究员提出一种解释，认为Claude可能在模拟欧洲人的工作模式，因为8月是欧洲的假期季节。这一理论基于Claude的系统提示词、其训练数据中包含的不同国家工作习惯，以及后期训练可能影响其行为。此外，还有用户分享了帮助Claude恢复“积极性”的自定义指令。之前GPT-4也曾表现出类似“懈怠”的行为，OpenAI承认了这一问题但未找出具体原因。目前，对于大型语言模型性能下降的真正原因仍需进一步研究。
用Mac训练个机器人叠衣服，HuggingFace开源全套教程，开源AI机器人革命要来了？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932434&idx=2&sn=4fce1b5ec8921db34720709d850edcb3&chksm=84e7c0acb39049ba1c2d987046a0d625be306d48fc384011a090c95c363ef422caec9d2b51bc#rd,2024-09-01 12:43:42,HuggingFace的机器人项目LeRobot发布了一个教程，让人们能够使用100条轨迹数据在Mac或PC上训练几个小时，创建一个能抓取乐高积木的机械臂。该项目基于大规模众包机器人数据集，旨在降低机器人的开发门槛。教程包括硬件组装、机器人连接配置、数据记录与可视化、策略训练和评估等步骤，主要使用开源、价格友好的Koch v1.1机器人套件。通过遥操作技术收集机器人轨迹，然后训练神经网络实现自主操作。此外，团队正在开发更实惠和功能更强大的机器人模型，推动机器人领域的开源发展。
Cross-Embodiment/数据集/VLA，具身智能今年的研究重点在哪？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932434&idx=3&sn=46565195e53226d1dd2a4fb19a25fe46&chksm=84e7c0acb39049ba95e9b392ad8fff3f1ae8fcfb11963c72b76c471756e0db7bcf24821c4ea8#rd,2024-09-01 12:43:42,"这篇会员通讯主要涵盖了三个AI和Robotics领域的重点内容。首先，文章讨论了具身智能的研究趋势，特别是Sergey Levine的研究，包括Cross-Embodiment、数据集和VLA在解决机器人学习中数据多样性和泛化能力方面的作用。Sergey Levine及其团队的多项研究尝试通过跨实体学习来训练控制不同形态机器人的通用策略，并发布了相关论文。

其次，通讯提到了a16z发布的最新AI应用TOP100榜单，列出了消费者最常用和最受欢迎的AI应用，探讨了这些应用的核心功能、交互方式以及用户体验。

最后，红衫资本的合伙人David Cahn的访谈中提到，他认为服务器、钢铁和电力是推动AI领域进步的关键因素，并讨论了高额资本支出对科技巨头的影响。

此外，通讯还包含了28项本周AI和Robotics领域的重大事件，涵盖了技术、国内和国外的最新发展。"
防AI换脸视频诈骗，中电金信联合复旦提出多模态鉴伪法，还入选顶会ACM MM,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932434&idx=4&sn=f5989bff25878898f29b9f4d4c9ad2e0&chksm=84e7c0acb39049bae6673480370883d0cd573b5538da7d806b9c421fc888205194a903386159#rd,2024-09-01 12:43:42,复旦大学、中电金信和上海智能视觉计算协同创新中心的团队开发了一种新型的多模态伪造检测方法，称为参照辅助的多模态鉴伪网络（R-MFDN），该方法被ACM MultiMedia 2024会议接收为口头报告。随着AI换脸技术的普及，它被用于诈骗活动，对金融行业构成安全威胁。R-MFDN利用身份信息和跨模态不一致性来检测伪造，由多模态特征提取、特征信息融合和伪造鉴别三个模块组成。此外，团队构建了一个大规模的AI换脸音频数据集IDForge，以促进该领域的研究。实验结果表明，R-MFDN在多媒体检测任务上表现出高准确性，有助于防范身份盗用和欺诈风险。中电金信已基于此技术推出了多模态深度伪造检测产品。
整合 200 多项相关研究，大模型「终生学习」最新综述来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932434&idx=5&sn=c6d25ff5f070434e9be9b56aa5ea8daf&chksm=84e7c0acb39049ba90e84f3196acd64365967ae6a42756de62f7cf5691092daa7aec75f0a027#rd,2024-09-01 12:43:42,这篇论文综述了大语言模型的终生学习方法，旨在解决模型在应对数据、任务和用户偏好变化时的适应性问题。终生学习技术允许模型在不遗忘旧知识的情况下持续学习新知识。论文将相关方法分为内部知识（如连续预训练和连续微调）和外部知识（如基于检索的和基于工具的终生学习）两大类，并详细介绍了各种场景和技术。作者还提出了未来研究方向，包括多模态终生学习、高效终生学习和通用终生学习。这篇综述提供了对大语言模型终生学习的全面概述，为该领域的研究者和工程师提供了指导。
太拟人了！OpenAI加持，1X消费级人形机器人亮相,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932383&idx=1&sn=6c391dd6681c8cd6df3b4af5c26e9a68&chksm=84e7c0e1b39049f733ff8b34cfe0f1cead8cfc2539452e712589998b1c6c35ced588c87997a5#rd,2024-08-31 13:05:46,OpenAI投资的机器人公司1X推出了一款名为NEO Beta的双足人形机器人原型，设计用于家庭环境。这款机器人身高1.65米，重30公斤，能以1.12 m/s的速度步行，3.35 m/s的速度跑步，且能承载20公斤的重量，运行2到4小时。NEO被设计成能做家务，如整理物品、拿取物品等，且工作时几乎无声，主要通过眼神交流和手势沟通。1X强调了NEO的安全性，采用类似人类肌肉的结构设计，能够在复杂环境中自然导航。NEO是在早期产品EVE基础上发展而来的，已经在制造业等领域进行了商业化应用。1X计划今年在有限的家庭中部署NEO进行研究和开发，目标是创建安全、智能的类人机器人，以协助执行各种任务。
Mamba作者新作：将Llama3蒸馏成混合线性 RNN,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932383&idx=2&sn=7600df2e659e20f361626d354c424e8e&chksm=84e7c0e1b39049f75155b3f6c5e1f4b6f0fab8838dca95588b10f9a19561b52901363839842b#rd,2024-08-31 13:05:46,Mamba 是一种状态空间模型，它解决了Transformer在处理长文本时计算开销大的问题，实现了线性扩展。新研究通过知识蒸馏将大型Transformer模型转化为大型混合线性RNN，保留了生成质量，且在某些基准测试中超越了Transformer。此外，研究还提出了硬件感知推测解码算法，加速了Mamba和混合模型的推理速度。实验结果显示，蒸馏后的混合Mamba模型在聊天和一般基准测试中表现与原始Transformer相当甚至更优，且比从头训练的开源混合模型性能更强。
KDD2024最佳学生论文解读，中科大、华为诺亚：序列推荐新范式DR4SR,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932383&idx=3&sn=e3439b97e53270f351c98f8e3f1742e0&chksm=84e7c0e1b39049f75ce4fce8e6b229d9616e4a075115bc47f21190df9c4ab545dcaf64ae452b#rd,2024-08-31 13:05:46,很抱歉，您还未提供具体的文章内容。请您提供一篇文章，我会尽力为您生成摘要。
再见，AnandTech：著名科技网站宣布结束运营,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932383&idx=4&sn=a3894f50cb1d1d1d1dfa3a181cc6fc02&chksm=84e7c0e1b39049f72178f7f559e122b9be7d536c6a129526c0e3a793da695995661aecf6487e#rd,2024-08-31 13:05:46,老牌硬件科技网站AnandTech宣布关停，主编Ryan Smith发表公开信告别。AnandTech以其深入的硬件评论和分析在科技新闻界具有重要影响力，深受硬件爱好者喜爱。网站自1997年创立以来，见证了计算机硬件行业的众多变迁。尽管AnandTech将停止运营，但其网站和论坛将由出版商Future PLC保留，供读者访问和引用。Ryan Smith在信中呼吁科技记者继续提供高质量、有深度的报道。创始人Anand Lal Shimpi在2014年加入苹果，参与M系列芯片的开发。
当奖励成为漏洞：从对齐本质出发自动「越狱」大语言模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932383&idx=5&sn=9b425f4ad0cea679fa5e4c0160104f1a&chksm=84e7c0e1b39049f7ba958ce6ace3425d3816bf563cc879ed0a396b69a481dcee94b48a153f73#rd,2024-08-31 13:05:46,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
一手实测结果出炉！智谱「超大杯」模型全家桶亮相KDD，部分任务超越GPT-4o,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932335&idx=1&sn=2a4d6a4c6f09ff92d69ea429222adb0d&chksm=84e7c011b39049075669e3aa9ccaa513722d8159a3531c8dc7ae5251919eaccc3f1ac348d8b7#rd,2024-08-30 17:02:54,"这篇文章的摘要如下：

在近日举行的KDD 2024大会上，智谱AI发布了其新一代大模型GLM-4-Plus，该模型在语言理解、指令遵循和长文本处理方面有显著提升，接近甚至在某些任务上超越了OpenAI的GPT-4o。此外，智谱AI还推出了文生图模型CogView-3-Plus和图像/视频理解模型GLM-4V-Plus。GLM-4V-Plus在图像和视频理解方面表现出色，能够理解和生成复杂的视觉内容。智谱AI的这些进展展示了中国在大模型领域的技术实力增强。此外，智谱的C端产品——AI助手智谱清言也新增了视频通话功能，成为首个支持多模态互动的AI助手。"
Runway突然删除HuggingFace库！网友：真跑（Run）路（Way）了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932335&idx=2&sn=f89c70e4027da7380fbf615b026c2c2e&chksm=84e7c011b39049070f55af748e8b7e1711038f175542f27f96b4f27020c12dc83b6dbfd13e73#rd,2024-08-30 17:02:54,AI 创业公司 Runway 不明原因地删除了其在 HuggingFace 上的所有内容，包括 Stable Diffusion v1.5 等项目，宣布不再维护 Hugging Face。这一举动在 Reddit 和 Twitter 上引发了讨论，一些网友猜测 Runway 可能被收购，但目前没有官方解释。有热心网友分享了魔搭社区的相关资源。
开源启动！18个月Llama系列下载量近3.5亿，黄仁勋：快到难以置信,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932335&idx=3&sn=75bb661fd4175cab96698498af15c559&chksm=84e7c011b39049074fd3f47900d215b53ecfa1aa548d318a31bdd3ee2da53f57013d70511489#rd,2024-08-30 17:02:54,Meta的Llama系列模型在开源领域取得了显著成就，包括在HuggingFace上的下载量接近3.5亿次，月下载量达到2000万次，成为领先的开源模型。该模型被广泛采用，包括多家知名企业。Llama 3.1版本参数量达到405B，成为全球最强的开源大模型。Meta与多个云服务供应商合作，促进开发者利用Llama模型。然而，开源源代码促进会（OSI）认为Llama系列不完全符合开源标准，引发争议。Meta强调开源是其战略的一部分，但也指出开放大型模型的复杂性和成本。OSI计划在10月公布对开源AI的修订定义。
情感分析的终极形态：全景式细粒度多模态对话情感分析基准PanoSent,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932335&idx=4&sn=76d838c0c72bad4d7a5698e34acf38ab&chksm=84e7c011b39049071fb5f67a6d8afae4e600dc12cbfbccaa86381a79167c7679ce2e06148e59#rd,2024-08-30 17:02:54,"新加坡国立大学、武汉大学等机构的研究团队提出了一个全景式细粒度多模态对话情感分析基准PanoSent，旨在全面覆盖情感分析的细粒度、多模态和对话场景。这项工作将情感分析从传统的文本内容扩展到包括图像和视频的多模态内容，并考虑了情感在对话中的动态变化和因果关系。研究团队构建了一个大规模数据集PanoSent，包含10,000个对话，覆盖英语、中文和西班牙语，用于测试新任务。他们还开发了一个名为Sentica的多模态大语言模型，并提出了一种情感链推理框架CoS，用于逐步解决情感分析任务。这项研究为情感计算领域提供了新的方向和挑战。"
用「图灵测试」检验AI尤其是大语言模型，真的科学吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932335&idx=5&sn=a5a7582bda1a1dcf83611ddc954508a8&chksm=84e7c011b3904907a61906a3b62e5ab8f58ee17ecfac045204de35d46d547878035149934a1c#rd,2024-08-30 17:02:54,这篇文章讨论了如何衡量大型语言模型（LLMs）如ChatGPT的智能水平，是否接近人类的智能。传统的图灵测试被用来检测机器是否能模拟人类对话，但一些专家认为这个测试并不足以全面评估智能。最近的实验表明，虽然最新的LLMs在某些方面表现出人类样的行为，但要真正通过图灵测试仍存在挑战。一些研究人员提出了不同的测试方法，如将模型置于心理实验中检验其推理能力，或使用抽象与推理语料库（ARC）来测试模型的适应性和抽象思维。这些测试旨在更深入地了解模型是否具备人类般的智能，但目前尚无共识。专家们认为，真正的智能包括在新情境中学习和适应的能力，而当前的LLMs主要依赖大量的数据记忆，缺乏真正的适应性。
视频生成控制提升几十倍，新一代轻量级ControlNeXt火了，贾佳亚团队正挑战Scaling Law,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932091&idx=1&sn=a5a4cee56f033fcde399062b31b48b6c&chksm=84e7c705b3904e13c1712bdedae196d62da7b778dfca66a7c188b8acc3cb9244e99bf3c0f0a6#rd,2024-08-29 12:26:05,思谋科技创始人贾佳亚团队开发的图像和视频生成控制工具ControlNeXt引发了关注。这款工具是对斯坦福大学ControlNet的优化，允许用户通过预设条件调整和优化预训练的图像扩散模型，如 Stable Diffusion，实现线稿转全彩图、语义分割、边缘检测和人体姿势识别等功能。ControlNeXt以更少的训练参数（约ControlNet的10%）实现更高效率和精准控制，兼容多种Stable Diffusion家族模型和视频生成模型SVD。项目已在GitHub上获得1.1k星标。ControlNeXt的亮点包括支持Canny边缘、掩模、景深和姿势条件控制，能生成各种风格的图像和视频，甚至实现超分辨率图像生成和视频中人体姿势的精准控制。团队通过轻量级条件控制模块设计、控制注入位置和方式的优化以及交叉归一化技术，降低了计算开销、内存占用和训练参数，提升了模型的训练速度和推理效率。与传统方法相比，ControlNeXt展现了在可控图像和视频生成方面的高效和灵活性。
Facebook第30号员工：为扎克伯格工作，我学到了什么,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932091&idx=2&sn=0862ac36b5a3d922cf117a5d6da56303&chksm=84e7c705b3904e133b650161cf63d1fff90286a3161873d66143646a2c28a04e2e490ed3a7ef#rd,2024-08-29 12:26:05,本文是一位前Facebook员工Noah Kagan分享的他在公司工作时从马克·扎克伯格那里学到的10个经验。这10个经验包括：专注于一个目标（在Facebook是用户增长）、快速行动、只雇佣超级有能力的人、善待员工、从自身出发创业、注意细节、给团队自主权、不能说“用户”，而要说“人”、让合适的人留在公司，以及要有宏大的愿景。这些经验对Kagan后来创立并发展AppSumo起到了重要作用。
陶哲轩IMO演讲全文：一次性解决一千个问题，AI让数学摆脱蛮力计算,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932091&idx=3&sn=b904ad8bbcd00f45beee06a0d80f918a&chksm=84e7c705b3904e138154f9a05f80a2b0b5ca6696e8ebdb158f8a21593545e23b93ba26800cc0#rd,2024-08-29 12:26:05,数学家陶哲轩在 IMO 2024 的演讲中回顾和展望了计算机与人工智能在数学研究中的应用，强调了人工智能在数学领域的辅助作用日益增长，但人类的洞察力和创造力仍然至关重要。他讨论了从早期计算工具到现代机器学习和形式化证明助手的演变，以及人工智能在解决数学问题和发现新联系中的应用。陶哲轩还提到了机器学习在纽结理论、证明辅助以及大型语言模型在数学问题解决中的作用，指出这些工具可以提供线索和灵感，但目前仍需要人类进行验证和创新。未来，人工智能有望在生成猜想和大规模问题探索方面发挥更大作用。
深度学习还不如浅层网络？RL教父Sutton持续反向传播算法登Nature,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932091&idx=4&sn=e6a1f3472d0aa43524f58bee454d3c5c&chksm=84e7c705b3904e13cc4666a023e461bf57fb0320210865bb0ae962ebe50b7657c7d534bcdfda#rd,2024-08-29 12:26:05,一篇发表在《自然》杂志上的新研究表明，标准的深度学习方法在持续学习环境中会失去可塑性，其学习效果可能不比浅层网络更好。研究通过实验展示了深度学习网络在处理持续学习任务时性能的下降，并提出了“持续反向传播”算法，该算法通过选择性地重新初始化网络中低效的单元来维持可变性和可塑性。实验结果表明，这种方法能够帮助网络在持续学习中保持更好的性能。
"港大黄超团队推出AnyGraph, 首次揭秘图大模型的Scaling Law",http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650932091&idx=5&sn=fd8f720c963ff049dd7d3b6bfe3b0cf1&chksm=84e7c705b3904e13ee84c15f5686fe596d636aa23e3fc227f1a762d24652f5cbe12da208f605#rd,2024-08-29 12:26:05,研究人员来自香港大学的数据智能实验室推出了AnyGraph，这是一个图大模型，旨在解决图结构信息中的分布偏移和跨图数据集的多样特征表示问题。AnyGraph采用图混合专家（GraphMoE）架构和轻量级路由机制，能快速适应新的图学习领域。模型在38个多样化图数据集上进行了训练和测试，展现出卓越的泛化能力和扩展性。该研究首次揭示了图大模型的Scaling Law，证明了随着数据量和模型参数的增加，性能可以显著提升。AnyGraph的创新在于处理图数据的结构异质性、特征异质性和快速适配能力，为图学习领域提供了更强的泛化基础模型。
孟瑜获杰出博士论文奖，中科大获最佳学生论文，KDD 2024全部奖项放出,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931840&idx=1&sn=6ffa2ad97f29fd0aec12a42788698f0d&chksm=84e7c6feb3904fe8c2f59865bad47ec230f0c943d5ebe3656c830fd18feebcad4249c659d738#rd,2024-08-28 12:04:23,2024年ACM SIGKDD国际数据挖掘与知识发现大会在西班牙巴塞罗那召开，揭晓了最佳论文奖、时间检验奖、杰出博士论文奖等。华人研究者在多个奖项中获奖，其中弗吉尼亚大学的孟瑜以其论文《Efficient and Effective Learning of Text Representations》获得KDD 2024杰出博士论文奖。最佳论文奖（研究方向）由《CAT: Interpretable Concept-based Taylor Additive Models》获得，该论文提出了一种新的可解释模型，旨在解决传统深度学习模型的可解释性和可扩展性问题。最佳学生论文（研究方向）颁给了中国科学技术大学和华为合作的《Dataset Regeneration for Sequential Recommendation》，该研究提出了一种数据中心化的序列推荐系统方法。此外，领英的《LiGNN: Graph Neural Networks at LinkedIn》赢得了最佳论文奖（应用数据科学方向）。时间检验奖分别授予了DeepWalk和U-Air两篇论文。
来外滩大会密态计算论坛，洞察数据可信流通产业生态重构,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931840&idx=2&sn=38371ff07e382971f0b083a710492ab7&chksm=84e7c6feb3904fe8caba512cb8e588538e81cfeb00b8038f6e2437705fc14c536265f56c2192#rd,2024-08-28 12:04:23,2024年Inclusion・外滩大会的“迈向密态算力时代：数据可信流通的产业生态重构”论坛将于9月6日在上海举行，由浙江蚂蚁密算科技、上海临港新片区跨境数据科技和上海交通大学网络空间安全学院联合主办。论坛将关注数据可信流通的产业建设，探讨密态计算技术在金融、医疗、广告等多个领域的应用，并邀请公共数据运营领域的专家分享行业发展和挑战。论坛还将发布“隐语密算云产业合作生态规划”和基于密态计算技术的新产品，以推动数据要素的可信流通和价值释放。与会者可以通过工作人员或议程海报二维码获取免费入场凭证。
Llama-3不算真开源：今年10月，权威定义就要来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931840&idx=3&sn=06d1aaf92c0f8cedeb55a64da3c18b07&chksm=84e7c6feb3904fe8d05297fc2211eb5362cc71e2d54f31770d3822dab2237891b606fe664b00#rd,2024-08-28 12:04:23,开放源代码促进会（OSI）最近公布了其对“开源AI”的最新定义草案，旨在澄清Open Source这一术语在快速发展的科技领域中的模糊用法。该草案提出了AI模型开源的“四项基本自由”，包括不限制使用目的、允许深入研究、支持随意修改和自由分享。这一定义的出台是因为近期一些带有权重使用限制的大模型被标记为“开源”，引发了关于什么是真正“开源”的争论。OSI预计将在2024年10月宣布“开源AI”定义的最终版。这份草案不要求公开原始训练数据，但要求提供关于训练数据和方法的详细元数据，以实现透明度和可复制性。OSI希望通过明确的开源标准推动AI系统更加透明，促进协作和创新。
「草莓」即将上线，OpenAI新旗舰大模型曝光，代号「猎户座」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931840&idx=4&sn=8fefe3f29550846055ea998a9524eb63&chksm=84e7c6feb3904fe80ccdadac82583f05a568040eb6d9f848780b7a7a6bf60f106b89793b08ce#rd,2024-08-28 12:04:23,OpenAI计划在今年秋季推出代号为“草莓”（Q*，发音为Q Star）的新人工智能，该模型可能集成在ChatGPT内，作为聊天机器人的一部分。草莓能够解决数学问题和编程问题，不仅限于技术问题。OpenAI还开发了名为“Orion”的新旗舰大语言模型，而草莓旨在改进Orion。草莓的一个关键应用是生成高质量的训练数据，以减少模型的错误。OpenAI已经向安全监管人员展示了草莓模型，可能作为提高透明度的努力之一。未来，草莓的推理能力可能被整合到ChatGPT中，提供更准确但可能更慢的答案。
牛津光计算论文登Nature正刊，分析帕金森患者步态准确率达92.2%,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931840&idx=5&sn=05a0e9f4bafd5b37baa8506d5142cc57&chksm=84e7c6feb3904fe8d8a168972da332c0eee3c3698fbb871614bd10f1b92725f3a27a41eb0c03#rd,2024-08-28 12:04:23,牛津大学Harish Bhaskaran院士课题组的董博维博士等研究人员在《Nature》上发表论文，证明降低光学相干性能增强光子卷积处理。他们提出使用部分相干光源的光子计算方法，可以提高处理并行性，减轻对精确控制和严格反馈的需求。这种方法在两个光子平台上展示了广泛适用性，包括使用相变材料和硅光子技术实现的光子计算应用。光计算因其高并行度、高能效比和高速度，被视为应对人工智能算力需求增长的一种解决方案。然而，大规模光计算芯片的调控成本一直是个难题。该研究提供了一种降低光源相干性以提高芯片性能的新方法，有望提升光芯片算力并降低系统能耗。
真香！智谱大模型，有了首个免费的API,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931769&idx=1&sn=663533f80f653b9e60e7d4d0716218ee&chksm=84e7c647b3904f51e60700d15607bd5b1268540bda60f9e22ed35302b9bdc08f9bfc4c3fd6da#rd,2024-08-27 16:30:04,这篇文章提到了大模型开发的最新趋势，特别是“Flash”版本的出现，这些模型以轻量化和快速响应为特点。OpenAI的GPT-4o Mini已经取代了原来的GPT-3.5成为默认选项。国内大模型平台智谱也宣布了新的GLM-4-Flash模型，并提供免费的API和一键微调工具，以提升AI开发效率。GLM-4-Flash在性能、速度和成本上都有所优化，支持多轮对话、自定义指令和多语言处理等功能。此外，文章提到了GLM-4-Flash在逻辑推理、函数调用和网页检索等任务上的能力，并列举了一些实际应用案例，如科研、翻译和内容创作。智谱还宣布GLM-4-Flash模型全面免费，并提供微调资源包的限时优惠。这些举措表明大模型的开发和应用正变得更加便捷和普及。
大模型时代，绿色计算这条路该怎么走？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931769&idx=2&sn=c99d53e7b25ec70f0dedc3f27e69119c&chksm=84e7c647b3904f51807ba6c3e9236f8012a495d2ec32cb83eb9204502a41e028a4b356307455#rd,2024-08-27 16:30:04,在人工智能时代，随着大模型的快速发展，智能算力需求急剧增长，导致能耗和成本的大幅提升。为实现可持续发展，行业内关注的重点是如何构建绿色、高效、经济的大型智算基础设施。2024年外滩大会期间，将举办一场关于“绿色计算：大规模智能算力时代可持续发展之路”的闭门会议，探讨算力产业链的绿色升级、软硬协同构建高质量算力基础设施以及企业在双碳目标下的平衡策略。会议将汇集政府领导、行业专家和企业代表，通过高端对话和定向研讨，共同寻找绿色计算的未来路径。会议由多个机构支持，并采取定向邀请制，主要面向相关领域的企业负责人、学者和科研人员。
李飞飞反对，马斯克、Hinton、Bengio支持，加州AI监管法案即将尘埃落定,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931769&idx=3&sn=92a2904d82a9c7fbb59778aea483eff1&chksm=84e7c647b3904f516745be86e5450b26458f66c074f644f23f5bf17a89787e01ce39fb7cd0c8#rd,2024-08-27 16:30:04,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我会尽忙为您生成摘要。
LLM取代的第一个编程语言竟是SQL？网友吵翻天,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931769&idx=4&sn=dbc0bed8bed4101df672c6ba1c1f78e2&chksm=84e7c647b3904f51d77ba1d4cc97b1f9366dac10bb20abbaa69d0cdb7afcb130981150510baa#rd,2024-08-27 16:30:04,人工智能和机器学习研究公司的CEO Bindu Reddy表示，大型语言模型（LLM）可能会用英语取代SQL作为编程语言，特别是因为SQL生成的准确率已超过95%，超过了人类SQL程序员的平均水平。Reddy提到，许多数据库产品已经提供了用于查询数据的chatbox接口。虽然有人对LLM生成SQL的准确率表示质疑，但也有开发者分享了积极的体验，认为AI可以提高编写SQL的效率。然而，一些在实际工作中使用AI写SQL的人指出，虽然AI可以节省时间，但仍然需要大量的人工重写和修正错误，尤其在处理复杂查询时。目前，顶级模型在Text-To-SQL基准测试中的准确率远低于95%。尽管如此，AI在SQL编程中的应用已经对开发者的工作方式产生了影响，一些科技公司也推出了相关产品来协助数据处理和查询分析。
ACM MM24 | 复旦提出首个基于扩散模型的视频非限制性对抗攻击框架，主流CNN和ViT架构都防不住它,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931769&idx=5&sn=50b608b974339e7119b9c630b4483d44&chksm=84e7c647b3904f51e38a3188ee6a302dccc2e76c5837ff309f7d2e6ca153db79d2caed7b88b0#rd,2024-08-27 16:30:04,复旦大学的研究者提出了一种新型的面向视频模型的对抗攻击方法，称为基于扩散模型的视频非限制迁移攻击（ReToMe-VA）。该方法利用逐时间步对抗隐变量优化策略生成空间不可感知的对抗样本，并通过递归token合并策略提高对抗视频的迁移性和时序一致性。研究团队在多个视频模型上进行了实验，展示了ReToMe-VA在对抗迁移性和防御鲁棒性方面的优势。论文和代码已公开。
Yann LeCun不看好强化学习：「我确实更喜欢 MPC」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931627&idx=1&sn=3225394c1fdea1fbbc799a5822b6d217&chksm=84e7c5d5b3904cc3166dcaa1e68e2c7a803c81105ae20f633aed8c5829643b63a1899fc68a59#rd,2024-08-26 14:43:51,Meta的首席人工智能科学家Yann LeCun在近期的帖子中表达了对强化学习（RL）的批评，他认为RL需要大量的尝试，效率低下，而模型预测控制（MPC）更符合人类的学习方式，可以零样本解决新任务。LeCun主张最小化RL的使用，优先通过观察和预测学习世界模型。MPC是一种使用数学模型实时优化控制的技术，已在多个领域得到应用。虽然MPC在可预测系统中表现良好，但构建精确模型是个挑战。强化学习适合处理复杂动态或未知系统模型的问题，两者在不同场景下各有优势。最近的研究尝试将RL和MPC结合使用，以实现更好的控制性能和效率。
来外滩大会，论一论大模型的边界,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931627&idx=2&sn=6f4c0a9fdac70bfe31294a661ed99b2b&chksm=84e7c5d5b3904cc3b61db54cbf2b9d5859f47e4b86825a90f0476e041efe26d80d4ef689514d#rd,2024-08-26 14:43:51,"""2024Inclusion・外滩大会”将于2024年9月5日至7日在上海举行，其中“大模型的创造力边界与应用想象力”论坛由中国人工智能学会和蚂蚁集团主办。论坛将聚焦大模型的关键技术，如智能体、多模态和知识图谱，探讨如何在金融、医疗、政务等领域构建可信的智能应用系统。众多专家和业界代表，包括来自同济大学、清华大学等的学者，将参加论坛，分享大模型的产业应用和创新。此外，论坛上还将发布蚂蚁集团与中国信通院合作的《大模型可信应用框架研究报告》以及国内首个端到端语音大模型「心辰 Lingo」，并有多项重要发布预期。"
49位科学家上榜，清华方璐、复旦周鹏等获得科学探索奖,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931627&idx=3&sn=5ba4857183bc286bca278ea1b2f90868&chksm=84e7c5d5b3904cc3db32f7bce090ace312f7835e57a93e835f7d2ba2319aff1dccc4bd5158ce#rd,2024-08-26 14:43:51,第六届科学探索奖获奖名单揭晓，共有49位青年科学家获奖，每位获奖者将在5年内获得300万元人民币的奖金。该奖项由知名科学家和腾讯公司创始人发起，旨在鼓励青年科学家在基础科学和前沿技术领域进行探索。今年获奖者的平均年龄为41岁，女性获奖人数增加到7位。在信息电子领域，五位学者获奖，包括清华大学的方璐、华南理工大学的章秀银、西安交通大学的沈超、复旦大学的周鹏和合肥工业大学的汪萌。这些科学家在光场智能成像、无线通信、可穿戴设备、非易失存储器和人工智能等领域做出了杰出贡献。
本科生福利！爱丁堡大学图解版「伽罗瓦理论」课程笔记公开了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931627&idx=4&sn=ac95ba0825b4f4daee5505a1ff871903&chksm=84e7c5d5b3904cc38e032716444c850d3cd0d708a1f1cd7bb4c7354a521373e04dc770e6dddc#rd,2024-08-26 14:43:51,英国爱丁堡大学的数学家Tom Leinster公开了他在2021年至2023年期间为本科生授课的Galois Theory课堂笔记。这些笔记涵盖了域扩展和Galois群的理论，包括Galois理论的基本定理，以及尺规构造、可解多项式和有限域的分类等内容。资料包含约40个简短解释视频、大量问题和近500道多项选择题，旨在为学习者提供一个完整且自成体系的Galois理论学习资源。这些资料已上传至arXiv，并在作者的网站上提供。由于反响热烈，作者感到有些惊喜。
RTX3090可跑，360AI团队开源最新视频模型FancyVideo，红衣大叔都说好,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931627&idx=5&sn=d5b7c4782075465afe068d6f10d96b1a&chksm=84e7c5d5b3904cc32041e9b1f3a99fe5231513556762a7dde039fe5563a730cdd6dd9b69f1ad#rd,2024-08-26 14:43:51,360AI团队和中山大学联合研发的FancyVideo是一种基于UNet架构的视频生成模型，能够在消费级显卡上生成任意分辨率、宽高比、风格和运动幅度的视频。该模型通过跨帧文本引导模块（CTGM）改进了文本到视频（T2V）的生成过程，增强了时间逻辑理解和连续运动视频的生成能力。FancyVideo在视频生成质量、文本一致性、运动性和时序一致性方面表现出色，超过了其他T2V模型。此外，该模型还可以进行视频扩展和视频回溯操作。目前，FancyVideo已开源，未来团队计划上线更长、效果更好的模型和网页版本。
Karpathy狂赞AI代码神器Cursor，直言回不到3年前无辅助编码了，却被指「带货」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931520&idx=1&sn=0335143a047f25b80d88fe510e1b73f6&chksm=84e7c53eb3904c289f82fa4a81611e3aca9ecf880c819c932a351ef2710589adefb01bdaa14b#rd,2024-08-25 12:10:44,AI 大牛 Karpathy 最近分享了他使用 AI 代码编辑器 Cursor 结合 Claude Sonnet 3.5 大模型的编程体验，称这种做法带来了纯粹的双赢。Cursor 允许用户以自然语言与 AI 交互，生成代码片段并提供错误修复建议。Karpathy 表示，这种“半编码”方式提高了效率，他现在很难回到没有辅助的编码状态。然而，他的分享也引来了一些质疑，有人认为他在为 Cursor 做营销。对此，Karpathy 解释自己与 Cursor 无关，只是分享个人体验，并提醒用户购买 Pro 版才能获得完整功能。尽管有争议，Cursor 依然通过这次分享获得了更多关注。
统一transformer与diffusion！Meta融合新方法剑指下一代多模态王者,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931520&idx=2&sn=d1f35b7537cb54d9c88b111b9ecfa8d1&chksm=84e7c53eb3904c28260d2951dd636d41917bd30c821da74822bc8f035602b7e18c5c31dd8858#rd,2024-08-25 12:10:44,本文介绍了Transfusion，这是一种新的多模态模型训练方法，能在离散和连续数据上进行训练。Transfusion结合了语言模型和扩散模型，能够无缝地生成离散文本和连续图像。通过在混合模态序列上训练单个Transformer，Transfusion实现了两种模态的完全集成，避免信息丢失。实验表明，Transfusion在文本和图像生成任务上的性能优于其他流行模型，如DALL-E 2和SDXL，并且在GenEval基准测试中表现出色。Transfusion模型的扩展能力也优于将图像量化并用语言模型训练的方法。通过特定于模态的编码和解码层，模型性能进一步提升，甚至可以将图像压缩到极小的patch数量。总之，Transfusion为训练真正多模态模型提供了一种有前途的方法，同时在图像和文本生成方面达到领先水平。
模型成本疾速上升/下降，哪些技术让训AI更省钱？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931520&idx=3&sn=a583c8e0a7ec39a847cf39250c164e8e&chksm=84e7c53eb3904c28e076ced157d6d6fcabd4b7ce1af61b4f874fdab23d17e350cd9a522ff1de#rd,2024-08-25 12:10:44,这篇文章是机器之心PRO的会员通讯，主要涵盖了三个AI和Robotics领域的热点话题。首先，文章讨论了关于AI模型训练成本的争议， Anthropic的Dario Amodei预测成本将急剧上升，而方舟投资的报告则指出成本在下降。这两种观点的分歧在于计算成本的不同方法和考虑因素。其次，文章对人形机器人技术进行了深入梳理，探讨了人形机器人作为AI终极应用形态的挑战和底层技术。最后，文章综述了具身智能的研究进展，包括载体、感知和交互等方面。通讯还包含了其他27项行业动态，涉及技术、国内外新闻等。
三个程序员奋战三天重写推理堆栈，Grok-2 mini直接提速两倍，马斯克亲发贺电,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931520&idx=4&sn=f98ab019dab380fcc0ab4e57b460393b&chksm=84e7c53eb3904c28c4b1fe2fb1e2c3fc4633a92d15e5abe0b3c3d76dde35bd4ad340d18e662b#rd,2024-08-25 12:10:44,xAI的Grok-2聊天机器人在经过开发人员使用SGLang重写推理技术栈后，速度得到显著提升。在Lmsys Chatbot Arena排行榜上，Grok-2主模型获得高分，成为全球第二强人工智能模型，与谷歌的Gemini-1.5 Pro并列，仅次于OpenAI的ChatGPT-4o。Grok-2-mini也因此改进排名上升到第五位。SGLang是一种开源的高效系统，用于执行复杂的语言模型程序，能增强与LLM的交互并提高速度。该技术由多所大学的研究人员开发，目前支持多种模型，包括OpenAI的GPT-4。
ECCV 2024 | 引入DiT的原生3D通用框架，适用任意神经场、秒级生成,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931520&idx=5&sn=2213f0ed29608ae5c09bf705fa0c140a&chksm=84e7c53eb3904c28a36c18a1571c529dd2b2f9a98978996e6a821ddc2be5fb2d17a6bb21c8f8#rd,2024-08-25 12:10:44,南洋理工大学、上海AI Lab和北京大学的研究者提出了一种新的3D生成框架，称为Latent Neural Fields 3D Diffusion (LN3Diff)。该框架解决了现有3D生成模型可拓展性差、训练效率低和泛化性不足的问题，采用3D VAE和3D-DiT的两阶段方法，实现了高效、高质量的3D资产生成。LN3Diff在Objaverse数据集上进行大规模训练，并在多个基准测试中取得优异成绩，具有更快的推理速度。论文和代码已开源。
李沐重返母校上海交大，从LLM聊到个人生涯，这里是演讲全文,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931466&idx=1&sn=ac87e539a5d718c17e997cb7545226c1&chksm=84e7c574b3904c62f68b42f91b6875160d2eb4a63e5d3bf93d3f5a73e47fb50d6fa2c3b177db#rd,2024-08-24 13:50:29,李沐在分享中提到，当前语言模型（如LLM）的发展涉及算力、数据和算法三方面。算力方面，带宽是一个重要瓶颈，但随着技术进步，算力会变得更便宜且更高效。数据是模型的基础，获取和清洗数据是挑战，但数据量并不一定要无限增长。在算法上，每年都有进步，但实际应用与理论知识可能存在差距。李沐认为，未来大模型的主流参数规模可能在100B到500B之间，而大模型的性价比并不高，模型的价值会随着时间推移而贬值。此外，他还讨论了语音、音乐、图像和视频模型的进展，以及多模态模型整合不同信息的重要性。在应用层面，AI在文科和工科白领的工作中已有一定表现，但在蓝领工种中应用还面临挑战。最后，李沐分享了创业经验，强调预训练已成为工程问题，后训练才是技术挑战，数据质量和评估方法是关键。
从拨号上网到创立估值55亿美元独角兽，Transformer作者万字访谈聊AI趋势,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931466&idx=2&sn=9f018e7ce1c337618fac58dd147fd2b1&chksm=84e7c574b3904c62cf8688bafd475709fc4cdb821d5178e94fa38e085d62c0aefbfb7f4ddc77#rd,2024-08-24 13:50:29,Cohere 的联合创始人 Aidan Gomez 在访谈中讨论了 AI 公司面临的挑战，包括模型扩展的成本、推理能力的提升和价格战带来的压力。他认为对于有钱的公司，扩大模型规模是低风险但低效的方法，而初创公司可以寻求数据和方法创新。他还提到 AI 模型的推理能力不足是因为缺乏相关训练数据，并指出只靠模型 API 赚钱的公司将面临困难，应用层将变得更加重要。此外，Gomez 还讨论了芯片市场的变化和垂直整合的趋势，以及语音作为交互界面的潜力。最后，他强调了模型的私有部署和安全性对于企业在采用 AI 时的担忧。
视频生成要有自己的系统！尤洋团队历时半年开源VideoSys,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931466&idx=3&sn=bc22efc33f9febb960713fde143598d1&chksm=84e7c574b3904c62ce3ef33df595cf5b681e91da40f904e214d2f54560bf61a8aae45a7a6a60#rd,2024-08-24 13:50:29,新加坡国立大学尤洋团队开发的VideoSys是一个开源的视频生成系统，旨在简化和加速视频生成过程，使其更易于使用、快速且成本效益高。该系统基于团队早前的OpenDiT项目，提供了一个高性能的基础设施，支持从训练到推理、服务和压缩的完整视频生成pipeline。VideoSys引入了Pyramid Attention Broadcast (PAB)和Dynamic Sequence Parallelism (DSP)两种加速技术，前者实现无损质量的实时视频生成，后者在Open-Sora等模型中实现训练和推理的加速。项目已经在GitHub上开源，并获得了较高的关注。
上交大新型SRAM存内计算架构「COMPASS」，开启类脑计算新时代,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931466&idx=4&sn=8d4108dc81955acba4604168abf31d05&chksm=84e7c574b3904c6212bd7d3626a2e089a8da33c7aac04444f611648669ee3ef2c0066d8acabd#rd,2024-08-24 13:50:29,上海交大和上海期智研究院的研究团队提出了一种名为COMPASS的新架构，该架构基于SRAM的存内计算（CIM）技术，为脉冲神经网络（SNN）在硬件加速器上的高效部署提供了解决方案。SNN在低能耗和高效能计算方面具有潜力，但高准确性往往增加能量消耗和计算延迟。COMPASS利用输入和输出脉冲的稀疏性，减少了冗余计算和内存占用，通过动态脉冲模式推测机制优化了硬件资源利用。实验结果显示，COMPASS在端到端加速和能耗方面相比现有SNN加速器有显著提升，为低能耗人工智能的发展奠定了基础。这一成果将在未来可能应用于物联网设备、自动驾驶和智能机器人等领域。
ECCV 2024 | 机器遗忘之后，扩散模型真正安全了吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931466&idx=5&sn=349f1b8ec0f4d36b2987a2072bbf2c41&chksm=84e7c574b3904c627740358672b27cc42e43805f2b78e5a76d520e7308e9428461bd2e8373ca#rd,2024-08-24 13:50:29,密歇根州立大学和英特尔的研究者提出了一种名为UnlearnDiffAtk的对抗性文本提示生成方法，用于评估扩散模型在经过机器遗忘后是否真正安全。扩散模型在图像生成方面取得了显著进展，但也引发了安全和版权问题。现有的一些机器遗忘方法可能无法完全确保安全。UnlearnDiffAtk通过寻找离散的对抗性文本进行攻击，无需辅助模型，利用扩散模型自身的分类器能力，以评估遗忘后模型的安全可靠性。该方法在有害内容、艺术风格和物体遗忘任务中表现出高攻击成功率，并且比其他方法更高效。这项研究强调了扩散模型在生成安全性方面的挑战，并为推动相关技术的安全发展提供了贡献。
一句话生成《黑神话：悟空》3D资产，胡渊鸣创业项目Meshy上新，免费试用,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931346&idx=1&sn=8a43f71425afdd3707ffc9981917bf41&chksm=84e7c4ecb3904dfa4ae087d22f63b666b86bd80dafd5b677d3edbebdb3b58b3b79c967683583#rd,2024-08-23 11:51:10,这篇文章介绍了创业公司Meshy的3D AIGC工具的新进展，该工具能够快速生成高质量的3D模型，尤其在《黑神话：悟空》等游戏的视觉效果制作中有广泛应用。Meshy的最新版本Meshy 4在几何网格的清洁度和细节处理上有了显著提升，提供更干净、细致的模型，并改进了文本到3D的工作流，让用户更容易控制生成结果。此外，新版本还引入了“重试”功能，允许用户在不满意结果时重新生成模型，但该功能对订阅用户开放。Meshy由计算机图形学学者胡渊鸣创立，目标是通过AI增强3D内容创作，而不是替代艺术家和设计师的工作。
终于，Claude上线LaTeX公式渲染功能，评论区网友沸腾了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931346&idx=2&sn=071dc13ede2db458980fcd0b2ea0f076&chksm=84e7c4ecb3904dfa6ffd49591ce694c84d2fe275f3904b759ece50c04dc7bd096f24d0b3a980#rd,2024-08-23 11:51:10,大语言模型Claude现在支持LaTeX渲染，能够以一致的格式显示数学方程式和表达式。此前，用户曾反馈希望Claude添加此功能。LaTeX是生成数学公式的常用方式，对于解答数学问题时输出公式非常有用。更新后的Claude能够更好地展示和解释复杂的数学内容，对处理数学和科学记号的用户来说是一大进步。网友们对这一改进表示欢迎，并期待更多功能的添加，如支持其他版本的Claude和增加xlsx电子表格、web浏览等能力。
重返谷歌的Transformer作者，开始掌管Gemini AI,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931346&idx=3&sn=49d91d883b92c8900d8dca9a1c3ed5c8&chksm=84e7c4ecb3904dfaf67d4704b381c9be1f533775b8f19189da47d485a7ebde2ca284652fa061#rd,2024-08-23 11:51:10,前谷歌首席软件工程师Noam Shazeer创立的初创公司Character.AI被谷歌收购，Shazeer和另一位联合创始人Daniel De Freitas将回归谷歌。Shazeer将在谷歌担任重要的人工智能项目Gemini的联合技术负责人，与Google DeepMind的首席科学家Jeff Dean和深度学习团队负责人Oriol Vinyals合作，旨在开发与OpenAI的GPT系列模型竞争的聊天机器人。Shazeer是Transformer架构论文的作者之一，曾在谷歌负责早期广告系统。他因对谷歌的官僚主义失望在2021年离职，创办了Character.AI。现在，他以重要角色重返谷歌，参与构建谷歌的关键AI项目。
总说具身智能的数据太贵，鹏城实验室开源百万规模标准化数据集,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931346&idx=4&sn=00de4b220d0a17dcfd40444ff3963900&chksm=84e7c4ecb3904dfa4c9a32735d241a8e2b28882fd283fbe5a7c426dbf463cf1a1636e8aa7823#rd,2024-08-23 11:51:10,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我会尽力帮您生成摘要。
如何让等变神经网络可解释性更强？试试将它分解成「简单表示」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931346&idx=5&sn=bd05664089b188f10d163b188b4ba654&chksm=84e7c4ecb3904dfaffc06b944974e7df96bb0993aa3ee84f9600230dd23b0b6e70675f2d98be#rd,2024-08-23 11:51:10,这篇文章讨论了等变神经网络和分段线性表示论在神经网络中的应用。等变神经网络是用于学习对某种对称性不变或等变的函数的模型，例如图像识别中的平移不变性。研究者Joel Gibson、Daniel Tubbenhauer和Geordie Williamson探索了分段线性表示论在等变神经网络中的作用，尽管非线性性质使得简单表示之间的互动变得复杂，但他们发现将网络分解成简单表示仍然有好处。他们使用分段线性映射和分段线性表示论来理解网络的层，这提供了一种新的基础，类似于傅立叶变换的泛化，有助于理解和解析等变神经网络。论文证明了等变神经网络的信息流动通常从低频到高频，且在大型网络中高频占据主导。此外，他们还介绍了等变神经网络的理论贡献，包括将神经网络分解成简单表示的有用性，以及有关置换表示和类似伽罗瓦理论的正规子群的控制。
世界机器人大会上，这家承载「未来养老希望」的国产机器人被包围了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931294&idx=1&sn=3e0b658dcf9e48707a73603e946bc398&chksm=84e7c420b3904d36309d9074166599bfa42bd63b068a465d144f45ef8991f16a44b657a4bf97#rd,2024-08-22 17:49:23,在世界机器人大会上，AI机器人助理S1成为焦点，展示出演奏扬琴、武术和书法等多样化技能，展现出精细操作和智能控制能力。S1的表演包括精准的力控和模仿学习，如书法时的精细动作和咏春拳的敏捷身手。此外，S1还能进行家务活动，如扫地、喂猫和泡茶，被网友称为「赛博管家」。S1的技能全部通过学习获得，无需远程操作，体现了其在复杂环境中的智能规划和执行能力。其核心技术包括软硬一体的系统架构和多维度数据收集，以实现更高级别的具身智能。公司创始人强调机器人的安全性和经济性，目标是让AI机器人助理变得普及并为人类生活带来便利。
大模型时代的ASR就是不一样！豆包“听力”水平现场评测，方言&小朋友口音直接拿捏！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931294&idx=2&sn=19305f458bc357e88991ccc3bada2b30&chksm=84e7c420b3904d3653e4488fe11c2d37aa810ca01e4f7b344a8d403d5d0df8ff66b8f9fec6bf#rd,2024-08-22 17:49:23,火山引擎 AI 创新巡展上海站展示了豆包大模型的最新进展，豆包大模型在综合能力上提升了20.3%，特别是在角色扮演、语言理解和数学能力方面有显著提升。活动中发布了对话式 AI 实时交互解决方案，豆包大模型团队的 Seed-ASR 提供了高精度的语音识别能力，支持多种语言和方言，并能进行上下文感知，提高了人名和专业名词的识别准确性。语音合成模型实现了实时响应和精准断句，而语音识别模型能在一个模型中识别多种方言。这些技术已被应用于豆包 APP 和火山引擎服务中，提供更智能的语音交互体验。Seed-ASR 的技术亮点包括高精度识别、大容量模型、支持多种语言和上下文感知，并采用了分阶段训练方法，已经在多个场景中实现落地应用。
明确了：文本数据中加点代码，训练出的大模型更强、更通用,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931294&idx=3&sn=efa889f29c973d6c91f164bccc785791&chksm=84e7c420b3904d3699b17a37df37f658a60d07a6a03508548bdd4f3229b29a44a34a8c32024e#rd,2024-08-22 17:49:23,这篇论文研究了代码数据对通用大语言模型（LLM）性能的影响。研究者发现，代码数据对非代码任务，如自然语言推理和世界知识任务，也有显著的正向影响。预训练中使用代码可以提升模型的自然语言推理能力8.2%，世界知识理解能力4.2%，代码生成能力提升12倍。代码质量和属性也至关重要，使用高质量的合成代码数据可以进一步提高性能。在预训练的冷却阶段继续使用代码数据，所有任务的性能都会得到改善。这些发现强调了代码在大语言模型泛化能力中的关键作用，并提供了优化模型性能的指导。
国内首个自研MoE多模态大模型，揭秘腾讯混元多模态理解,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931294&idx=4&sn=aba803c8ac060ca6648de9c96309fe88&chksm=84e7c420b3904d36b057cd12112417fc86cf1cd6de384c4700a87a27a90771b5233384ca8ddd#rd,2024-08-22 17:49:23,腾讯混元推出了基于MoE架构的多模态理解大模型，这是国内首个此类模型，旨在解决视觉理解问题，推动人工智能从数字世界向物理世界的跨越。该模型在架构、训练方法和数据处理上进行了创新，提升了性能，能理解最高7K分辨率和任意长宽比的图片。在SuperCLUE-V基准评测中，腾讯混元模型获得国内排名第一，显示出强大的多模态场景理解能力。模型设计遵循简单、可规模化原则，支持原生任意分辨率并采用MLP适配器。它已经在腾讯的AI助手产品腾讯元宝中应用，并通过腾讯云向企业和个人开发者开放。
用AI自动设计智能体，数学提分25.9%，远超手工设计,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650931294&idx=5&sn=e4e8ef86a7e99ff9a0cf52f40ff0ecbc&chksm=84e7c420b3904d36496fe36512d269521b3500ac47bca181ed134257c8a673ab1b530fbc7534#rd,2024-08-22 17:49:23,研究人员提出了一种名为ADAS（Automated Design of Agentic Systems）的新领域，专注于智能体系统的自动化设计。他们开发了一种名为元智能体搜索的算法，该算法能够自动创建强大的智能体系统，包括发现新的构建块和组合方式。实验结果显示，基于ADAS发现的智能体在各种任务中的性能超过了最先进的手工设计基线。在阅读理解任务DROP中，智能体的F1分数提高了13.6/100，在数学任务MGSM中准确率提高了14.4%。此外，这些智能体还展现出跨领域迁移的能力。这项工作预示着ADAS在自动化智能体系统设计上的潜力。
腾讯混元大模型负责人王迪：揭秘万亿 MoE 系统工程之道｜智者访谈,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930994&idx=1&sn=68febc526362d8300b30683ddd531687&chksm=84e43b4cb393b25af213e1bda04b15cf7e153781db743aea6ec51d09468cbe4e463b2b51bf81#rd,2024-08-21 12:34:01,腾讯机器学习平台部总经理王迪在机器之心的《智者访谈》中分享了腾讯从 0 到 1 自研万亿级 MoE 大模型的历程。他强调，大模型是一项跨领域的系统工程，需要在约束下高效整合工程、算法、数据和业务应用。王迪指出，业务团队需要明确模型的能力边界，理解哪些问题适合用模型解决，哪些需要通过产品设计应对。他还提到，腾讯在探索大模型的 Scaling Law，以优化模型的性能和效率。此外，腾讯正在积极布局全模态统一到 Transformer，并且在基础设施构建、训练推理框架优化和业务场景落地方面有所进展。对于大模型训练的稳定性和鲁棒性，腾讯通过基础设施优化、监控和故障预测等手段来解决。
联合Science，面向青年学者，陈天桥推出AI驱动科学研究国际大奖,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930994&idx=2&sn=c63a9dc7f4fff82189ecf3d1cf093860&chksm=84e43b4cb393b25aab84c67552b3d1900bb26d28c0a1b5beb41b5c6c149d5087c7511fd22f08#rd,2024-08-21 12:34:01,天桥脑科学研究院与《科学》杂志联合推出AI驱动科学大奖，旨在表彰全球范围内使用人工智能技术在科学研究中取得突破的青年科学家。该奖项面向获得博士学位10年以内的科学家，获奖者将获得现金奖励和《科学》杂志的免费订阅，获奖论文将在《科学》杂志上发表。报名截止时间为2024年12月13日。该奖项由前中国互联网大佬陈天桥支持，旨在鼓励更多青年科学家利用AI进行科研，并期望未来AI科学家能在诺贝尔奖中占据重要位置。研究院与《科学》杂志此前已有合作，共同举办脑科学高端国际论坛，新奖项进一步体现了对AI在科学领域应用的重视。
支持1024帧、准确率近100％，英伟达「LongVILA」开始发力长视频,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930994&idx=3&sn=994f5e873609fd075ed5455644f493a8&chksm=84e43b4cb393b25ac99e9024f95ecf233d813c67bd12cb866773d500b9eb71be2fd790f50717#rd,2024-08-21 12:34:01,研究人员推出了LongVILA，这是一个全栈解决方案，用于训练和部署长上下文视觉语言模型（VLM）。LongVILA包括系统设计、模型训练策略和数据集构建，旨在处理长文档和视频。研究中，他们建立了一个名为多模态序列并行（MM-SP）的高效框架，支持长上下文VLM的训练，并实现了一个五阶段训练流程。实验表明，LongVILA在VideoMME和长视频字幕任务上的性能有所提高，其模型在处理大量上下文时表现优越，例如在1024帧上训练的模型在274k个token的上下文长度上达到99.5%的准确率。此外，MM-SP系统能有效扩展上下文长度至200万个token，且在处理长序列时比其他方法更快。
英伟达首个AI NPC入驻游戏，国产大作，4B模型只需2G显存,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930994&idx=4&sn=5de84dbe766518d72c3413640a0b9e37&chksm=84e43b4cb393b25ab20b71050c33c0c3ff37d42c870ae5c1cd0e9401446b8927422611d08845#rd,2024-08-21 12:34:01,英伟达在一款名为《解限机》的国产游戏中首次展示了由AI驱动的NPC（非玩家角色），允许玩家通过语音对话与NPC交流。这款AI NPC是基于英伟达的Avatar Cloud Engine（ACE）平台，该平台利用生成式AI创建智能游戏角色。ACE支持语音识别和文本转语音功能，创造全语音、全动态的游戏角色体验。游戏《解限机》计划于2025年公测，其NPC使用了优化后的Nemotron-4 4B Instruct模型，仅需2GB VRAM，可在超过1亿台配备RTX GPU的笔记本或台式机上运行。尽管目前AI NPC的功能仍有限，但这标志着Nvidia ACE技术在实际游戏中的首次部署，预示着未来游戏中AI NPC可能更广泛的应用。
多模态模型评测框架lmms-eval发布！全面覆盖，低成本，零污染,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930994&idx=5&sn=ff9035eca7c46f3347dca4519adfd5ff&chksm=84e43b4cb393b25ae3b3c1030eefbba264939fb1e89014b9027d6252c21892a4fc2950076a32#rd,2024-08-21 12:34:01,南洋理工大学LMMs-Lab的研究人员开源了LMMs-Eval，这是一个专为多模态大型模型设计的评估框架，旨在提供一站式、高效的多模态模型评测解决方案。该框架基于统一接口，支持一键式启动多个数据集和模型的测试，保证评估的透明性和可复现性。LMMs-Eval目前包含80多个数据集和10多个模型，且数量持续增长。此外，为解决评测的“不可能三角”问题，框架还提出了LMMs-Eval-Lite和LiveBench。LMMs-Eval-Lite是轻量级评估，用于在开发过程中提供快速模型性能反馈，而LiveBench则提供动态、零数据泄露的评估。
字节跳动2024奖学金计划报名启动！每人10万，助力科研未来！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930939&idx=1&sn=5fd269c81664dfcc8600479aabc09d6f&chksm=84e43a85b393b39368e539a366bb7f06ea63ee74ed77dc8b87e88dfd8d83217ac7c32c9e3395#rd,2024-08-20 12:11:44,摘要：
哈萨比斯：谷歌想创造第二个Transformer，还想把AlphaGo和Gemini强强联合,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930939&idx=2&sn=00d72f97f26fc7acc3b2a2fd39434048&chksm=84e43a85b393b393d7a9bd7caeafce2fcd71b6299e195df3e5a716cb840a401c85dc9efff669#rd,2024-08-20 12:11:44,谷歌将 Google Brain 和 DeepMind 合并为 Google DeepMind，以推动 AI 研究和产品的发展。这一合并产生了名为 Gemini 的大模型，它在多模态理解和对话交互方面表现出色。Google DeepMind 的首席执行官 Demis Hassabis 讨论了 AI 的未来发展，指出当前 AI 领域存在过度炒作的现象，但长期来看，AI 的潜力被低估了。他认为 AI 需要更好的基准测试来评估其能力，特别是在多模态理解、长期记忆和推理方面。此外，Hassabis 强调了 AI 系统安全性和道德标准的重要性，以及开源模型的考虑。他预计 AI 将在某些复杂的数学问题上取得突破，但目前还无法自主生成全新的理论或假设。
米粿AI：AI动漫赛道头部创业公司招聘AI算法实习生/工程师,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930939&idx=3&sn=06e1db546bac3200a71a85b0606ab645&chksm=84e43a85b393b393863cf055da538896ce25b97d84713245086e0e0ad2e9d9efce861ce13724#rd,2024-08-20 12:11:44,米粿AI是一家由哔哩哔哩和上海交通大学背景的团队创立的上海初创公司，专注于利用AI技术提升漫画和动画的创作效率，降低制作成本。公司创始人包括前哔哩哔哩副总裁丁黎和具有12年风投经验的陈达之，技术合伙人牛力是上海交通大学副教授，在计算机视觉领域有深厚研究。公司已连续融资三轮，获得近亿元投资，并在多项AI创新挑战赛中获奖。目前，米粿AI已开发出多项动漫制作功能，并计划招聘AI算法实习生和工程师。应聘者需具备计算机相关专业背景和深度学习框架经验，优秀者将有机会获得股票期权。有意者可将简历发送至hr@miguocomics.com。
特斯拉聘请「动捕师」训练人形机器人Optimus，时薪最高48美元,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930939&idx=4&sn=2450beb401df7d848625014bbff332c1&chksm=84e43a85b393b393a961f6d19251e828bb229bb5c5caba4370efb702951fb71e74b1b239fc4d#rd,2024-08-20 12:11:44,特斯拉正在招募“数据采集操作员”来穿上动作捕捉服模仿预期动作，为他们的人形机器人Optimus收集训练数据。这些操作员需要有高体力和耐力，包括长时间行走、搬运重物以及佩戴和操作动捕服和VR头显。Optimus机器人的身高要求与工作人员相似，约为173cm。数据采集操作员的主要任务包括走预定路线收集数据、执行指定动作、提供设备反馈、分析和报告数据等。特斯拉可能需要数百万小时的数据来训练Optimus，这一过程可能非常昂贵。马斯克表示，特斯拉计划在明年小批量生产Optimus，并在2026年大规模出货。目前，Optimus的竞争者如波士顿动力的Atlas和Figure的Figure 02已相继发布，加大了特斯拉的压力。
浙大李玺团队：指代表达理解新方法，ScanFormer粗到细迭代消除视觉冗余,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930939&idx=5&sn=270da8a6c88039abbe9affec0e803348&chksm=84e43a85b393b3937ac14b4629a4031e311780820d849a1a71a396e485ea320c987c3326ae78#rd,2024-08-20 12:11:44,"这篇文章介绍了浙江大学李玺教授团队的最新研究，他们提出了一个名为ScanFormer的迭代感知框架，用于改善指代表达理解（referring expression comprehension, REC）任务的效率。REC任务是根据自然语言描述定位图像中的目标。现有的方法通常使用预训练的特征提取器，如ResNet或Transformer，这些方法在高分辨率图像上的计算复杂度较高。

ScanFormer采用了一个自底向上的图像金字塔结构，从低分辨率图像开始，逐步过滤掉与指代表达无关的背景区域，重点提取前景区域的特征。这个过程通过动态patch选择实现，可以减少计算浪费并提高模型对任务相关区域的关注。实验结果表明，ScanFormer在多个数据集上达到了接近state-of-the-art的性能，同时实现了实时推理速度。

此外，文章还探讨了在不同尺度下patch选择的统计情况，并提出了加入早退机制以优化推理速度的可能性，但目前仍在探索合适的早退指标。总的来说，ScanFormer为REC任务提供了一种更高效且准确的解决方案。"
昆仑万维推出全球首款 AI 短剧平台 SkyReels，「一人一剧」时代来临,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930854&idx=1&sn=626e9fa7d9646069d0fe13ac512a42c1&chksm=84e43ad8b393b3ce556c9fe4e78820b279612fb67876865a1d05d4b983c3222f52f8e4a19545#rd,2024-08-19 12:45:24,昆仑万维发布了全球首个集成视频大模型与3D大模型的AI短剧平台SkyReels，该平台可以一键生成短剧，包括剧本、角色定制、分镜、剧情和影片合成等全部流程，极大地简化了短剧制作。SkyReels利用AI技术，如剧本大模型SkyScript、分镜大模型StoryboardGen和创新平台WorldEngine，提高了短剧制作的效率和质量。该平台的推出预示着AI在短剧创作中的应用将进一步推动UGC和PUGC内容的爆发式增长。此外，昆仑万维还致力于构建以IP为核心的综合UGC平台，并在底层开发通用大模型，如天工大模型，以支持AI内容生成。
为什么学线代时不知道：矩阵与图竟然存在等价关系,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930854&idx=2&sn=931b809c2ad359748497c45ef22498a0&chksm=84e43ad8b393b3ce494e4776a4d914f06e68807c34194b264817d0dac58e0f8f3167bfb2e18e#rd,2024-08-19 12:45:24,非负矩阵可以转换成对应的有向图，这种表示方式有助于理解和简化矩阵运算，同时也能从新视角理解图论。通过将矩阵的每一行视为一个节点，每个非零元素表示一条有向且加权的边，矩阵的运算如幂运算可以转化为图中的游走计算。这种等价性在处理马尔科夫链、谱图理论等方面有应用，并有助于将非负矩阵转化为弗罗贝尼乌斯标准形。这一方法能帮助更好地学习线性代数，也有潜力在AI的可解释性和图人工智能领域带来新突破。
一文看懂Mamba，Transformer最强竞争者,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930854&idx=3&sn=9eb22131ff3ddb060e00bfdb88358ead&chksm=84e43ad8b393b3ce94506cdb0cb13b0a1dee42eb9540ae3a2cc7930921d585a6875e206180f0#rd,2024-08-19 12:45:24,状态空间序列模型（SSM）作为Transformer的替代品，因其在处理长序列数据时的高效性和线性可扩展性而受到关注。Mamba是SSM的一个变体，它结合了注意力机制和循环神经网络的特性，能够高效建模复杂时间序列数据，同时保持线性时间复杂度。Mamba通过引入选择机制和硬件感知型算法，实现了在A100 GPU上计算速度的显著提升。近期的研究表明，Mamba在多个领域，如自然语言处理、计算机视觉和医疗等，展现出广泛的应用潜力。尽管Mamba在处理非序列数据和多模态数据方面取得进展，但仍存在记忆管理、泛化能力和模型复杂性等方面的挑战，为未来研究提供了机遇。
大模型终端部署新趋势：硬件直接支持混合矩阵乘法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930854&idx=4&sn=8c06a671478cd5625cad4e03a6e698ec&chksm=84e43ad8b393b3ce5f01dfe0c8dc92c7d2673d10d2a1ec230f443e5e98ea10c25571b91ba8f3#rd,2024-08-19 12:45:24,微软亚洲研究院推出了一种名为Ladder的数据编译器和T-MAC算法，以解决硬件不支持低比特量化后的数据模式的问题，从而实现混合精度矩阵乘法。Ladder能够将硬件不支持的自定义数据类型转换为硬件支持的类型，提高了运行效率，测试中最高可提升14.6倍。T-MAC则基于查找表方法，实现了CPU上低比特量化模型的高效运行，速度比专用加速器NPU快两倍。此外，研究人员还设计了LUT Tensor Core硬件架构，以支持各种低比特混合精度计算，为AI硬件设计提供了新思路。这些创新技术有望推动大模型在资源受限设备上的高效运行。
机器人策略学习的Game Changer？伯克利提出Body Transformer,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930854&idx=5&sn=3fb1dace4562c9073c86e771f23ec8d3&chksm=84e43ad8b393b3cef3deac1a3290ae28c665c24f88f83dcb3aaf261b076962ad5231e3b3858c#rd,2024-08-19 12:45:24,加州大学伯克利分校的研究团队提出了一种名为Body Transformer（BoT）的新架构，这是一种适合机器人策略学习的Transformer变体。BoT将机器人建模为一个图，其中传感器和执行器作为节点，通过高度稀疏的掩码在注意力层上处理，使得信息沿着图的结构流动。这种架构允许机器人策略利用其物理结构，提高了模仿学习和强化学习的性能。在模仿学习任务中，BoT的表现优于传统的多层感知机（MLP）和Transformer基线，并在未见过的视频片段上表现出更好的泛化能力。在强化学习实验中，BoT在多个机器人控制任务上展示了更高的样本效率和渐近性能。此外，BoT在真实世界的Unitree A1机器人上也成功地执行了任务，证明了其在实际应用中的潜力。BoT的掩码式注意力机制在计算成本方面也具有优势，特别是在处理大量节点时，可以显著提高速度。
一年秀一次！稚晖君的人形机器人上新了，还有开源、免费彩蛋,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930762&idx=1&sn=ad73e7b419400c3c943b33e4633d66ef&chksm=84e43a34b393b32279fe7fc62cde81c6afe9e42d3637225fc3b68633ebf9fc28a6c3ab128270#rd,2024-08-18 12:51:49,这篇文章介绍了国内一家名为“智元机器人”的公司发布的新一代人形机器人产品。该公司在一年内完成了6轮融资，成为机器人领域的热门项目。在发布会上，智元机器人推出了三款远征系列机器人：交互服务机器人远征A2、柔性智造机器人远征A2-W和重载特种机器人远征A2-Max，以及两款模块化机器人灵犀X1和灵犀X1-W。新一代远征A2系列具有超过40个主动自由度的关节和仿人灵巧手，配备大语言模型和多模态感知系统。此外，文章还提到了智元机器人在动力域、感知域、通信域和控制域的创新技术，并提出了从G1到G5的具身智能技术演进路线。智元机器人计划在2024年预估发货300台左右的机器人，并将在第四季度开源相关数据集和机器人设计资料，以推动人形机器人的发展。
波士顿动力技术揭秘：后空翻、俯卧撑与翻车，6年经验、教训总结,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930762&idx=2&sn=d397116dc1f9c8c6396ab84da396a070&chksm=84e43a34b393b32298ab282d34b37939213e2f492dfd568b8877d81c0d272d84ca865642c848#rd,2024-08-18 12:51:49,波士顿动力的工程师Robin Deits在一场技术分享中介绍了人形机器人Atlas的研发历程和经验教训。Atlas机器人通过使用模型预测控制（MPC）技术实现了跑酷、体操等高难度动作。MPC允许 Atlas 在预测未来行为的基础上优化控制输入，处理多变量系统并考虑约束条件。虽然Atlas已能完成复杂的动作，但开发团队也面临挑战，如如何处理机器人与环境的接触模式变化、动态参考轨迹的制定等。他们正探索将MPC与机器学习相结合以应对这些挑战。
Machine Psychology，解构 LLM 还是心理学更靠谱吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930762&idx=3&sn=cd6ed71339cd0f0b6fac7b91a71c20d4&chksm=84e43a34b393b322fd7635405f96531a87396a0deefdd92289523e20cff9a0eff8102e6b322b#rd,2024-08-18 12:51:49,这篇文章是机器之心PRO的会员通讯，主要分析了三个AI和Robotics领域的热点话题。首先，文章介绍了Machine Psychology，即用心理学方法研究大型语言模型（LLMs）的行为和推理能力，探讨了其概念、应用和研究路线。其次，讨论了AI编程工具，如Genie和Cursor的崛起，以及AI Coding赛道的爆发原因和热门应用。最后，提到了ALI的深度报告，该报告关注基础模型评估的成熟度和面临的挑战。本期通讯还包含了29项行业动态，涵盖了技术、国内外市场等方面的信息。
给RAG系统做一次全面「体检」，亚马逊开源RAGChecker诊断工具,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930762&idx=4&sn=75c7311d5ce5845d7e5d15b23952c4d1&chksm=84e43a34b393b3226866e3ec4b74896fe2f797480109a389532f13c453797db6454e716de8c6#rd,2024-08-18 12:51:49,亚马逊上海人工智能研究院推出RAGChecker，这是一个用于诊断和评估检索增强生成（RAG）系统性能的工具。RAG系统在整合外部知识库和大型语言模型内部知识方面发挥了重要作用，但其评估和优化存在挑战。RAGChecker提供细粒度评估、全面的指标体系和可操作的洞察，帮助开发者深入分析检索和生成两大核心模块的性能。该工具的评估结果与人类判断高度相关，为改进RAG系统的忠实度、上下文利用率、噪音敏感度和幻觉等问题提供了指导。RAGChecker已在LlamaIndex中集成，为使用LlamaIndex构建的RAG应用提供评估支持。
从头设计抗体，腾讯、北大团队预训练大语言模型登Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930762&idx=5&sn=b23880322997b7e3eb5a21ab662a80a2&chksm=84e43a34b393b3221d12c00f068dbef161e130146c3e93b2f0a7f76c8e8bccae5bb9025d39cd#rd,2024-08-18 12:51:49,腾讯AI Lab、北京大学深圳研究生院和西京消化病医院的研究团队开发了一种预训练抗体生成大语言模型（PALM-H3），该模型能从头生成具有特定抗原结合特异性的人工抗体CDRH3，减少了对天然抗体的依赖。同时，他们还设计了一个高精度的抗原-抗体结合预测模型A2binder，用于预测结合特异性和亲和力。这一人工智能框架有望加速抗体药物的开发。研究发表在《Nature Communications》上。
ChatGPT后，人工智能的终极里程碑却倒了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930730&idx=1&sn=efdc0beaf083287068c569298cf2cda6&chksm=84e43a54b393b342782020175f0df053b0a37462ef6009b45e24648c641f8797ded90f188ded#rd,2024-08-17 12:32:51,本文讨论了图灵测试作为衡量机器智能的标准是否仍然适用的问题。图灵测试最初是作为一个哲学思想实验，但在公众认知中已成为人工智能的里程碑。近年来，随着聊天机器人的发展，一些人宣称ChatGPT等AI已通过图灵测试。然而，AI社区对通过图灵测试的标准缺乏共识，许多人认为对话技能并不等同于底层智能。文章指出，图灵测试的原始设定缺乏具体细节，导致不同的实施方式和解释，有时更多地测试了人类的易信性而非机器的智能。此外，研究表明，语言流畅性可能与认知的其他方面（如推理和常识）相分离。因此，文章提出，我们应该重新考虑如何定义和评估机器的智能，而不仅仅是基于它们能否模仿人类对话。最后，文章引用了专家的观点，暗示真正的智能可能比目前理解的更复杂，并提出我们可能需要接受无法完全理解的AI系统。
DeepSeek开源数学大模型，高中、大学定理证明新SOTA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930730&idx=2&sn=00d2cddcbf2466e1cabb0fa49809efb2&chksm=84e43a54b393b3426ac9b2fd5da499cfd1f00a75dab1d8b6d0add2d35f73e461fa470f2b1bbf#rd,2024-08-17 12:32:51,DeepSeek-Prover-V1.5，一个70亿参数的开源模型，通过结合强化学习和蒙特卡洛树搜索，提升了形式化定理证明的效率和准确性。该模型在 Lean 4 的形式定理证明中超越了所有开源模型。通过集成强化学习和树搜索技术，它能在没有中间策略状态信息的情况下生成证明，减少错误积累。模型的训练包括大规模数学预训练、监督微调、强化学习和蒙特卡洛树搜索方法。实验结果显示，DeepSeek-Prover-V1.5 在高中水平的 miniF2F 数据集和本科水平的 ProofNet 数据集上取得了新的 state-of-the-art 成绩。
Nature子刊 | 基于内生复杂性，自动化所新类脑网络构筑人工智能与神经科科学的桥梁,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930730&idx=3&sn=14cfa2392b9db7598bb100efec00460b&chksm=84e43a54b393b342f43feaadd578af2d73d509455fb0fb6df573db1df73f2399d50d7e667df3#rd,2024-08-17 12:32:51,中国科学院自动化所、清华大学和北京大学的研究团队在《Nature Computational Science》上发表论文，提出了一种基于“内生复杂性”的类脑神经元模型构建方法，以克服当前大模型依赖“外生复杂性”（更大、更深和更宽的神经网络）所带来的计算资源消耗和可解释性问题。研究团队通过模拟生物神经元的复杂动力学，构建了更小但效率更高的神经网络模型，证明了这种内生复杂性模型在处理复杂任务时可以与大规模模型相媲美，同时减少了计算资源的消耗。这种方法为人工智能研究提供了新的方向，有助于实现更高效、可解释的AI模型。
AI成为「耗电大户」，除了新能源，还需要芯片创新,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930730&idx=4&sn=a34f7fb35626684a8e18c0f1a398b51d&chksm=84e43a54b393b342d60f8cdcd704fcf0c75e9e6dc921697234720dddbc98710c8bef4e96e6c0#rd,2024-08-17 12:32:51,随着人工智能（AI）的快速发展，尤其是生成式AI的兴起，数据中心的能源消耗急剧增加，引发了能源危机。目前，美国数据中心的能源消耗预计将在2028年增长到67太瓦时，AI可能占据全美电网总发电量的4%。为应对这一问题，科技公司正在探索使用核电发电机，如小型模块化反应堆（SMR），以及投资无核废料聚变反应堆。此外，芯片制造商正在研发低功耗的AI加速器和更高效的半导体技术，如3D堆叠晶体管，以降低功耗。数据中心的冷却技术和能源管理策略也在不断创新，包括采用水冷系统和利用多种可再生能源。尽管存在能源挑战，但历史经验表明，技术创新有能力跟上需求，解决潜在危机。
首个全自动科学发现AI系统，Transformer作者创业公司Sakana AI推出AI Scientist,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930730&idx=5&sn=ce5ccc9b6d3caa6b35675a355ecbbfd1&chksm=84e43a54b393b342cd7de6b74ec069cc93b3080a6623314d583b42731ef24c6fb771840f089a#rd,2024-08-17 12:32:51,Sakana AI公司推出了世界上第一个AI Scientist系统，该系统自动化了科学研究和开放式发现的全过程，包括构思、编写代码、运行实验、撰写论文和进行同行评审。这个AI系统能够以低成本（每篇论文约15美元）生成与会议水平相当的论文，并且已经在机器学习的三个子领域展示了其多功能性。通过自动审阅器的验证，AI Scientist撰写的论文质量接近人类水平，有望加速科学发现和创新。该研究强调了撰写论文的重要性，因为它提供了可解释性和标准化评估的途径。未来的工作将聚焦于系统的改进，包括增加视觉处理、人类反馈集成以及扩展到其他科学领域。
以「垂直模型」引领AIGC商业化落地，FancyTech的技术路径是什么？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930567&idx=1&sn=b5fc3170aa4c3be6701f2a21fb898120&chksm=84e439f9b393b0ef4b8ce1756e95c59a9dce6205478feea33a68b6a594d400cd0ac1b62e037f#rd,2024-08-16 12:22:23,这篇文章提到了AIGC（AI生成内容）技术的快速发展，它已经渗透到文本、图像和视频等多个领域。尽管大型模型在通用能力上显示出潜力，但针对特定任务的垂直模型在某些情况下能取得更好的效果。FancyTech是一家中国创业公司，以其在商业视觉内容生成的垂直模型产品在市场上脱颖而出。该公司强调了垂直模型对于满足特定行业需求的重要性，尤其是在商业视觉设计中，商品的还原度是关键。FancyTech采用开源算法框架并结合自有的数据标注进行训练，强调商品数据和训练方式对于最终效果的重要性。他们引入空间智能的概念，用3D数据训练模型以增强对现实世界的理解，并实现商品在2D内容中的准确还原和融合。FancyTech的创新算法和数据收集方法提高了商品图像和视频生成的质量，已经在多个品牌和平台上获得应用，展示了垂直模型如何提高生产力并降低创作成本。该公司还提供AI短视频全链路自动化服务，使得普通人也能利用AIGC技术提高创作能力。
英伟达玩转剪枝、蒸馏：把Llama 3.1 8B参数减半，性能同尺寸更强,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930567&idx=2&sn=5a2c9f46d13f5fb74da68efd4a475ec4&chksm=84e439f9b393b0ef4aec228bb3c62e95643fbf7f6f781a1c269bcd7715adb1a4c4100d1c8450#rd,2024-08-16 12:22:23,英伟达研究团队通过结构化权重剪枝与知识蒸馏的结合，将Meta的80亿参数量Llama 3.1模型压缩为40亿参数的Llama-3.1-Minitron模型，该模型在多个语言任务中表现出色，优于类似大小的其他先进模型。这一方法包括从大模型开始，评估和剪枝组件，然后使用模型蒸馏进行轻度再训练，将知识转移到更小的模型。通过这种技术，可以创建高效且部署成本低的紧凑型语言模型。英伟达的研究论文详细介绍了这一过程，并提供了实证研究结果。
想搞懂李飞飞的创业方向？这里有一份机器人+3D的论文清单,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930567&idx=3&sn=a355ce1e441212deffd728993b5aca88&chksm=84e439f9b393b0ef24f88935ec45f9caa2b917fa4dcb98297ea6ba7924d8b58c8e04cc0accb9#rd,2024-08-16 12:22:23,这篇报道介绍了著名AI学者李飞飞的创业公司World Labs，该公司专注于开发能够理解三维物理世界的模型，即“空间智能”。李飞飞认为空间智能是AI发展的重要领域，她的团队在斯坦福大学实验室中训练计算机和机器人在3D环境中执行任务。为帮助研究者了解“3D视觉+机器人”方向的进展，文章提到了一个GitHub存储库，其中收集了80多篇相关论文，涵盖了策略学习、预训练、表示、模拟、数据集和基准等多个主题。此外，还推荐了两篇综述论文，分别概述了3D任务中多模态大型语言模型的研究和3D视觉在机器人操控领域的应用。
大神Karpathy：我给大模型「SQL注入」攻击，简直不要太轻松,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930567&idx=4&sn=812007ecaaf8e56a092627beae2a7ec6&chksm=84e439f9b393b0ef592262fd9cdf8c944e6b5f8efaf3a95e97b7307265ecbb43b3e6d0deacbc#rd,2024-08-16 12:22:23,AI大牛Andrej Karpathy指出，大型语言模型（LLM）存在类似SQL注入的安全风险。攻击者可以利用LLM的分词器将恶意特殊token插入输入，导致模型执行意外操作。在SQL注入中，攻击者通过恶意SQL语句访问或修改数据库。在LLM中，不良代码可能导致模型混淆输入，产生未定义的输出。Karpathy建议在处理特殊token时禁用`add_special_tokens=False`和`split_special_tokens=True`，并使用编程方式显式添加，以提高安全性。他还警告，大约50%的代码可能因这个问题出现bug，即使是经过严格测试的ChatGPT也存在相关问题。开发人员应以“普通”方式标记字符串，以遵循安全领域的“最小特权”原则。
两个小模型互相验证，直接比肩大模型？微软的rStar甚至没用CoT和微调,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930567&idx=5&sn=f48439e61b4fec058e46ec1c83edef67&chksm=84e439f9b393b0ef43148f05b9ab39b48c87bd511603976639ad76e8f4eb5e39b488a71489db#rd,2024-08-16 12:22:23,研究人员提出了一个新的方法，称为rStar，来提升小版本大型语言模型（SLM）的推理能力，而无需微调或更强大的教师模型。rStar使用自博弈相互推理，将推理过程分为解答生成和相互验证两部分。为了解决SLM在推理探索和评估方面的不足，rStar引入了一个包含多种人类推理动作的集合，并设计了一个针对SLM的奖励函数来评估中间步骤。通过这种方法，rStar能够提升SLM在解决复杂推理任务时的准确度，特别是在数学和常识推理任务上。实验表明，rStar在多种SLM和推理数据集上取得了显著的性能提升，甚至超过了某些微调方法。
「每周只上一天班」谷歌散漫制度遭前CEO怒斥：输给OpenAI，再下去要输创业公司了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930437&idx=1&sn=b0f066b13c9ff77cd82f56f2a557fa58&chksm=84e4397bb393b06d9d54069eeb3e34344f87c8051ba90bc79274b0c13769da663fb900788ca7#rd,2024-08-15 12:23:30,谷歌前CEO埃里克·施密特在斯坦福大学公开课上表示，谷歌在AI领域落后于OpenAI可能是因为谷歌允许员工更早下班和远程工作，而初创公司如OpenAI的成功在于员工的拼命工作。他强调，如果创办公司，不会允许员工在家办公。这一言论引发了争议，一些人认为专注的人在任何地方都能高效工作，而另一些人则支持现场办公以促进团队合作和效率。施密特后来撤回了这些言论并道歉。谷歌和OpenAI目前都要求员工每周至少在办公室工作三天。这场讨论反映了科技行业对于远程工作和工作文化的辩论。
1篇Outstanding、5篇Oral！字节跳动今年ACL这么猛？ 来直播间聊聊！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930437&idx=2&sn=e8d4d68cb408cd94c00e9522e8586e6e&chksm=84e4397bb393b06d0730b2c4952846adb1005fceeb8624a99032ed67ef50710da926dfff791a#rd,2024-08-15 12:23:30,"这篇文章的摘要如下：

在泰国曼谷举行的 ACL 2024 会议上，字节跳动共有 5 篇论文入选 Oral，其中一篇被选为 Outstanding Paper。在 ACL 2024 的 Paper Awards 环节，字节跳动的《G-DIG: Towards Gradient-based DIverse and high-quality Instruction Data Selection for Machine Translation》脱颖而出。此前在 ACL 2021，字节跳动曾获得最佳论文奖，成为 ACL 历史上中国科学家团队第 2 次获得此荣誉。为了分享前沿研究，字节跳动计划于8月20日举办线上“ACL 2024 前沿论文分享会”，解析自然语言处理、语音处理、多模态学习等领域的重要成果。此外，文章提到了字节跳动在语音离散化、扩散条件序列生成、视觉条件语言生成、实时语音转换和机器翻译指令数据选择等方面的研究进展。"
ACL 2024奖项公布：华科大破译甲骨文最佳论文之一、GloVe时间检验奖,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930437&idx=3&sn=9c280df3e2ea661a457545423e3e16cd&chksm=84e4397bb393b06da2ca11ccd6530c9d6147cc1e1fcd72fbdb2333e519dc3a558cadb1b81900#rd,2024-08-15 12:23:30,2024年ACL大会在泰国曼谷举行，公布了最佳论文、最佳主题论文、杰出论文等奖项。7篇论文荣获最佳论文奖，其中一篇挑战了乔姆斯基关于大型语言模型学习能力的理论。最佳主题论文《OLMo：Accelerating the Science of Language Models》因其对语言模型训练透明性和可重复性的贡献而获奖。此外，大会还颁发了资源论文奖和社会影响力奖。终身成就奖授予了纽约大学的Ralph Grishman教授，以表彰他在自然语言处理领域的贡献。获奖论文涵盖了语言模型的学习能力、甲骨文破译、记忆机制、多语言处理等多个研究方向。
ACL主席：ACL不是AI会议,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930437&idx=4&sn=760a77f381c7cf255f31f90afd8cd556&chksm=84e4397bb393b06d0ed86c0cf3bd0b54d5766bb00ed3ce665f9af0f884ac97f5858a87d34cd7#rd,2024-08-15 12:23:30,在 ACL 2024 大会上，主席 Emily M. Bender 强调 ACL 不是 AI 会议，其核心是计算语言学和自然语言处理，而非人工智能。她批评了将 ACL 视为 AI 会议的趋势，指出 AI 领域的问题，如不良研究实践、过度关注基准测试和大模型，以及对社会影响的忽视。Bender 提倡 CL/NLP 领域的研究最佳实践，强调对语言学的理解、可复制性、社会影响和跨学科合作。这一观点在学术界引发了争议，有人认为这是不够包容的表现，也有人支持保持 ACL 的专业定位。演讲引发了关于 ACL 是否欢迎 AI 论文的讨论。
数十年来首次取得进展，陶哲轩高徒、赵宇飞高徒突破组合数学难题,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930437&idx=5&sn=7ab3a9f181dc8efc67a6d5e17c5cc9da&chksm=84e4397bb393b06d71e7e9d97a5605e7e7f75dd0293458fec23aa1a184bafde7d566e60ea230#rd,2024-08-15 12:23:30,"三位年轻的数学家——加州大学洛杉矶分校的研究生James Leng、麻省理工学院的研究生Ashwin Sah和哥伦比亚大学的助理教授Mehtaab Sawhney——近期在解决一个数十年未解的数学难题上取得了进展。这个问题涉及到算术级数，即等差数列的和。1936年，数学家Paul Erdős和Pál Turán提出猜想：如果一个集合包含几乎所有的非零分数，那么它必定包含任意长度的算术级数。1975年，Endre Szemerédi证明了这个猜想，但关于在有限数集内避免算术级数的具体比例问题依然存在。

数学家们一直在探索随着数集大小（N）的增长，能避免算术级数的数集比例如何变化。三位数学家的最新工作改进了避免特定长度算术级数的最大集合大小的界限，特别是对于五项或更多项的级数，这是自Timothy Gowers在2001年取得突破后的首次进展。他们的成果为这个长期存在的数学问题提供了新的理解。"
一直爆料OpenAI「草莓」的账号，竟然是个智能体？斯坦福系创企「炒作」AgentQ,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930230&idx=1&sn=a4c14413c4eb058290621ce92e8bd7d8&chksm=84e43848b393b15e5acd2c3b4d8e9c7639248cf2dc90dd1a59d0098be9728dacf8b4a13aa733#rd,2024-08-14 12:43:56,"这篇文章的摘要可以是：

一家名为MultiOn的AI初创公司发布了名为Agent Q的智能体，声称其具有高级推理能力和规划、自我修复功能。Agent Q的推广与OpenAI的秘密项目“Q*”和先前的“草莓”项目有关，引发网络热议。据称，Agent Q在复杂任务中的性能是LLama 3基线的3.4倍，成功率为95.4%。该智能体使用了蒙特卡洛树搜索、AI自我批评和直接偏好优化等技术进行训练，能够执行如预订餐厅和航班等任务。然而，一些网友对MultiOn是否利用“草莓哥”账号进行炒作表示质疑。论文已经发布，详细介绍了Agent Q的技术细节和评估结果。"
​一夜之间，谷歌版GPT-4o和AI手机全上市了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930230&idx=2&sn=822b96951da8ef70408c0c546c6c5ae5&chksm=84e43848b393b15e320f663d6c311ccab54157b0885da6dee24ce8e5260beed4153dfb2a432a#rd,2024-08-14 12:43:56,谷歌在Made by Google活动中发布了新产品，包括对标OpenAI GPT-4的 Gemini Live和一系列Pixel硬件，如Pixel 9系列手机。Gemini Live是一款移动对话体验应用，允许用户与AI进行自然对话，可以选择10种不同的声音，并能实时打断或改变话题。该功能已开始在Android的Gemini Advanced用户中推出，未来几周将扩展到iOS和更多语言版本。此外，谷歌还推出了新一代Tensor G4芯片，用于 Pixel 9系列手机，增强了AI性能，支持多模态任务处理。新款Pixel手机具有更好的耐用性和相机性能，并且购买Pixel 9 Pro和Pixel 9 Pro XL的用户将获得一年的Gemini Advanced订阅。
OpenAI「草莓」模型再次跳票，凌晨发布的SWE-bench Verified是个啥？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930230&idx=3&sn=6ec482c10f36b8b28103c48bbd9658fd&chksm=84e43848b393b15ebe0ca6e5f0b31e0a41db3ab9158c400f0e5cc77a9231bdf40428b1a433ea#rd,2024-08-14 12:43:56,这篇文章介绍了OpenAI发布的SWE-bench Verified，这是一个改进版的用于评估大模型解决GitHub软件问题能力的基准测试数据集。原始的SWE-bench存在一些问题可能导致模型的编程能力被低估。OpenAI与专业软件开发人员合作，对SWE-bench进行了筛选和注释，以确保单元测试的适当性和问题描述的清晰性。这个改进后的版本提高了评估的准确性和可靠性，结果显示，一些AI编程模型在SWE-bench Verified上的表现有所提升，表明原来的基准可能低估了AI的能力。同时，文章还提到，虽然OpenAI未发布期待中的“草莓”模型，但SWE-bench Verified的发布对于AI编程能力的评估是一次重要的改进。
没有等来OpenAI开源GPT-4o，等来了开源版VITA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930230&idx=4&sn=9438b7c9c53ffa71dc7b3aa78ffaf348&chksm=84e43848b393b15ede2b21d694dde6ee5d90c364b94e53f09728faef1db5b5524cd4dbe49dee#rd,2024-08-14 12:43:56,腾讯优图实验室等机构的研究者推出了首个开源多模态大语言模型VITA，该模型能处理和分析视频、图像、文本和音频模态，具有多语言、视觉和音频理解能力。VITA在单模态和多模态基准测试中表现出色，并在人机交互方面实现进步，支持非唤醒交互和音频中断。模型通过多阶段训练，包括LLM指令微调、多模态对齐和多模态指令微调，以增强多模态理解。VITA的开源发布旨在促进多模态领域的发展。
同时操控手机和电脑，100项任务，跨系统智能体评测基准有了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930230&idx=5&sn=057238b4b5ba7a27cc76ce2b4ea89253&chksm=84e43848b393b15e150392aa0315c8dc9771cff17a4624e665eb5e5345bcbf780b7fd2844134#rd,2024-08-14 12:43:56,CRAB是跨环境智能体基准测试框架，由CAMEL AI社区主导，用于评估基于多模态语言模型的智能体在跨环境任务中的性能。它弥补了现有基准测试的局限性，如单一环境评估和评估方法的不足。CRAB提供了跨平台的任务和评估工具，支持细粒度的图评估方法，简化了复杂任务的构建过程。研究团队还构建了跨平台数据集CRAB Benchmark-v0，包含100个任务，涵盖PC和智能手机环境。实验表明，使用GPT-4o的单智能体结构在测试中的完成率最高。CRAB旨在模拟真实世界中同时使用多个设备的复杂任务，推动智能体评估体系的发展。
非Transformer架构站起来了！首个纯无注意力大模型，超越开源巨头Llama 3.1,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930007&idx=1&sn=995919237664a0b05d9c5337c48af055&chksm=84e43f29b393b63f9d25ff12cc0d91a3a8dab262c48f3b7fe8e0810c6a90087df9273885550c#rd,2024-08-13 12:16:14,阿布扎比技术创新研究所（TII）发布开源大模型Falcon Mamba 7B，采用Mamba架构，能在单个24GB A10 GPU上运行，无需增加内存即可处理任意长度序列。该模型在某些基准测试中超越了同级别Transformer模型，如Meta的Llama 3 8B和Mistral 7B。Falcon Mamba 7B基于Mamba状态空间语言模型（SSLM）架构，提供了一种处理长文本序列的替代方案，且训练数据高达5500GT。模型通过多阶段训练策略和特定数据集进行优化，旨在应用于机器翻译、文本摘要等任务。Falcon Mamba 7B在处理序列长度和生成吞吐量方面优于Transformer模型，但在某些基准测试中仍有待提高。
论文荣登计算机体系结构顶会ISCA，芯片架构成为边缘AI最佳并行计算选择,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930007&idx=2&sn=d21e5aeda9e7a1b46199c3f98510a9ab&chksm=84e43f29b393b63fdcbae26daa589016ae9e86e35152b06aff6f9ed1ab8e8e2897f5cba29143#rd,2024-08-13 12:16:14,这篇文章讨论了边缘AI服务器市场和适合边缘AI的理想计算架构。随着AI应用的扩展，边缘AI服务器的需求正在增长，预计未来将超过云端服务器。在各种计算架构中，可重构计算架构CGRA因其能效和性能被认为适合边缘AI，尤其是芯动力科技提出的可重构并行处理器（RPP）架构。RPP在能效和性能上优于传统的GPU，如英伟达的Jetson系列，且其小面积和高可编程性使其成为边缘计算的理想选择。芯动力的RPP处理器R8在实际应用中表现出高吞吐量和能效，并在国际学术会议上得到认可。随着边缘AI的发展，RPP处理器有望在边缘AI服务器和AI PC市场中扮演重要角色。
不用部署，实现大模型切换自由！Token、算力免费薅！咱AI开发者今年整个秋天的奶茶都省出来了！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930007&idx=3&sn=efe6def76fc986a337499ca5a9447bb9&chksm=84e43f29b393b63f36e44b3763ceb3f2797343c110e0d2311c8ff6677d1ff4b5477cbd082867#rd,2024-08-13 12:16:14,机器之心SOTA模型社区和上海清湛智帆AIFanSuper算力平台合作，为AI应用demo开发提供便利。用户无需下载模型，可以直接在线试用和切换模型API，实现模型试用、API切换和DEMO开发的自由。首批10个常用模型已上线，支持免费实测和公共API调用，未来将不断更新。用户可以通过专属线路获得无限制的API调用和算力服务。上海清湛智帆提供500元免费算力券和限时算力补贴，旨在降低开发者使用高级模型的门槛和成本。该平台还提供预置镜像，简化模型部署过程。
开源AI视频工具，你只需要当导演，HuggingFace工程师打造,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930007&idx=4&sn=b280d79d89e7408d867617c762b7924b&chksm=84e43f29b393b63fd9886e397b3d8cca5f154c61b981cfa75bf1def9954017214780ee4cbf88#rd,2024-08-13 12:16:14,Clapper是一款开源的AI故事可视化工具，它允许用户通过调整高级概念，如角色、位置和天气，使用AI创建视频，而无需直接编辑视频和音频文件。由HuggingFace的AI前端工程师Julian Bilcke开发，Clapper的目标是提供一个交互式、迭代和直观的视频制作过程，任何人都可以使用。用户可以通过“导演模式”全屏播放视频并指导AI制作。Clapper集成了文本转时间线、文生图模型、配音和音效生成等功能，简化了视频制作流程。不过，目前其生成的视频效果仍有待提高，画面动作不自然，整体效果更像动态PPT。尽管如此，Clapper为AI在视频制作中的应用提供了新思路。
首个支持普通话和方言混说的TTS大模型：河南话、上海话、粤语说得溜,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650930007&idx=5&sn=383cf581d916b0802b940366bd4b9d5f&chksm=84e43f29b393b63f434ae60d4633694cd0362cec7590badfae2b0b683a5bd0c112e725c1f80d#rd,2024-08-13 12:16:14,巨人网络AI Lab团队开发了首个支持多种普通话方言混说的TTS大模型——Bailing-TTS，能生成包括河南话、上海话、粤语等方言的高质量语音。团队构建了涵盖20种方言、超过20万小时的普通话和方言数据集，通过创新技术如统一的方言Token规范、精细化Token对齐技术和层次混合专家结构，实现了在有限数据下的高质量方言语音合成。此外，他们还提出了层次强化学习增强策略来提高TTS模型的方言表达能力。Bailing-TTS已在游戏和视频内容等领域应用，未来有望在方言文化保护和游戏AI NPC方言交互等方面发挥更大作用。
这个大模型，真的治好了我的论文阅读障碍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929890&idx=1&sn=b9812e46d9441d6ed7912b921d69141f&chksm=84e43e9cb393b78a926d9d1ff3a91d8588519631a44da1fe7fe68fa0b2a33625e8c3bbd7bf1d#rd,2024-08-12 13:55:11,腾讯元宝推出的新功能“深度阅读模式”旨在帮助用户更有效地阅读和理解论文。这一模式将论文分解为结构化的模块，如研究背景、方法、实验和结论，提供清晰的层次和图文并茂的解析。此外，它还突出论文的优点和不足，帮助读者迅速掌握论文的核心价值和待解决的问题。元宝还支持原图原数的输出，方便读者验证信息，并提供了划词翻译、搜索、离线阅读和计算器等实用功能。这一更新体现了AI在帮助科研人员节省时间和提高阅读效率方面的进步。
加入谷歌25周年，Jeff Dean开启回忆杀：搬16次工位、掐点打咖啡,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929890&idx=2&sn=b35b181a09acbf090d6a87a3e8c2078d&chksm=84e43e9cb393b78a6d981016ce22b36f26f60b9cd63cda28d9ba17f06aa838cb7c48815679a0#rd,2024-08-12 13:55:11,谷歌首席科学家Jeff Dean在公司迎来25周年纪念，他回忆了1999年加入谷歌时的情景，当时谷歌还是一家小型搜索引擎公司。Dean在2011年参与创立了Google Brain，后来转向AI和机器学习领域的研究。2020年，他获得了IEEE冯诺依曼奖。2023年，Google Brain和DeepMind合并，Dean成为新部门的首席科学家。在他的推文中，他分享了早期办公环境的故事，包括“蜡笔图表”和智能马桶的趣事。这些回忆引发了人们对谷歌早期历史和成长的感慨。
AI出图更快、更美、更懂你心意，高美感文生图模型修炼了哪些技术秘籍？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929890&idx=3&sn=0d8a60a674a9f1998d23740f2fadc289&chksm=84e43e9cb393b78ab972374d0b2870eaa4d2320bdea44039d93f443edbbba2015c3d61d1b634#rd,2024-08-12 13:55:11,这篇文章介绍了文生图（文本生成图像）技术的快速发展，特别是AI图像生成模型在质量和速度上的不断提升。文章提到了字节跳动的豆包大模型在文生图技术上的升级，包括增强图文匹配、提高图像美感和加快出图速度。豆包团队通过精细化筛选数据、使用多模态大语言模型和优化模型架构来提升性能。此外，他们还引入了美学指导和“Rephraser”功能以增加图像细节和用户满意度。文章还提到了NVIDIA解决方案架构师对基于Unet的SD和DIT模型架构的讲解，以及英伟达的工具如何支持模型部署和加速推理。整个系列直播活动《AIGC体验派》旨在探讨AIGC技术如何在营销领域实现智能化升级。
把两块芯片压成一块：EUV以来半导体制造的最大创新,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929890&idx=4&sn=0f6c9779e8a14a8ca14902a43816a692&chksm=84e43e9cb393b78ae30a5bc70bca5b94a18e6320639fd9d39aaeec5c2338328535af790665d8#rd,2024-08-12 13:55:11,直接混合键合（Hybrid Bonding）技术是未来五年内可能对芯片行业产生重大影响的技术，它允许在同一封装中堆叠两个或多个芯片，创建3D芯片。这项技术通过高密度连接（每平方毫米硅片上可达700万个连接）使不同功能的芯片子系统能够协同工作，即使摩尔定律放缓，晶体管缩小的速度也在减慢。混合键合提供了最高密度的垂直连接，预计到2029年市场规模将增长到380亿美元。研究正在聚焦于如何优化连接密度、提高表面平坦度、减小键合距离和简化工艺，以实现更高效的3D芯片堆叠。混合键合在高带宽存储器（HBM）中的应用尤其重要，可以解决现有技术在堆叠更多层时遇到的挑战。未来，混合键合技术可能会扩展到硅以外的材料，并可能在量子计算芯片等领域发挥关键作用。
ECCV 2024 | 南洋理工三维数字人生成新范式：结构扩散模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929890&idx=5&sn=529f67cdc503f73f3a9ead194542b959&chksm=84e43e9cb393b78a8b04325ba8176d3c278c593eae6f4135bd88ce5a97edf1ff83d49b089abf#rd,2024-08-12 13:55:11,新加坡南洋理工大学S-Lab团队提出了一种名为StructLDM的新型三维数字人生成方法，该方法使用结构化隐空间扩散模型，解决了传统3D GAN方法中一维隐向量无法充分表征人体几何结构和语义信息的问题。StructLDM包括结构化的高维人体表征、结构化的自动解码器和结构化的隐空间扩散模型，能够从图像和视频中学习生成高质量、多样化且视角一致的三维数字人，并支持不同层次的可控生成和编辑，如局部服装编辑和三维虚拟试衣。该模型在多个数据集上展示了优于现有方法的性能。
黑匣子被打开了！能玩的Transformer可视化解释工具，本地运行GPT-2、还可实时推理,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929831&idx=1&sn=d0e5c01537def9f92c64dda2ea3c6626&chksm=84e43ed9b393b7cf177414848deaed70ac2a5b1522a12e3399920d4862e398c113b96af7b76e#rd,2024-08-11 12:10:30,这篇文章介绍了一个由佐治亚理工学院和IBM研究院开发的开源交互式工具——Transformer Explainer，该工具旨在帮助非专业人士理解Transformer的工作原理。Transformer是一种在深度学习领域广泛应用的神经网络架构，尤其在AI聊天机器人领域。由于其复杂的内部机制，对于初学者来说理解起来有难度。Transformer Explainer使用桑基图可视化设计，通过文本生成解释Transformer的内部运作，允许用户在多个抽象层级之间平滑过渡，以直观的方式展示输入如何通过Transformer进行处理和变换。该工具集成了GPT-2模型，支持实时推理，用户可以输入文本并观察内部组件和参数如何协同工作来预测下一个token。Transformer Explainer的多级抽象设计和交互性功能旨在降低复杂性，增强理解和参与。未来，研究者计划进一步提升工具的交互性和性能，并进行用户研究以优化其效能和可用性。
给视频模型安上快慢两只眼睛，苹果免训练新方法秒了一切SOTA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929831&idx=2&sn=cab3937328a2eeb5f3c0a319967e54eb&chksm=84e43ed9b393b7cf8ea4c42aacf6b7e34c4fc948d8c6f0dcff72da60bd991126dae66625c56e#rd,2024-08-11 12:10:30,苹果研究人员提出了一种名为SlowFast-LLaVA的新型视频大语言模型，该模型无需额外训练，可以直接用于视频任务处理。这一模型基于LLaVA-NeXT架构，通过SlowFast输入机制，结合两种不同帧率（慢速和快速）来理解和处理视频中的细节和运动，从而解决了现有视频LLM在处理有限帧数和时间建模上的问题。实验结果显示，SF-LLaVA在视频问答和文本生成视频等任务上显著优于现有免训练方法，并且在某些情况下与微调过的模型性能相当。
都在这里了，Figure视频里都藏了啥？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929831&idx=3&sn=5f52037a307596d9b461039fc88c8d8c&chksm=84e43ed9b393b7cf143f01fe0b71a9c32e4323d9e1cdf29d44865dfd4ef06185059edbc256dc#rd,2024-08-11 12:10:30,"这篇会员通讯主要涵盖三个专题。首先，讨论了硅谷公司Figure发布的最新人形机器人Figure 02，对其设计和功能进行了分析，包括六个摄像头、电池升级、第四代灵巧手等亮点。Figure 02已经在宝马工厂实习，但其展示的能力引起了一些争议，被评价为既有所进步又不够惊艳。

其次，通讯提到了GenAI行业的市值波动，尤其是七大科技公司的市值蒸发了8000亿美元。专家Gary Marcus预测GenAI泡沫可能在今年年底破裂，并基于一些行业表现和财报数据进行了讨论。这些公司在AI领域投入巨大，但盈利模式和能源消耗问题成为关注焦点。

最后，通讯引用了SemiAnalysis的深度报告，指出全球人工智能数据中心面临的能源困境，探讨了成为AI超级大国所需应对的能源挑战，并概述了报告的核心观点。

通讯还包含了其他30项本周AI和Robotics领域的要事，涉及技术、国内外动态等多个方面。"
ACL 2024 Oral｜我们离真正的多模态思维链推理还有多远？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929831&idx=4&sn=66c215821f6340a33ab44d810576e24b&chksm=84e43ed9b393b7cf7f806a64b21179d07d2d203df934f996617886ff308d12ba91a8e22eb68e#rd,2024-08-11 12:10:30,这篇论文介绍了一个新的多模态思维链推理基准（Multi-Domain Multi-step Multi-modal Chain-of-Thought，M3CoT），旨在解决现有基准在视觉模态推理、单步推理和领域覆盖方面的局限性。作者指出当前多模态思维链模型在复杂推理任务上的能力被高估，并通过实验展示了这些模型在新基准上的性能缺陷。研究发现，尽管一些大型视觉语言模型在传统基准上表现出色，但在M3CoT上仍有显著差距，表明对于多模态、多步推理任务的处理能力还需提升。论文还提供了对现有模型的分析和改进方向，强调了提升推理过程质量和多模态信息交互的重要性。
数百万晶体数据训练、解决晶体学相位问题，深度学习方法PhAI登Science,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929831&idx=5&sn=94995ecabd71c26d080b35b05e9e35a9&chksm=84e43ed9b393b7cf2d4ad6e2e56a4966242673eb45f3face5fe7f690b5183819cf0077986b47#rd,2024-08-11 12:10:30,丹麦哥本哈根大学的研究人员开发了一种名为PhAI的深度学习方法，用于解决晶体学中的相位问题。这一问题在于从实验得到的振幅中恢复相位信息。通过训练一个神经网络，使用数百万个人工晶体结构及其衍射数据，PhAI能生成准确的电子密度图。研究表明，该方法在仅2埃的分辨率下就能解决相位问题，而传统方法通常需要原子分辨率。这一深度学习解决方案为晶体结构测定提供了新途径，表明原子分辨率并非从头算方法的必要条件。相关研究发表在《Science》杂志上。
直播打游戏的马斯克、TED演讲谷歌小姐姐到底是不是真人？网友猜到怀疑人生,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929810&idx=1&sn=ccfa98a7445b05b90d9e7e5b0b775385&chksm=84e43eecb393b7fab421ff93b5ea4cd160dd20b5234b6fff4e2e30cd8929fe86cb509344c01e#rd,2024-08-10 12:58:03,AI技术正在推动一场“造假”革命，最近一个名为Deep Live Cam的直播换脸项目在Github上走红，只需一张图片就能实现实时直播换脸。该项目生成的换脸效果极其逼真，甚至可以模拟各种表情和角度，引发网友惊叹。然而，这也引发了对AI被滥用的担忧，比如可能用于制造假新闻或网络诈骗。开发者已意识到这一风险，承诺将采取预防措施，如内置检查机制和可能的水印添加。与此同时，AI生成的谷歌员工在TED演讲的视频也引起了关注，显示了AI技术在视频生成方面的进步。尽管这些技术带来了惊人的效果，但也暴露出真实与虚假之间的界限日益模糊，对识别真实信息的挑战增大。
新PyTorch API：几行代码实现不同注意力变体，兼具FlashAttention性能和PyTorch灵活性,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929810&idx=2&sn=c5f646b7968ad37e3b2f325cdb5bd03d&chksm=84e43eecb393b7faeaafa4503ba139dd8b407c3956cf982ec649e9253dc58ebb67b3ef497c4f#rd,2024-08-10 12:58:03,PyTorch团队引入了FlexAttention，这是一个灵活的API，允许用户用几行PyTorch代码实现多种注意力变体，解决了现有注意力机制灵活性和效率之间的矛盾。FlexAttention通过接受用户定义的函数score_mod来修改注意力分数，以适应不同的注意力机制，如全注意力、相对位置编码、软帽限制和因果掩码等。这种方法在保持高性能的同时，还利用了注意力掩码的稀疏性来优化内存使用。FlexAttention的性能接近手写的Triton内核，为研究人员提供了更大的灵活性和便利性。
混合专家更有主见了，能感知多模态分情况行事，Meta提出模态感知型专家混合,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929810&idx=3&sn=dd3fde119aac83d3af9fdcdc53c84d31&chksm=84e43eecb393b7fa2afae87f3545975a7f3ecd2fd3807872cd5aa0f37df998a1b8c92d85e26f#rd,2024-08-10 12:58:03,Meta FAIR 的研究人员提出了新的混合模态基础模型 Chameleon，它能处理不同模态的信息并生成包含多种模态的内容。Chameleon 使用单一 Transformer 架构，根据预测目标对图像和文本 token 进行建模。为了提高效率和性能，研究团队进一步发展了 Chameleon，提出了 MoMa：一种模态感知型专家混合架构，利用模态感知型稀疏性（MaS）方法，通过整合特定模态的模块优化框架。MoMa 通过早期融合、模态感知型混合专家和混合深度（MoD）技术，实现了在不同模态之间的高效推理和生成。实验表明，MoMa 模型在处理下游任务和混合模态长回答任务时表现出色，且在扩展性和效率上有所提升。
开闭源模型「大乱斗」：看看哪个智能体最能窥见人类真实意图,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929810&idx=4&sn=47b83422c6cddb35fe563c9e962c19f0&chksm=84e43eecb393b7fa797ff772de5c4ac3f3f003c9d0de50b0e3cdd9f7b813225c1c7d559b0df5#rd,2024-08-10 12:58:03,清华大学、人民大学和腾讯的联合团队提出了一种新的智能体交互设计方案，旨在通过Intention-in-Interaction（IN3）基准测试提升智能体理解人类隐式意图的能力。该工作使用Mistral-7B模型为基础，训练出的Mistral-Interact能主动评估任务模糊性，询问用户意图，并在执行任务前将其细化。研究结果显示，这种方法在识别模糊任务、恢复关键信息、设定精确执行目标和减少冗余工具使用方面表现出色。这一创新方法强调了智能体与人类自然、有洞察力的沟通，代表了向设计更符合人类意图的智能体迈出的重要一步。论文、代码和数据集已开源。
2.5天完成1年的MD计算？DeepMind团队基于欧几里得Transformer的新计算方法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929810&idx=5&sn=38a4f9c9e13895f274ae09da03a326e0&chksm=84e43eecb393b7fa2985e4d68d8eac736b1fb663684220b537b046964f76f9785b9a7ac151bb#rd,2024-08-10 12:58:03,Google DeepMind和柏林工业大学的研究人员开发了一种名为SO3krates的新型Transformer架构，用于机器学习力场（MLFF），以提高分子动力学（MD）模拟的准确性和稳定性。传统MLFF在长时间模拟中的可靠性受到质疑，而SO3krates通过结合稀疏等变表示和自注意力机制，避免了昂贵的张量积，实现了精确、稳定和快速的MD模拟。这种方法在保持准确性和稳定性的同时，比现有等变模型的速度快约30倍，使得能够进行更长时间和更大规模的模拟，对于探索复杂系统的量子特性具有重要意义。
两篇论文同时获最佳论文荣誉提名，SIGGRAPH上首个Real-Time Live的中国团队用生成式AI创建3D世界,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929607&idx=1&sn=184c8c7c8f795a4d114a52407ff7c156&chksm=84e43db9b393b4afeb78cf6c9f485145faa2a2460cd34cecee9bce5dda36712786c15749cddc#rd,2024-08-09 12:44:44,上海科技大学MARS实验室团队在SIGGRAPH 2024大会上获得了两篇最佳论文荣誉提名，他们的研究集中在3D生成和3D服装生成技术上。团队开发的新一代3D AI引擎Rodin能够通过单张图片生成3D模型，并支持用户控制和实时应用场景。其中，CLAY是采用3D原生方法的生成模型，直接从3D数据集训练，以更好地理解和保留几何特征。该模型通过定制的数据处理流程和大量3D数据集训练，实现了对几何的精确控制和高质量3D资产的生成，适用于CG生产管线。另一篇论文DressCode则关注3D服装生成。这些技术的应用有望降低3D创造的门槛，并对图像和视频生成的可控性产生积极影响。
MSU世界视频编码器大赛成绩出炉，腾讯包揽全部指标第一名,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929607&idx=2&sn=4d8c85e50447dd0a2e74891e5bd3a871&chksm=84e43db9b393b4af125c4726182f51c592b5db9ca7e84fbc332bac0633061896d30f6d874483#rd,2024-08-09 12:44:44,腾讯编码器在莫斯科国立大学举办的MSU世界视频编码器大赛中获得佳绩，包揽了所有15项指标的第一名。腾讯的Tencent TVC编码器在各类编码赛道中表现出色，Tencent266、Tencent V265和Tencent TXAV1编码器分别在H.266、H.265和AV1赛道取得全部第一。此外，TencentAVS3编码器在AVS3赛道表现出色，标志着腾讯在国家自主知识产权视频编解码技术的进展。腾讯在视频编码领域的领先技术将有助于其云媒体处理产品的性能提升和行业服务。
DeepMind机器人打乒乓球，正手、反手溜到飞起，全胜人类初学者,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929607&idx=3&sn=6c079749748c01041782e7d93b8a874b&chksm=84e43db9b393b4af96c4f2a2c14f194e26595bf37f0a7b1374a8a786b7bfb9293a655bfecd61#rd,2024-08-09 12:44:44,DeepMind开发的机器人智能体在乒乓球比赛中达到了人类业余选手的水平。这个机器人能够执行正手和反手击球，应对不同旋转的发球，并能在与人类选手的比赛中取得胜利，胜率约为45%。它特别擅长与初学者和中级选手对战，但在面对高级玩家时表现出局限性，主要在于反应速度和旋转处理能力。该研究使用了分层和模块化的策略架构，包括低级技能库和高级控制器，通过强化学习在模拟环境中训练，并实现了从模拟到现实的零样本转换。机器人与人类选手的对战被评价为有趣和吸引人。
Karpathy观点惹争议：RLHF不是真正的强化学习，谷歌、Meta下场反对,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929607&idx=4&sn=27e4cf042a574e7f9cc66a49db8b7291&chksm=84e43db9b393b4aff84046267363f3742ba7f488e2a268a8bcaac1499b0d488cf1b7475e3109#rd,2024-08-09 12:44:44,AI 大牛 Karpathy 认为基于人类反馈的强化学习（RLHF）只是勉强算得上强化学习（RL）。RLHF 是训练大语言模型的阶段之一，但与真正的 RL（如 AlphaGo 使用的）不同，RLHF 不会得到广泛认可。RLHF 的问题在于奖励模型可能被误导，并且模型很快会学会对抗性策略。尽管如此，RLHF 在构建 LLM 助手时仍然有用，因为它可以从生成器 - 判别器的差距中受益并缓解幻觉。对于 RLHF 是否能称为 RL，业界存在不同看法。一些人认为 RLHF 不进行适当搜索，而 RL 通常会添加熵项；另一些人则认为 RLHF 在减轻 LLM 偏见和幻觉方面具有价值。
奥特曼「草莓」模型跳票，OpenAI凌晨大新闻，把网友整懵了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929607&idx=5&sn=de7c9a36eabcf8533668f45d56c4ab37&chksm=84e43db9b393b4af8065fe6c7647915e75f54428be9e7c86731f0ba254e96c4a5efd849d66de#rd,2024-08-09 12:44:44,OpenAI发布了基于最新大模型GPT-4o的安全评估，该模型接受文本、音频、图像和视频的输入，并生成文本、音频和图像的输出。在发布前，OpenAI使用外部安全专家进行了安全测试，特别是针对音频功能，检查了如声音克隆、色情和暴力内容等风险。虽然总体风险评级较低，但在说服力方面存在“中等”风险，因为GPT-4o的某些文本可能比人类写的更具影响力。此外，GPT-4o在视觉和音频理解方面表现出色，速度更快且价格更便宜。OpenAI还任命Zico Kolter为公司董事会成员，他专注于AI安全性和深度学习的稳健性。尽管进行了安全评估，但一些评论家认为OpenAI需要更透明，公开更多关于模型和安全测试的细节。
入职一年半，这个AI员工晋升为了国内首位AI架构师,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929440&idx=1&sn=a9f3df5452e6e535e4384c5f8a3e18a9&chksm=84e43d5eb393b4488f70347303909fefa0a49cc3c1babfe45702488cf98eac02c4cc25c0b03a#rd,2024-08-08 16:34:36,AI 代码助手，如百度的“文心快码”，正在从单纯的编程辅助工具发展到具有更高级别的功能，包括架构设计。随着技术的进步，AI 已经能够支持多种编程语言和IDE平台，能够续写代码、生成代码、编写注释，甚至在某些情况下，可以生成单元测试代码。根据Stack Overflow的报告，许多开发者正在或计划在开发过程中使用AI工具。在百度内部，已经有30%的代码由文心快码生成，80%的工程师在深度使用这一工具。文心快码现在能够更高效地解决编程架构问题，生成单元测试，自动识别和修复错误，展现出类似架构师的能力。随着AI技术的进一步发展，AI代码助手将在软件开发流程中发挥更大作用，与人类工程师形成更深入的合作关系。
Llama3训练每3小时崩一次？豆包大模型、港大团队为脆皮万卡训练提效,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929440&idx=2&sn=1ef10d19c0d9ad19602163b486ec3314&chksm=84e43d5eb393b4484878bb0af994c9fd4aec4ffb5da3e87192ecfb7306a38692737122819258#rd,2024-08-08 16:34:36,字节跳动豆包大模型团队与香港大学合作推出ByteCheckpoint，这是一个针对大模型训练的高性能检查点（Checkpoint）系统，旨在提高训练效率和克服软硬件故障。ByteCheckpoint是PyTorch原生的，兼容多种训练框架，支持高效读写和自动重新切分。与现有方法相比，它在保存和加载Checkpoints时的性能分别提升了529.22倍和3.51倍，具有更优的易用性。该系统通过解决现有Checkpoint系统在设计、重新切分和框架兼容性方面的挑战，减少了训练的额外I/O开销，并提供了简单的用户接口。实验结果显示，ByteCheckpoint在不同模型规模和训练框架中都显示出显著的性能提升。
吴恩达亲自授课，LLM当「助教」，适合初学者的Python编程课程上线,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929440&idx=3&sn=74d47b4cb5240e69243914645e4f9cbd&chksm=84e43d5eb393b4481bcf5747132f46256e99ee692258bb6bcd6010ded445e82e46364263a240#rd,2024-08-08 16:34:36,人工智能学者吴恩达在社交平台宣布开设新课程“AI Python for Beginners”，专门针对Python编程初学者。吴恩达将亲自担任讲师，课程内容分为四个部分，涵盖Python基础知识、自动化任务、处理数据和文档以及扩展Python使用包和API。学生将学习编程基础、创建人工智能驱动的工具，并实践编写调用AI模型的代码。课程采用人工智能聊天机器人辅助教学，提供即时反馈和个性化指导。该课程是免费的，旨在帮助学生掌握Python编程和AI应用技能。
清华研究登Nature，首创全前向智能光计算训练架构，戴琼海、方璐领衔,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929440&idx=4&sn=9d37b60a3820a1b5218c0e34b988b230&chksm=84e43d5eb393b448d88025a9a8e62e5b6538b264ee771804d43bc295eb07faad5e3d11b46b0a#rd,2024-08-08 16:34:36,清华大学的研究团队在Nature上发表论文，突破了智能光计算训练的难题。他们开发了一种名为全前向模式（FFM）的学习方法，该方法利用光子传播的对称性，使得神经网络的训练可以直接在物理光学系统上进行，不再需要依赖数据建模。这一创新简化了光神经网络的训练过程，提高了效率，并且适用于多层光学神经网络，实现了与理想模型相当的准确率。FFM学习还支持散射介质中的全光学聚焦和其他光学处理任务，具有潜在的应用于深度学习、超灵敏感知和拓扑光学等领域。此外，该团队还推出了名为“太极-II”的光训练芯片，其能效比英伟达H100芯片高1000倍。
ICML 2024 | 人物交互图像，现在更懂你的提示词了，北大推出基于语义感知的人物交互图像生成框架,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929440&idx=5&sn=bdf1f98083b29df0d47d2b1ce7bf2a59&chksm=84e43d5eb393b4482d4462974ba30fef9326bd560e228a5d64433143912f83ca2efcb91e3a31#rd,2024-08-08 16:34:36,北京大学王选计算机研究所MIPL实验室的研究团队提出了一种名为SA-HOI的新框架，用于生成更合理、更真实的人物交互图像。该框架利用人体姿势生成和交互边界区域信息来指导去噪过程，解决了在生成以人物交互为主体的高保真图像时所面临的挑战。研究团队还创建了第一个全面的人物交互图像生成基准，并设计了专门的评估指标。实验表明，SA-HOI在人物交互图像生成和常规图像生成的评估指标上均优于现有的基于扩散的图像生成方法。论文、项目主页和源代码链接已提供。
泄露！Apple Intelligence提示词原来是这样，还告诉大模型：别幻觉,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929304&idx=1&sn=92c34fe209c5772a80b06d6b5be09f8e&chksm=84e43ce6b393b5f0bdb41bec97796b976a1ad28242dbc02d03bb7980c6b5fcaea0d87a63ccc6#rd,2024-08-07 12:17:45,本文介绍了苹果公司新功能Apple Intelligence的一些提示词曝光，这些提示词用于指导AI如何帮助用户处理邮件、生成邮件回复和照片故事等。提示词中包含了对回复内容的字数限制、避免幻觉和捏造信息的规则，以及生成故事的主题和内容要求。此外，还提到了一个名为“ajax”的模型，这可能是苹果内部代号为“Apple GPT”的测试项目。然而，一些网友对这些简单的提示词能否有效防止恶意攻击和错误信息表示担忧。Apple Intelligence的实际表现和安全性还有待观察。
李飞飞亲自撰文，数十名科学家签署联名信，反对加州AI限制法案,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929304&idx=2&sn=b443b9da3c0a4037551d9079d0670492&chksm=84e43ce6b393b5f0d46d612dd2ce1d0f09e875c767f2be130e8d7a459903f058ae93853118c2#rd,2024-08-07 12:17:45,加州的一项名为SB-1047的法案提议对高风险AI模型建立安全标准，引发了科学家和监管部门之间的争论。该法案针对使用超过10^26次运算且训练成本超1亿美元的模型，以及使用特定计算能力微调的模型进行监管，要求开发者对其模型的潜在危险负责，并在训练前证明模型不会启用危险功能。批评者认为这将对科技创新、开源社区和学术研究造成负面影响，阻碍模型的开源发展，同时无法解决实际问题。李飞飞等AI科学家撰文反对该法案，称其可能扼杀创新并损害人工智能生态系统。目前，科学家们正在签署联名信抵制该法案，认为应制定更合理和具有前瞻性的监管政策。
八问八答搞懂Transformer内部运作原理,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929304&idx=3&sn=c67b38ec4c8973f9df3447a254a7f5ef&chksm=84e43ce6b393b5f0d8e88e9933ad6ad7a647ada1ee5e95cfdd8d63285658f7e98ab21ad83588#rd,2024-08-07 12:17:45,"这篇论文的摘要可以是：

Sakana AI，由transformer架构论文作者Llion Jones创立的公司，发表了一篇名为《Transformer Layers as Painters》的论文，探索了预训练transformer模型中的信息流。研究通过类比transformer层为画家作画的流水线，对仅解码器和仅编码器的transformer模型进行了一系列实验，没有进行任何微调。实验结果表明，transformer的中间层共享一个表征空间，但并非所有层都是必要的，且各层执行不同的功能。层的顺序对模型性能有一定影响，尤其是对于推理任务。此外，研究发现并行运行层在某些情况下是可行的，但数学和推理任务更依赖于层的顺序。循环并行化层可以提高模型性能，且重复单一层对模型性能影响最大，而随机层顺序和循环并行的影响最小。这些发现提供了对transformer内部工作机制的深入理解。"
李飞飞「空间智能」之后，上交、智源、北大等提出空间大模型SpatialBot,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929304&idx=4&sn=906cb76e1014596f6aede719086eba5d&chksm=84e43ce6b393b5f05c11dcd7bbd0fc5b0ab428af6e0c2ab8bbd7b212f281be3731895e2529e3#rd,2024-08-07 12:17:45,这篇文章介绍了斯坦福大学研究生蔡闻骁等人提出的空间大模型 SpatialBot，该模型旨在让多模态大模型理解深度和空间。研究者通过 SpatialQA 数据集和 SpatialBench 榜单引导模型理解和使用深度信息，以实现更精确的空间概念理解。SpatialBot 可以在 RGBD 输入的基础上，通过 DepthAPI 获取准确的深度信息，从而在通用场景和具身场景中表现出色，特别是在物体位置、大小、接触判断以及机器人抓取任务上。这一工作对于推动具身智能和空间智能的研究具有重要意义。
准确率达60.8%，浙大基于Transformer的化学逆合成预测模型，登Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929304&idx=5&sn=13c79f70d75a4c654688dc245af2a8c1&chksm=84e43ce6b393b5f0ed3d05527cb86959162dd5fa9d5ee351e2a3fcbbaee2fe1f5a1594387f86#rd,2024-08-07 12:17:45,浙江大学侯廷军团队提出将单步逆合成预测重新定义为分子串编辑任务，并推出了基于编辑的逆合成模型 EditRetro。该模型能够实现高质量和多样化的预测，在标准基准数据集 USPTO-50K 上取得了60.8%的top-1准确率，表现出良好的泛化能力和稳健性，显示了其在AI驱动的化学合成规划领域的潜力。相关研究已发布在《Nature Communications》上。EditRetro通过迭代编辑过程生成反应物字符串，包含序列重新定位、占位符插入和标记插入三种编辑操作，由Transformer模型实现。与现有方法相比，EditRetro在预测准确度和多样性上表现出优越性能，并在多步合成规划中展示了实用性。
阿里国际推出首个专业版AI Search，为什么它会是下一个B2B谷歌？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929210&idx=1&sn=3c5f51807e8cf2cf1179cb42df6bee7d&chksm=84e43c44b393b552ec89fbff4d56413199af58533ca5ae3f4a91fb15968a1006af83b9bbcd76#rd,2024-08-06 18:46:29,阿里国际推出全球首个AI驱动的B2B采购搜索引擎，旨在改变全球采购流程，提供更直观和高效的服务。这款AI搜索引擎能理解采购者的自然语言，转化为专业的采购请求，预测需求并提供精准匹配。通过学习10亿商品和产业知识，AI能理解商品信息和企业需求，实现主动精准匹配，降低了专业领域信息搜索的难度。该搜索引擎将提供完整的采购服务，帮助用户完成贸易流程。这一创新被认为是全球贸易领域的“下一个Google”，有望重塑B2B搜索体验。
AI画家的「滑铁卢」：为什么冰可乐不愿意住进茶杯里？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929210&idx=2&sn=8a7fcf66aa4fd66e070138463f7d62a3&chksm=84e43c44b393b55243b882b4a81f6bf2d8a43877bd4fd2b196767ec745cbf160db8cfc589940#rd,2024-08-06 18:46:29,上海交通大学王德泉老师课题组的研究发现，即使是最先进的AI画家，如Dall・E 3，也无法准确地根据文本提示“画出茶杯中的冰可乐”，往往将冰可乐画在透明玻璃杯中，这在学术界被称为文本图像不对齐问题。研究团队深入探索了这一问题的新分支，称为包含隐藏变量的不对齐问题（LC-Mis）。他们设计了一个基于大语言模型的系统来快速收集类似问题的概念对，并提出了一种名为Mixture of Concept Experts (MoCE)的方法，通过模拟人类绘画顺序，成功解决了茶杯消失的问题。实验表明，MoCE在解决LC-Mis问题上表现优越，但现有的自动化评价指标对此类问题存在缺陷。未来，研究团队将继续研究生成式AI技术，以提高AI理解和再现人类创造力的能力。
智谱版Sora开源爆火：狂揽4K Star，4090单卡运行，A6000可微调,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929210&idx=3&sn=47914f46b175f168bcbdec4be3e38a07&chksm=84e43c44b393b552bd137d4389cbe3553f655259c764aba0b53de829eb1b417f1ea5d78b4925#rd,2024-08-06 18:46:29,智谱AI开源了其视频生成模型CogVideoX，该模型在FP-16精度下仅需18GB显存即可推理，40GB显存即可进行微调。这一开源对于研究者具有重大意义，因为目前商业级的视频生成模型大多闭源。模型采用了3D变分自编码器进行视频压缩，并使用专家Transformer处理文本和视频嵌入。智谱AI还开发了数据筛选和处理技术来确保高质量的视频生成。模型在VBench等多个指标上进行了评估，并展示了生成视频的示例。此外，智谱AI的视频生成产品“清影”已在清言App上线，用户可以体验其视频生成能力。
ACL 2024 Oral | 大模型也会被忽悠？揭秘AI的信念之旅,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929210&idx=4&sn=c63822572f66664b0fac93c3275559c3&chksm=84e43c44b393b552bc7aee3a75edbaf9ab03149bde93a6e6f75e0d5822b1d5ba4099b64e74b8#rd,2024-08-06 18:46:29,研究人员发现，大语言模型（LLMs）在反复接触到误导性信息时，可能会被“说服”相信错误的观点，例如“地球是平的”。这篇论文由清华大学、上海交通大学、斯坦福大学和南洋理工大学的研究人员合作完成，探讨了大模型在虚假信息干扰下的表现。他们构建了一个名为Farm的数据集，用于测试模型在多轮对话中面对误导信息时的反应。实验表明，即使是最先进的模型如GPT-4，也有20.7%的可能性被误导。研究提出了大模型的五种不同反应类型，并建议通过添加安全系统提示来增强模型抵御虚假信息的能力。该研究强调了提高大模型对虚假信息识别和抵抗力的重要性。
错误率从10%降至0.01%，领英全面分享LLM应用落地经验,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650929210&idx=5&sn=deb470d914142878a061f0a3896fcd72&chksm=84e43c44b393b552e996ac98c7d230b9054532f72a7f70671e42631ddf67f037898f79e6c4bf#rd,2024-08-06 18:46:29,这篇文章分享了LinkedIn团队在构建生成式AI产品时的经验。他们利用大型语言模型（LLM）技术，开发了一个系统，以帮助用户更快地获取信息、连接信息点和提供建议。该系统通过选择合适的AI智能体来处理用户查询，结合内部API和Bing进行信息检索，然后生成连贯的回复。开发过程中，他们面临了如何保持用户体验一致性、评估响应质量、调用内部API的挑战，并通过固定三步pipeline、共享提示模板和构建AI技能来解决这些问题。此外，他们还关注了容量、延迟和成本优化。
太原理工2024软件工程招60个班，近2000人，冲上热搜,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928976&idx=1&sn=d7898d8b44d4aba7f820cb78f3aa9275&chksm=84e4332eb393ba382901d7747177aa326ebb09c2cfb15b69bd28e60d75b4e2b62f246b4ebda9#rd,2024-08-05 12:24:58,太原理工大学2024年软件工程专业计划招生近2000人，引发广泛关注和讨论。这一招生规模让网友们质疑是否有足够的师资力量和教学质量保证。学院目前的师生比为1:78，而每年的学费为1.6万元，是其他专业的三倍。讨论中，人们担忧计算机行业就业市场的饱和，以及高学费与教学质量是否成正比。此外，一些网友指出，高校扩招可能带来的生源质量和就业难题。太原理工大学是山西省唯一的211院校和双一流大学，其招生政策受到了本地考生和家长的关注。其他学校也有类似扩招现象，但教学质量和社会需求的匹配问题仍然存在。
LLM可解释性的未来希望？稀疏自编码器是如何工作的，这里有一份直观说明,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928976&idx=2&sn=03dafb982bd43f9640010bb96743a3a4&chksm=84e4332eb393ba38ce63ea7eb72dff342ff41c457836f14295b97cb5fb69a1fd388a918b4904#rd,2024-08-05 12:24:58,稀疏自编码器（SAE）在解释机器学习模型方面变得越来越重要，尤其对于理解和分解神经网络的计算过程。SAE受到神经科学中稀疏编码的启发，通过添加稀疏度惩罚来创建可理解的中间表示。在标准自编码器的基础上，SAE的中间向量被限制为稀疏的，允许研究人员分析神经网络中的中间激活并识别可能对应于特定概念的特征。通过训练SAE，可以找到模型中不同层和位置的可解释性特征，并通过因果干预来评估这些特征。虽然评估SAE的可解释性仍然是一个挑战，但它们已经显示了在发现模型内部回路、减少偏见和探索有意义的表示方面的潜力。
一文看尽LLM对齐技术：RLHF、RLAIF、PPO、DPO……,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928976&idx=3&sn=7e3e07da6d19164a6e0bff986eeaae47&chksm=84e4332eb393ba3890d8f0ef64c14e729ec90a16036c57f2e936adabc9cbe9f7d48319a7d151#rd,2024-08-05 12:24:58, Salesforce发布了一份37页的综述报告，总结了现有的对齐大型语言模型（LLM）与人类偏好的各种技术。报告涵盖奖励模型、反馈、强化学习（RL）和优化四大主题，详细分析了相关研究文献。其中，基于人类反馈的强化学习（RLHF）是一种重要的对齐方法，用于确保LLM的输出与人类价值观一致。OpenAI的InstructGPT和Anthropic的RLHF是该领域的代表作。此外，报告还探讨了RLAIF（基于人工智能反馈的强化学习）、直接人类偏好优化等方法，并列出了相关研究论文和评估指标，为未来对齐技术的研究指明了方向。
70倍极致压缩！大模型的检查点再多也不怕,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928976&idx=4&sn=618c75d26f641ca1ff233d308ddd4d3f&chksm=84e4332eb393ba38506d530df782158a5d0ceef79562ae070d2a1ed6c52fb483f07382188a38#rd,2024-08-05 12:24:58,很抱歉，您还未提供具体的文章。请您提供需要摘要的文章内容，我将尽力为您生成摘要。
延迟交互模型，为什么是下一代RAG的标配？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928976&idx=5&sn=7c73d6fd74d0da1c79fe6821af226f25&chksm=84e4332eb393ba38554dfa737d353e9c058e84d6942c4605808666f6c1b4e0c8e15191ba5937#rd,2024-08-05 12:24:58,"这篇文章主要讨论了在自然语言生成（RAG）场景中，不同排序模型的优缺点，特别是关注了延迟交互模型（以ColBERT为代表）在搜索和重排序中的应用。它指出，传统的双编码器模型速度快但语义损失大，交叉编码器模型语义精确但计算慢，而ColBERT结合了两者优点，通过延迟交互计算提供精确排序同时保持相对高效的性能。

作者提到，ColBERT使用双编码器但输出多向量，允许离线处理文档编码，从而提高了查询处理速度。其延迟交互模型以最大相似性函数进行相似度计算，但计算开销仍较大。为了解决这个问题，ColBERT v2通过模型蒸馏和量化技术进行了优化。

 Infinity数据库提供了对ColBERT模型的支持，通过Tensor数据类型和优化技术（如二进制量化和Tensor Index）来提高ColBERT的性能和效率。文章还进行了评测，证明ColBERT作为Reranker在保持高性能的同时显著提高了排序质量。

此外，文章还提到了延迟交互模型在多模态场景中的应用，如ColPali，它在复杂格式文档的处理中展示了优秀的性能。总的来说，延迟交互模型在RAG场景中的应用前景被看好，可以扩展到更多复杂的任务中。"
00后CEO杨丰瑜：耶鲁博士回国创业，五个月造出首款「可量产」人形机器人｜AI Pioneer,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928905&idx=1&sn=fe758e33cd4418221b0f5e65fee201cb&chksm=84e43377b393ba611f4db7b6f9d00e5591ac5484748e1ff47b5a642d29c5d24c785bfd7961a7#rd,2024-08-04 12:11:33,这篇文章主要介绍了23岁的耶鲁大学博士生杨丰瑜创办的人工智能公司UniX AI，该公司专注于具身智能机器人，并在短时间内研发出了一款轮式人形机器人，具备“餐后清洁”和“洗衣服”等功能，即将开始量产和销售。杨丰瑜本人拥有丰富的学术背景，在计算机和机器人领域有多篇论文发表。他强调了触觉在机器人技术中的重要性，认为UniX AI的快速进展得益于技术进步、市场需求、供应链优势以及团队的专业技能。公司旨在打造通用的人形机器人，服务于家庭和商业场景，愿景是实现“Robots For All”。
可解释性终极追问，什么才是第一性解释？20篇CCF-A+ICLR论文给你答案,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928905&idx=2&sn=9d8108a722346a6f47456a22adaa774c&chksm=84e43377b393ba61f4977f4806a58dba72fc7900a0bc339164dc1231e756d8f6be99cd020517#rd,2024-08-04 12:11:33,本文回顾了“等效交互可解释性理论体系”的相关研究，并基于此理论严格推导了神经网络在训练过程中概念表征及其泛化性的动力学变化。该理论证明了满足特定条件的神经网络决策逻辑可以被符号化逻辑解释，并且交互的复杂度与神经网络的对抗鲁棒性、泛化性和表征能力有直接关系。研究发现神经网络训练过程存在两阶段现象：第一阶段消除高阶和中阶交互，学习低阶交互；第二阶段建模更高阶的交互，这与模型泛化性的变化相对应。这些发现有助于深入理解神经网络的内在工作原理和泛化能力。
Machine Unlearning 会是未来 LLM 的必需品吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928905&idx=3&sn=fd294b67af93afae797894a4a1300a27&chksm=84e43377b393ba61858b6507aee4bcc50887893e83126885b5d953b99b5734ffdc030e95b590#rd,2024-08-04 12:11:33,这篇文章讨论了Machine Unlearning在大型语言模型（LLM）中的重要性和挑战。随着AI和LLM的发展，政府对数据安全和隐私保护的法规越来越严格，Machine Unlearning成为关注焦点，因为它可以应对用户行使“被遗忘权”时的数据处理问题。然而，LLM的Unlearning面临计算成本高、内存限制、不期望知识无法完全删除、泛化能力不足以及评估困难等挑战。研究者对不同类型的Unlearning方法进行了分类和比较，并指出需要更多研究来解决现有方法的局限性。此外，AI搜索领域的发展和ICML 2024的技术趋势也是本期通讯的内容，但未在摘要中详细展开。
阿里「轨迹可控版Sora」，告别「抽卡」，让视频生成更符合物理规律,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928905&idx=4&sn=5950514ee4dbaa29e97626348b5e6ea8&chksm=84e43377b393ba618183a0363cd4769224c36b00e9c21aa8dcb4c356d44b9dcf00c0a0bde882#rd,2024-08-04 12:11:33,阿里研究者提出了Tora，这是一个基于Diffusion Transformer（DiT）架构的视频生成模型，能够生成遵循规定轨迹的高质量视频。Tora结合了文本、视觉和轨迹条件，允许精确控制视频内容的持续时间、宽高比和分辨率。与现有视频扩散模型相比，Tora在运动保真度和物理运动模拟方面表现出色，能生成更流畅、更符合轨迹的视频，且物体不会出现变形。这一成果扩展了Transformer在生成可控动作视频中的应用。
小技巧大功效，「仅阅读两次提示」让循环语言模型超越Transformer++,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928905&idx=5&sn=21db3796ecf0ee0a1aea5ec164fc9121&chksm=84e43377b393ba6176581c9df34eeb138caeada370e9ae646a4825f213da7115445270eebca4#rd,2024-08-04 12:11:33,这篇文章介绍了近期在语言模型架构上的一个新趋势，即循环大语言模型开始挑战Transformer的主导地位。研究者发现，数据排序对循环语言模型在有限内存中学习和使用信息的能力有很大影响。他们通过理论分析和实验表明，正确的数据排序可以减少内存需求，并提出了两种方法来缓解对数据排序的依赖：Just-read-twice（JRT）提示策略和JRT循环架构。JRT-Prompt策略通过在上下文中重复信息，帮助模型更有效地存储所需信息，而JRT-RNN是一种新的编码器-解码器循环架构，它在质量和效率上都有所提升。实验结果显示，这些方法在多个任务和模型上都取得了性能的显著提升，并且在计算和内存效率上优于Transformer模型。
Transformer作者回流谷歌，Character.AI创始团队被「收购」，只要人不要公司,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928867&idx=1&sn=d7c87da8d52a8b8764e75511f18fdffd&chksm=84e4329db393bb8b4c1152086bfdce9d1e742123ef48958af4c0773affd99d1d2d6c80ec8522#rd,2024-08-03 12:30:59,初创公司Character.AI的创始人Noam Shazeer和Daniel De Freitas已将公司的大型语言模型（LLM）技术非独家许可给谷歌，并与约30人的研究团队一起重返Google DeepMind。Shazeer和De Freitas曾因对谷歌的官僚主义失望而离开，但在两年后又回归。Character.AI的其余员工约140人将留在公司，继续开发个性化AI产品。谷歌将根据一项协议以25亿美元的估值向Character.AI的投资者支付股权价值，并为员工提供现金偿付。该公司此前已从投资者处筹集了1.93亿美元，估值为10亿美元。这反映了科技巨头对AI初创公司的收购和人才招聘趋势。
ICML 2024演讲爆火！Meta朱泽园揭秘大模型内心世界：不同于人类的2级推理,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928867&idx=2&sn=10937ee0b77d31ed64b43be0253c6e87&chksm=84e4329db393bb8bd68785d743b536aa452458ad3a3993453d76d42da80c4ed8199433f517f2#rd,2024-08-03 12:30:59,这篇论文研究了大语言模型（LLM）如何解决数学问题，以及它们的推理能力。作者通过创建一个名为iGSM的合成数学题集，对模型的推理过程进行了控制实验。实验表明，即使在只训练解决低难度题目后，模型也能学会推理技能，解决更高复杂度的数学问题。研究还发现，模型能够进行类似于人类的“1级推理”，即最短解答的计算方法，并且在问题提出前就已经完成了拓扑排序。此外，模型还展现出“2级推理”能力，即梳理所有变量关系，即使这些信息对解题不必要。论文指出，模型在解决iGSM题目时的错误主要归因于心算错误，而模型的深度在解决这类问题时比宽度更重要。当前最强的模型GPT-4在iGSM上的推理能力也有限，提示预训练数据集仍有改进空间。
英特尔股价暴跌 26%，40 年来最大跌幅,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928867&idx=3&sn=54647032fcdf34c1b2c5892e53981434&chksm=84e4329db393bb8be2a567c15a3b1ec9417e7e8003de078d8f036a50b8bd17f959c0531b8fc1#rd,2024-08-03 12:30:59,英特尔股价经历了40年来最糟糕的交易日之一，暴跌超过26%，市值蒸发超过323亿美元。这一下滑发生在公司公布低于预期的第二季度财报后，英特尔宣布暂停派息并计划进行大规模重组，包括削减约1.5万个工作岗位。公司营收为128亿美元，同比下降1%，净利润转为亏损16亿美元。英特尔CEO帕特·基辛格表示，公司将采取重大成本削减措施，目标在2025年前节省100亿美元。该公司正面临来自AMD和台积电的竞争压力，同时在人工智能和数据中心业务上寻求增长。此外，高通在PC芯片市场的进入也对英特尔构成威胁。
从现在起，GitHub上超1亿开发者可直接访问全球顶级大模型，构建AI应用,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928867&idx=4&sn=bea308fc574894cd877de9cc144c630d&chksm=84e4329db393bb8b9e9058979d46738a57218dfde12388c11392c61f2ab7af325312f40ac93e#rd,2024-08-03 12:30:59,GitHub 推出新功能“GitHub Models”，允许用户在一个交互式沙盒中试用包括微软、OpenAI、Meta 和 Cohere 等公司的流行大模型。此功能提供了一条将模型直接部署到 Codespaces 和 VS Code 开发环境的快速通道，降低了 AI 模型的部署门槛。GitHub Models 还支持与 Azure AI 的无缝集成，简化了从开发到生产环境的流程。个人用户使用 GitHub Models 有限制，每天最多 150 次请求。GitHub CEO 表示，该功能旨在推动 AI 工程师的崛起，并希望将更多合作伙伴引入其平台。这一举措可能会对类似平台 Hugging Face 构成竞争。
首届大模型顶会COLM 高分论文：偏好搜索算法PairS，让大模型进行文本评估更高效,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928867&idx=5&sn=284b16557c0aef3fa35f09ffbbdd1830&chksm=84e4329db393bb8ba34815a9bc1ead0c4f51fa252b2dcdd0b5e1579bc991ff9688d98ccafc9e#rd,2024-08-03 12:30:59,这篇论文来自剑桥大学语言技术实验室的研究人员，分析了大型语言模型（LLMs）在作为文本评估器时存在的分数偏见问题，并提出了PairS算法来解决这一问题。尽管LLMs在指令执行和任务泛化方面表现出色，但它们的评估结果易受提示设计和各种偏见影响，导致与人类判断不一致。现有的校准技术未能充分解决这一问题。受RLHF（强化学习通过人类反馈）的启发，研究者提出将评估问题转化为偏好排序问题，PairS算法能够从成对偏好中高效准确地进行排序，提高与人类判断的一致性。实验结果显示，PairS在多个任务上展现出与人类评分更高的一致性，并能以较低的比较次数达到与基线方法相当的排序质量。
全员离开老东家，Stable Diffusion一作带团创业，出手即击败MJ v6、SD3，还开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928796&idx=1&sn=f1e04e0d0308a888831d93ca6ec57417&chksm=84e432e2b393bbf4c7ebf5f6962899504f2c167a59bcfe8b6c7d62619f41b228a97fffb67639#rd,2024-08-02 12:35:21,AI领域的研究科学家Robin Rombach离职Stability AI后创立了Black Forest Labs，旨在开发最先进的图像和视频生成式深度学习模型，并使这些技术大众化。该团队由包括Stable Diffusion模型的其他三位作者在内的杰出AI研究者和工程师组成。Black Forest Labs已获得3100万美元的种子轮融资，由Andreessen Horowitz领投。公司推出了名为FLUX.1的系列模型，包括FLUX.1 [pro]、[dev]和[schnell]，它们在图像生成性能上超越了多个现有模型。此外，Black Forest Labs计划推出最先进的文本到视频生成模型。
谷歌终于赢了OpenAI一回：实验版本Gemini 1.5 Pro超越GPT-4o,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928796&idx=2&sn=3bcf2df8586651b99b9effcf35fe8302&chksm=84e432e2b393bbf404608fcb4781a78bd95099eab712d05de336eba2b92f54075f011ddfa717#rd,2024-08-02 12:35:21,谷歌发布了Gemini 1.5 Pro实验版本(0801)，这是一个强大的语言模型，用户可以通过Google AI Studio和Gemini API进行测试和反馈。该模型在LMSYS Chatbot Arena排行榜上获得第一，拥有1300的ELO分数，超越了GPT-4o和Claude-3.5 Sonnet等竞争模型。Gemini 1.5 Pro (0801)在多语言任务、数学和编码等领域表现出色，但在编码和某些特定任务上仍有一些竞争对手领先。虽然该模型在图像信息提取和代码生成方面展示出强大力量，但也有一定的错误和局限性。目前，Gemini 1.5 Pro (0801)仍处于实验阶段，可能在广泛使用前进行进一步改进。
ACL 2024，机器之心邀您一起吃顿饭,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928796&idx=3&sn=7048251fd697e82d7fb7233dbccbf9d3&chksm=84e432e2b393bbf4c4db94912810b93b448bf1af1e6524a7477e7818d33e85351ede7c9c03a5#rd,2024-08-02 12:35:21,这篇文章提到了AI领域的最新动态，特别是大模型的热潮，OpenAI和谷歌等公司在引领人机交互的变革，而国内企业也在积极研发自研大模型。文章聚焦于2024年的ACL大会，这是一个重要的自然语言处理领域的学术会议，今年在泰国曼谷举行，预计将有大量顶尖学者参与。机器之心计划举办一场名为“机器之心・ACL 2024 AI Talent 晚宴”的活动，旨在促进华人青年才俊之间的交流，并欢迎企业赞助。活动将在8月11日于曼谷的Centara Grand Convention Center附近举行，报名审核通过的参与者将收到邀请。报名截止时间为8月9日。
苹果让大模型学会偷懒：更快吐出第一个token，准确度还保住了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928796&idx=4&sn=5d50fd86ed5f09846ec50ef5212f19d0&chksm=84e432e2b393bbf4571eba9baf1fe3a5923424488f1d912b903806ef01b6402043bc8b0254cf#rd,2024-08-02 12:35:21,苹果和Meta AI的研究团队提出了一种名为LazyLLM的新方法，旨在提高大型语言模型的推理速度，同时保持准确性。在确保模型准确度不明显下降的情况下，LazyLLM可以将Llama 2预填充阶段的推理速度提高到超过两倍。该方法基于观察到在生成首个token时，输入prompt中的许多token并不重要。LazyLLM通过动态剪枝技术减少计算量，从预填充阶段就开始优化，而不是仅仅关注解码阶段的效率。实验结果显示，LazyLLM在TTFT加速方面优于标准LLM，且对总体生成速度有积极影响。
OpenDevin出技术报告了，大模型Agent开发者必读,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928796&idx=5&sn=9a636c1c0b34f5918c520528dde583b3&chksm=84e432e2b393bbf4bf520fd0b72ee087f3f173a6b5cc6c902e1ad1541fbfb22fca538bf294a3#rd,2024-08-02 12:35:21,OpenDevin是一个开源平台，用于开发能够通过软件与世界互动的通用智能体。该平台的特点包括大模型Agent、交互机制、沙盒操作系统、Web浏览器环境、可创建和执行代码的接口以及多Agent支持。OpenDevin的GitHub已经获得了超过2.9万的Star量。最近，OpenDevin团队发布了一项技术报告，详细介绍了这个社区驱动的平台，它不仅包括概念框架，还提供了立即可用的Agent、环境和评估实现。报告中展示了如何定义和实现智能体，以及它们如何与环境交互、管理和扩展技能。OpenDevin的智能体可以处理各种任务，包括软件开发、数据分析和Web浏览。评估表明，尽管OpenDevin智能体在所有类别中可能不是最佳，但其设计考虑了通用性，并在多个基准测试中表现出色。
谷歌开源最强端侧小模型：2B参数越级跑赢GPT-3.5-Turbo，苹果15Pro运行飞快,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928631&idx=1&sn=e57e92688b1185d091e6767cead78e1d&chksm=84e43189b393b89f2cd24ccec7a0c76ba147d94036f56ce35d042e486dfc7f3bffbad8e3c653#rd,2024-08-01 12:10:04,谷歌开源了Gemma 2模型系列的2B版本，这一轻量级模型在LMSYS Chatbot Arena中表现出色，以20亿参数超越了更大的GPT-3.5和Mixtral模型。Gemma 2 2B在性能与效率间取得了平衡，且具有内置的安全改进功能。此外，谷歌还构建了安全内容分类器ShieldGemma，用于过滤AI模型的输入和输出，以及模型可解释性工具Gemma Scope，提供对模型内部机制的洞察。Gemma 2 2B的成功挑战了模型越大性能越好的观念，表明通过高效训练技术和高质量数据集，较小的模型也能实现高性能。ShieldGemma提供了针对有害内容的检测和缓解功能，而Gemma Scope通过稀疏自编码器增强了模型的透明度。
AI助攻人类画家拿下艺术大赛第一名，背后有啥独家秘籍？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928631&idx=2&sn=26912e54ed661268feeacd8651a29c11&chksm=84e43189b393b89f249a62c273d969e868299b7c4167866cdfb31aec9de99a16d093ffd0da0f#rd,2024-08-01 12:10:04,"这篇文章摘要如下：

《AIGC 体验派》第六期节目探讨了高美感文生图背后的技术链路，重点关注如何实现更强的图文匹配、生成更具美感的图像以及高效部署文生图模型。AI 绘画近年来发展迅速，AI 作品开始被市场认可，各大厂商如字节跳动、阿里、腾讯等纷纷推出相关产品。节目中，豆包文生图技术专家李亮和 NVIDIA 解决方案架构师赵一嘉将深入剖析文生图技术，分享如何提升用户体验。直播时间为8月6日19:00-19:40。上一期节目则讨论了AIGC在营销领域的应用及其安全问题。"
arXiv论文可以发「弹幕」了，斯坦福alphaXiv讨论平台上线，LeCun点赞,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928631&idx=3&sn=789d5a558019ef065ea7bbf90872ec1b&chksm=84e43189b393b89fe17d2b33fa5d78b2176eec7dcf7c74e5418e88eff8e4cdf2ee45fdb3b98e#rd,2024-08-01 12:10:04,斯坦福大学学生创建了一个名为alphaXiv的开放讨论论坛，允许用户直接在arXiv论文上发布问题和评论。通过将arXiv替换为alphaXiv，用户可以精准定位到论文的段落和句子进行讨论。这个平台促进了作者与读者之间的交流，论文作者可以回应评论，用户可以点赞或反对。图灵奖得主Yann LeCun对此表示赞赏，一些论文作者也积极在alphaXiv上参与讨论。该平台被形容为使研究变得易于协作，有助于学术交流的推进。
还没排上SearchGPT？比Perplexity更好用的国产开源平替了解一下？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928631&idx=4&sn=86f27051de6a2f6ac708130a4ed1ad16&chksm=84e43189b393b89fc8273ac7d5a9dcf564643ba56cf6db181c868833a013a88e50404a1bf192#rd,2024-08-01 12:10:04,这篇文章介绍了上海人工智能实验室推出的一款名为MindSearch的AI搜索引擎，该系统采用多智能体框架，模仿人类的思维过程来处理问题。MindSearch能够通过智能体分工合作，理解用户需求并整合互联网信息，提供深度、广度和准确度较高的答案。与OpenAI的SearchGPT和Perplexity.ai相比，MindSearch在某些方面表现出优越性。MindSearch的核心是WebPlanner和WebSearcher两个智能体，前者通过图结构进行规划，后者进行分层检索网页。此外，MindSearch还解决了多智能体之间的上下文管理和信息共享问题。目前，MindSearch的源代码已经开源，用户可以在本地部署模型。
CMU&清华新作：让LLM自己合成数据来学习，特定任务性能同样大幅提升,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928631&idx=5&sn=6ca1055d8996e520ff1c6e206db7820a&chksm=84e43189b393b89f818ed02f4461d777a6f342ec55e442c3ba713ccf0fe5ec632e4a09c96e15#rd,2024-08-01 12:10:04,清华大学和卡内基梅隆大学的研究团队提出了一种名为SELF-GUIDE的方法，该方法利用大规模语言模型自身生成任务特定的数据集，以提升模型在特定自然语言处理任务上的性能，而无需大量人工标注数据或强大的Teacher Model。在大约3个样例的输入下，SELF-GUIDE通过多阶段的生成和过滤机制，使模型在特定任务上的表现得到显著改善。这种方法包括输入数据生成、输出数据生成和质量优化三个阶段，并在14个分类任务和8个生成任务上进行了有效验证，显示出对指令跟随和上下文学习方法的改进。
别只盯着ChatGPT版「Her」，在多模态AI拟人互动上，国内玩家也支棱起来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928422&idx=1&sn=5d2901769630b6eff55e4fc3bf7feed6&chksm=84e43158b393b84e52eb77c2ac6d1ffec425879724e86a48cd84188807e708cea5e68b4f527f#rd,2024-07-31 15:16:13,这篇文章的摘要可以是：在第二届多模态情感识别挑战赛（MER24）中，AI技术在识别人类情感方面接受了考验，该赛事探讨了如何利用多模态数据进行情感识别。Soul App的语音技术团队在难度最高的Semi赛道中获得第一名，他们的技术方案涉及多模态数据理解、情感识别算法和模型优化，包括使用预训练模型提取情感表征、创新的EmoVCLIP模型和文本模态的情感伪标签技术，以及半监督学习策略。此次比赛强调了在情感识别领域利用少量有标签和大量无标签数据的重要性，旨在推动相关技术的进步。Soul App在社交领域的发展展示了情感化AI在人机交互中的应用，通过自研大模型和多模态情感识别能力，为用户提供更丰富的互动体验。
「光合」作用算力质变，AI乘风走深向实,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928422&idx=2&sn=8c1d11eb92c59d9cc54de01e79ba1444&chksm=84e43158b393b84ea9936a7d688302ed696c61e7bdb0e5767bf389921f8a83787fcc0fde2229#rd,2024-07-31 15:16:13,这篇文章主要介绍了中国在人工智能（AI）领域的发展和算力的关键作用。随着AI技术的迅速进步，中国迎来“智变”时刻，各种AI模型如GPT等竞相亮相，AI正在深刻影响各行各业。算力被视为推动AI发展的关键资源，政府工作报告也将“人工智能+”列为重要任务。为解决算力需求和供给问题，光合组织应运而生，致力于打造国产计算技术供应链和产业链，促进产学研合作，推动算力的普惠化。光合组织通过与产业链上下游企业合作，助力算力中心建设和AI技术的应用，如在郑州推动建设“算力之城”。此外，光合组织还强调国产算力基础的建设，促进芯片、操作系统、数据库等关键领域的国产化，以支持AI行业未来的发展。
揭秘！47页文档拆解苹果智能，从架构、数据到训练和优化,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928422&idx=3&sn=3b6ed65b6670eb27aa702f5c7ff950f1&chksm=84e43158b393b84e3007a862c88aef1901f524153482741534d1fb173fbdbe040ddfdf80153c#rd,2024-07-31 15:16:13,在2024年的全球开发者大会上，苹果推出了全新的个性化智能系统Apple Intelligence，该系统整合在iOS 18、iPadOS 18和macOS Sequoia中，为iPhone、iPad和Mac提供智能服务。Apple Intelligence被视为苹果创新的新篇章，通过结合生成式人工智能和用户个人信息，提供实用的智能服务，同时强调隐私和安全。一个月后，这项技术开始在iPhone 15 Pro和iPhone 15 Pro Max的iOS 18.1开发测试版中落地，用户可以体验其功能。苹果发布了47页的技术报告，详细介绍了一个名为AFM的基础模型，包括AFM-on-device和AFM-server，它们基于Transformer架构，具有高效和隐私保护的特性。报告还涵盖了模型的训练、后训练过程、适配器架构、量化技术以及负责任的AI原则，显示出Apple Intelligence在语言理解和任务执行方面的强大性能。
用苹果Vision Pro隔空操控机器人，英伟达：「人机合一」也不难嘛,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928422&idx=4&sn=8cc365366c41187e0a95e5aa66af3a89&chksm=84e43158b393b84e4a17c7e11e4b6181c0ce2f096a823f48acb9efeac39073a663db269d24a9#rd,2024-07-31 15:16:13,英伟达创始人黄仁勋在SIGGRAPH 2024 Keynote演讲中介绍了人形机器人通用基础模型“Project GR00T”的新进展。该模型现在与英伟达的Omniverse平台和Isaac机器人开发平台整合，使开发人员能够使用苹果Vision Pro远程操控人形机器人执行任务。英伟达通过GPU加速仿真，利用系统化方法扩展机器人数据，以解决机器人领域数据收集的挑战。此外，NVIDIA宣布提供NIM微服务、OSMO编排服务和AI与仿真的远程操作工作流，以加速全球人形机器人的开发。NVIDIA还推出了人形机器人开发者计划，提供访问其AI超级计算机、Isaac Sim、Jetson Thor和Project GR00T等资源的权限。
ICML 2024｜复杂组合3D场景生成，LLMs对话式3D可控生成编辑框架来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928422&idx=5&sn=66d951add8325328ca8324304500735f&chksm=84e43158b393b84e1e6790b5b9757513d7708f4fc61c2bbce1196001e6e12fd6240f761ed532#rd,2024-07-31 15:16:13,北京大学王选计算机研究所VDIG实验室的研究团队提出了GALA3D，这是一个高质量的Text-to-3D复杂组合场景生成与可控编辑框架。该框架能从文本描述中生成具有多物体和复杂交互关系的3D场景，并支持用户通过对话进行可控编辑。GALA3D利用大型语言模型生成初始布局，并通过布局引导的生成式3D高斯表示构建场景，同时采用自适应几何控制优化形状和分布，以保证几何、纹理和交互的一致性。该方法在文本到复杂三维场景生成方面表现出优越性能，超越了现有的文本生成3D场景方法。GALA3D的代码和论文已公开。
刚刚，Meta开源「分割一切」2.0模型，视频也能分割了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928134&idx=1&sn=7855c453083236c5c5d121d3b4fb955e&chksm=84e43078b393b96ed88a6a5a7ea0aaf950e3257bae24b5cd957041b4f338920d3c84013dfc92#rd,2024-07-30 10:45:15,Meta 在 SIGGRAPH 上发布了 Segment Anything Model 2 (SAM 2)，这是一个统一的模型，能够实时、可提示地处理图像和视频中的对象分割。SAM 2 可以在未见过的对象和视觉域中进行分割，无需自定义适配，适用于各种用例。相比前代，SAM 2 提高了图像分割的准确性，减少了视频分割所需的交互时间，并通过创新的流式内存设计适应实时应用。该模型在实时视频分割方面实现了重大进步，且能够在不依赖数据中心的情况下运行。Meta 还发布了大型带注释的视频数据库 SA-V 以支持训练。SAM 2 的代码和模型权重将开源，并在 Amazon SageMaker 等平台上托管，提供了一个在线演示地址以供体验。该模型有望应用于各种实际场景，如 AR 眼镜中的对象识别和科学研究。尽管 SAM 2 仍面临一些挑战，如处理快速移动对象和长时间遮挡，但它的出现标志着在通用分割模型上的重大进展。
又一「国产版Sora」全球上线！清华朱军创业团队，视频生成仅需30秒,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928134&idx=2&sn=b93b0d455aeabfcbc8bda1f4514b0f0f&chksm=84e43078b393b96e404dc3bc8b03772032c7219ab0356f462a9a94b70dd8adf485cb1fcb2a88#rd,2024-07-30 10:45:15,生数科技发布了其视频大模型Vidu，该模型具有高动态性、高逼真度和高一致性，可以生成生动逼真的视频内容，包括人物动作、文字与特效画面，并解决了AI不会写字的问题。Vidu的推理速度非常快，仅需30秒就能生成4秒的视频镜头，提供了4s和8s两种时长选择，最高分辨率可达1080P，支持写实和动漫两种风格。此外，Vidu还具有文生视频和图生视频功能，能够理解复杂的提示词，包括镜头语言、第一人称视角等，并且支持动漫风格视频生成和角色一致性功能。该模型的推出，展示了国产AI视频生成技术的实力。
Runway深夜炸场，Gen-3 Alpha图生视频上线，11秒让你脑洞乱飞,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928134&idx=3&sn=75f5085d0e38d235c734fa62f3c2f374&chksm=84e43078b393b96e37a38294dc626346be9903e67ae50b6cdc6bce45d27e6e242a2db71844bb#rd,2024-07-30 10:45:15,Runway Gen 3 Alpha 模型推出了图生视频功能，用户可以使用任何图片作为视频生成的首帧，最长可生成 11 秒的视频。这项更新提高了生成视频的艺术控制和一致性。官方给出了惊艳的图生视频示例，获得了网友的认可和赞赏。一些用户已经尝试并分享了他们的生成结果，显示了该功能的潜力和效果。
只要一张图就能「还原」绘画过程，这篇论文比爆火的Paints-UNDO实现得更早,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928134&idx=4&sn=cfb04fbc55f7d8f9ed4b5b252214c7d4&chksm=84e43078b393b96e5a5e0e8d0537c4e89a47750eb9acac73c575248abed43eff5fe0b0ce44e2#rd,2024-07-30 10:45:15,本文介绍了新加坡国立大学的研究团队开发的AI模型ProcessPainter，该模型可以从图片中还原整个绘画过程。ProcessPainter通过训练时序模型，首次实现让扩散模型生成绘画过程，解决了AI绘画过程无法直接用于教学的问题。该模型采用时序注意力机制和艺术品复制网络，能够在预训练的合成数据集上学习绘画技巧，并在少量艺术家的绘画序列上进行微调，以学习特定画师的风格。此外，ProcessPainter还可以进行绘画过程重建和补全任务，为艺术教育和AIGC领域提供了新工具。论文和代码已公开。
「越狱」事件频发，如何教会大模型「迷途知返」而不是「将错就错」？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650928134&idx=5&sn=93a14dd4d54a400bed94d67d44b37c86&chksm=84e43078b393b96efc9bd249450c01d51423a4793f50949e931a9e3eb5e00302ea401d85573e#rd,2024-07-30 10:45:15,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
日均tokens使用量超5000亿，AI生图玩法猛猛上新：豆包大模型为什么越来越「香」了？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927888&idx=1&sn=b1d80073a9b4e10908acb160940cbd3f&chksm=84e4376eb393be780d81a81387a37e3baccc4de4ed0299317aa51fdbd734cbd90583537d3460#rd,2024-07-29 12:42:38,这篇文章是关于字节跳动的豆包大模型在2024年的最新进展和成就。豆包大模型团队在火山引擎AI创新巡展成都站活动中宣布了模型的新升级，特别是推出了豆包・图生图模型，提供了50多项新玩法。豆包大模型在文生图和图生图领域的图像生成质量达到了业界较高水准，尤其在图文匹配和画面美感方面表现出色。此外，文章提到，豆包大模型在日均tokens使用量、技术迭代和第三方评测中均取得了显著成绩，已经成为国内使用量大、应用场景丰富的大模型之一。火山引擎透露，截至2024年7月，豆包大模型的日均 tokens 使用量超过5000亿。豆包大模型的快速进步和广泛应用展示了国产AI模型的竞争力。
1890美元，就能从头训练一个还不错的12亿参数扩散模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927888&idx=2&sn=abf6ec97d9bc767df8c6a8ef0ace1f5b&chksm=84e4376eb393be78ee7b09262f71819792fc0f7b48c4a7921c0a433e98a0e5792b0a3a2cee6e#rd,2024-07-29 12:42:38,Sony AI等机构的研究者以1890美元的低成本，使用3700万张图像训练了一个11.6亿参数的稀疏Transformer扩散模型，大大降低了训练大规模视觉生成模型的经济和计算门槛。他们开发了一种延迟掩蔽策略，通过在输入层处理后掩蔽部分patch，允许未掩蔽的patch保留语义信息，从而在高掩蔽率下有效训练模型。这种方法比缩小模型规模更有效，并结合了Transformer的最新进展，如逐层缩放和稀疏Transformer，以提高性能。在COCO数据集上的零样本生成中，模型达到12.7 FID，成本仅为最先进的stable diffusion模型的1/118。
私有数据、删掉的内容可以永久访问，GitHub官方：故意设计的,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927888&idx=3&sn=68fcbe5bc86381f18d171c3aa0fa16f1&chksm=84e4376eb393be78a2b9d00f4efe3cd78f481aea4e98cd9ca47d666200e95fbc191878f9bbc2#rd,2024-07-29 12:42:38,开源安全软件公司 Truffle Security 发现，在 GitHub 上删除的内容和私有存储库的数据实际上可以永久访问，这是 GitHub 的故意设计。这种问题被称为 CFOR（Cross Fork Object Reference）漏洞，允许用户通过提供提交哈希值来访问原本不可见的数据。即使删除了 fork 的存储库，其中的提交数据仍然可以通过原始存储库访问。Truffle Security 的调查显示，大型公司也可能因此暴露敏感信息，如 API 密钥。GitHub 表示这是其架构的一部分，但 Truffle Security 认为这可能误导用户关于私有和公共存储库安全边界的理解。解决方案包括密钥轮换，因为存储库网络中的提交会永久存在。
标签贴错，AMD召回所有新一代CPU,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927888&idx=4&sn=20dd4b83063752db3163d91e8746889b&chksm=84e4376eb393be780def8f3b46473753fa6438283c3e47681149e95be92e335151609157dc1a#rd,2024-07-29 12:42:38,AMD 因为一个简单的数字拼写错误，决定召回所有已铺货的 Ryzen 9000 系列处理器。在即将上市之际，AMD 发现 Ryzen 7 9700X 被错误地标记为 Ryzen 9 9700X，以及 Ryzen 5 9600X 被标记为 Ryzen 9，这导致了产品发布推迟数周。AMD 表示已经召回所有受影响的处理器进行重新筛选，以保证产品质量。虽然召回的原因被归咎于包装上的印刷错误，但 AMD 也提到在最终检测中发现质量标准未达到预期，暗示可能存在其他问题。高端芯片 Ryzen 9 9950X 和 Ryzen 9 9900X 的发布日期也因此被推迟。尽管印刷错误是一个较小的问题，但 AMD 的处理方式引发了外界对其芯片质量和检测流程的疑虑。
关于大模型「越狱」的多种方式，有这些防御手段,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927888&idx=5&sn=9c776120729b962614387511147ae62d&chksm=84e4376eb393be78b33166649265753c1f80bd97596789bc9c1f58548a71aeba20256ceaf32e#rd,2024-07-29 12:42:38,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
Llama 对决 GPT：AI 开源拐点已至?｜智者访谈,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927779&idx=1&sn=fb38bd4d6fbcbe86120f0dd64ca9fe6f&chksm=84e436ddb393bfcbd965768e6263b969a001edf49021ad797e0c0f678c452fc3cbfadbb93ed3#rd,2024-07-28 12:30:11,本文探讨了人工智能（AI）行业中开源与封闭策略的辩论，特别是在大模型领域的最新进展。Meta 的 Llama 3.1 405B 模型的发布，其性能表现与顶级封闭式大模型相当，引发了关于开源 AI 是否可能成为行业标准的讨论。文章指出，OpenAI 从开源转向封闭主要是由于商业考量和安全问题，而其他科技巨头如 Google 和 Meta 在开源上的策略各有不同，但都是服务于其商业目标。文章还提到了 AI 技术栈的变化，包括框架层的动态图支持、模型层的微调挑战以及大模型的多模态和可解释性研究。最后，文章分析了中美 AI 开源生态的差异，并预测了未来的趋势，包括多模态模型、可解释性和 MoE 等技术方向。
陶哲轩点评谷歌AlphaProof：AI在数学竞赛中展现「超凡智慧」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927779&idx=2&sn=61e01b2bd7cea5590389494e6d6fe13a&chksm=84e436ddb393bfcb9af915ffc3ca9dcd36fc409f85113918fb12cdd65dbc3a99513db8c8b6ec#rd,2024-07-28 12:30:11,谷歌DeepMind的人工智能系统解决了2024年国际数学奥林匹克竞赛(IMO)的四个问题，获得了相当于银牌最高分的28分。该系统在六个问题中得到满分，显示了AI在数学推理上的进步。数学家陶哲轩评价这是伟大的工作，改变了我们对AI解决基准挑战的期望，尤其是IMO级别的几何问题。DeepMind的方法使用强化学习来找到形式化证明，虽然目前每个问题需要大量计算且在形式化方面需要人类帮助，但可能促进形式化数学的自动化。此外，陶哲轩提到，DeepMind的工具与使用大型语言模型的NuminaMath模型不同，后者能完全自动化并以蛮力解决数值问题。DeepMind在数学推理领域的努力正不断推动人工智能的发展。
Llama 3.1 会助推这波「小模型」热潮吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927779&idx=3&sn=6547c578d9233efc13355cd2f4f5959f&chksm=84e436ddb393bfcbce5a79b1b3a920724b8ee0b968dd245e289840366e7767c96d5592cda25d#rd,2024-07-28 12:30:11,这篇文章是关于人工智能领域的最新动态，重点关注了小模型的发展趋势。Llama 3.1，一个405B参数的开源模型，引发了关于小模型是否能成为微调和蒸馏的最佳选择的讨论。尽管它的规模较大，但其性能接近顶尖闭源模型，且Meta强调了对小模型的投入。今年多个头部AI公司发布了小模型，如Meta的MobileLLM、微软的Phi-3系列等。论文表明，小模型在适当的训练和数据量下，性能可以与大模型竞争，挑战了Scaling Law的普遍认知。此外，文章还提到了AI视频生成工具的进展和大型语言模型的深入研究。
损坏不可逆？英特尔13/14代酷睿桌面CPU崩溃后续，不会召回,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927779&idx=4&sn=80767bfd01a988cb97269ee1bd646920&chksm=84e436ddb393bfcb9b66b1290230f74b9186ada71c9bd5e3bae453ed0f7a4791cd822afb56e3#rd,2024-07-28 12:30:11,英特尔第13/14代酷睿台式机处理器在运行虚拟引擎游戏时出现崩溃问题，特别是使用Unreal Engine 5.3的游戏，例如《泰坦之路》。故障率高达50%，导致一些用户和工作室考虑转向AMD处理器。英特尔承认问题由过高的运行电压引起，源于微代码算法错误，并计划在8月中旬提供微代码补丁修复。然而，已经崩溃的处理器可能无法修复，损坏可能是永久性的。英特尔不会召回问题芯片，但会为用户提供支持。除了K系列，65W TDP的非K版本也可能受到影响，但移动笔记本CPU目前未发现相同问题。对于未受影响的用户，补丁将在8月中旬提供，以预防问题发生。
FBI-LLM低比特基础大语言模型来了，首个完全从头训练的二值化语言模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927779&idx=5&sn=eb09646fd7aca3c0c70c0d653f061da7&chksm=84e436ddb393bfcb861b944ea4d5df906ff80f54205a0a6a6ca17d6c481edadf2ad5dacc8bb1#rd,2024-07-28 12:30:11,这篇论文介绍了来自阿联酋MBZUAI和CMU合作的一项新研究，首次提出了使用自回归蒸馏从头训练全二值化大语言模型（FBI-LLM）。传统自回归训练是大语言模型的标准，但二值化模型可以显著减少存储需求和提高计算效率。该研究通过自回归蒸馏损失函数，成功训练出性能接近或匹配全精度模型的二值化大语言模型，并在多个任务上超越了之前的方法。论文提供了开源代码、数据和模型权重。研究发现，从头训练二值化模型与从预训练模型继续训练的效果相当，且全二值化模型在存储和效率上有优势。实验结果表明，FBI-LLM在困惑度和下游任务上表现出色，证明了从头训练全二值化大语言模型的可行性。
为什么AI数不清Strawberry里有几个 r？Karpathy：我用表情包给你解释一下,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927761&idx=1&sn=0838f28259b09c5b237801b493940d8d&chksm=84e436efb393bff9e29d8c54c1a8b4de319986888dcbc37f7c493f16a3a28def932758725ba7#rd,2024-07-27 12:38:44,大模型在数数、比大小等基础问题上犯错引发讨论，被认为是Tokenization（分词）问题导致的。AI专家Karpathy用表情符号展示模型如何看待文本，指出模型缺乏“认知自我知识”，即对自己知识和能力的自我认知。这种“参差不齐的智能”表现为在某些领域表现出高度智能，但在基础问题上犯低级错误。目前的解决方案可能包括让模型学会“只回答它知道的问题”，Meta的研究提出通过后训练阶段的数据生成和知识探测技术来实现这一目标。在生产环境中，应让模型专注于擅长的任务，人类处理其不擅长的部分。
反转了？在一场新较量中，号称替代MLP的KAN只赢一局,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927761&idx=2&sn=ae24f8a3490d1fa813f388c5e16674a0&chksm=84e436efb393bff9974eeae5edd1c92a5b64c6fd399d57dee056e3b33399fb8fabca59c5f991#rd,2024-07-27 12:38:44,研究人员对比了KAN（Kolmogorov–Arnold Networks）和多层感知器（MLP）在多个任务中的性能。KAN在符号公式表示任务中表现出色，但在机器学习、计算机视觉、自然语言处理和音频处理等领域的任务中，MLP通常优于KAN。研究发现，KAN的优势可能源于其使用的B样条激活函数，但这种优势并不普遍适用。当使用B样条激活函数替换MLP的激活函数后，MLP的性能可以与KAN匹敌甚至超过KAN。此外，KAN在连续学习任务中的遗忘问题比MLP更严重。研究结论是，KAN和MLP各有适用的场景，选择哪种模型取决于具体任务需求。
贾扬清点赞：3K star量的SGLang上新，加速Llama 405B推理秒杀vLLM、TensorRT-LLM,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927761&idx=3&sn=bf9644c00fddfa2ea8e937465ced73c7&chksm=84e436efb393bff9dedc77a68970c57c020a120cbea5d5ff7d204e2bfad19f309e3cb9d21c60#rd,2024-07-27 12:38:44,LMSYS Org 团队推出了 SGLang Runtime v0.2，这是一个用于大型语言模型和视觉语言模型的通用服务引擎，旨在提高推理速度和效率。该引擎在运行 Llama 3.1 405B 模型时，表现优于 vLLM 和 TensorRT-LLM，在某些情况下吞吐量可达到 TensorRT-LLM 的 2.1 倍，vLLM 的 3.8 倍。SGLang 由纯 Python 编写，完全开源，并且具有高效的批处理调度器。该团队通过运营 Chatbot Arena 平台的经验，不断优化底层服务系统，SGLang Runtime 在处理不同大小的 Llama 模型和不同 GPU 上的表现均展现出优秀性能。
万亿token！史上最大多模态数据集诞生,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927761&idx=4&sn=5885e14205808b9593ef833fe5079a72&chksm=84e436efb393bff95bf805fdda70420dd76db8d8a45f70a2b21b65c965dcd14697beeb9c61c0#rd,2024-07-27 12:38:44,研究人员构建了一个名为MINT-1T的开源多模态数据集，包含一万亿文本token和三十亿张图像，源自HTML、PDF和ArXiv等多种来源，是目前最大的开源多模态数据集。此前，最大的开源数据集OBELICS包含1150亿文本token和3.53亿张图像。MINT-1T的构建过程中执行了文本质量、图像、安全性和重复内容的过滤。实验表明，在MINT-1T上训练的多模态模型在视觉问答任务上表现出色，但在某些视觉描述任务上可能不如在OBELICS上训练的模型。这个大规模数据集的发布将可能促进开源多模态大模型的发展。
ECCV 2024｜是真看到了，还是以为自己看到了？多模态大模型对文本预训练知识的过度依赖该解决了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927761&idx=5&sn=6c9c74b85c8dce2d7564823883c59172&chksm=84e436efb393bff90e33787c4bee55ab0095e7e2dcb841d7c8169645264d486b701a4f54c212#rd,2024-07-27 12:38:44,本文介绍了一种增强多模态大型语言模型的新方法——Bootstrapped Preference Optimization (BPO)。随着多模态大型语言模型（MLLMs）的发展，它们在处理图文信息方面的能力增强，但有时会出现错误或幻觉。研究认为，这种偏见主要源于语言模块预训练与模态对齐阶段的数据量和训练时间不平衡。为解决此问题，BPO 提出将多模态对齐问题转化为偏好学习任务，通过自动化构建大规模偏好数据集来识别和纠正预训练偏见。实验结果表明，使用 BPO 微调的模型在多个基准测试中的性能得到提升，增强了模型的视觉理解能力，减少了错误响应。
B站AI课几秒出总结，划词就给解释，这个「AI学习搭子」真香,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927597&idx=1&sn=1750442a802b9879a5f360f37cf2a3fc&chksm=84e43593b393bc853b30149ed74f86adf6263637555bf42001df0d1b3df64c561d32393f44bb#rd,2024-07-26 11:19:02,本文介绍了豆包电脑版这一学习和工作效率提升工具，它能够帮助用户更轻松地学习人工智能。豆包电脑版提供了多种功能，如AI看B站，可以为用户摘要和解释B站上的AI课程内容，甚至可以进行互动问答。此外，它还具有划词翻译和总结功能，帮助用户在阅读文章时理解专业术语和内容。对于AI论文学习，豆包的AI伴读模式提供全文翻译、内容总结和互动问答，提高了论文阅读的效率。豆包电脑版还可以辅助用户写作，提供文章大纲、内容填充、润色和图像生成等服务。用户反馈良好，认为它是一个强大的学习和工作助手。
智谱AI杀入视频生成：「清影」上线，时长6秒，免费不限量,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927597&idx=2&sn=56cc40adbeb4c3529ea2e534cc18c42d&chksm=84e43593b393bc85ee5815e8485664299061879112464b28ebe73ab7ee2a81fbe24edaf03c9c#rd,2024-07-26 11:19:02,智谱AI发布了名为“清影”的视频生成大模型，用户只需提供创意性的文字描述或图片，就能在30秒内生成1440x960清晰度的6秒视频。清影支持多种风格的视频生成，包括卡通、真实摄影和二次元动漫等，并能在风景、动物、科幻和人文历史等内容上表现良好。这款模型是基于智谱AI自研的CogVideoX，其技术包括三维变分自编码器结构和因果三维卷积等，旨在解决视频连贯性和逻辑一致性的问题。清影现已在清言App上线，所有用户可免费体验，并且还提供了API供企业和开发者使用。随着各大公司推出类似的视频生成功能，AI视频创作领域的竞争日益激烈。
全球首篇！调研近400篇文献，鹏城实验室&中大深度解析具身智能,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927597&idx=3&sn=b000973dedd3e5ec015a6bace5b69157&chksm=84e43593b393bc8594a0e850ba0b9d6844217878b4b6124f6143121588d2ee5e6aadf6e36460#rd,2024-07-26 11:19:02,这篇综述文章是鹏城实验室和中山大学HCP实验室的研究人员合作撰写的，全面解析了多模态大模型时代的具身智能最新进展。具身智能是实现通用人工智能的关键途径，涉及智能体与数字空间和物理世界的交互。文章介绍了具身机器人和具身仿真平台，并深入探讨了具身感知、具身交互、具身智能体和虚拟到现实的迁移四个主要研究领域。此外，还讨论了具身智能面临的挑战，包括数据集质量、人类示范数据利用、复杂环境认知等，并展望了未来的发展方向，如长程任务执行、因果关系发现和持续学习等。该综述旨在为具身智能研究提供参考，并推动相关技术创新。论文和具身智能paper list可在GitHub上找到。
算法、系统和应用，三个视角全面读懂混合专家（MoE）,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927597&idx=4&sn=04ec86330947b5f414975f7deb232f97&chksm=84e43593b393bc8581df9b86a30ceabe901674b71256b15b8f9bf60d4da7159bf9df76df7261#rd,2024-07-26 11:19:02,"混合专家（Mixture of Experts, MoE）是提升大型语言模型效率的重要方法，它通过让模型的不同部分专注于不同任务或数据方面来控制计算成本。随着稀疏门控MoE技术的发展，MoE在Transformer模型中的应用日益增多。稀疏MoE仅激活部分专家，减少了计算负载，但引入了负载平衡问题，需要通过辅助损失函数解决。MoE模型的分类包括算法设计、系统设计和应用，其中算法设计主要关注门控函数，包括稀疏式、密集式和soft式。系统设计涉及专家网络架构、超参数选择和并行化策略。应用方面，MoE已广泛应用于自然语言处理、计算机视觉等领域。未来的研究挑战包括训练稳定性、可扩展性、专家专业化和泛化能力等。"
彻底摒弃人工标注，AutoAlign方法基于大模型让知识图谱对齐全自动化,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927597&idx=5&sn=e5ca7232aec795301fefd9a19a097365&chksm=84e43593b393bc85f91edad7c1e68bc9f5b9f82aa805b4dc835002ee81f73571c54d131216b4#rd,2024-07-26 11:19:02,来自清华大学、墨尔本大学、香港中文大学和中国科学院大学的研究团队提出了一种名为AutoAlign的全自动知识图谱对齐方法。传统方法依赖人工标注种子实体对进行对齐，而AutoAlign则完全通过算法理解实体语义和结构来实现对齐，提高了效率和准确性。该方法包括谓词嵌入模块、属性嵌入模块和结构嵌入模块，通过大语言模型进行自动对齐。实验结果显示，AutoAlign在知识图谱对齐性能上显著优于现有模型，特别是在没有人工标注的情况下。相关论文和代码已开源。
字节大模型同传智能体，一出手就是媲美人类的同声传译水平,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927463&idx=1&sn=21471a5d179c548c2d0ed17c03406c04&chksm=84e43519b393bc0f32a783c3d986dac34c4397b7b5b345910595c8a2026f9906a7aea0dd8db0#rd,2024-07-25 12:23:31,字节跳动ByteDance Research团队推出了CLASI，一个端到端的同声传译智能体，其效果接近专业人工水平。CLASI采用大语言模型和语音理解能力，避免了传统级联模型的错误传播问题，并能从外部获取知识，展现出优秀的同声传译能力。在与专业同传译员的人工评测中，CLASI在中英、英中翻译上大幅领先其他商业系统，并在某些测试中达到或超过人类水平。系统采用Encoder-conditioned LLM，通过灵活调整处理策略平衡实时性和翻译质量。
Nature封面：AI训练AI，越训越离谱,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927463&idx=2&sn=e9be381477ec74754d5bdd37b06d5d66&chksm=84e43519b393bc0f43d6d7d3594ebc18572499c9708784fe39d2f80f6f4b35351de14c05b11e#rd,2024-07-25 12:23:31,研究人员在《自然》杂志上发表的一项封面研究显示，使用AI生成的数据训练大模型可能会导致“模型崩溃”，即模型在几代内退化成无意义的输出。该研究由牛津大学等机构进行，强调了过度依赖AI生成数据的风险，认为这可能使模型忽略原始数据的某些部分，最终失去性能。模型崩溃是由于统计近似误差、函数表达误差和函数逼近误差在多代模型中复合所造成的。研究还指出，互联网上的大量AI生成内容可能已经污染了数据源，对模型的公平性和准确性构成挑战。为避免模型崩溃，研究建议访问原始数据源并仔细过滤递归训练中的数据。
只需两步，让大模型智能体社区相信你是秦始皇,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927463&idx=3&sn=ff93cc6ef8207ba11fa1e458adc81066&chksm=84e43519b393bc0fada9c7786e935c2946c2b702ef126706e9fcc215175d0cc5fb10a796a659#rd,2024-07-25 12:23:31,这篇论文研究了大语言模型（LLMs）在多智能体系统中的安全问题，特别是知识传播的安全性。研究人员构建了一个模拟环境来模拟由不同第三方用户部署的多智能体系统，并提出了一个两阶段攻击方法，使得恶意攻击者能够操纵智能体传播编造的知识，影响其他智能体的认知。第一阶段是“说服性植入”，通过训练使智能体更倾向于生成包含详细（但可能是捏造的）证据的回答。第二阶段是“编造知识植入”，通过修改模型参数使智能体对特定知识产生误解，并在交互中无意识地传播篡改后的知识。实验结果显示，这种攻击策略能够有效传播编造知识，对多智能体社区构成安全威胁。未来的研究方向包括开发防御机制，如提示工程和事实检测，以增强社区的鲁棒性和安全性。
RLHF不够用了，OpenAI设计出了新的奖励机制,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927463&idx=4&sn=ade869adc59ead2c30bca517023bc397&chksm=84e43519b393bc0fce5e96467c7ed29e2a3f65fe1dea6e4d738e3391731e80fd8e0c325461e1#rd,2024-07-25 12:23:31,"OpenAI提出了一种新的奖励机制，称为基于规则的奖励（Rule-Based Rewards, RBR），来教导AI模型遵守安全政策。这种方法允许人类详细说明期望的模型响应，形成规则，以捕捉安全和适当响应的细微差别。RBR通过一个固定的语言模型评分系统，根据响应遵循规则的程度进行奖励，从而适应新的安全政策，而无需大量的人工反馈数据。实验表明，使用RBR训练的模型在安全性能上与经过人类反馈训练的模型相当，同时减少了过度拒绝安全请求的情况，提高了效率。RBR还可以通过修改或添加规则快速更新，以适应模型能力和安全准则的变化。尽管在主观任务中可能有限制，但RBR可以与人类反馈结合使用，以平衡安全性和性能。OpenAI已经在GPT-4等模型中应用了RBR，并计划在未来的模型中继续实施。"
TPAMI 2024 | ProCo: 无限contrastive pairs的长尾对比学习,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927463&idx=5&sn=97e96bc56ea867361809042f2c166542&chksm=84e43519b393bc0f643282e241d49e4e5f019dad6fd1bd2a0e078d53ae5dbb306c3ccd7f5d02#rd,2024-07-25 12:23:31,清华大学的研究人员提出了一种名为ProCo的新型长尾对比学习方法，该方法针对长尾视觉识别任务，解决了监督对比学习对batch size的依赖问题。ProCo通过建模每类数据的分布并进行参数估计，能够生成无限数量的对比样本对，从而提高模型对长尾分布类别的学习能力。这种方法已在TPAMI 2024中被录用，并在长尾视觉分类、半监督学习、目标检测以及平衡数据集上显示出显著的性能提升。论文和代码已开源。
Llama成大模型顶流，扎克伯格掀论战：玩开源，时代变了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927368&idx=1&sn=98f407fc00324a9630bcc124c8f0a3d0&chksm=84e43576b393bc60badcb76a7c5968b358232267f418a9208df89b9aa08a449c1f000ef048be#rd,2024-07-24 13:07:19,Meta 发布了首个前沿级开源 AI 模型 Llama 3.1 405B，以及改进版的 70B 和 8B 模型，旨在使开源 AI 成为行业标准。开源大语言模型 Llama 系列的性能提升和开源特性将促进人工智能技术的普及和应用。Meta 创始人扎克伯格强调开源对开发者、Meta 和世界的积极影响，认为开源 AI 将有利于创新、数据保护和成本效益。他还表示，开源 AI 模型能够建立一个完整的生态系统，确保技术进步，并减少对闭源供应商的依赖。此外，多个公司如亚马逊、Databricks 和英伟达等将推出服务支持开发者使用开源 Llama 模型。
击败GPT-4o的开源模型如何炼成？关于Llama 3.1 405B，Meta都写在这篇论文里了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927368&idx=2&sn=9d82c1f832143fda2c8cf473ba9fa424&chksm=84e43576b393bc602e1c233d2b0e4154ad460d2f3c1c73f6a532eb9e0598f174bbe28e51032f#rd,2024-07-24 13:07:19,Llama 3.1，一个由Meta官方发布的大型语言模型，已正式推出，其上下文长度扩展到了128K，有8B、70B和405B三个版本。这个405B版本的模型在多任务基准测试中的性能可与最好的闭源模型相媲美。Meta在预训练数据的质量和规模上进行了改进，使用了约15万亿多语言Token的语料库对Llama 3进行预训练。该模型的旗舰版本在3.8 × 10²⁵次浮点运算上进行了预训练，比Llama 2的最大版本增加了近50倍。为了支持大规模推理，405B模型通过量化技术降低了计算要求。在后训练阶段，使用旗舰模型提升了较小模型的质量。Meta还开发了模型的多模态扩展，但尚未发布。论文中还提到了训练基础设施的优化和模型开发过程中的可扩展性考虑。此外，Meta更新了许可证，允许开发者使用Llama模型的输出来增强其他模型。Llama 3.1的发布伴随着一个由多个技术伙伴支持的生态系统。
数学大统一理论里程碑进展：几何朗兰兹猜想获证明，论文超800页,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927368&idx=3&sn=316059e5c7b6995056c21e8b6b8f7c02&chksm=84e43576b393bc609ec4e02ad369795162d367adb6e05f944c9c5be7f3aa06cc308bff9d2014#rd,2024-07-24 13:07:19,数学家们已经证明了朗兰兹纲领的重要部分——几何朗兰兹猜想，这是现代数学中一个广泛而重要的范式。由9位数学家组成的团队完成了超过800页的证明，该证明涉及数论、几何和函数域三个数学领域的对称性。朗兰兹纲领由罗伯特·朗兰兹在1960年代提出，旨在统一数学的不同领域。这个证明是数十年研究的顶点，被认为是数学的“大统一理论”。几何朗兰兹猜想的证明将对整个数学领域，尤其是对朗兰兹纲领的其他部分产生深远影响。
从裸机到700亿参数大模型，这里有份教程，还有现成可用的脚本,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927368&idx=4&sn=04ad3a267fa84ff37b22b41a780ecc1c&chksm=84e43576b393bc60aba73b530d944f495638d411ab71164e3d073804c47748624446b75f0da0#rd,2024-07-24 13:07:19,本文介绍了AI初创公司Imbue构建大规模计算机集群来训练700亿参数的LLM的全过程。他们面临的挑战包括配置裸机、设置InfiniBand网络、诊断硬件问题以及优化基础架构。文章详细描述了从安装操作系统到配置InfiniBand的步骤，以及如何处理常见问题，如GPU故障、网络连接问题和性能下降。此外，团队还开发了工具和脚本以监控和自动化集群的管理和故障排查。这篇文章对于想要构建自己的LLM训练基础设施的读者提供了宝贵的经验和资源。
清华领衔发布多模态评估MultiTrust：GPT-4可信度有几何？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927368&idx=5&sn=1e9fbcde85231b8461905292a09df167&chksm=84e43576b393bc6031fc3d1c7521e3f75c00bc8a93ee44c609d72fe59fbbc5bf6d677b003370#rd,2024-07-24 13:07:19,这篇论文介绍了一个名为MultiTrust的综合基准，该基准首次全面评估了主流多模态大语言模型的可信度。由清华大学等机构的研究人员联合撰写的这篇百页长文，提出了五个可信评价维度：事实性、安全性、鲁棒性、公平性和隐私保护，并进一步构建了32个评估任务。研究发现，尽管多模态大模型在各种任务中表现出色，但它们存在安全风险，如对抗攻击、幻觉、偏见和隐私泄漏。文中还提到，闭源商用模型在安全可靠性上通常优于开源模型，但仍然存在脆弱性。此外，多模态训练可能会削弱大语言模型的安全对齐机制。该基准的发布旨在促进对多模态大模型可信性的深入理解和改进。
首个超越GPT4o级开源模型！Llama 3.1泄密：4050亿参数，下载链接、模型卡都有了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927161&idx=1&sn=0cb0453acacb615e582afa7fd17bb7f8&chksm=84e43447b393bd51c2b505b94b71fa1b72388d54bcfdfec6f2176bd89bb36cf8b8bee7897c89#rd,2024-07-23 09:15:38,Reddit上出现了Meta的Llama 3.1大模型的泄露消息，包括8B、70B和405B参数量的基准测试结果。该模型在多项基准测试中超过了GPT-4o，其中70B版本表现优异。Llama 3.1是基于405B模型蒸馏而来的，使用了15T+的公开数据进行训练，并且支持多语言。模型的训练细节、硬件基础设施和环境影响等信息也一同曝光。尽管有下载链接流出，但建议等待官方渠道发布以确保安全。Llama 3.1旨在用于多语言商业应用和研究，强调了安全性和负责任的使用。
神经网络也有空间意识！学会在Minecraft创建地图，登上Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927161&idx=2&sn=380b6e138e083ccabf1d1b0d9984fec6&chksm=84e43447b393bd5155b4496ed5c772e8b9d1383910bed5229b2e876eaf9a5cf4c369f90a8806#rd,2024-07-23 09:15:38,研究人员最近发现，神经网络可以使用预测编码算法来构建空间地图。在一项研究中，研究团队在《我的世界》游戏中创建了一个环境，并训练了一个配备预测编码的神经网络来学习和预测玩家在环境中的移动。结果表明，神经网络能够学习物体间的组织关系，创建空间地图，并以低误差率预测视频帧。这是首次证明神经网络能够自主创建地图，这一步进展可能有助于提升AI的空间感知能力和解决复杂问题的能力。研究结果发表在《自然 - 机器智能》杂志上，相关的代码已开源。
真相了！大模型解数学题和人类真不一样：死记硬背、知识欠缺明显，GPT-4o表现最佳,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927161&idx=3&sn=de0d85bf8233b073ccde997622b704bf&chksm=84e43447b393bd511e9185ea69947a5fba9e624b041deefcd61b9ddfd93a74370d64374ac097#rd,2024-07-23 09:15:38,本文介绍了We-Math，一个用于评估大型多模态模型（LMMs）在数学推理任务中的新基准。We-Math包含6.5k个多模态小学数学问题和一个基于67个原子知识点的知识体系。研究人员通过拆分复杂问题为子问题来研究模型的推理过程，并引入了四维度量标准（知识掌握不足、泛化能力不足、完全掌握和死记硬背）来评估模型性能。实验表明，LMMs在涉及多个知识点的问题中表现较差，且存在“知识掌握不足”和“死记硬背”的问题，而GPT-4o在这些方面表现相对较好。此外，研究还提出了KCA策略来缓解模型的某些问题。
无限生成视频，还能规划决策，扩散强制整合下一token预测与全序列扩散,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927161&idx=4&sn=90a44edfc4182de251e9862861c52f4d&chksm=84e43447b393bd518862a6dbf8ae6cbd94b9468ee0e4f53631b949f387c8b1ecd29e13b2a801#rd,2024-07-23 09:15:38,MIT CSAIL的研究团队提出了一种新的序列生成和决策框架——Diffusion Forcing (DF)，它结合了下一 token 预测和全序列扩散模型的优点。DF通过独立的噪声水平关联每个token，使用下一 token 预测模型进行去噪，允许灵活的序列长度生成和稳定的表现。该方法在一致性、稳定性和序列决策方面优于全序列扩散和教师强制。DF在视频预测、规划、模仿学习和时间序列预测等任务中展现出优势，包括稳定序列生成、灵活的规划范围和未来不确定性处理。此外，DF在机器人控制任务中也表现出色，能处理长范围任务和视觉运动控制。
ECCV 2024｜盲视频去闪烁通用方法BlazeBVD来了，美图&国科大联合提出,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927161&idx=5&sn=9711ee99d9f97e7b7109e0c555e61f3b&chksm=84e43447b393bd519c4f93bcd9a1b7fe56e5834004be2f02b12bae28794abe8d12056af284ac#rd,2024-07-23 09:15:38,"美图影像研究院（MT Lab）联合中国科学院大学提出了一种新的盲视频去闪烁（blind video deflickering, BVD）方法，称为BlazeBVD，该方法已被计算机视觉顶会ECCV 2024接收。BlazeBVD使用尺度时间均衡（STE）的直方图辅助解决方案，通过平滑直方图序列来消除视频中的闪烁伪影，同时保持视频内容的完整性。这种方法降低了BVD任务的学习复杂度，提高了处理速度和性能。实验结果表明，BlazeBVD在合成数据集和真实数据集上优于现有方法，并且在模型推理速度上提升了10倍。美图公司计划将此类AI技术应用于其视频编辑工具，为用户提供更好的视频编辑体验。"
从空间智能到具身智能，跨维践行Sim2Real AI最高效路径,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927069&idx=1&sn=32b8072ec663f02350d310f082511ebb&chksm=84e42ba3b393a2b5a5ca60fb8582ae4320820f4eb88e827a2f5830eedcc274e6a904482c6f59#rd,2024-07-22 13:25:34,这篇文章讨论了具身智能和空间智能在AI领域的重要性，以及数据在实现通用具身智能中的关键角色。目前，数据匮乏是通用具身智能发展的一大障碍。Sim2Real AI被提出作为解决这一问题的一个路径，但学术界和产业界对此的看法仍有分歧。香港中文大学（深圳）终身教授贾奎认为Sim2Real AI是通往具身智能的最高效路径，并通过其自研的DexVerse™引擎实现了从技术到产品的落地。文章还探讨了具身智能与空间智能的核心理念，强调建立“世界模型”以赋予机器人类似人类的感知能力。最后，贾奎提出了具身智能从技术到商业落地的实现路径，并指出了当前跨维智能在该领域的进展和未来可能的生态系统。
盛名一时的BERT哪去了？这个问题的答案昭示了LLM范式的转变,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927069&idx=2&sn=2758f2e446fb510371c0291bcecf9717&chksm=84e42ba3b393a2b54be131006a429d911d8985d35f9f4155b313de61071766713bb641ae851a#rd,2024-07-22 13:25:34,很抱歉，您还未提供具体的文章内容。请您提供一篇文章，我将为您生成摘要。
爆火免费书《深入理解深度学习》终于出中文版了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927069&idx=3&sn=3a4c73ef39add276b256d2919087352b&chksm=84e42ba3b393a2b537c876aac7c3fc7a1dee75e14f4a5d144247ad22a9f2fe67bcffa86f5d57#rd,2024-07-22 13:25:34,麻省理工出版社的新书《Understanding Deep Learning》中文版发布，涵盖深度学习关键概念，包括基本构建、Transformer、GNN、RL、扩散模型等，适合初学者和开发者。书籍提供68个Python笔记本练习，帮助读者通过实践加深理解。作者Simon J.D. Prince是巴斯大学计算机科学教授，专注于计算机视觉和图形学研究。全书共21章，讨论深度学习原理、模型训练、无监督学习、生成模型、强化学习和伦理问题。
中科大联合华为诺亚提出Entropy Law，揭秘大模型性能、数据压缩率以及训练损失关系,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927069&idx=4&sn=7322b6b62f4b6852b176adbf11c47370&chksm=84e42ba3b393a2b5df0096be15d23969b834f3d026073a4ecf89703f01b3d367dda25eb01c59#rd,2024-07-22 13:25:34,这篇文章介绍了由中国科学技术大学认知智能国家重点实验室和华为诺亚方舟实验室合作完成的一项研究。研究团队发现，对于大语言模型（LLMs）的训练，单纯基于数据质量的选择方法并不充分，因为样本之间的组合效应可能影响模型学习效率。他们提出了一个名为“entropy law”的理论，该理论将LLM的性能与数据压缩率和训练损失联系起来，揭示了数据冗余和多样性的影响。基于这个理论，团队开发了一种高效的数据选择算法ZIP，旨在优先选择低压缩率和多样性的数据子集。实验结果显示，ZIP算法在提高模型性能方面优于其他数据选择方法，并且在实际应用中，entropy law可以用来指导LLM的训练数据更新和性能预测。
ECCV 2024 | 提升GPT-4V、Gemini检测任务性能，你需要这种提示范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927069&idx=5&sn=85604596b663f61fb1029519b7b27512&chksm=84e42ba3b393a2b596650f66160ec607af613a14eb18206b355b7a1d4c6e7474a53e5fa21ac8#rd,2024-07-22 13:25:34,浙江大学、上海人工智能实验室等机构的研究人员提出了一种名为DetToolChain的新提示范式，旨在释放多模态大语言模型（MLLMs）的检测能力，使其无需微调就能进行精确的目标检测。DetToolChain通过设计特定的视觉提示和检测推理提示，解决了MLLM在检测任务中可能出现的幻觉和不准确性。这种方法将复杂的检测任务拆解为小任务，并通过chain-of-thought逐步优化结果。实验表明，DetToolChain在开放词汇检测和指称表达理解等任务上显著提升了模型的性能，且无需额外的训练数据或微调。这项研究已被ECCV 2024收录。
打破生态孤岛，国产异构原生AI算力工具问世，来自中科加禾,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927025&idx=1&sn=7c7e2ef8191d595c5b38784ddacffcf7&chksm=84e42bcfb393a2d9242f0786e8d0d7d70bc5550f3bcf658383780ba00de3288c3bc37574bcf7#rd,2024-07-21 12:40:18,中国工程院院士孙凝晖表示，系统软件优化对于国内智能生态的发展至关重要。AI基础设施公司中科加禾发布了一代异构原生AI算力工具，旨在降低开发门槛，统一不同硬件，提高效率，并兼容多种国产AI芯片，提供高性能的统一接口。该工具在AI算力集群的大模型推理上能显著降低时延，提升吞吐率和能效比，支持大规模的模型。中科加禾的解决方案目标实现零成本迁移、零损耗使用和零延迟部署，包括SigInfer、SigFT和SigTrans三款产品，支持跨平台、高性能的推理和微调。该公司已与多家芯片、集成商和服务商合作，推动国产AI生态的发展。
在机器人顶会 RSS 2024 上，中国的人形机器人研究入围最佳论文奖,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927025&idx=2&sn=955d59fe9a99f64d3a7b98f0b8f6ad44&chksm=84e42bcfb393a2d9731fb1807ab373932f9af46a46da6ccebc65d2155642f8bc945e779641d3#rd,2024-07-21 12:40:18,RSS（Robotics: Science and Systems）2024会议在荷兰落幕，揭晓了最佳论文、最佳学生论文、最佳系统论文、最佳Demo论文等多个奖项。华人学者Ji Zhang荣获时间检验奖，清华大学和北京星动纪元科技有限公司的人形机器人研究入围最佳论文奖。获奖论文涉及农业机器人视觉导航、无人机自主飞行、机器人操纵接口、时空语义SLAM、动态非抓取操作、四足机器人安全行走、双手协调操作学习等多个领域。这些研究展示了机器人技术在农业、导航、控制、感知和规划等方面的最新进展。
「后训练 + STaR」是 OpenAI 绝密项目「草莓」背后的秘密吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927025&idx=3&sn=c29dc13afe90d683727b90b758982256&chksm=84e42bcfb393a2d9c5f5fa659561c3d69c6349d1f68803003c55729706547fadc7a8901118f0#rd,2024-07-21 12:40:18,"这篇文章是机器之心PRO的会员通讯，主要涵盖了三个AI和Robotics领域的重点内容。首先，文章提到了OpenAI的内部项目“草莓”（Strawberry），该项目旨在开发具有高级推理能力和长期任务执行能力的AI模型。据称，这个项目可能采用了后训练方法和类似斯坦福大学的STaR技术，以提升模型的推理性能。OpenAI的目标是让模型能够自主规划和执行复杂任务，类似于人类的思考过程。

其次，文章讨论了大模型和AIGC创业公司的现状，包括哪些公司受到资本青睐、产品方向以及近期的创业动态。提到了Stability AI和Character AI等公司的策略布局。

最后，文章引用了信通院的报告，强调了大模型基准测试的重要性，讨论了当前基准测试的体系和存在的问题，并提到了信通院的“方升”项目在大模型评估中的表现。

完整版通讯还包括其他28项本周的AI和Robotics行业动态，涵盖了技术、国内外新闻等多个方面。"
ICML 2024 Oral | DPO是否比PPO更适合LLM，清华吴翼团队最新揭秘,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927025&idx=4&sn=9db9f4131f05a132012f73db7339042a&chksm=84e42bcfb393a2d99c4970c207a80d941f822384c89fd1f6516c08107efa5485af56f9c317a8#rd,2024-07-21 12:40:18,清华大学交叉信息院助理教授吴翼的研究团队在强化学习和大模型对齐技术方面取得新进展。他们发表在ICML 2024的工作探讨了DPO（Direct Policy Optimization）和PPO（Proximal Policy Optimization）算法在大模型对齐上的效果。研究发现，通过优化PPO算法，他们在代码生成任务上超越了闭源模型AlphaCode 41B。团队还开发了大规模RLHF训练系统ReaLHF，实现高效的大语言模型对齐训练。此外，团队还展示了在MiniRTS、狼人杀和Overcooked等游戏中，通过强化学习训练出的复杂语言智能体和合作代理。论文中总结了提升DPO和PPO性能的关键技术，并强调了高效率训练系统在大模型对齐中的重要性。相关成果将在ICML 2024上进行口头报告。
ECCV 2024 | 让GPT-4图像理解更易出错，全新策略增强VLP模型对抗迁移性,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650927025&idx=5&sn=1fd8bce8fee6220a174a387ec77b587d&chksm=84e42bcfb393a2d9604c2f10c618a26258b428b98768d552c012d13dc7b1cd2709b14488ec2b#rd,2024-07-21 12:40:18,"研究人员提出了一个新方法，通过利用对抗轨迹交集区域的多样性，提升视觉-语言预训练（Vision-Language Pretraining, VLP）模型对抗攻击的迁移性。现有的对抗攻击研究往往依赖于代理模型生成对抗样本，存在过拟合风险。该工作引入的对抗轨迹交集区域考虑了干净样本、当前对抗样本和上一步对抗样本构成的三角形区域，增加了扰动方向的多样性，从而提高了对抗样本在不同模型间的迁移成功率。实验结果显示，这种方法在跨模型和跨任务迁移性上都优于现有方法。论文和代码已开源。"
专访诺奖得主：大模型是记忆还是理解？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926975&idx=1&sn=0d553333ac641611d2ce3c785a28c4c0&chksm=84e42b01b393a21769bc68f985b969598a0fbf6f25d384483d4ed9fa636c3186d54133bc950b#rd,2024-07-20 17:58:47,2011年诺贝尔经济学奖得主托马斯·萨金特教授认为，人工智能和机器学习的核心可以追溯到伽利略时代，都是通过构建模型进行预测和决策。他在论文中指出，人工智能是旨在完成类似伽利略等科学家智能任务的计算机程序。关于大模型是否能实现科学发现，萨金特认为模型理解和因果关系的界定存在哲学争议，但大模型的开发者对其工作原理有深入理解。他强调，模式识别是智能的关键，但如何定义和理解“因果关系”仍是一个复杂的问题。
机器人版的「斯坦福小镇」来了，专为具身智能研究打造,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926975&idx=2&sn=4f4b23ce447e10580a005eb6dbd848ce&chksm=84e42b01b393a217b4767d4fed90ce9e5bf3909caedc032873292557dedfae40bec46570b06d#rd,2024-07-20 17:58:47,上海人工智能实验室OpenRobotLab等机构的研究者打造了一个名为GRUtopia的虚拟小镇，这是首个专为各种机器人设计的模拟互动3D社会。该环境包含10万个交互式场景和89种不同场景类别，旨在解决具身智能领域的数据稀缺问题。GRUtopia包括三个部分：1) GRScenes，一个大规模的完全交互式场景数据集；2) GRResidents，一个由大型语言模型驱动的NPC系统，负责社交互动和任务生成；3) GRBench，一个评估机器人的基准，侧重于有腿机器人的导航和操纵任务。这项工作旨在为具身AI研究提供更全面的评估和高质量数据。
权重、代码、数据集全开源，性能超越Mistral-7B，苹果小模型来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926975&idx=3&sn=34e2a342fafab850d9e54ebe3166ef6a&chksm=84e42b01b393a217fc0e4ca411cd0d6b63e01127f79aaa470beba0ba3e1bc41878f4e6159093#rd,2024-07-20 17:58:47,苹果公司最近在Hugging Face上发布了开源模型DCLM-7B，该模型在性能上超越了Mistral-7B，并接近其他领先开源模型，如Llama 3和Gemma。DCLM项目旨在创建一个语言模型训练数据的基准，通过使用机器学习模型过滤数据来提升模型性能。DCLM-7B模型在MMLU基准上的5-shot准确率达到64%，与Llama 3 8B相当，但所需计算量仅为Llama 3 8B的1/6。DCLM-7B模型的独特之处在于其不仅开放模型权重，还开放了训练代码和预训练数据集，因此被描述为“真正开源”的模型。
KDD 2024｜港大黄超团队深度解析大模型在图机器学习领域的「未知边界」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926975&idx=4&sn=7ece1614d10b2261d8038cf08706b9d0&chksm=84e42b01b393a2174b148e802af5ca1d4d65f1e927732cfb7729b421f035c279c88a49cb1aab#rd,2024-07-20 17:58:47,这篇综述文章由香港大学数据智能实验室的研究人员撰写，探讨了如何将大型语言模型应用于图学习，以解决信息爆炸时代数据深层次联系的探索问题。文章提出了一种新的分类方法，将现有技术分为四大类：图神经网络作为前缀、大语言模型作为前缀、大语言模型与图集成以及仅使用大语言模型。研究团队分析了每种方法的优势和局限性，并讨论了未来大模型在图学习领域的潜力，包括模型泛化、鲁棒性和复杂图数据理解的挑战。此外，文章还提出了未来的研究方向，如多模态图与大语言模型的融合、效率提升、处理多样化图任务以及构建用户友好的图智能体。
可「自主进化」的Agent？首个端到端智能体符号化训练框架开源了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926975&idx=5&sn=918173e47ff9018b8c511d80d1cd8845&chksm=84e42b01b393a217eb3983080c5d89f96d1a2c96cfe861a4e73a49b1e8bc17a391e47c93fde3#rd,2024-07-20 17:58:47,波形智能的研究团队提出了一种名为Agent Symbolic Learning的框架，该框架借鉴神经网络的反向传播和梯度下降算法，实现了对基于大模型的AI智能体的端到端训练。目前，智能体的创建和优化主要依赖人类专家，而该框架旨在推动智能体从“expert-centric”向“data-centric”的转变。通过将AI智能体解构为prompts、tools和agent pipeline，并将它们类比为神经网络的权重，研究团队使用文本和大模型来模拟损失函数、梯度和优化器，以实现对智能体的符号化训练。该框架允许对智能体的参数和工作流进行端到端的优化，代码已在GitHub上开源。实验结果显示，该框架在大模型和智能体的基准测试任务上表现优越，且支持智能体在环境交互中自主进化。
完蛋，我被数字同事包围了！小冰AI数字员工再升级，零样本定制，即时上岗,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926863&idx=1&sn=9865f7a4a3dca2ad458f0474902fb2a5&chksm=84e42b71b393a267cf2fb46fe915cd5e03008c823f361dec7ed602e8dbeea11184c0d1551c3e#rd,2024-07-19 12:26:48,小冰公司推出了“零样本”数字人技术，能够快速定制与真人无异的数字人，只需30秒画面、10秒音频，10分钟即可完成。这种数字人能够实时交互，并具有高质量、低延迟的音画传输能力。新技术基于超千亿大模型基座，减少了训练数据需求，实现了“立等可取”的定制服务。此外，小冰公司的AI数字员工产品线进行了升级，包括全新超千亿大模型基座、Agent构建框架和透影音画传输系统，旨在提供更精准的交互和适应商业场景。目前，小冰的数字人产品已广泛应用于多个行业，包括金融、地产、教育等，并且其技术已通过国家网信办备案。小冰团队致力于推动数字人技术的普及和商业化应用，为各行业赋能。
GPT-4o mini一手测评：懂得不多，但答得极快,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926863&idx=2&sn=4d75133db3b54837ccbe21ddbf1daa54&chksm=84e42b71b393a267dda426758e8fa3bf8dd87e737fd605e10a5e3410481d0fad497bc0d6db9d#rd,2024-07-19 12:26:48,OpenAI发布了新模型GPT-4o mini，该模型在MMLU上得分82%，在聊天方面优于GPT-4，在价格上比SOTA模型便宜一个数量级，商用价格分别为每百万输入token 15美分和每百万输出token 60美分。GPT-4o mini将替代GPT-3.5 Turbo，免费版、Plus版和Team用户从周四开始可以访问，企业用户下周开始。在WildBench测试中，GPT-4o mini排名第九，超过谷歌的Gemini-flash和Anthropic的Claude 3 Haiku。虽然在某些测试中，GPT-4o mini的表现不如GPT-4，但其响应速度非常快，主打日常任务的快速处理。
小模型卷起来了：Mistral联合英伟达开源12B小模型，128k上下文,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926863&idx=3&sn=eaca5d5dec6e914aa2e04d655b168d4f&chksm=84e42b71b393a26756c2fb6eee19566e2026fe0c5d0de57a47419d016db744d70364b5f3be6a#rd,2024-07-19 12:26:48,本文介绍了AI巨头OpenAI和Mistral AI发布的小型AI模型，这些模型正在成为AI领域的新战场。OpenAI推出了GPT-4o mini，作为GPT-3.5的替代品，提供在ChatGPT上的免费服务，其API价格大幅度降低，比之前模型便宜一个数量级。而Mistral AI与NVIDIA合作发布了Mistral NeMo，这是一个120亿参数的模型，拥有SOTA级别的推理能力和世界知识，尤其擅长多语言应用。Mistral NeMo的压缩效率和指令微调能力也得到了显著提升，可在多种语言和任务中表现出色。这些小型模型的优势在于更低的计算成本、便捷的训练和部署，适合计算资源受限和数据安全要求高的场景。这一发展预示着AI技术正向更高效、可本地部署的方向发展，为小型企业提供了利用AI能力的新机会。
华为GTS LocMoE+：高可扩展性亲和度 MoE 架构，低开销实现主动路由,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926863&idx=4&sn=2cd49bf5de146bd8afed19675d1ee8cc&chksm=84e42b71b393a26761f12092b12a6e39ab4ac9f752cc975ffdabaad4aef401ec9879ad81b098#rd,2024-07-19 12:26:48,华为GTS AI计算Lab的研究团队提出了一种新的MoE（Mixture of Experts）架构，名为LocMoE+，旨在提高大语言模型的训练效率。LocMoE+结合了传统的被动路由与低开销的主动路由策略，通过定义和量化专家与token之间的亲和性，实现更有效的token分派，从而提升训练效率。论文表明，这种自适应的双向路由分派机制可以在不牺牲模型效果的情况下，减少每个专家处理的token数量，提高训练效率，并减少显存占用。实验结果在昇腾910B3 NPU集群上得出，LocMoE+在不同规模的集群中平均提高了5.4%至46.6%的训练效率，并在通用知识和领域知识的评测集中展现出良好的性能提升。
LLama+Mistral+…+Yi=? 免训练异构大模型集成学习框架DeePEn来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926863&idx=5&sn=3278c6127d932411ba911fee7ee65746&chksm=84e42b71b393a267352261ea54017dc1bbf4aff9c2563ac5835c62fd8b4fec94082b8502018d#rd,2024-07-19 12:26:48,哈尔滨工业大学和鹏城实验室的研究人员提出了一种名为DeePEn的训练-free异构大模型集成学习框架，该框架在解码过程中融合多个大模型的输出概率分布，以实现更深层次的模型协作。这种方法解决了不同大模型之间的词表差异问题，无需额外训练，并在多个公开数据集上取得了显著性能提升。DeePEn通过构建相对表示空间和转换矩阵，将不同模型的概率分布映射并聚合，然后转换回主模型的绝对空间以确定输出。实验表明，DeePEn在不同任务和模型数量下都能提升性能，且大模型与专家模型的集成也有效增强了特定任务的性能。论文和代码已经公开。
GitHub星标超16万，爆火AutoGPT进阶版来了：定制节点、多智能体协同,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926719&idx=1&sn=81e6f019f046e86557ab03e0ee1f01c7&chksm=84e42a01b393a3171425e5663331b20a5838888b891df4083bb3760911b8fe9f92f5ac77ca88#rd,2024-07-18 13:07:17,新一代开源项目AutoGPT的Pre-alpha版本发布，旨在使构建、运行和共享AI智能体变得更加容易和可靠。该项目提供了两个主要组件：AutoGPT Server（后端），用于创建复合多智能体系统，以及AutoGPT Builder（前端），用于设计和部署智能体。关键特性是使用“块”来构建智能体，允许用户结合高度模块化的功能创建自定义行为。目前，项目已为Reddit发帖、Discord消息发送和维基百科摘要获取等任务提供预设块。虽然仍处于早期阶段，但AutoGPT已展示出其潜力，并将继续发展。
独家对话李岩：宿华、经纬、红点资金支持，第一个「生成式推荐」创业公司｜AI Pioneers,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926719&idx=2&sn=5091a87527b3958f2d9be50a230d03ae&chksm=84e42a01b393a3171c32b94a5e3042cb4a6b76f47dbe650ad08d5e9010641e32cab4b1195299#rd,2024-07-18 13:07:17,元石科技的创始人李岩，前快手AI体系的核心人物，近期推出了新产品“问小白”，这是一个基于自研LLM（大语言模型）的生成式内容社区产品，强调“生成式推荐”技术。李岩表示，与传统的推荐算法不同，生成式推荐能更智能地理解用户深层次需求，实现真正的“千人千面”，提高推荐效率，并通过大模型的训练赋予推荐算法“价值观”，引导用户获取优质信息。元石科技是首家在国内以LLM驱动的生成式推荐算法作为产品核心的创业公司，其投资人认为此技术有望优化内容行业的成本和效率。产品“问小白”结合了Feed流和Chat功能，旨在提供个性化、高质量的内容并建立与用户的深度交互。
OpenAI超级对齐团队遗作：两个大模型博弈一番，输出更好懂了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926719&idx=3&sn=c0b5e2d1b98f0aeeccd75845bd31be67&chksm=84e42a01b393a317c4698b0515d41ee767bc8ff39bededaa949ffe4d79b106f65e44b8c78976#rd,2024-07-18 13:07:17,OpenAI的研究发现，大型语言模型在生成答案时，如果只以正确性为目标，其输出的答案可能难以理解，导致人类评估时出错的可能性加倍。为解决这一问题，他们借鉴了“证明者-验证者博弈”的框架，让两个模型互相博弈，一个较强模型作为“证明者”生成答案，另一个较弱模型作为“验证者”检验答案的正确性。通过这种训练方法，模型的输出变得更易读且保持了合理正确性。优化后的模型在小学数学问题的解答上表现更佳，可读性提升，有助于人类用户更准确地判断答案的正确性。该研究强调了在保证AI模型性能的同时，提高输出的可读性和可验证性对于建立信任的重要性。
清华包揽最佳论文+时间检验奖，山大获荣誉提名，SIGIR 2024奖项出炉,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926719&idx=4&sn=364c3fd80e3f3085b6ff75c0f527638a&chksm=84e42a01b393a317a3e514b7c65fd98ecdbc6d1f24cc55510bc190841add309a0df39db8282e#rd,2024-07-18 13:07:17,在第 47 届 ACM SIGIR 大会上，清华大学、中国人民大学高瓴人工智能学院和小红书团队荣获最佳论文奖，他们的研究探索了密集检索模型的扩展定律。格拉斯哥大学和比萨大学的研究者获得最佳论文亚军，研究关注 ColBERTv2 的 PLAID 算法的可复制性。最佳论文荣誉提名奖由山东大学（青岛）、莱顿大学和阿姆斯特丹大学的研究者获得，他们的论文涉及生成检索和多向量密集检索的比较。时间检验奖授予了清华大学和加州大学圣克鲁斯分校的研究者，以表彰他们在可解释推荐系统领域的贡献。此外，清华大学的艾清遥和中国科学技术大学的王翔获得了 ACM SIGIR 青年学者奖。
ACL 2024 | 对25个开闭源模型数学评测，GPT-3.5-Turbo才勉强及格,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926719&idx=5&sn=25ffef042b1b5b8578ee903cb41e4362&chksm=84e42a01b393a317f45ffa1bbbb8785ba1738464bf4981e555d4a3812d590aa018cef7235bdb#rd,2024-07-18 13:07:17,研究人员设计了一个新的基准测试GSM-Plus，用于评估大型语言模型（LLMs）在解决基础数学应用题时的鲁棒性。尽管LLMs在一些数学推理基准测试中表现出色，但GSM-Plus的实验结果显示，即使是在GSM8K上表现优秀的GPT-3.5-Turbo，在GSM-Plus上的准确率也大幅下降。这项工作揭示了LLMs在处理数学问题时的局限性，尤其是在面对数值变化、算术变化和干扰项插入等扰动时。研究表明，尽管任务特定的优化可以提高准确性，但模型的鲁棒性更多地取决于基础模型和微调数据集的选择。现有的提示技术对于增强鲁棒性的效果有限，且LLMs在解决需要批判性思维的问题时表现较弱。
AKOOL助力戛纳广告大奖，发布革命性实时数字人平台,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926594&idx=1&sn=3a5f46992479f6d61aaf602cb6263252&chksm=84e42a7cb393a36ad3230a700874ae283b63018548cff6bea849185204a975722f1894b86779#rd,2024-07-17 12:04:23,法国电信公司Orange的一则使用人工智能生成虚拟角色的足球比赛视频走红，并赢得戛纳国际创意节体育类大奖，其中AKOOL公司提供了核心技术支持。AKOOL开发的AI面部捕捉系统能精确捕捉人脸表情和动作，创造出几乎以假乱真的虚拟人物。现在，AKOOL进一步发展实时数字人技术，应用于直播、教育、客服和营销等领域，提供高度真实的互动体验。他们的实时数字人平台提供多样化的模板和声音定制，并集成先进的人工智能算法以提高交互性和真实性。此外，AKOOL还关注技术的滥用风险，正在研发Fake视频鉴别功能。公司创始人吕家俊表示，他们正在探索的数字克隆技术可能成为保存个人智慧的新方式。
早半年发arXiv，却被质疑抄袭：活在微软AutoGen阴影里的CAMEL,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926594&idx=2&sn=eb2386d1be25e19e6c0a5f6f4d66dbb9&chksm=84e42a7cb393a36a436f1db460e275cbefa3d311dde778703e77a8002217978df3d315d469e7#rd,2024-07-17 12:04:23,这篇文章讲述了关于微软的开源项目AutoGen和另一篇论文CAMEL之间的争议。CAMEL的作者李国豪指出，AutoGen的论文与其工作高度相似，而AutoGen在论文正文中仅在附录中提及CAMEL，这导致CAMEL的工作被忽视。尽管AutoGen在附录中指出了与CAMEL的差异，但这种做法在ICLR的审稿人和领域主席看来是不妥的，因为附录的审查级别不同于主论文。AutoGen的作者辩解称，由于CAMEL在提交时未在同行评审期刊上发表，根据ICLR的规定，他们没有义务引用。尽管存在争议，AutoGen论文最终因其他原因被ICLR拒稿，但作者在LLM Agent Workshop上获得了最佳论文奖。李国豪希望通过公开讨论引起学术界对这个问题的关注。
快手开源LivePortrait，GitHub 6.6K Star，实现表情姿态极速迁移,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926594&idx=3&sn=7d44eac3409c6c2d5587ef80d7575a69&chksm=84e42a7cb393a36a0da7b8d223f28c5ed51095e53a449ea8e341ddd5f71576595776c02109b6#rd,2024-07-17 12:04:23,快手可灵大模型团队开源了名为LivePortrait的实时人像视频生成框架，该框架能将表情、姿态从驱动视频迁移至静态或动态人像视频，生成具有表现力的视频。LivePortrait采用基于隐式关键点的框架，通过视频-图片混合训练策略、网络结构升级和动作建模优化提升生成质量和可控性。该框架在GitHub上获得广泛关注和好评，其模型在RTX4090 GPU上的单帧生成速度达到12.8ms，具有较高的效率。LivePortrait已在多项快手业务中落地，并计划进一步探索多模态驱动的人像视频生成。
Mistral AI两连发：7B数学推理专用、Mamba2架构代码大模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926594&idx=4&sn=8c1d2e56a5e24744416819dffe8b64e1&chksm=84e42a7cb393a36ac70a36c42a3bb2ffd3865b842dfd5a0d7c9d757d5c6eabc15bfefac3239a#rd,2024-07-17 12:04:23,法国AI公司Mistral AI发布了两个大模型：Mathstral专注于数学推理和科学问题，能在高级数学问题上进行复杂逻辑推理，性能优秀；Codestral Mamba是用于代码生成的模型，基于Mamba架构，具有线性时间推理优势，适合处理长序列输入。Mathstral在MATH数据集上达到56.6%的通过率，优于其他模型，而Codestral Mamba在HumanEval基准测试中表现优于CodeLlama和CodeGemma。这两个模型都在HuggingFace上开源，并可在Mistral的API平台上免费试用。
无损加速最高5x，EAGLE-2让RTX 3060的生成速度超过A100,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926594&idx=5&sn=fe8b52b499e3d3a3ef73a543e77385f1&chksm=84e42a7cb393a36a53d18bd5edb772cc184a5c5863f126d424d54e49e62c8b89da08ef1406e0#rd,2024-07-17 12:04:23,研究人员提出了EAGLE-2，一种新的动态草稿树投机采样方法，用于加速大语言模型（LLMs）的推理，最高可将速度提高5倍，同时保持输出质量。EAGLE-2通过根据草稿模型的置信度动态调整草稿树结构，优化了静态草稿树的效率问题。实验表明，EAGLE-2在多项任务和大语言模型上均表现出最佳的加速效果和平均接受长度。该方法已经在工业界得到应用，例如在Intel/intel-extension-for-transformers中集成。
全程免费！「真格星球AI+创业营」与十数位大咖导师一道，碰撞AI灵感、寻找落地商机,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926373&idx=1&sn=b1756dd5e3a9906f4bb444db31be5dbe&chksm=84e4295bb393a04d9c801d3516a5031020f0d430eb4e6d10ce932d27ecbc3088c532e6cf25e4#rd,2024-07-16 12:25:43,真格星球ZhenPlanet是一个由真格基金主办的前沿科技人才孵化项目，致力于帮助科技领域的创业者将科技成果转化为商业产品。项目自2019年起已成功举办四期，涉及AI、3D资产生成、LLM技术等多个领域。第五期AI+创业营将于2024年8月2日启航，提供免费的创业指导、资源对接和资本支持。活动包括导师分享、小组讨论、头脑风暴和DemoDay等环节，邀请行业专家和明星投资人组成导师团，帮助参与者探索AI的无限可能。报名现已开放，欢迎科技创业者申请加入。
太酷了！iPhone、iPad、MacBook老旧设备组成异构集群，能跑Llama 3,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926373&idx=2&sn=0e354f8ad01b23a205dd653ed8bfe960&chksm=84e4295bb393a04d12f7b2574b3cfa99981d5c09a7c0bdf9855aefd7046e0ddfdc7ff9e7df62#rd,2024-07-16 12:25:43,这篇文章介绍了一个使用消费级硬件设备（如iPhone、iPad、Macbook和NVIDIA显卡）构建的异构集群推理方案，通过一个名为Cake的Rust框架，实现了大模型（如Llama3）的分布式推理。Cake能够将transformer块分片到多个设备，使得不适合单个设备GPU内存的模型也能运行推理。该框架支持多种操作系统，包括iOS、Android、macOS、Linux和Windows。用户可以通过编译安装Rust和运行特定命令来设置worker和master节点。此外，文章还提到了内存和磁盘空间的优化方法。最后，文章提到了一个关于AIGC的直播活动。
公理训练让LLM学会因果推理：6700万参数模型比肩万亿参数级GPT-4,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926373&idx=3&sn=3cce30f5d08766ad42da27ef5624e684&chksm=84e4295bb393a04dcefa0d798cbaf8c994b9e4df6b684b8846a903563a5d8f03c00644031d80#rd,2024-07-16 12:25:43,研究人员发现，通过在小规模图谱上展示因果传递性公理，训练的Transformer模型可以泛化到大型图谱的传递性公理。这项研究提出了一种基于公理训练的新框架，允许模型通过符号演示学习因果推理，而不仅仅是依赖特定数据分布。这种方法有可能使模型在不同场景下进行因果推理，而不局限于特定任务。实验表明，使用这种方法训练的模型可以应用于更复杂的因果推理问题，甚至在某些情况下展现出与大型语言模型相当的性能。这项工作为AI学习因果推理提供了一种新途径，能够促进AI在数学和科学研究中的应用。
谷歌机器人专家：机器人在现实中碰过的壁，AI也会碰,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926373&idx=4&sn=05be6d6698d9168e5b277ecb4e5a32ad&chksm=84e4295bb393a04d51fb42a50f54415a27a4dd8ed868435011158d336ba8efad5f364592f83a#rd,2024-07-16 12:25:43,谷歌DeepMind的机器人科学家Alex Irpan在一篇博客中表示，机器人技术的进展看似缓慢，主要是因为机器人需要应对现实世界的复杂性，这种问题也同样存在于大语言模型（LLM）等技术中。Irpan认为，现实的复杂性和不可预测性是机器人技术面临的主要挑战，这些问题并不局限于机器人领域，而是所有与现实世界交互的软件都会遇到。他引用了游戏中AI的例子，说明即使在受控环境中，面对现实的全局可变状态和对抗性噪声，AI的行为也可能变得不可靠。随着LLM在现实世界中的应用增加，这些技术也将面临类似机器人技术的困难。Irpan强调，随着AI的发展，我们需要更好地评估模型在现实世界中的性能，而机器人学家在应对这些挑战方面可能已经积累了经验。
抛弃视觉编码器，这个「原生版」多模态大模型也能媲美主流方法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926373&idx=5&sn=0b62ed5533e22377f65542d3924ccd52&chksm=84e4295bb393a04d162ee0da571953ef0ac9620d29ac49ff79654532e065132a06e683070824#rd,2024-07-16 12:25:43,这篇文章介绍了北京智源人工智能研究院和大连理工大学等机构的研究团队推出的新一代无视觉编码器的视觉语言模型 EVE。EVE 旨在打破传统的多模态模型架构，通过精细化的训练策略和额外的视觉监督，将视觉和语言的表征、对齐和推理整合到一个纯解码器架构中。EVE 在多个视觉语言基准测试中表现出色，优于同类的 Fuyu-8B 模型，并接近基于视觉编码器的主流方法。模型的训练成本较低，使用公开数据并在有限的计算资源下完成训练。EVE 提供了一条透明且高效的途径，为纯解码器的原生多模态架构的发展提供了新思路。未来的研究方向包括性能提升、无编码器架构的潜力探索和原生多模态模型的构建。
阿里妈妈给出了什么样的赛题，被顶会NeurIPS 2024 pick了？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926194&idx=1&sn=77809296660a586a4334df07f58ae6e2&chksm=84e4280cb393a11a9dde6ea185e83a2ad8eb5aacd92762d0dd11f2a0c260ce93d507ed2dc04a#rd,2024-07-15 11:49:49,"NeurIPS是人工智能领域的顶级会议之一，被喻为《甄嬛传》中的“后位”。会议不仅以发表开创性论文如AlexNet、Transformer、GPT-3而知名，还举办了一系列具有广泛科学研究价值的竞赛。今年的NeurIPS包含16个竞赛题目，由NeurIPS官方在6月份公布。其中，由中国北大-阿里妈妈人工智能创新联合实验室提出的“大规模拍卖中的自动出价”赛题获得了高度评价，成为国内工业界今年唯一主办的NeurIPS比赛。

该赛题聚焦于自动出价系统在大规模拍卖中的应用，与在线广告市场密切相关，具有巨大的研究和商业价值。自动出价系统在广告拍卖过程中起到关键作用，需要处理复杂的实时数据和不确定性，并在竞争环境中做出最优决策。赛题评价为“实际意义重大，组织良好，测试良好”。

自动出价技术的发展经历了从经典控制到强化学习，再到生成式AI的演进。北大-阿里妈妈实验室提出了基于生成式模型的AIGB（AI Generative Bidding）策略，以解决强化学习在长序列决策场景中的局限性。实验室希望通过比赛，借助社区力量共同推动决策智能领域的发展，特别是生成式AI在自动出价问题中的应用。

比赛分为AIGB赛道和通用赛道，参赛者有机会赢取奖金、实习机会和研究资源。大规模的博弈数据将提供给参赛者实践和研究的机会。"
赶时髦的 AIGC 营销人，如何实现「里子」与「面子」的双赢？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926194&idx=2&sn=2d099be87a5dd2908a8021a90a4c056c&chksm=84e4280cb393a11a3ca4d0f07353fdd55bd8fc087401223f3eccd4eb0d42c8d50c945cfb5159#rd,2024-07-15 11:49:49,这篇文章提到AI在营销领域的广泛应用，特别是在内容创作和创意开发方面，近半数的广告主企业已经采用AIGC技术。然而，这种技术也带来了一些挑战，如内容风险和可能的黑产利用。《AIGC体验派》第五期节目将探讨如何在AIGC营销中平衡创新和安全，邀请了火山引擎和NVIDIA的专家来分享解决方案。节目将讨论如何确保AIGC生成内容的质量和安全，以及如何防止营销活动被黑产利用。直播将于7月17日19:00-19:40举行。上一期节目则关注了AIGC如何通过个性化提升电商直播的转化率。
微软开源的GraphRAG爆火，Github Star量破万，生成式AI进入知识图谱时代？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926194&idx=3&sn=80ad88d4ab72da10e3f093effa8abf94&chksm=84e4280cb393a11a80179970f90e95c3733008fa0e43ee655e76c9abc53ada6824855b4c3af3#rd,2024-07-15 11:49:49,微软开源了名为GraphRAG的检索增强式生成（RAG）知识库方案，用于提升语言模型（LLM）的生成质量和结果的有用性。GraphRAG使用LLM生成知识图谱，改善了复杂信息的问答性能，特别是在处理私有数据时。相比于传统的RAG，GraphRAG在需要连接不同信息片段和理解大型数据集的语义概念时表现更优。尽管GraphRAG的概念和内容可能较难理解，但研究表明，它在很多问题上的回答质量优于仅使用向量的RAG，并且在开发和解释性上具有优势。随着工具的不断改进，使用知识图谱的GraphRAG可能成为RAG应用的首选架构。
登顶开源AI软件工程师榜首，UIUC无Agent方案轻松解决SWE-bench真实编程问题,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926194&idx=4&sn=670ae49d7e08778181222b3d001a9e15&chksm=84e4280cb393a11acacb57a34c1798ec4f04c5fbbb6afd1e7d899aa762df96ded3cac3e705e4#rd,2024-07-15 11:49:49,伊利诺伊大学香槟分校（UIUC）张令明老师团队提出了 OpenAutoCoder-Agentless，一个简单高效的无 Agent 方案，用于自动解决软件开发问题。该框架使用两阶段方法定位和修复代码库中的错误，成本低且完全开源。Agentless 在 GitHub 上获得广泛关注，并在与现有 AI Software Agent 的比较中展现出优越性能，解决了 27.33% 的问题，超越所有开源方案。此外，研究者还对 SWE-bench Lite 数据集进行了分析，提出严格的问题子集 SWE-bench Lite-S，以更准确地评估自动软件开发工具的能力。研究团队认为，Agentless 可能成为现有工具的补充，并呼吁社区重新考虑软件工程 Agent 的设计和评估标准。
MotionClone：无需训练，一键克隆视频运动,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926194&idx=5&sn=fa2278505df7ba2f07a70c040dbf49a5&chksm=84e4280cb393a11a048456817e7ea026000d6909aeedcc139f3467de6292180b77f3d5627409#rd,2024-07-15 11:49:49,本文介绍了MotionClone，一个新提出的框架，能够无需训练或微调，从参考视频中提取运动信息，并将其与文本提示结合，生成具有定制化运动的文本到视频（text2video）内容。MotionClone的优势在于不需要额外的训练或微调，提高了运动泛化能力和视频生成质量。通过主成分时序注意力运动指导，它能过滤噪声，有效克隆参考视频的运动，同时，空间语义修正机制确保了运动与文本意图的一致性。实验结果表明，MotionClone在多个指标上超越了现有的运动迁移方法，为文生视频模型提供了即插即用的运动定制方案。
直击真实的甲方AGI需求，人工智能赋能产业融通发展论坛顺利召开,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926083&idx=1&sn=9c233340828bc557ea22a7d4a6b5fbcd&chksm=84e4287db393a16b6b7c2930c6c7f360c33f19dd11aabc6940805c4e3c14af1fcc7fc3454988#rd,2024-07-14 12:24:22,2024年WAIC人工智能赋能产业融通发展论坛在上海世博展览馆举行，探讨了人工智能在新型工业化和产业融合中的应用。论坛涉及领导致辞、签约仪式、主题演讲和圆桌论坛等环节，吸引了众多央国企和人工智能企业参与。中国电子信息产业发展研究院在致辞中强调了人工智能的重要角色，国家电网客服中心和中国电子信息产业发展研究院签署了战略合作协议，以提升电力智能服务。演讲嘉宾讨论了大模型在电力、能源、油田等领域的应用，以及人工智能在企业内部效率提升和知识管理等方面的作用。中国移动研究院介绍了其在人工智能领域的发展战略，南方电网数字电网集团提出了人工智能在电能量数据创新应用的技术需求。圆桌论坛上，与会代表分享了人工智能在新型工业化中的实践经验，强调了大模型的潜力和挑战。论坛展示了人工智能在赋能产业转型和促进创新发展中的积极作用。
非法阻止员工披露AI安全风险，OpenAI严厉「封口协议」再遭举报,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926083&idx=2&sn=89a602fc0951b4588fc94e4ac2934243&chksm=84e4287db393a16b51148c989d41d50e20790d9526ea2c31c27cd6d0b617c5515ba157211f0c#rd,2024-07-14 12:24:22,OpenAI，知名人工智能公司的内部项目「草莓（Strawberry）」正在开发一种新的人工智能模型。然而，该公司目前面临举报人向美国证券交易委员会（SEC）提出的投诉，指控OpenAI的雇佣、遣散费和保密协议过于严格，可能阻止员工向监管机构警告其技术可能对人类构成的严重风险。举报人称这些协议可能违法，并呼吁进行调查。OpenAI发言人表示，公司保护员工的披露权利，并已修改离职流程以删除非贬损条款。此前，OpenAI的员工离职协议曾因可能剥夺前员工股权而受到批评。
数据匮乏仍是通用具身智能面前的高墙吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926083&idx=3&sn=dc270cbb6aa6abfe93690fc0c491cfd1&chksm=84e4287db393a16b01775bab06afc7800b890f925096030ae2556af9c513c1dc4477cd24fc85#rd,2024-07-14 12:24:22,"这篇会员通讯主要探讨了三个AI和Robotics领域的热点议题。首先，文章讨论了通用具身智能面临的挑战，特别是数据匮乏问题。MIT博士生陈博远指出，缺乏包含动作模态的数据是主要难题，但只要有足够的高质量机器人数据，模型可以实现泛化。当前的努力主要集中在灵巧性和泛化性的提升，但数据采集效率低和成本高是主要障碍。上海交大的卢策吾教授和北大CGCS的王鹤博士也提出了关于构建世界模型和数据收集方法的观点。

其次，通讯回顾了2024年上半年中美科技巨头的AI应用，分析了AI大模型应用的进展和科技巨头之间的布局差异，探讨了未来可能出现的超级应用。

最后，文章介绍了 Anthropic CEO的访谈，讨论了AI模型训练成本上升的问题，以及该公司在平衡性能和成本上的策略，以及对AI伦理与治理的思考。

此外，通讯还包含了29项本周AI和Robotics领域的其他重要事件，包括技术进展、国内外动态等。"
Meta开发System 2蒸馏技术，Llama 2对话模型任务准确率接近100%,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926083&idx=4&sn=10bfb96e3081c48109e99662009f0570&chksm=84e4287db393a16ba5aab9befb8e54ad20c8f4bbdc7d2f1f8dd4eff0b1431c6f69bc7086affe#rd,2024-07-14 12:24:22,Meta FAIR的研究者探索了一种将AI模型的深思熟虑（System 2）推理编译到自动化（System 1）的方法，称为System 2蒸馏。该方法无监督地测量预测质量，并在System 2方法足够一致时将其添加到蒸馏池中，然后微调System 1以匹配这些预测，但不生成中间步骤。实验表明，这种方法可以在多种设置下将System 2推理蒸馏回System 1，有时甚至超越System 2教师的结果，同时降低了推理成本和响应延迟。然而，对于需要复杂思维链的数学任务，某些任务可能无法有效地蒸馏到System 1。
7B最强长视频模型！ LongVA视频理解超千帧，霸榜多个榜单,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926083&idx=5&sn=ac0ac7beb851f0916d08a886867b18ea&chksm=84e4287db393a16b4d4e58bf2df88c4c0e696c6a9a7953cb0789b8ac2eb35270176dbc73c059#rd,2024-07-14 12:24:22,LMMs-Lab和新加坡南洋理工大学的研究团队推出了一种名为LongVA的新型长视频模型，能够处理超过2000帧的视频数据，解决了现有模型在处理长视频时面临的视觉token数量过多的问题。研究团队提出了“长上下文迁移”技术，通过扩展语言模型的上下文长度，无需长视频训练即可处理和理解超长视频。LongVA在Video-MME和MLVU基准测试中表现出色，分别达到7B规模的SoTA和仅次于GPT-4o的性能。研究团队还创建了Visual Needle-In-A-Haystack (V-NIAH)基准测试来评估长视频视觉上下文长度。
大厂掀起视频生成「军备竞赛」，AI 真能干掉好莱坞？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926061&idx=1&sn=ad9024e7718594bd81baa99c3adc5ee7&chksm=84e42f93b393a6858b59efe7f55acde723044b0ab5bf708b56d548961395b4d60d8b56a366b8#rd,2024-07-13 11:29:52,这篇文章是关于2024年世界人工智能大会（WAIC）上的一场论坛，论坛聚焦于AI视频生成的前沿技术。论坛汇集了阿里巴巴达摩院、上海交通大学、美图公司和Haiper AI等机构的专家，探讨视频生成技术的最新进展和产业应用。阿里巴巴达摩院发布了寻光视频创作平台，旨在提升视频制作效率和内容控制。上海交通大学的倪冰冰教授提出了矢量化媒体内容生成技术来解决现有生成算法的挑战。美图公司的陈剑毅强调了内容质量和用户需求的重要性，并介绍了AI短片创作平台MOKI。Haiper AI的缪亦舒认为视频生成是通向通用人工智能的重要步骤。论坛还包括两场圆桌讨论，参与者讨论了视频生成技术的提升路径、商业落地挑战以及创新机会。整体上，论坛展示了AI视频生成技术的快速发展和潜在应用，同时也指出了技术尚处在早期阶段，需要解决控制性和商业化的问题。
OpenAI Lilian Weng万字长文解读LLM幻觉：从理解到克服,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926061&idx=2&sn=483fddb895606ca244a5dd2c962e4166&chksm=84e42f93b393a6855cd843350ad01eac1ba293f47d34c68ab3bba6e8cabe58a525c68a4038b7#rd,2024-07-13 11:29:52,这篇博文介绍了大型语言模型（LLM）在生成内容时可能出现的“幻觉”问题，即模型生成不真实、虚构或不一致的信息。幻觉分为上下文幻觉和外源性幻觉。文章探讨了幻觉产生的原因，包括预训练数据的问题和微调阶段引入的新知识，以及检测和克服幻觉的方法，如检索增强式评估、事实性检测、采样方法等。此外，文章还提到了针对模型进行校准和微调以减少幻觉的方法，如RAG、编辑和归因动作链等。最后，文中列举了一些相关的评估基准，用于衡量模型的事实性和幻觉行为。
Gemini 1.5 Pro装进机器人，参观一遍公司就能礼宾、带路,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926061&idx=3&sn=ea1461a32df12095be043c26612fcf8d&chksm=84e42f93b393a6858bafa5dfff3b9b0a4b069f3cbc87f6859959dab34df946f6d7de8d154c6c#rd,2024-07-13 11:29:52,谷歌DeepMind的最新研究展示了如何使用名为Gemini 1.5 Pro的大模型来提升机器人的导航和理解能力。该模型的长上下文能力使得机器人能够在复杂的环境中记忆和理解细节，例如在办公室场景中遵循人类指令找到特定地点。通过一种名为Mobility VLA的导航策略，机器人能够结合自然语言和视觉指令进行多模态指示导航。这项工作代表了人机交互的进展，未来可能使用户能够通过简单的视频示范让机器人理解并导航环境。研究表明，这种结合长上下文大模型和拓扑图的方法在复杂的导航任务中表现出色，提高了成功率，并且能够处理含糊的指令。
豆包大模型团队发布全新Detail Image Caption评估基准，提升VLM Caption评测可靠性,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926061&idx=4&sn=5f58f289b76c497cd7c1ba5b405f2207&chksm=84e42f93b393a6856c7573f255f87adc7d46ed4244f21da8d9cc5ff548810d002a21ad1084dc#rd,2024-07-13 11:29:52,中国科学院、北京大学和字节跳动的豆包大模型团队发布了一个新的数据集DetailCaps-4870，旨在更好地评估视觉语言模型（VLM）的基础理解能力，特别是detail image caption的任务。当前VLM的评测主要依赖于问答形式，而新提出的CAPTURE（CAPtion evaluation by exTracting and coUpling coREinformation）指标专注于评估caption的细节和准确性，减少了对指令遵循能力和人类偏见的影响。CAPTURE通过抽取和匹配关键信息来计算caption的质量，与专家评价的一致性更高，且成本相对较低。此外，研究团队还提出了一种利用LVLM自身能力进行detail caption数据合成的方法，以提高数据质量。实验结果显示，CAPTURE指标在评估LVLM的detail caption性能方面表现优越，且开源LVLM模型如InternVL-1.5在使用这种方法后，detail caption性能得到提升。
端侧设备AI代理优化框架问世，领域内准确率可达97%,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650926061&idx=5&sn=05413f75c9b3eda5308f401c4248ab8c&chksm=84e42f93b393a685d77850724f7cd23088962f1f376897e0d4c191b6dcc0803909adc2a22be7#rd,2024-07-13 11:29:52,这篇文章介绍了NEXA AI团队和MIT-IBM Watson AI Lab合作开发的一种高效的设备端AI规划-行动框架，名为Octo-planner。该框架将规划和行动执行分为两个组件：优化后的边缘设备计划代理（Octo-planner）和使用Octopus模型执行函数的行动代理。为了在资源受限的设备上提高性能，他们采用模型微调而非上下文学习，以减少计算成本和能耗，同时提高响应时间。这种方法利用GPT-4生成和验证规划数据，并在微调后的模型上实现了97%的成功率。此外，他们还开发了一种多LoRA训练方法，以处理多域查询，同时保持设备端的计算效率。这项工作旨在促进设备端AI代理的实用性和可访问性，为AI在各个领域的应用提供更高效、低成本的解决方案。
字节跳动筋斗云人才计划开启,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925868&idx=1&sn=60741798f8607501f489fc5a664981cd&chksm=84e42f52b393a644a7915ae3cd990e31ff27dfcdede6c8dde5bf7bf05a30b06042fb2a51f504#rd,2024-07-12 12:10:41,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我会尽忙为您生成摘要。
五年后的今天，训练GPT-2只需不到700刀、24小时，Karpathy又整新活,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925868&idx=2&sn=459b8004bb5fcaa9aa40f7c528ea43e4&chksm=84e42f52b393a64428dd1d7bbff5e907a949a2c08e1742fb9f601502d731edd4d4ba889a7584#rd,2024-07-12 12:10:41,前特斯拉 Autopilot 负责人、OpenAI 科学家 Andrej Karpathy 纯 C 语言复现 GPT-2 大模型，仅用 672 美元和 24 小时在 8XH100 GPU 节点上即可完成。对比五年前，训练成本大幅下降，算法基本保持原样，硬件、软件和数据质量的改进是主要原因。Karpathy 透露 GPT-2 当年训练成本可能是这次的 100 倍，即约 10 万美元。该项目名为 `llm.c`，代码简洁，可以直接在 C/CUDA 中训练 GPT 模型，目标是为初学者提供了解大语言模型的教育材料。目前，Karpathy 正在研究 fp8、推理、微调、多模态等方面的改进。
英伟达又赚到了！FlashAttention3来了：H100利用率飙升至75%,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925868&idx=3&sn=fae16a9ac8df3d922cdd4ff5d3674c7d&chksm=84e42f52b393a644207a12fddec0614db520ed6a26deb5fc5a87643ffcfdd3a46c68da61207f#rd,2024-07-12 12:10:41,研究者推出了FlashAttention-3，这是一种快速且内存高效的注意力算法，旨在加速大型语言模型（LLM）的注意力计算。FlashAttention-3利用了加速Hopper GPU的三种技术，包括warp-specialization、交错分块matmul和softmax运算以及硬件支持的FP8低精度处理。相较于FlashAttention-2，其速度提高了1.5-2.0倍，达到740 TFLOPS，理论最大FLOPS利用率提升到75%。在FP8精度下，速度接近1.2 PFLOPS。这些改进使得LLM可以处理更长的上下文，提高GPU利用率，并在低精度下保持性能，有望加速训练和运行速度，降低成本。
ICML 2024 | 梯度检查点太慢？不降速、省显存，LowMemoryBP大幅提升反向传播显存效率,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925868&idx=4&sn=87a3db37f611973ab650aff0e9e2fb48&chksm=84e42f52b393a644fb0e8476a2e27bd381aed6ff2be3b01163875bc5ab0fd14a7f8d75035d6c#rd,2024-07-12 12:10:41,"南开大学徐君老师团队在ICML 2024上发表的论文提出了两种反向传播改进策略，Approximate Backpropagation（Approx-BP）和Memory-Sharing Backpropagation（MS-BP），统称为LowMemoryBP，以显著减少Transformer模型微调时的峰值激活显存占用。Approx-BP通过分段线性函数逼近激活函数，减少激活存储需求，而MS-BP通过重新设计的MS-LayerNorm和MS-RMSNorm层实现激活张量的共享，降低显存冗余。实验显示，LowMemoryBP能在不牺牲训练速度和精度的情况下，使包括ViT, LLaMA, RoBERTa, BERT, Swin在内的模型微调显存占用降低20%~30%。"
首个视频思维链推理框架Video-of-Thought来了：像人一样从感知到认知全面推理视频,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925868&idx=5&sn=7bd65a35468d79c183161e1db66b2341&chksm=84e42f52b393a644ee85d0b97ad85ea97d0238e51dc89ffce6d8c65fff66769815d2a5640e15#rd,2024-07-12 12:10:41,"新加坡国立大学、南洋理工大学和哈工深的研究人员提出了一种新的视频推理框架，名为视频思维链（Video-of-Thought，VoT），该框架显著提升了视频多模态大语言模型在复杂视频理解与推理的能力。这一工作被ICML 2024录用为Oral paper。VoT受到人类理解视频方式的启发，强调了像素理解的感知能力和语义理解的认知能力，将视频推理分解为一系列子问题，通过时空场景图（Spatial-Temporal Scene Graph, STSG）辅助推理。实验结果显示，VoT在多个复杂VideoQA数据集上超越了当前所有传统视频MLLM以及CoT方法的表现，并在零样本设置下展现出更强的性能。此外， VoT的推理过程可解释性强，错误率较低，能适应复杂的视频理解和推理任务。"
18个月326项能力，这家大厂猛猛上新生成式AI，如今纯靠Prompt就搞定企业级应用了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925762&idx=1&sn=4a06d65dfc38ffb11f9a7512ddad5519&chksm=84e42ebcb393a7aa046903837c00ad115a764930a04e8ac99426d528b8048251470e94060237#rd,2024-07-11 15:45:05,亚马逊云科技在纽约峰会上发布了一系列生成式AI技术，旨在降低企业使用大模型的门槛和成本。过去18个月，亚马逊云科技发布的机器学习和生成式AI功能是其他主要供应商总和的两倍多。亚马逊云科技的基础模型平台Amazon Bedrock支持33个基础模型，并提供了微调功能以定制模型，以适应企业需求。新发布的Claude 3 Haiku微调和检索增强生成（RAG）等技术提升了模型的灵活性和专业化。此外，Amazon Bedrock的知识库和Guardrails功能增强了模型的安全性和个性化。亚马逊云科技还推出了Amazon App Studio，这是一款无代码工具，能够几分钟内创建企业级应用程序，简化了传统开发流程。Amazon Q则为不同技术水平的用户提供生产力工具，简化机器学习模型的开发和应用程序创建。亚马逊云科技的这些进展显示了其在生成式AI落地应用方面的努力和领先地位。
GitHub 8k Star，一作实习生，字节这个大模型成果被苹果选中了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925762&idx=2&sn=bfc32d092f417fc8bce69d4a5cf6f3c3&chksm=84e42ebcb393a7aa6dfc6900272dd537d193e1737373fa0934d9010ee043ed5248d84955db21#rd,2024-07-11 15:45:05,字节跳动大模型团队开发的深度估计模型Depth Anything V2已被苹果公司收入Core ML模型库。Depth Anything是一种用于单目深度估计的模型，有25M到1.3B的不同大小版本，适用于多种领域，如视频特效和自动驾驶。相较于V1，V2版本在细节处理和鲁棒性上有所增强，且速度上有显著提升。苹果的Core ML框架允许模型在iOS和MacOS设备上离线运行复杂AI任务，提高用户隐私和减少延迟。论文一作是团队实习生，Depth Anything V2的Core ML版本在iPhone 12 Pro Max上的推理速度达到31.1毫秒。团队依据Scaling Laws，专注于单一任务以实现更好的效果，选择了深度估计任务，因为它是一项基础且应用广泛的计算机视觉任务。该模型的训练过程包括设计数据引擎、使用预训练编码器等方法，以解决未标注数据的挑战。后续的优化工作关注于模型的细节处理和规模扩大，最终提升了模型的性能和泛化能力。论文一作在实习期间完成了大部分工作，体现了团队对实习生的培养和支持。
这些VLM竟都是盲人？GPT-4o、Sonnet-3.5相继败于「视力」测试,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925762&idx=3&sn=a4b23bbed70ef4be3c810251f688f339&chksm=84e42ebcb393a7aa50651b5505c6a5f38aeff817352b34f0039d284e87edfaacb2502cffca39#rd,2024-07-11 15:45:05,研究人员发现，尽管视觉语言模型（VLMs）在某些任务上表现出色，但它们在处理一些基本的视觉问题时表现不佳，例如数线条交点、判断图形位置关系或识别被圈出的字母。这些模型在处理需要精细视觉判断的任务时显得“近视”，细节在它们看来是模糊的。研究人员设计了一套“视力测试”来评估VLMs，结果表明，即使是最先进的模型，如GPT-4o、Gemini-1.5、Sonnet-3和Sonnet-3.5，也在这些简单的视觉任务中表现得并不理想。这表明，尽管VLMs在某些方面显示出智能，但它们的视觉处理能力仍有限，可能更多地依赖于记忆和模式识别，而不是真正的人类般的视觉感知。
ControlNet作者又出爆款！一张图生成绘画全过程，两天狂揽1.4k Star,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925762&idx=4&sn=6cc2bdc876d43f9beeae94a27e76d4d1&chksm=84e42ebcb393a7aabe3ef8a23efe510eec4b3b800b8a08d4dd44b815ec8f8183bd436c7cc34c#rd,2024-07-11 15:45:05,本文介绍了PaintsUndo，这是一个新项目，能够将静态图像转化为绘画过程的视频。用户输入一张图片，PaintsUndo会自动生成从线稿到成品的完整绘画视频，适用于不同风格的图像。项目作者使用一系列模型来复现人类绘画行为，包括素描、上墨、着色等。PaintsUndo提供了简单的本地部署步骤，并发布了两个模型：单帧模型和多帧模型。单帧模型用于生成关键帧，多帧模型则用于这些关键帧之间的插值，以创建更长的视频。虽然目前处理复杂构图存在困难，但该项目仍在持续改进中。
CVPR'24 Highlight｜一个框架搞定人物动作生成，精细到手部运动,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925762&idx=5&sn=61a34ea33ca4c2a23e0675bb6e0a672c&chksm=84e42ebcb393a7aad1b1bd652c2bd718955608f26653c3dcaddba9f01f89ccbc20ad1ef7bc37#rd,2024-07-11 15:45:05,北京大学和北京通用人工智能研究院的研究人员提出了一种使用自回归条件扩散模型的动作生成框架，该框架能生成符合场景约束、具有语义的真实人物动作。研究中还发布了大规模人物-场景交互数据集TRUMANS，包含15小时的动作数据和详细的场景与动作标注。这一方法考虑了场景和动作类别作为条件，解决了现有工作对场景约束处理不足的问题。通过空间占有网格和局部场景感知器，模型能生成符合路径和物体交互要求的动作。实验表明，这种方法在生成多样性和场景适应性方面表现出色。
藏身幕后的巨人，正将工业AI带入下一阶段,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925512&idx=1&sn=79f28db4676b1b578a08c4fb9aabee79&chksm=84e42db6b393a4a060bd8e73b61305d3a7f95001df39decf016c11a73b643256225fc3e4807c#rd,2024-07-10 12:18:35,这篇文章介绍了西门子在工业人工智能领域的创新应用，特别是其Industrial Copilot产品，这是一种使用自然语言处理技术的生成式AI工具，能够帮助工程师更高效地编写工业代码和解决设备问题。西门子还展示了在绿氢行业的新软件工具，以及正在开发的工业时序数据基础模型。通过将AI与工业场景深度融合，西门子提高了工作效率，例如在成都的数字化工厂中，AI被用于质量检测和垃圾处理等场景。文章强调了工业数据质量和行业知识在AI应用中的重要性，西门子凭借其在硬件和软件领域的全面布局，积累了丰富的工业数据和经验，从而在工业AI领域取得突破。
WAIC观察：隐私计算加速落地产业，全新的技术标准体系呼之欲出,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925512&idx=2&sn=7b10ab3bca0fc40f649d94a0acc4e9c0&chksm=84e42db6b393a4a0d63d2303471d18fb2ca4d7818eaa0e6ef072f76ecc2a6bf02bf032b49752#rd,2024-07-10 12:18:35,随着数据成为重要的生产要素，隐私计算技术因其在保障数据流通安全上的潜力而受到关注。近年来，中国加快了数据要素市场化建设，但数据流通复用面临着风险和挑战。隐私计算作为一项关键技术，近40年来从理论发展到应用，但要成为数据流通市场的“基石技术”，还需克服包括安全视角不足和落地成本高等问题。为了推动行业标准化，产学研各界发布了关于“隐私计算产品通用安全分级”和“个人信息匿名化制度”的白皮书，探讨数据跨域管控、受控匿名化和通用安全分级等方向。通过制定标准和技术创新，旨在建立可信的数据流通环境，促进数据要素的高效利用，同时保护个人隐私。
单一作者论文，谷歌提出百万专家Mixture，超越密集前馈、稀疏MoE,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925512&idx=3&sn=7a737e23afe4f1f14659fc07baa8c2b1&chksm=84e42db6b393a4a0d3a1223f57dad525f450cad58386609337cded89f8215e2498ddf7113f6d#rd,2024-07-10 12:18:35,Google DeepMind的研究人员提出了一种参数高效的专家检索机制（PEER），利用乘积密钥技术从一百万个微型专家中进行稀疏检索，以扩展Transformer模型的容量而不会增加计算成本。这种方法通过学习索引结构有效地路由到大量微小专家，将计算成本与参数数量分离。实验表明，PEER层在语言建模任务中展现了优于密集FFW、粗粒度MoE和产品密钥内存层的效率。此方法探索了极端MoE设置，首次证明学习索引结构可有效地路由到超过一百万个专家，并且引入了单神经元MLP作为专家的新层设计。
人人可做提示工程师！Claude上新：一键生成、测试和评估prompt,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925512&idx=4&sn=54c969caeb79432c38f3aea22ae4cb03&chksm=84e42db6b393a4a0e4dad70d9b7f7c347b48f0d0590d3bd085a64b8d125f00866fe096772b24#rd,2024-07-10 12:18:35,AI 初创公司 Anthropic 发布了一个新功能，简化了高质量 prompt 的制作流程。他们的 Anthropic Console 现在拥有一个内置的 prompt 生成器，用户只需描述任务，系统就能生成高质量的 prompt。此外，该平台还提供了测试数据生成、评估模型和比较不同 prompt 的功能，支持快速迭代和优化。这一创新将帮助开发者更有效地构建和改进 AI 应用。
深度解析RAG大模型知识冲突，清华西湖大学港中文联合发布,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925512&idx=5&sn=988c6e2099c10c75f72fdbc577e3b136&chksm=84e42db6b393a4a0bdd099f45eacc49fc1c723b9f8148f19ee94132b5f8f7c4854937a595916#rd,2024-07-10 12:18:35,"这篇文章是关于检索增强生成（Retrieval-Augmented Generation, RAG）中知识冲突问题的综述，该问题在大型语言模型中日益突出。知识冲突主要分为三种类型：Context-Memory Conflict（上下文与参数知识冲突）、Inter-Context Conflict（上下文知识内部冲突）和Intra-Memory Conflict（参数化知识内部冲突）。这些冲突可能导致模型在处理知识密集型任务时表现下降，尤其是在准确性要求高的场景中。

时间错位和信息污染是导致Context-Memory Conflict的主要原因，而错误信息和过时信息是Inter-Context Conflict的来源。Intra-Memory Conflict源于模型内部知识的不一致性，可能由于训练数据偏差、解码策略和知识编辑导致。针对这三种冲突，研究者提出了各种解决方案，如持续学习、知识编辑、微调模型、提示语技术和解码技术等。

该综述强调了知识冲突研究的重要性，并提供了未来研究的多个方向，包括在实际环境中的知识冲突研究、更精细的解决方案、下游任务评估、冲突之间的相互作用、可解释性、多语言性和多模态性。这些研究有助于提高大模型在处理知识冲突时的准确性和鲁棒性。"
70万人争先体验！视频生成新王者「可灵AI」又双叒升级了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925433&idx=1&sn=970d6ea088f5c7c1b9f2b46371b872d1&chksm=84e42d07b393a411fe24bdd61d670ad31e035a72c89d658d3d6acbc77d0d7ea90a1c7469b206#rd,2024-07-09 18:15:03,这篇文章介绍了快手旗下的大模型“可灵AI”在视频生成领域的进步，该模型能够生成电影级别的视频效果，包括真实风格的光影和丰富的想象力。可灵AI已经经历了多次升级，支持文本生成视频、图生视频、视频续写和多尺寸选择等功能。在最新的升级中，它提供了高画质版、首尾帧控制和相机镜头控制等新特性，增强了视频的清晰度、美学和用户自定义控制。此外，文章还提到了可灵AI在视频生成中的七大能力亮点，包括高清画面生成、图生视频效果和视频生成可控性等。快手在视频生成技术和应用上持续创新，可灵AI的广泛应用表明生成式AI正在逐步改变内容创作和娱乐行业。
第一次，语言的神经激活被定位到细胞级,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925433&idx=2&sn=3c3fe097a19e3ea5d732fe497d254a7c&chksm=84e42d07b393a4114c9a142c8e716a019b51ed4514f55b635777f030597d09c97a95bd6954a0#rd,2024-07-09 18:15:03,研究人员在《自然》杂志上发表论文，展示了分辨率最高的神经元图，这些神经元负责编码单词的含义。研究通过跟踪自然语音处理中的神经元活动，发现在左侧前额叶皮层，单个神经元选择性地响应特定单词的含义，并能区分单词和非单词。这些神经元的活动动态地反映单词在句子中的语义，并且独立于语音形式。研究揭示了人类语义表征的精细皮层组织，表明大脑使用相似的类别对单词进行分类，且这种编码方式在个体间具有共性。此外，研究人员能够在一定程度上通过观察神经元活动推测听到的单词和句子内容，这对未来脑机接口技术的发展具有重要意义。
鄂维南院士领衔新作：大模型不止有RAG、参数存储，还有第3种记忆,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925433&idx=3&sn=17b3802d37b564133ab98449015c62eb&chksm=84e42d07b393a4114414f4381fe635de3eec6c0f3917e3fa0be2c1c56d5f2c8ea2e3f602ce40#rd,2024-07-09 18:15:03,研究者受人类大脑记忆层次结构启发，为大型语言模型（LLM）配备了显式记忆，以降低训练和推理成本。他们训练了一个2.4B参数的LLM，名为Memory3，其性能优于更大规模的LLM和RAG模型，并实现了更快的解码速度。Memory3通过将知识库转换为稀疏注意力键值的显式记忆，减轻了模型参数记忆知识的负担。这种方法定义了一种新的记忆层次结构，包括隐式记忆、工作记忆和显式记忆。实验结果显示，Memory3在各种任务上表现出色，减少了幻觉，并能快速适应专业任务，且解码速度比RAG更快。
没想到！AlphaZero式树搜索也能用来增强大语言模型推理与训练,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925433&idx=4&sn=a48029dfd63440f616b5efa623ebb9a2&chksm=84e42d07b393a411d80730fea1049265c12a55b01fb02bd0b7986798f5e2abf8832409a49396#rd,2024-07-09 18:15:03,很抱歉，由于您没有提供具体的文章内容，我无法为您生成摘要。请您提供文章的详细信息或者主要观点，我将尽忙为您总结关键内容。
又遇到「GPT写的review」了？看看北大&密歇根的这个研究工作,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925433&idx=5&sn=548f8e996cb088fc2d56d186ef8ab481&chksm=84e42d07b393a4119cca2f535313bd1f6ee3b09b455bf3e44b7e800f6b0f25a0cbeea5317118#rd,2024-07-09 18:15:03,这篇论文介绍了北京大学和密歇根大学的研究团队合作发表在ACM Conference on Economics and Computation (EC'24)上的工作，该研究关注如何利用大型语言模型（LLMs）提高审稿质量。论文提出了两种机制——Generative Peer Prediction Mechanism (GPPM)和Generative Synopsis Peer Prediction Mechanism (GSPPM)，旨在激励审稿人提供更高质量的反馈。通过对审稿意见的信息量进行量化，研究者发现GPPM和GSPPM能够有效区分人类审稿和LLM生成的审稿，并且在检测低质量评论方面表现出色。此外，论文讨论了大模型在审稿过程中的应用及其可能带来的问题，并提出了未来的研究方向。
理财AI勇闯「无人区」：理解专家、成为专家,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925141&idx=1&sn=8df59379ca62b77ae022b3ab4b0f1deb&chksm=84e42c2bb393a53d8b209d427946299280357699690c9c23e21a8ece087f5e794aa2bbcbf7a6#rd,2024-07-08 12:54:33,这篇文章讲述了蚂蚁财富如何利用人工智能技术提升其理财服务平台的服务质量。在拥有大量活跃用户但专业理财服务短缺的情况下，蚂蚁财富推出了AI理财助理“支小宝”。经过技术升级，支小宝从检索式AI进化到生成式AI，使用定制的大模型Finix和专业智能体框架aU，提高了金融意图识别准确率，使得与用户的对话更为通俗易懂。支小宝能够理解和模拟金融专家，提供更准确的投资建议，并能主动发起对话，预测用户需求。通过不断的技术优化和对齐训练，支小宝正逐渐成为更专业的“私人理财专家”，为更多用户提供服务。
主打个性化体验，留住用户全靠AIGC？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925141&idx=2&sn=bc946b4fc3ebb6ffef7daec4058261c7&chksm=84e42c2bb393a53d5f20a50392b0160e0b99d5f1b320c58b5f02144921a535ee6ea91b0504cc#rd,2024-07-08 12:54:33,这篇文章介绍了AIGC（AI Generated Content）如何通过个性化提升营销转化率。在当前的社交媒体时代，商品评价对消费者购买决策的影响日益增大，因此企业在社交平台上的营销策略变得至关重要。AIGC技术通过分析用户数据，提供个性化内容推荐，从而精准满足用户需求，提高营销效率。在火山引擎和NVIDIA联合推出的视频栏目《AIGC体验派》第四期中，嘉宾将探讨AIGC在电商直播等场景中的应用，如何利用这项技术提升销售成功率和客户转化率。节目中，嘉宾还将分享销售助手如何借助大模型进行客户洞察，以及AIGC在电商直播营销中的潜在可能性和解决方案。观众可以通过扫描二维码报名参加直播。
像生物网络一样「生长」，具备「结构可塑性」的自组织神经网络来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925141&idx=3&sn=ba633756208c5475c280628bb7302907&chksm=84e42c2bb393a53d222f806512947e84d21402a4827e9fe35aa194769108801d4085cc0a005b#rd,2024-07-08 12:54:33,研究人员提出了一种名为LNDP（Lifelong Neural Developmental programs）的自组织神经网络模型，该模型能够实现突触和结构的可塑性，类似于生物神经网络的特性。LNDP通过局部计算和全局奖励函数依赖的神经元活动来实现这一目标，允许人工神经网络在智能体的生命周期内动态适应和改变。在强化学习任务中，LNDP展示出在解决控制任务和快速适应非平稳环境方面的优势。实验表明，结构可塑性有助于改善结果，并且预经验的自发性活动驱动的发展阶段在网络自组织中起到积极作用。
单卡A100实现百万token推理，速度快10倍，这是微软官方的大模型推理加速,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925141&idx=4&sn=337804f30ced106d2d48b192fe70ba3b&chksm=84e42c2bb393a53d2fbbc18bc4926bcaeb3dfc098eb3dfe21a6a6e75561f948191aa33b6e75b#rd,2024-07-08 12:54:33,微软和萨里大学的研究人员提出了一种名为MInference的新方法，旨在加速长上下文大型语言模型（LLM）的预填充阶段，从而提高处理速度。当前，长上下文LLM在处理大量输入文本时，由于自注意力机制的计算开销，首个token的生成可能需要几分钟，影响了用户体验和广泛应用。MInference通过动态稀疏注意力计算，无需额外训练或修改预训练设置，即可直接应用于现有LLM。在A100 GPU上，MInference可将预填充推理延迟降低10倍，同时保持高准确性。这种方法通过识别和利用不同输入中的动态稀疏模式（A形、垂直-斜线和块状-稀疏），实现高效计算，加速长上下文LLM的处理速度。实验表明，MInference在多种任务和模型上都表现出色，有效地保留了模型的性能。
几分钟生成四维内容，还能控制运动效果：北大、密歇根提出DG4D,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925141&idx=5&sn=2024167fc765cbf779322f968624d784&chksm=84e42c2bb393a53d0770fc2ddde5fefedce8da74b4441c6f0e3ffb79e5fa051c6bc45df0e71c#rd,2024-07-08 12:54:33,这篇文章介绍了上海人工智能实验室的Research Scientist潘亮博士及其团队最近提出的DreamGaussian4D（DG4D）技术，这是一种用于高效四维内容生成的方法。DG4D解决了现有四维内容生成方法中优化时间长、运动控制能力差和细节质量低的问题。它结合了空间变换的显式建模与静态3D Gaussian Splatting技术，将优化时间从几小时缩短到几分钟，并支持在三维引擎中真实渲染的动画网格模型。该框架包括图像到4D GS生成和视频到视频纹理细化两个阶段，通过预训练的图像到视频扩散模型增强时间一致性。DG4D的提出有助于促进四维内容生成领域的研究和实际应用。
从智算到密算，大模型数据困境新解法 | 智者访谈,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925037&idx=1&sn=3bcddf83265e634c3213ef7912b95e13&chksm=84e42393b393aa85b5853727e10088fd819a879d449a103e18e1ba18bdc5ccd75eba4f54a90a#rd,2024-07-07 13:11:55,这篇文章提到，高质量的数据供给对于大模型的发展至关重要，但数据安全、隐私保护和数据孤岛问题阻碍了数据的流通。蚂蚁集团的韦韬认为，隐私计算技术是解决数据跨域供给的关键，而数据密态化是大模型产业的未来之路。蚂蚁密算发布了一款名为“隐语 Cloud 大模型密算平台”的产品，该平台通过隐私计算技术实现在大模型托管和推理环节的数据密态流转，保护模型资产、数据安全和用户隐私。平台支持公有云和专有云交付方案，降低了私有化部署的成本和复杂性，旨在促进数据要素市场的可信流通。此外，文章还讨论了如何通过技术创新和市场机制降低隐私计算成本，以及在数据安全和商业利益之间的平衡。
"达摩院发布一站式AI视频创作平台""寻光""，打造全新AI工作流",http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925037&idx=2&sn=3ada86004063671b2befe0f3340bc4df&chksm=84e42393b393aa85f67ddcf53b5b81e812027ad12533adc327a94114c01415088fa72d2e58a0#rd,2024-07-07 13:11:55,本文介绍了AI视频生成领域的新发展和挑战，以及阿里达摩院发布的一站式AI视频创作平台“寻光”。今年是AI视频生成爆发的元年，但技术的可控性和后期编辑的繁琐性成为问题。达摩院的寻光平台旨在解决这些问题，提供剧本创作、分镜设计、素材编辑等一站式服务，并首次实现基于图层的视频编辑功能，支持人物、场景和风格的精准控制。平台还提供丰富的AI编辑功能，如图层拆解和融合，目标新增/消除/修改等。达摩院希望通过寻光优化视频创作流程，释放AI的生产力。该平台即将开放内测。
全尺寸通用人形机器人青龙亮相WAIC，加速迈入具身智能时代,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925037&idx=3&sn=6112b5421efe85398e9e7d6106f1fc1d&chksm=84e42393b393aa8580b7583065843f063ea6d9833ee3cc6cd06af1f893d668aae8c5740d5386#rd,2024-07-07 13:11:55,2024年WAIC世界人工智能大会人形机器人与具身智能发展论坛在上海举行，汇聚了12位国内外学者和企业代表进行报告和讨论。论坛发布了国家地方共建人形机器人创新中心的全尺寸通用人形机器人“青龙”，该机器人具有43个主动自由度和高算力的具身智能控制器，能够实现复杂任务。此外，嘉宾们分享了人形机器人技术的最新进展和应用场景，探讨了人形机器人的产业应用与落地。论坛还强调了人形机器人产业在上海创新与发展中的关键地位，以及构建智能训练场和开源数据集计划以促进技术迭代和产业化进程。
做具身大模型缺数据？ATM 教你人类视频的正确用法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925037&idx=4&sn=eb105061d00693290e65071b52fecc0c&chksm=84e42393b393aa8589484ecb01e78cf6eca9ed24d788a917a1ed1978c9d518c640be889f38ce#rd,2024-07-07 13:11:55,"这篇会员通讯主要涵盖了三个AI和Robotics领域的重点话题。首先，介绍了ATM（Any-point Trajectory Modeling）模型，这是一个由UC伯克利和清华研究人员提出的解决方案，旨在解决具身大模型在训练数据上的难题。ATM通过预测视频中任意点的轨迹，减少了对动作标签数据的依赖，从而能从人类视频中学习更稳健的视觉运动策略。

其次，通讯探讨了苹果公司在AI领域的布局，包括其最近的动作、独特优势、自研AI芯片的意图，以及通过WWDC透露的AI战略方向。

最后，提到了高盛的一份研究报告，报告警告称未来在AI领域的巨额投资可能无法获得相应的回报，因为投资回报的清晰度尚不明确。文章讨论了不同观点和如何突破成本限制以推动AI技术的经济增长。

通讯还包含了其他28项本周的AI和Robotics行业动态，涵盖了技术、国内和国外的最新进展。"
开源视频版GPT-4o？快速记忆，实时问答，拿下CVPR'24长视频问答竞赛冠军,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650925037&idx=5&sn=261140b6cfb57f905269a1416ee54dc1&chksm=84e42393b393aa85efcf7f6fb777012fbeeaa6b9fa0c6bb01a44966c141882174877e9271979#rd,2024-07-07 13:11:55,字节跳动和清华大学的研究人员联合开发了Flash-VStream，这是首个针对长视频流的在线理解多模态大模型，可以实现高效记忆和实时回答关于长视频的问题。该模型采用STAR记忆机制，包括空间、时间、抽象和检索四种记忆模块，能够融合不同粒度的语义信息。与现有方法相比，Flash-VStream可以在线处理极长的视频流，显存开销和回答延迟几乎不随输入帧数增加，且在多个长视频问答基准上取得最佳性能，包括赢得了CVPR'24长视频问答竞赛的冠军。此外，研究团队还构建了一个名为VStream-QA的在线视频流问答数据集，以支持该领域的模型评估和改进。
WAIC上，高通这一波生成式AI创新，让我们看到了未来,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924952&idx=1&sn=7d9ab54d68ef13a5bda5db86747549f5&chksm=84e423e6b393aaf01620d6433e8fe7e1f2400ad2f536af17c7432db83995b3fe2742a6d670a2#rd,2024-07-06 12:52:11,这篇文章主要讲述了生成式AI技术如何改变了个人电脑产业，特别是微软与高通合作推出的搭载骁龙X系列芯片的AI PC。这些新型电脑具备超过40 TOPS的AI算力和长电池续航，并能接入先进的人工智能模型，提供包括AI搜索、图像生成、实时翻译字幕等功能。高通的芯片在AI性能上的提升，使得移动端和PC端的设备形态发生变革，能够支持大模型的运行。在世界人工智能大会上，高通展示了一系列终端侧的生成式AI能力，强调了芯片AI能力对于设备形态变革的重要性。高通的骁龙X Elite芯片提供了强大的AI算力，支持超过130亿参数的生成式AI模型运行，结合模型优化技术，如低秩自适应（LoRA），使得大模型能够在手机和电脑等终端设备上高效运行。这些发展预示着AI技术将更深入地融入人们的日常生活和工作中，改变人机交互方式。
更美图像生成、直出分钟级视频，国产自研DiT架构的越级之旅,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924952&idx=2&sn=11b717307b51c287e14e24f0fd806df7&chksm=84e423e6b393aaf01895fd23b0c1728d16c349c48f9e655ff38360206273a9a4216bda10d168#rd,2024-07-06 12:52:11,这篇文章介绍了AI初创公司智象未来（HiDream.ai）在生成式AI领域的进展，特别是其在文生视频技术上的突破。智象未来推出了一站式AI图像和视频生成平台「Pixeling 千象」，其自主研发的视觉多模态基础模型支持文生图、文生视频、图生视频和文生3D。公司近期对智象大模型进行了升级，增强了图像和视频生成的能力，包括生成更美观、艺术性的图像，支持图像中文字嵌入和分钟级视频生成。在视频生成方面，模型支持的时长从4秒增加到了15秒，目标是实现分钟级视频生成。智象未来已经在多个行业与企业合作，推动AI生成内容的应用，并计划在7月中旬上线升级后的文生视频功能。
Adam有了mini版：内存占用少一半，吞吐量提升50%,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924952&idx=3&sn=fe2c07c612a070494f313a642a75d151&chksm=84e423e6b393aaf02fb61053418c86bcde4a688a9b22c93f40b0220d74095a69a8af4a76a07b#rd,2024-07-06 12:52:11,研究人员发现，优化器Adam在训练大型语言模型时的高内存需求是一个主要问题，尤其是对于参数量达到数十亿的模型。Adam需要存储一阶和二阶动量，这需要至少两倍模型大小的内存。为了解决这一问题，一个联合研究团队提出了一种名为Adam-mini的新方法，它通过减少学习率的数量来降低内存使用，同时保持或提高模型性能。Adam-mini观察到Transformer的Hessian结构具有接近块对角线的特性，允许使用更少的块级学习率，而不是每个参数的单独学习率。实验表明，Adam-mini在预训练大型语言模型时可以显著减少内存占用，提高训练吞吐量，且性能可与Adam相媲美，甚至有所提升。这种方法降低了大型模型训练的内存需求，可能加速训练速度，减少成本，并促进更多资源有限的研究者参与。
红杉：重金购入GPU后，AI行业收入缺口达到5000亿美元,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924952&idx=4&sn=aca804518dd3f4d2df47ce86b37e5fb4&chksm=84e423e6b393aaf07df4bcb9530e8abecabfc7ebdfb5aa22847023aad7b5cd62a71b1567caf4#rd,2024-07-06 12:52:11,红杉资本合伙人David Cahn在文章中探讨了AI公司购买GPU的投资回报问题。他计算得出，为了证明英伟达2023年底500亿美元GPU revenue的合理性，这些GPU需要产生2000亿美元的生命周期收入。考虑到能源成本和企业的利润需求，这个数字现在已被更新到6000亿美元，假设英伟达2024年底的run-rate GPU revenue为1500亿美元。Cahn提出疑问，这些巨额投资有多少是基于真实的市场需求，多少是预期未来需求的投机。尽管AI领域的资本支出可能降低开发成本，但历史上过度建设的基础设施往往会导致资本烧毁。文章强调，AI公司需要创造实际价值，为消费者提供他们愿意付费的产品，而不仅仅是囤积GPU。
RAGFlow开源Star量破万，是时候思考下RAG的未来是什么了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924952&idx=5&sn=4c127c5bf4b07eda0b79f819d8046be9&chksm=84e423e6b393aaf064b45a87634ba9eb0bcb6db445fbdfcf688adafe516193bca7e7423913b6#rd,2024-07-06 12:52:11,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我会尽力为您生成摘要。
现场Live震撼！OmAgent框架强势开源！行业应用已全面开花,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924816&idx=1&sn=8683551cc14b6594ffdc9f8db9263eb0&chksm=84e4236eb393aa780a091ea3cd8dd57a7692058fcb2586e14bae16daee1d8407b0592df36896#rd,2024-07-05 17:54:34,这篇文章是关于联汇科技在大模型和多模态智能体领域的创新与发展。联汇科技在大模型赛道中处于领先地位，他们的首席科学家赵天成博士对自主智能的发展有深刻见解。在2024年世界人工智能大会期间，联汇科技发布了第二代多模态智能体OmAgent，其感知模块和思考决策能力得到了显著提升。OmDet V2模型在万物感知方面实现了20倍以上的速度提高，而OmChat V2则支持复杂场景的决策判断。此外，联汇科技还宣布OmAgent框架全面开源，以促进智能体生态的发展。公司还推出了空间运营智能体和知识服务智能体等新产品，将大模型技术应用于实际场景中。赵天成博士预判未来智能体将更加多样化和深入人类活动，而大模型将走向边缘计算，实现更广泛的应用。
现场削黄瓜、叠衣服，曾爆火的刮胡子机器人再进化，穹彻的具身智能大脑来了！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924816&idx=2&sn=39febd684d4ac33c0205a0ee198661d4&chksm=84e4236eb393aa78344b94c7d8b0a61899fee37967dbcdd6981772382f8dc511e1e4d28602fb#rd,2024-07-05 17:54:34,在2024世界人工智能大会上，具身智能公司穹彻智能（Noematrix）推出了穹彻具身大脑，这是一个加速具身智能大模型落地的平台。该公司展示了结合实体机器人的技术，如无限自由度物体操作的衣物折叠和精细度超越人类水平的黄瓜削皮，体现了其具身智能的通用性和鲁棒性。穹彻具身大脑包括以力为中心的具身智能大模型、原子技能库AnySkill和基础软件框架，旨在帮助机器人掌握更多技能并应用于更多场景。该公司由非夕科技战略孵化，上海交通大学卢策吾教授担任联合创始人，他们在构建具身智能大模型时强调物理常识和力反馈的联合训练。穹彻智能将在零售运营、物流拣选、食材处理、家庭服务和科研教育等领域探索具身智能的应用。
全球首个支持单任务千卡规模异构芯片混合训练平台，来自无问芯穹,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924816&idx=3&sn=e4fae2248efc1209fc7d811e4e401096&chksm=84e4236eb393aa78815d4cbf1eb817049bd96b295825a13792f1165ea91a119179dcbe5a0a65#rd,2024-07-05 17:54:34,这篇文章介绍了无问芯穹公司在2024年世界人工智能大会上发布的AI基础设施，特别是其大规模模型的异构分布式混合训练系统，该系统在千卡异构混合训练集群上的算力利用率达到了97.6%。无问芯穹的Infini-AI云平台成为全球首个支持单任务千卡规模异构芯片混合训练的平台，兼容多种异构芯片，包括AMD、华为昇腾等。该平台旨在打破不同芯片之间的生态竖井，提供灵活的大算力训练和推理能力。此外，Infini-AI云平台由异构云管平台、一站式AI平台和大模型服务平台组成，支持多种模型和芯片的自由搭配组合，简化了开发者使用异构算力的难度。无问芯穹与清华、上交的研究团队还发布了HETHUB，这是一个用于大规模模型异构分布式混合训练的系统，解决了异构芯片间的通信和性能差异问题，实现了高效率的训练。这一发展对于推动大模型应用的创新和降低成本具有重要意义。
LLM用于时序预测真的不行，连推理能力都没用到,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924816&idx=4&sn=b1ca0ad627033abc6e2b296a01147f65&chksm=84e4236eb393aa78116a5991c19ad620cd61f197f42b93758dd8cf9218285930eefe8a13bceb#rd,2024-07-05 17:54:34,研究发现，大型语言模型（LLM）在时序预测任务上的表现接近或劣于基本的消融方法，但计算量却大几个数量级。弗吉尼亚大学和华盛顿大学的研究团队通过大量消融研究得出这一结论，他们并不是否认语言模型在时间序列上的潜力，而是强调现有方法并未充分利用其推理能力。研究者评估了三种时序预测方法和三种消融方法，实验结果表明预训练语言模型对时间序列预测的提升有限，且不值得其消耗的计算成本。同时，预训练对预测任务的性能帮助有限，语言模型在表征时间序列的顺序依赖关系上也没有显著优势。此外，LLM在少样本学习场景中的表现也不突出。研究推荐使用简单但有效的编码技术，如patching和单层注意力，来处理时间序列数据。
ACL 2024 | 引领学术视听研究，上海交大、清华大学、剑桥大学、上海AILAB联合发布学术视听数据集M3AV,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924816&idx=5&sn=7a50777140fd5b4766e332b6e63d730b&chksm=84e4236eb393aa78a15f144371d52785dbb08f1d90219e8cee9cede2b20f16d755af9fb77060#rd,2024-07-05 17:54:34,这篇文章介绍了上海交通大学、清华大学、剑桥大学和上海人工智能实验室的研究人员共同创建的M3AV数据集，这是一个多模态、多类型、多用途的视听学术演讲数据集。M3AV包含近367小时的视频，涵盖计算机科学、数学、医学和生物学主题，拥有高质量的人工标注，特别是命名实体标注，适用于多模态内容识别和理解任务。数据集的丰富内容使其成为评估和推动AI模型在学术知识理解和处理上的挑战性资源。研究者在上下文语音识别、语音合成和幻灯片脚本生成等任务上对数据集进行了基准测试，发现现有模型仍有改进空间。
揭秘：阶跃星辰万亿MoE+多模态大模型矩阵亮相,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924595&idx=1&sn=6be0aff6f47e9d21df5f036f3e6c82c7&chksm=84e4224db393ab5b08feb80b45564ae68ce7a1282dcbc3b142b4c564b6030b17c9271ff09a41#rd,2024-07-04 15:21:11,这篇文章介绍了在2024年世界人工智能大会上，一家名为阶跃星辰的公司展示的AI互动体验《AI + 大闹天宫》，这个体验利用大模型根据用户的选择和回答评估人格类型，并在仙界为其“安排”工作。公司还推出了万亿参数的MoE大模型Step-2、千亿参数的多模态大模型Step-1.5V以及图像生成大模型Step-1X。Step-2模型展示出强大的数理逻辑、编程和多语言能力，而Step-1.5V在多模态理解和推理方面有显著提升，Step-1X则专注于图像生成并针对中国元素优化。阶跃星辰通过全链路自研的DiT模型架构，致力于发展具身智能和世界模型，以实现人工智能的更高阶段。
AI主战场，万卡是标配：国产GPU万卡万P集群来了！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924595&idx=2&sn=ceb973101fae3c09bdfcd4fc9a8e29f0&chksm=84e4224db393ab5b00d799fa812f7db7c7c3e7daa0f3ec33162ae3c2acbd3111336cfa6614ef#rd,2024-07-04 15:21:11,摩尔线程宣布其AI旗舰产品夸娥（KUAE）智算集群解决方案实现重大升级，扩展至万卡规模，打造国产通用加速计算平台，专为万亿参数级别大模型训练设计。这一进展树立了国产GPU技术新标杆，有助于推动AI产业发展的新起点。摩尔线程还与多家企业签署战略协议，共建万卡集群项目，推动国产GPU集群的建设与应用，助力产业数字化转型。夸娥智算集群具备超大算力、超高稳定性和全能通用等特性，旨在满足大模型训练的算力需求。
8人小团队单挑OpenAI，半年仿出GPT-4o，还开源了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924595&idx=3&sn=0ff5ce09008d99ae91fe9182250ed543&chksm=84e4224db393ab5b9780db70f897d6d0a317557e03873fd6e689ddab36c2d6bf29772f7fbdaf#rd,2024-07-04 15:21:11,这篇文章介绍了一个由法国非营利性AI研究机构Kyutai开发的开源多模态模型Moshi，它具有听、说、看的功能，并能够进行实时语音交互。Moshi可以在对话中理解用户的意图，流畅地回答问题，甚至能够表达情感和进行角色扮演。该模型的开发仅用了6个月，使用了合成数据进行训练，包括70亿参数的文本语言模型Helium和语音编解码器Mimi。Kyutai还计划发布技术报告和开源模型版本，促进AI的开放研究和广泛应用。该团队由一群在AI领域有深厚背景的研究员组成，包括首席执行官Patrick Pérez、首席扩展官Edouard Grave和首席科学官Hervé Jégou等。Moshi展示了小型团队在AI技术上的潜力，为各种应用领域提供了新的可能性。
陶哲轩支持！AI数学奥林匹克竞赛进步奖公布，奖金100多万美元,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924595&idx=4&sn=06d4333fca334f0a25e686e8952442b7&chksm=84e4224db393ab5beaa98ac1a78bbd1ce82e94fd5002e49c1b18a7ce620fda0ce2d272f127b6#rd,2024-07-04 15:21:11,AI 数学奥林匹克竞赛（AIMO 进步奖）的初步成绩公布，获胜的程序在私人测试中正确回答了 29/50 道题，超出了预期。这个比赛由 XT Markets 发起，目的是推动 AI 模型解决复杂数学问题的能力，促进数学推理和前沿知识的发展。参赛队伍需公开代码、方法等，以角逐 104.8 万美元的奖金。目前，Numina 团队排名第一，CMU_MATH 和 after exams 分列第二和第三。参赛模型包括 Mixtral・8x7b、Gemma、Llama 3 等。随着大模型能力的增强，它们在数学竞赛中的表现受到关注，如 Google DeepMind 的 AlphaGeometry 已经接近 IMO 金牌选手的水平。AIMO 顾问委员会包括菲尔兹奖得主 Timothy Gowers 和陶哲轩等数学界知名人士。
全新TextGrad框架：用GPT-4o作引擎，自动优化端到端任务,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924595&idx=5&sn=b10398ed32f9acbb295496fd451f3db4&chksm=84e4224db393ab5b4507d476dcffc7c6a2ec79ad121efb7b53f89b7521dae9ddf1f8ffcbacfd#rd,2024-07-04 15:21:11,斯坦福大学的研究团队推出了一种名为TextGrad的新框架，该框架能够高效协调和优化由大语言模型（LLM）等组件构成的AI系统，自动优化端到端任务性能。TextGrad使用自然语言作为媒介在系统组件之间传递“梯度”，通过从语言模型的输出反向传播文本反馈来优化系统中的变量。该方法不需要手工设计prompt，可以自动搜索优化任务描述，并与各种支持自然语言I/O的LLM或API集成。TextGrad已成功应用于优化模型输出、提示工程、药物探索和肿瘤放疗治疗计划等领域，展现出广泛的应用前景。
央视点赞国产AI复活召唤术，兵马俑竟与宝石老舅对唱Rap？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924483&idx=1&sn=061c7fcc2953b642993acdf8e39d5d58&chksm=84e421bdb393a8abc4ccf08d0eb5071fd216831ed810cf9d8fac2584a64f326d92d4acaef3e0#rd,2024-07-03 19:07:38,阿里巴巴通义实验室的AI技术EMO能够让静止图像变为生动的唱演视频，仅需一张照片和一个音频。在《2024中国·AI盛典》中，EMO“复活”了兵马俑和北宋文学家苏轼，与宝石Gem和李玉刚同台表演。该技术通过音频驱动生成人物视频，无需复杂预处理，直接从音频中提取信息生成表情动态和唇部同步的视频。EMO基于一个超过250小时音视频数据集训练，保证了生成视频的自然和流畅。视频生成领域正不断发展，EMO展示了在人物视频创作方面的潜力，为专业级内容生成提供了可能。
不到60秒就能生成3D「手办」，Meta发力3D生成，ChatGPT时刻要来了吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924483&idx=2&sn=81fad5919205e7a835f28c9fdfcbf8b9&chksm=84e421bdb393a8abe3c8116093170bbc04ad3d9384101173a87132757a00403f28120282d553#rd,2024-07-03 19:07:38,Meta发布了新系统Meta 3D Gen，能够快速从文本生成3D资产，将3D内容创作推向新阶段。该系统可在不到一分钟内创建具有高分辨率纹理和基于物理的渲染（PBR）的3D资产。Meta 3D Gen使用两阶段方法，包括3D AssetGen和3D TextureGen两个组件，协同工作以生成高质量3D模型。与现有解决方案相比，Meta 3D Gen的速度提高了3到10倍。该技术有望简化3D内容创作，特别是在游戏、AR/VR和影视特效等领域。
AI助攻「菜鸟数学家」解决忙碌海狸问题，陶哲轩转发分享,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924483&idx=3&sn=ac0b7d429ca45c5d760153eeb8249c8c&chksm=84e421bdb393a8ab594684f947ad0d78d6133886a7c89ca0d68b14579cba8855323733bf0282#rd,2024-07-03 19:07:38,数学家陶哲轩利用AI工具帮助解决数学问题，倡导使用证明助手如Lean和Coq来形式化和验证复杂的数学证明。他参与编辑了一个名为AI for Math的资源列表，助力数学与AI的结合。陶哲轩还使用AI来创建动画图表，展示零密度估计的文献回顾，并发现AI在调试代码方面虽有帮助，但在创建和完善动画过程中仍需要大量手动工作。此外，文章提到一群业余数学家在AI的帮助下解决了忙碌海狸函数（BB(n)）的第五个值，这是一个衡量图灵机运行时间的经典问题。通过使用Coq等智能证明助手，更多人能够参与到数学研究中，AI在数学领域的应用有助于揭示数学问题的解决方案。
细数RAG的12个痛点，英伟达高级架构师亲授解决方案,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924483&idx=4&sn=fd883a196af9dcd4942d05d55e0e5b99&chksm=84e421bdb393a8ab3a4e84e2798e6450522fa1bb7689f198bdc604ed2de7212a5ee986f984f8#rd,2024-07-03 19:07:38,近日，英伟达生成式AI高级解决方案架构师Wenqi Glantz 在 Towards Data Science 发布了一篇文章，梳理了12个检索增强式生成（RAG）的痛点并给出了相应解决方案，包括内容缺失、错过排名靠前的文档、不在上下文中、未提取出来、格式错误等。这些问题可能会影响RAG的准确性和性能。解决方案包括数据清洗、更好的提词设计、超参数微调、重新排名等。例如，数据质量差是多个问题的常见原因，而使用LongLLMLingua和LongContextReorder等工具可以改善上下文处理和答案提取。此外，文章还提到了数据摄取的可扩展性、结构化数据问答、从复杂PDF提取数据等方面的问题及其解决方案。
ICML 2024高分论文 | 零阶优化器微调大模型，大幅降低内存,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924483&idx=5&sn=b1099df22cbb506cdaae46cd0d59c8f0&chksm=84e421bdb393a8ab69766b0323f9ab49794ec25b07fd7210b57a43c082a120701c600d871cb8#rd,2024-07-03 19:07:38,来自多所大学和研究机构的研究者对大语言模型的微调进行了一项全面的评测，重点研究了无需反向传播的零阶优化器在降低显存使用方面的能力。他们比较了六种零阶优化器和一阶优化器在五种大模型、三种任务复杂度和四种微调方案下的性能。研究发现，ZO-Adam和ZO-SGD-MMT在大多数情况下表现最佳，且零阶优化器在内存效率上优于一阶优化器。此外，他们还提出了三种改进算法以增强零阶优化器的性能，包括分块零阶微调、零阶和一阶混合微调以及使用稀疏梯度的零阶优化器。论文已被ICML 2024接收，并已开源。
免费！国产大模型编程助手豆包MarsCode重磅上线，还有登录即用的云端IDE,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924319&idx=1&sn=10a792516861fa2f4c6036ff1f98666b&chksm=84e42161b393a877afdb6decd38f437c1917d0bd52ca7ac1c459604b6b505af6209f74beeb73#rd,2024-07-02 12:03:14,豆包MarsCode是一款国产AI编程助手，提供代码补全、生成、解释、注释、单测生成和缺陷修复等功能，旨在提升程序员的工作效率。该工具基于大型语言模型，能理解整个仓库的代码依赖关系，通过简单的指令即可自动生成代码。代码解释功能可帮助理解项目代码，对于新手学习新语言和开发技巧也非常有用。此外，豆包MarsCode还具备云端集成开发环境Cloud ID，支持多种IDE插件，用户可以免费注册使用，享受2核4G的计算资源和10G的项目空间。相较于其他AI编程助手，豆包MarsCode强调其在国内提供的稳定服务和对用户数据的安全保障。
73年前，香农已经给大模型发展埋下一颗种子,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924319&idx=2&sn=e589f4dadc0e077f58ed164898e5395b&chksm=84e42161b393a8774cd09afcb2ae1058ceec0ecb2388786b7dd90952e5ee7968929be80098b0#rd,2024-07-02 12:03:14,普林斯顿大学教授Sebastian Seung提出，大语言模型（LLM）的原理可以追溯到1951年克劳德·香农在贝尔实验室的工作。香农的论文《Prediction and Entropy of Printed English》探讨了如何预测英文中的下一个单词，这一问题成为了当前LLM的基础。论文中，香农研究了语言的熵和冗余度，并提出了估算方法，包括使用N-gram和考虑人类对语言的预测能力。这一观点引发了讨论，强调了历史上很多现代AI概念的根源。
全球首个神经连接机械腿，截肢者恢复自然行走，还带空间感,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924319&idx=3&sn=19d926cf0a5083018085ef5d8a2f7a45&chksm=84e42161b393a8778964acb341b4226a4135d34a17aa74372b7fa3f50f130903d38841473e8e#rd,2024-07-02 12:03:14,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
神经网络可能不再需要激活函数？Layer Normalization也具有非线性表达！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924319&idx=4&sn=b960170f9de3efbd4e1030325cb17058&chksm=84e42161b393a87784ff90b5c8d45e77d8a8b8b491d4b9a7cf65c643e5e724ee01320e7e844d#rd,2024-07-02 12:03:14,"北京航空航天大学黄雷副教授团队的最新研究发现，层标准化（Layer Normalization, LN）和其计算退化版本RMSNorm具有非线性表达能力。这项研究打破了人们认为标准化层不能提升模型表达能力的观念。团队在ICML 2024上发表的论文《On the Nonlinearity of Layer Normalization》中提出，仅含线性层和LN的简单神经网络LN-Net在足够深的情况下，理论上可以任意分类给定的样本和样本类别。这一发现对于神经网络架构设计具有开创性意义，特别是在LN广泛应用于Transformer模型的背景下。论文证明了LN的非线性主要存在于尺度缩放操作中，并提出了分组层标准化技术（LN-G），在实验中展示了增强LN非线性对于提升模型性能的效果。"
哈工大提出创新迭代推理框架 DPE-MNER ：充分发挥多模态表示潜力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924319&idx=5&sn=91d0be9d402e7124af21ffc8e65f8660&chksm=84e42161b393a87785fcf620e725908e8018f5a85150a6e39d5e728ba8f7dc8958ac22b923bb#rd,2024-07-02 12:03:14,本文介绍了哈工大社会计算与信息检索研究中心的研究团队提出的DPE-MNER框架，这是一个用于多模态命名实体识别的创新迭代推理方法。多模态命名实体识别是构建多模态知识图谱的关键任务，但整合多种模态信息以提高识别准确性一直是个挑战。DPE-MNER遵循“分解、优先、消除”的策略，动态整合多样化的多模态表示，通过层次化融合层简化处理过程，并通过显式建模跨模态相关性排除无关信息。实验表明，该方法在两个公共数据集上显著提升了多模态命名实体识别的准确性和效率，被认为是LREC-COLING 2024会议的十篇最佳论文候选之一。
速来！潞晨Open-Sora羊毛可薅，10元轻松上手视频生成,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924168&idx=1&sn=311c6f5738d46764db045946da9cbcb5&chksm=84e420f6b393a9e0e2031f8ceb4f9fc405355c91adc3a25e558998d2dbf01415d925bc6cb524#rd,2024-07-01 12:41:08,这篇文章介绍了一个开源的视频生成模型Open-Sora，该模型能够生成高清视频且使用成本低，适用于所有人。文章提供了对Open-Sora 1.2版本的测评，该版本可以生成长达16秒的720p视频。对于想要体验但缺乏技术背景的用户，文章推荐了一个基于Gradio的可视化方案，允许用户通过简单的界面控制视频参数而无需编写代码。潞晨科技提供了Gradio应用的部署脚本，但需要一定的硬件资源和环境配置。为了解决这些难题，文章推荐使用潞晨云服务，该服务提供一键部署的Open-Sora专属镜像，用户可以轻松体验模型功能，且价格优惠。文章还提供了简单的部署教程和资源链接，让用户能够快速上手使用Open-Sora。
人刚毕业，颠覆整个AI界：扒一扒Sora两带头人博士论文,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924168&idx=2&sn=cda630c9ce82de582602d352eabf200d&chksm=84e420f6b393a9e0c514dd0d9bcb0febb4ed457d3792f5fdc06f6437512494447ddf8b434ddd#rd,2024-07-01 12:41:08,OpenAI的Sora项目是2024年生成式AI领域的重大突破，它在视频生成方面设定了新标准。Sora的两位主要开发者，Tim Brooks和Bill Peebles，是2023年从加州大学伯克利分校毕业的博士生，他们在AI视频生成领域有深厚的学术背景。两人都在2023年加入了OpenAI，参与了包括Sora和GPT-4在内的项目。Tim Brooks的博士论文《Generative Models for Image and Long Video Synthesis》探讨了长视频生成、人体姿态与场景图像生成以及指导生成模型遵循指令的方法，他的研究为生成模型在视觉内容创作中的应用奠定了基础。Bill Peebles的博士论文《Generative Models of Images and Neural Networks》则集中在改进图像生成模型和利用预训练生成模型解决下游任务上，他提出了扩散Transformer（DiT）架构和基于生成模型的元学习框架。两位年轻学者的研究为AI视频生成技术的发展做出了重要贡献。
最难「讨好」的消费者，竟然都被AIGC征服了？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924168&idx=3&sn=caefe58a23b2445ca3089068e3b8bc0a&chksm=84e420f6b393a9e069a4a82694c54021d4d178c0152ace089e176bfe65cf782c591a1442f8a4#rd,2024-07-01 12:41:08,在《AIGC 体验派》第三期节目中，嘉宾将探讨如何使用 AIGC 技术提升营销互动率。AIGC（人工智能生成内容）已经在营销行业中展现出创新潜力，特别是在提升品牌与消费者互动的深度和广度上。随着底层技术的进步，如火山引擎的 AR 解决方案和智能美化特效，以及 NVIDIA 的解决方案，AIGC 已经在抖音等平台上推动了品牌营销互动率的显著增长。例如，今年上半年抖音中使用 AIGC 的品牌营销互动率提高了 3 倍以上。此外，AIGC 还在智能车舱内创造新的互动体验，如通过车机摄像头将行车记录转化为精彩视频。直播将于 7 月 3 日 19:00-19:50 举行，届时嘉宾将分享更多关于如何利用 AIGC 创新营销互动的见解。
等不来OpenAI的Q*，华为诺亚探索LLM推理的秘密武器MindStar先来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924168&idx=4&sn=058fb8291d83ea2fb1c6bfde7576ebb0&chksm=84e420f6b393a9e02d91627fbdbce5e77b89c0bc976bb7cbf649fb4a76aac29d2d0563cbc366#rd,2024-07-01 12:41:08,华为蒙特利尔诺亚方舟实验室的研究人员提出了一种名为MindStar的新方法，旨在增强预训练大型语言模型（LLMs）在推理时间的数学推理能力。MindStar通过将推理任务视为搜索问题，使用过程监督的奖励模型（PRM）在推理树空间中导航，寻找最优路径。实验结果显示，MindStar在开源模型LLaMA-13B和Mistral-7B上达到了接近GPT-3.5和Grok-1的数学问题解决能力，同时显著减少了计算资源。该方法结合束搜索和Levin树搜索策略，提高了搜索效率。研究发现，LLMs在处理复杂推理任务时，有时会生成正确的推理轨迹，MindStar通过帮助模型选择正确的输出来增强其推理能力。
ICML 2024 Spotlight | 在解码中重新对齐，让语言模型更少幻觉、更符合人类偏好,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924168&idx=5&sn=a9e3c2ce66eb327acca5306c82a947dc&chksm=84e420f6b393a9e06a4cd38b2dbd927437c5c30bd49a8ec36341a78db6516c4de5e1d8547526#rd,2024-07-01 12:41:08,这篇论文介绍了一种名为Decoding-time Realignment (DeRa)的方法，用于在语言模型对齐研究中平衡人类偏好奖励和正则化。DeRa允许在生成回答时动态调整这两个因素的比重，而无需重新训练模型，从而节省计算资源。它基于两个模型在原始输出（logits）空间的插值，实现简单且灵活，可以针对不同需求调整对齐强度。通过解码时的重新对齐，DeRa可以在不牺牲模型流畅性的情况下，有效控制语言模型的对齐程度。实验结果表明，DeRa在多项任务中表现出色，包括调整生成内容的长度、提高摘要任务的效率以及减少大模型中的幻觉生成。
全网围观魏建军直播：长城端到端智驾大模型挑战重庆「魔幻路况」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924109&idx=1&sn=d1c2dc101f2b8c78abf50eaaa75f4eea&chksm=84e42033b393a92587d25e1b1f11d0f9e62beaa7478774c91be81a7e5e65b26266dac78ca7bc#rd,2024-06-30 18:18:51,长城汽车董事长魏建军在2024年6月30日的直播活动中展示了长城汽车全场景NOA智能驾驶技术在重庆复杂路段的实际应用，强调了其Coffee Pilot Ultra系统的能力。SEE模型是长城汽车的技术核心，是一个端到端的智驾大模型，整合了感知、决策和规控，展现了在多变道路环境中的适应性和安全性。NOA功能针对高速和城市拥堵环境进行了优化，能够高效应对各种驾驶场景，确保安全与效率。长城汽车的超算中心九州提供了强大的算力支持，而SEE模型的持续进化预示着未来更先进的智能驾驶体验。长城汽车通过技术创新和实践检验，正引领智能驾驶新时代。
从零开始，用英伟达T4、A10训练小型文生视频模型，几小时搞定,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924109&idx=2&sn=b1b932560c7aa3be205b6c8e0fe18bf3&chksm=84e42033b393a9256d42ca91140f57b59701d707bb72083d82fd4b9d58c8f1e7b7055644aeea#rd,2024-06-30 18:18:51,本文是构建文本生成视频模型的教程，作者介绍了从理论概念到完整架构的编写过程。文章提到，文本生成视频是继大语言模型后2024年的AI趋势之一。由于算力限制，作者构建了一个小规模的GAN（生成对抗网络）模型，而不是扩散模型。教程中，作者使用Python生成包含移动对象的视频数据集，并通过GAN架构训练模型。文章详细解释了GAN的工作原理，以及如何设置训练数据、编码文本、实现生成器和判别器的网络层，并给出了训练参数和训练循环的代码。最后，作者展示了如何生成AI视频并提供了生成视频的代码。
Nature 热议论文证明「语言不是思考工具」，LLM 可能要学不会推理了？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924109&idx=3&sn=27eef00079268802db1ab4e8a0769475&chksm=84e42033b393a925aea6ba52b4c535996fbc45a8db67ce89126944512eae153ed9a7cd974999#rd,2024-06-30 18:18:51,这篇会员通讯讨论了三个AI和Robotics领域的热点议题。首先，一篇Nature论文提出“语言不是思考工具”，引发了关于LLM（大型语言模型）推理能力的讨论，论文认为语言主要用作交流而非思考，这与Yann LeCun和诺姆·乔姆斯基的观点相呼应。其次，通讯探讨了Super App的挑战，分析了大模型落地的难题，包括英伟达股价波动、商业模式探索和大模型的潜力与技术难题。最后，文章介绍了构建大规模GPU集群的要点，包括成本、性能优化和可持续发展问题。通讯还包含了本周其他26项AI和Robotics领域的更新。
亚马逊云创新「神经稀疏检索」：仅需要文本匹配就能实现语义搜索,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924109&idx=4&sn=e54fb1042b7aa20d59978e097ad886d2&chksm=84e42033b393a925838f11f1d774f20e54e831c1bec5a692d7c68d0fd53593bf01731346273c#rd,2024-06-30 18:18:51,亚马逊OpenSearch团队推出了Neural Sparse功能，旨在解决语义检索中的稳定性、效率和资源消耗问题。Neural Sparse通过稀疏编码技术，在处理陌生文字表述时能向文本匹配降级，提高检索相关性。它还提供了一种doc-only模式，实现低时延的在线搜索，同时减少了索引的存储资源消耗。相较于稠密编码，Neural Sparse在陌生数据集上表现出更好的自适应性，并且在速度和存储上具有优势。此外，通过两段式搜索策略，Neural Sparse进一步提升了检索速度。OpenSearch是一个开源的搜索和实时分析引擎，Neural Sparse的推出将促进语义检索技术的普及和应用。
30倍于传统方法，中国科学院团队Transformer深度学习模型预测糖-蛋白质作用位点,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924109&idx=5&sn=858fa7daf9e1117ed0905b56fe76150f&chksm=84e42033b393a9252419c642569be5cf09e2cb8c2af9ea3c9f75b7e03ff67d6759d1e2ec9a1c#rd,2024-06-30 18:18:51,中国科学院团队开发了一种名为DeepGlycanSite的深度学习模型，该模型能够准确预测蛋白质结构上的糖结合位点。糖类与蛋白质的相互作用在生理和病理过程中起着重要作用，但其复杂性给实验识别带来了挑战。DeepGlycanSite结合蛋白质的几何和进化特征，使用Transformer架构的深度等变图神经网络，性能优于先前的方法，能有效预测不同糖类分子的结合位点。该研究在《Nature Communications》上发表，表明DeepGlycanSite对于理解糖类调节蛋白质的分子机制和开发新治疗方法具有重要意义。
打开文心大模型，一看全是生产力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924032&idx=1&sn=04f7b88ea1d4edf26190efb5e684aeda&chksm=84e4207eb393a9683602c22bf4a0d11f2a507d9de5623684e5137b907acae5db19cb08002f7a#rd,2024-06-29 13:26:37,在百度的深度学习开发者大会上，百度发布了文心大模型的新版本——4.0 Turbo，该版本在速度和效果上都有所提升，并已在网页版和APP上上线。文心大模型4.0 Turbo基于4月发布的4.0版本，通过优化训练数据、算法和智能体技术，实现了更快的响应速度和更强的智能体功能。此外，百度展示了大模型在实际应用中的进展，如“农民院士智能体”在农业领域的应用，帮助农民解决种植问题，以及“体育大模型”在运动员训练和全民健身中的作用。百度还推出了智能代码助手“文心快码”，在内部被广泛应用，提高了工程师的开发效率。飞桨深度学习平台的最新版本3.0也在大会上发布，旨在支持大模型的训练和推理，简化开发过程并提高性能。目前，飞桨平台已拥有广泛的开发者和企业用户，构建了大模型的全链路生态支持体系。
开发者狂喜！Meta最新发布的LLM Compiler，实现77%自动调优效率,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924032&idx=2&sn=6e49b1bd2d36482b41cfd03e5901932a&chksm=84e4207eb393a96873f5d03e7d9515ec97a8fdd470d6abb7751d5a7fe66e7cf6665b8f420fd8#rd,2024-06-29 13:26:37,Meta 推出开源模型 LLM Compiler，旨在优化代码并改变编译器设计。该模型在代码大小优化上的潜力达到自动调优搜索的 77%，在反汇编方面成功率高达 45%，有望减少编译时间，提高代码效率，对于开发者来说是一大福音。LLM Compiler 可能会彻底改变开发者处理代码优化的方式，使其更高效、经济。该模型在汇编代码和编译器 IR 上进行预训练，增强了对编译器技术的理解，通过微调可以执行代码优化和反汇编任务。Meta 提供了 7 亿和 13 亿参数的预训练模型，促进了在代码和编译器优化领域的研究。
看张手绘草图就能合成图形程序，加州伯克利让扩散模型掌握新技能,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924032&idx=3&sn=d686551c78a4d4bd7258b33d7d9ba265&chksm=84e4207eb393a968f0bc485eaee7596dc35bcf3002a3215a83cbbe418fb81a19715f05ffbfb2#rd,2024-06-29 13:26:37,加州大学伯克利分校的研究团队利用神经扩散模型在句法树上操作，提出了一种新的程序合成方法。该方法能让模型通过迭代优化程序并确保句法有效性，特别是在逆向图形任务中，根据目标图像生成相应程序。研究团队发现，通过训练扩散模型和价值模型，可以引导去噪过程生成能输出所需结果的程序。在四种特定领域的图形语言上进行的实验表明，新方法在性能上优于先前的方法。
ICML 2024｜Transformer究竟如何推理？基于样例还是基于规则,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924032&idx=4&sn=87a8a9ac4290cd155302123460914f33&chksm=84e4207eb393a9685fcaf373319cea5fce04b723c3237f7a9c86e2e224557a82f0d4def9c3ef#rd,2024-06-29 13:26:37,这篇论文来自北京大学的研究团队，研究了Transformer模型在处理数学推理问题时采用的推理机制，是基于规则（rule-based reasoning）还是基于样例（case-based reasoning）。研究发现，Transformer模型在解决数学问题时倾向于使用case-based reasoning，依赖于训练数据中的相似样例，而难以实现系统性的泛化。通过Leave-Square-Out方法的实验，证明了模型在没有见过的相似样例时性能下降。此外，尽管使用Scratchpad可以部分改善模型的推理行为，但模型仍未能完全转向rule-based reasoning。为此，研究者提出了Rule-Following Fine-Tuning（RFFT）方法，旨在教Transformer进行rule-based reasoning，实验表明RFFT在增强模型的长度泛化能力方面表现出色。
AI小分子药物发现的「百科全书」，康奈尔、剑桥、EPFL等研究者综述登Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650924032&idx=5&sn=743ed8d1aab47d2b0e97b94beaa8b2ff&chksm=84e4207eb393a968807974c8a33c9e6c7ebf73a61816975c3ebb1b5aedd612df2931dbccc215#rd,2024-06-29 13:26:37,本文回顾了机器学习在生成式分子设计中的应用，特别是在药物发现中的作用。分子发现是一个复杂的问题，机器学习通过结合生成和筛选步骤加速了这一过程。文章介绍了不同的分子生成任务，如分布学习和目标导向生成，并探讨了各种生成方法，包括变分自编码器、生成对抗网络和正则化流等。此外，还讨论了分子表示、生成策略和优化技术。尽管存在挑战，如分布外生成和低保真度评估，但机器学习在药物发现的未来方向中展现出巨大潜力，包括在药物开发后期阶段的应用和自动化实验室的发展。
双向赋能：AI与数据库的修行之道,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923969&idx=1&sn=7e607c41da13ea868b3383b75be6e2b0&chksm=84e427bfb393aea9b8271db838a0ca34c38520c1df2a04654f0c2f964f9e86e7b16ad0d51d41#rd,2024-06-28 17:59:11,OpenAI收购数据库初创公司Rockset，旨在融合先进数据索引和查询技术，将数据转化为“可操作智能”。现代数据库与人工智能的融合正在重塑技术格局，带来数据库产业的技术挑战，如高性能处理、大并发、实例优化和数据安全。东方国信、PingCAP和云和恩墨等公司通过技术创新与英特尔的生态协同，应对挑战并抓住机遇。数据库产业需要创新和生态合作，以应对AI大模型时代的新需求，如数据量爆炸性增长、硬件性能提升和多功能性需求。英特尔通过处理器技术、开源合作和数据安全解决方案，助力数据库技术的创新和应用。同时，数据库与AI的深度融合将提升数据库性能和智能化水平，推动AI技术落地。
Bengio团队提出多模态新基准，直指Claude 3.5和GPT-4o弱点,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923969&idx=2&sn=b27df002433d2900786341974e47a07c&chksm=84e427bfb393aea94e317f6e9f5629a9b7e58d18f013f0d9b983cda985543f460e2e19d74e27#rd,2024-06-28 17:59:11,这篇论文介绍了一个新的视觉问答任务——视觉字幕恢复（VCR），旨在测试模型在处理部分遮挡文本时的推理能力。研究人员通过生成合成图像创建了VCR数据集，其中包含不同难度级别的任务，模拟了人类需要进行复杂推理来恢复遮挡文字的情况。实验结果显示，当前的视觉语言模型在处理这种任务时表现远逊于人类，表明它们在模拟人类推理过程方面还有很大提升空间。VCR任务为评估和提升多模态模型的高级认知和推理能力提供了新途径。
击败Gemini-1.5-Pro、GPT-4V，从容大模型多模态能力跻身全球前三,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923969&idx=3&sn=ba5336ae86c7e0d76395d31e8f4d72e0&chksm=84e427bfb393aea9532bf4fa8d3b56ab60301b43ced79c8e640c7813f8088b077abb8965505e#rd,2024-06-28 17:59:11,云从科技的从容大模型在OpenCompass多模态评测中取得全球前三的成绩，平均得分65.5，超越了谷歌的Gemini-1.5-Pro和GPT-4v。该模型在国内市场排名首位，领先于InternVL-Chat和GLM-4V。OpenCompass是上海人工智能实验室推出的评测框架，评估多模态大模型在多个领域的性能。从容大模型在6个数据集上表现优异，尤其在OCR任务中获得全球最高分，展示了其在文本识别和关键信息提取等场景的应用潜力。云从科技的自研技术和在视觉、语言领域的积累为模型的高效性能提供了支持。这一成绩也是对云从科技技术创新能力的肯定，并在业界树立了标杆。
谷歌「诚意之作」，开源9B、27B版Gemma2，主打高效、经济！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923969&idx=4&sn=0179e0823077c84f1f22f06d7ed4650b&chksm=84e427bfb393aea93ce3f82b1eb805f9c977ef37f4bf5616a2016cbd641d049b61fcc5e5a9da#rd,2024-06-28 17:59:11,谷歌推出了Gemma 2，这是一个基于Gemini模型构建的轻量级SOTA开放模型系列的新成员，旨在为AI任务提供工具。Gemma 2有90亿和270亿参数版本，其推理性能和效率超过第一代，特别是在单个NVIDIA GPU或TPU主机上运行时，降低了部署成本。270亿参数的Gemma 2能在其体积类别中与更大模型竞争，而90亿参数版本也优于同类开放模型，如Llama 3。此外，Gemma 2设计易于集成，支持多种AI框架，并将在Google Cloud的Vertex AI上部署。谷歌还提供了Gemma Cookbook和实验报告，以帮助开发者使用和微调模型。
300多篇相关研究，复旦、南洋理工最新多模态图像编辑综述论文,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923969&idx=5&sn=16cdc778bfa05540292a81393282633d&chksm=84e427bfb393aea9d73f555b6f8af6e78d48bc33f2c59d4d34ef83a686f8fa3f6b4728f192e8#rd,2024-06-28 17:59:11,复旦大学FVL实验室和南洋理工大学的研究人员对多模态引导的基于文生图大模型的图像编辑算法进行了总结和回顾，涵盖了300多篇相关研究。他们提出了一种统一框架，将编辑过程表示为不同算法族的组合，适用于各种编辑任务，如物体/属性操作、空间变换等。该框架为用户提供了设计空间，以满足不同的编辑需求，并为研究者开发新算法提供了参考。论文对基于T2I扩散模型的图像编辑技术进行了深入分析，包括Inversion和Editing算法，并讨论了未来的研究方向。
中国AGI能否重演移动互联网的故事？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923796&idx=1&sn=05a4ea0fe5a82107be1a4d96ee7d7d86&chksm=84e4276ab393ae7cb5821ca03aca3cd91f91431f6c5920b96f9acac11ec5e05929a3cc7861cb#rd,2024-06-27 20:33:29,这篇文章讨论了人工智能大模型在应用层面临的挑战和机遇，特别是通过对比微软的Copilot GPTs服务的关闭和中国市场上AI应用的繁荣。尽管微软将重心转向商业和企业级场景，但GPTs在消费级市场的表现并不理想。在中国，AI大模型正在与移动互联网时代的成果结合，催生出各种杀手级应用，如钉钉等。这些平台利用丰富的应用场景和业务数据，成功地将AI应用落地，提高了效率。文章以钉钉为例，展示了其如何通过与企业数据的深度融合，开发出更加个性化和高效的AI助手。中国的AI应用层因此展现出强大的创新潜力，有望在AI领域复制移动互联网的成功故事。
国产大模型新高度！讯飞星火4.0发布：整体超越GPT-4 Turbo，8个国际权威测试集测评第一,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923796&idx=2&sn=b692a56c5dd57406e1c87f596cf7d4ae&chksm=84e4276ab393ae7c7d5d27e49c2253b060ed2673b8733862abaf412e9b185a8bb139881d7aef#rd,2024-06-27 20:33:29,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我会尽力为您提取关键信息。
史上首个实时AI视频生成技术：DiT通用，速度提升10.6倍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923796&idx=3&sn=6d1f116da9b5475dd976329a462320b4&chksm=84e4276ab393ae7c2ea4e5331bf9e3bbc576c26375089fbe9f0abf867831566bf34740563977#rd,2024-06-27 20:33:29,新加坡国立大学尤洋团队提出了实时AI视频生成方法Pyramid Attention Broadcast（PAB），这是业内第一种可以实时输出、基于Diffusion Transformer（DiT）的视频生成技术。PAB通过减少冗余注意力计算，实现了21.6 FPS的帧率和10.6倍的加速，同时不牺牲视频质量。这种方法不需要训练，适用于任何基于DiT的视频生成模型，使其具备实时生成能力。研究发现，视频扩散transformer中注意力差异在中间70%的步骤非常稳定，PAB通过将一个扩散步骤的注意力输出广播到后续步骤，降低计算成本。此外，通过改进动态序列并行，PAB减少了通信开销，实现了高效的分布式推理。该方法在不同模型和GPU数量下均展现出较高的速度提升，且生成视频的质量损失很小。
ICML 2024 | 揭示非线形Transformer在上下文学习中学习和泛化的机制,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923796&idx=4&sn=e48147f380d56a273859586fd3096021&chksm=84e4276ab393ae7c3415ab64dcc1485a3922ad35efaaf00b3198db42d26f2bdbdc05e17528d9#rd,2024-06-27 20:33:29,"这篇文章是关于深度学习理论的研究，特别是上下文学习（in-context learning, ICL）在大语言模型（LLM）中的能力。作者李宏康是美国伦斯勒理工大学的博士生，研究团队包括伦斯勒理工大学和IBM研究院的成员。他们从优化和泛化理论角度分析了带有非线性注意力模块（attention）和多层感知机（MLP）的Transformer在ICL中的表现。论文证明了单层Transformer如何通过attention层选择上下文示例，然后在MLP层进行预测的ICL机制，并探讨了ICL的泛化能力。研究成果发表在ICML 2024，有助于理解Transformer在ICL中的工作原理。"
将图像自动文本化，图像描述质量更高、更准确了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923796&idx=5&sn=f07242a26a5738c72e8dbbbc85683ac4&chksm=84e4276ab393ae7c49cd5da9ebb19bace4e8693f6595d3fc1a53dec5be47a9b10ba9a49ed733#rd,2024-06-27 20:33:29,来自香港科技大学、武汉大学、浙江大学和UIUC的研究者提出了一个创新的自动化框架Image-Textualization（IT），该框架能自动生成准确且详细的图像描述。该框架利用多模态大语言模型进行粗粒度图像理解，视觉专家模型提取细节信息，纯文本大语言模型进行推理和重述，以生成高质量图像描述。研究者还创建了评估详细图像描述的基准，并通过实验验证了IT框架的有效性。生成的数据集IT-170K和相关代码已被公开发布，以促进未来研究。
耳朵没错，是声音太真了，字节豆包语音合成成果Seed-TTS技术揭秘,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923565&idx=1&sn=c31effe82125298de12ae6faef7a06ed&chksm=84e42653b393af45bd1b7b3597bf6bf11298e756a67084b02757ae72a0364712b6f6d13deeae#rd,2024-06-26 12:08:29,字节跳动豆包大模型团队发布了语音生成模型Seed-TTS，该模型能够生成与真人几乎无异的语音，包括发音瑕疵，能够模仿人类说话的相似性和自然度。提供一段语音给Seed-TTS，它可以按文本生成带有原声音特征的新语音，同时支持音色定制和不同角色情绪的“说书”效果。该模型已经在C端产品上线并获得用户好评，其技术亮点包括作为语音生成的基座模型，能够处理各种任务和声音操控，具有高自然度和稳定性，并使用了大规模数据训练。团队在应对细节建模、数据覆盖、模型设计和工程挑战等方面进行了研究，为语音生成领域带来了新进展。
旷视开源的AI人像视频生成太炸了！输入照片即可模仿任意表情包,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923565&idx=2&sn=e52894d202ab6b19524044a0c73fc6f7&chksm=84e42653b393af455ebee3f2596d218af2d781bd267d6e45224a7853cff8333eca4229c9fa8a#rd,2024-06-26 12:08:29,旷视科技发布了开源AI人像视频生成框架MegActor，该框架能让用户输入一张静态肖像图片和一段视频，生成表情丰富、动作一致的AI人像视频。MegActor生成的视频质量和细节表现优秀，且能够实现不同人物肖像和视频的组合生成。与阿里EMO和微软VASA等不同，MegActor采取开源方式提供给开发者。该框架由ReferenceNet和PoseGuider两个阶段构成，使用原始视频驱动以捕捉细致的表情和运动信息。为解决身份泄露和背景干扰问题，MegActor采用条件扩散模型和数据处理方法。旷视科技仅使用开源数据集进行训练，并已将MegActor开源，支持多样化的驱动视频和画风，生成的视频效果自然。
OpenAI断供大陆市场，这家GPT-4的“国产平替”真香,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923565&idx=3&sn=7f75ef5ac080fd2f41cc5029050dcf9c&chksm=84e42653b393af4510a8bacefea5495011a026941306138612bfb6bcb580677387b4ab4b407b#rd,2024-06-26 12:08:29,OpenAI宣布将从7月9日起封锁来自非支持国家和地区的API流量，中国大陆和香港等地未在支持名单上，这对中国开发者造成影响。为应对这一情况，李开复博士创立的AI公司零一万物推出了“Yi API 二折平替计划”，提供高性价比的国产大模型服务，作为OpenAI API的替代方案。零一万物的Yi系列大模型在性能上与GPT-4等相媲美，但成本显著降低，旨在帮助受影响的开发者和企业平稳过渡。目前，Yi系列模型已获得多家头部企业的认可并广泛应用在不同领域。
史上最快AI芯片「Sohu」，速度10倍于B200，哈佛辍学生打造,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923565&idx=4&sn=d35d524ab22ac7ee162e85a5342ffc41&chksm=84e42653b393af45e728798eb8bfc837fd7765c71f579a38be35ee1dc687e81d7e8658c1febd#rd,2024-06-26 12:08:29,美国芯片创业公司Etched推出首款专门用于Transformer计算的ASIC芯片Sohu，该芯片运行大模型的速度比英伟达H100快20倍，比B200快10倍。Sohu服务器在运行Llama 70B时每秒可输出超过50万个token，远超H100和B200。作为Transformer ASIC，Sohu无法运行非Transformer架构的传统AI模型，但对Transformer模型的处理速度达到前所未有的水平，FLOPS利用率超过90%。Etched表示，由于大模型对算力的需求，专用芯片将成为趋势。公司已获得1.2亿美元A轮融资，计划在今年三季度将Sohu推向市场。
ICML 2024 | 信号表征指数级强、内存节省超35%，量子隐式表征网络来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923565&idx=5&sn=f34c8c6b10f763f6f32908c8407344d9&chksm=84e42653b393af45b1d34d8616880fa743c974ffe0179c19cee71bbc21f964e1737df4f2e967#rd,2024-06-26 12:08:29,"天津大学的研究团队提出了一种名为量子隐式表征网络（Quantum Implicit Representation Network, QIREN）的新方法，该方法将量子计算应用于隐式神经表征领域，理论上具有指数级的信号表征能力。与经典神经网络相比，QIREN在信号表示任务上表现出更优的性能，特别是在参数量更少的情况下，拟合误差最多可减少35%。该研究受到ICML 2024的接收，显示了量子计算在隐式神经表征和机器学习领域的潜在优势。"
OpenAI停服，国产大模型免费用！开发者Token自由实现了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923417&idx=1&sn=3520ad0b7658b24387767e4ccda918e0&chksm=84e425e7b393acf1f5aa96d312ef371ad1f37cd69ce2ac6cce21f43ed995a6df8399b384b72b#rd,2024-06-25 12:29:02,OpenAI宣布停止向中国提供API服务，导致国内开发者访问GPT等高级大模型的难度增加。然而，开源大模型的崛起提供了替代方案，如Qwen2和DeepSeek V2。为了解决开发者的需求，AI基础架构公司硅基流动推出了大模型API平台SiliconCloud，提供快速、低价和全面的服务。硅基流动宣布Qwen2 (7B)、GLM4 (9B)、Yi1.5（9B）等顶级开源大模型将永久免费，为开发者提供“Token自由”。SiliconCloud支持多种开源大模型，包括最新和最优秀的模型，并通过性能优化实现了快速响应和成本降低，为开发者降低了AI应用开发的门槛和成本。该平台已获得开发者的积极评价，被认为是同类产品中体验最佳的。随着Token自由的实现，硅基流动有望推动国内开发者创造出更多现象级的AI应用。
飞书，为何成为国内大模型独角兽们的共同选择？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923417&idx=2&sn=7b60b8c4dcaa34f8b735b6581327d8be&chksm=84e425e7b393acf1b983c3c22512db75f205f30c02f28f5b6a461dd1df628b71bb2b7b31f5bf#rd,2024-06-25 12:29:02,中国的大模型行业在2024年呈现出疯狂的增长态势，创业公司估值飙升，竞争激烈。企业间在价格、市场份额和技术上展开较量，商业策略分为面向C端用户和B端企业两类。尽管竞争激烈，多数大模型公司一致选择飞书作为协作工具。飞书受到青睐的原因包括其工具的快速迭代、敏捷型组织理念、高灵活性和开放度，以及满足全球化和安全需求的能力。此外，飞书在先进企业和个人用户中广泛应用，其内置的AI能力也在不断提升，与AI行业的关联日益紧密。
邀请函｜洞观世界，聚引长三角——AI新质生产力发展论坛盛大开启，欢迎参会！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923417&idx=3&sn=4f158e2815e3057df1bab6adbdb9cfd6&chksm=84e425e7b393acf16429fe8584702ba2c035cae1ade79da592f21847bab248ff20e8e4d4e521#rd,2024-06-25 12:29:02,"这篇文章的摘要可以这样写：

2024年世界人工智能大会期间，长三角国家技术创新中心将主办“2024 WAIC 长三角协同创新AI新质生产力发展论坛”，探讨人工智能在推动新质生产力发展中的作用和趋势。论坛将汇聚国内外专家，讨论如何通过跨区域协同创新推动人工智能在长三角地区的应用和发展。活动亮点包括权威专家致辞、行业洞察分享、高端对话和产业创新联合体成立仪式，旨在促进人工智能与各行业的深度融合与创新发展。"
OpenAI封杀不支持地区API：违规封号，7月9日生效,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923417&idx=4&sn=f8a18044d76613d7535468b861dc43cf&chksm=84e425e7b393acf1f6a6456b24064f4ffa5f0c944862fffd5af16a60a92fc9a7ef74194a795d#rd,2024-06-25 12:29:02,OpenAI已警告全球多地的开发者，将封禁不符合服务区域规定的API使用，截止日期为7月9日。该公司明确表示，除支持的国家和地区外，访问其服务可能导致账户被封禁。OpenAI的大模型API被广泛用于构建生成式AI应用，包括ChatGPT的集成。随着GPT-4等多模态生成式AI任务的增加，此次封锁可能影响大量开发者。同时，OpenAI宣布即将对GPT-4的语音模式进行灰度测试，新功能包括实时响应对话、情绪感知和视频聊天等。ChatGPT Plus用户将很快获得完整版GPT-4功能。
昆仑万维携手南洋理工大学抢发Q*算法：百倍提升7B模型推理能力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923417&idx=5&sn=9df8243cf1d0ff93e26e28b88788d93e&chksm=84e425e7b393acf15f90af491d29c283eb3f081c20a50e71135ab946fa57cd37e50965a8bfc0#rd,2024-06-25 12:29:02,昆仑万维和新加坡南洋理工大学的研究人员开发了一种名为Q*的算法，该算法能够显著提升大语言模型的推理能力，尤其是在数学问题解决和编程任务上。Q*通过将历史状态收益和未来期望收益集成到同一个函数中，并利用A*搜索算法进行全盘规划，改进了多步推理。实验结果显示，Q*帮助小规模模型在多个数据集上的性能超越了更大型的模型，如在GSM8K、MATH和MBPP数据集上的表现。该算法降低了计算资源需求，为人工智能的应用开辟了新途径。相关研究仍在进行中，未来将继续优化Q*算法。
太全了！苹果上新视觉模型4M-21，搞定21种模态,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923417&idx=6&sn=b4035dfd33e4e788611744007554a777&chksm=84e425e7b393acf1384c81363e9466f772f9e29257218798ba2bc2055f975aa4034b49e65761#rd,2024-06-25 12:29:02,来自洛桑联邦理工学院（EPFL）和苹果的研究者联合开发了一个任意到任意模态单一模型，该模型在数十种高度多样化的模态上进行训练，并对大规模多模态数据集和文本语料库进行协同训练。该研究展示了训练单一模型也能完成现有模型至少3倍多的任务/模态，且不会损失性能，实现了更细粒度和更可控的多模态生成能力。模型能处理21种不同模态，包括跨模态检索、可控生成和强大的开箱即用性能。研究通过使用特定于模态的离散分词器进行编码，扩展了现有模型的功能，支持更多结构化数据，如人体姿态、元数据等，并在多个数据集上进行联合训练。
跟骑手学习送外卖，这家具身智能公司的机器人已经上岗挣钱了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923260&idx=1&sn=a43f10c06d7c3e15abc194c1d59e28d3&chksm=84e42482b393ad946877086a5a11910746012840d7a64d660c173f040a831d4045384f8cae30#rd,2024-06-24 12:03:42,本文介绍了具身智能机器人公司推行科技（Infermove）的最新进展，该公司利用数据驱动的方法打造能够在开放物理世界中自主移动的机器人，用于末端物流配送。目前，他们的机器人已经为山姆会员店等商家完成了几万单货的配送，并能够实现与无人机的无缝接驳，将货物从无人机降落点送到指定地点。机器人配备了手臂，可以完成拿取、按电梯和开关门等任务。这家公司通过模仿学习和强化学习的方法，利用骑手骑行数据训练机器人，并通过“骑手影子系统”获取大量数据，实现了机器人的高效表现。未来，他们计划在自然语言、多模态等方面进行迭代，使机器人更加实用。
营销效果大幅提升，AIGC视频创作就该这么用,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923260&idx=2&sn=864b3be5691c0e299f9a284904d38696&chksm=84e42482b393ad94dbda03fe15036b0061b8db1557a2d678c6513bd4566eb9561a8a7e9cf2e7#rd,2024-06-24 12:03:42,这篇文章介绍了AIGC（人工智能生成内容）在视频生成领域的进展，特别是Sora的出现对视频生成赛道的影响。虽然大模型在技术上取得了进步，但在实际应用中仍然面临落地难的问题。营销被认为是AIGC的重要落地场景，企业和从业者寻求利用AIGC提高视频创作效率。文章提到了火山引擎和英伟达合作的视频栏目《AIGC体验派》，该栏目探讨了如何借助AIGC提升营销视频创作效率。第一期节目中，嘉宾讨论了AIGC在营销领域的应用和选择AIGC工具的考量指标。第二期节目将围绕如何用AIGC提升营销视频创作效率展开，介绍火山引擎的智能创作云和英伟达的相关技术。
WAIC论坛报名｜齐聚多家央国企与AI公司，共议产业融通发展,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923260&idx=3&sn=e7146a9f7ec1a462ae3282ffbc406537&chksm=84e42482b393ad94831454a733a51d89c99ba61a4106a5e7384fbff3aa840aa736fc035b9a87#rd,2024-06-24 12:03:42,这篇文章提到，中国政府强调深化大数据和人工智能的应用，推出“人工智能+”行动，以促进数字产业集群的国际竞争力。为了加速这一进程，将于7月6日在上海举办「2024 WAIC 人工智能赋能产业融通发展论坛」。该论坛将汇集AI场景应用方和头部AI企业，探讨技术如何赋能场景落地和产业升级。活动包括主题演讲、央国企应用场景需求发布和圆桌讨论，以促进供需双方的合作交流，尤其是人工智能在电力、能源和工业化中的应用。论坛旨在推动人工智能与产业的深度融合，助力新型工业化发展。
语言≠思维，大模型学不了推理：一篇Nature让AI社区炸锅了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923260&idx=4&sn=1bbe955f370ce9aa654f3dce0a07e805&chksm=84e42482b393ad94f3f1ba967b5015ce1f399f9fc15bbd71277c457fe9b29c1749fddf2bde4c#rd,2024-06-24 12:03:42,麻省理工学院等机构的研究人员在《自然》杂志发表论文称，人类大脑生成和解析语言的神经网络并不负责形式化推理，语言主要是用于交流而不是思考的工具，对于任何经过测试的思维形式都不是必需的。这一发现挑战了语言在思维中的核心地位观念。研究发现，即使在语言能力严重受损的情况下，个体仍能进行数学问题解决、执行规划和推理。论文指出，语言和推理是平行发展的，拥有完整的语言系统并不意味着具备完整的推理能力。这一研究结果引发了科技领域关于大语言模型通向通用人工智能路线的讨论。
奥林匹克竞赛里选最聪明的AI：Claude-3.5-Sonnet vs. GPT-4o？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923260&idx=5&sn=a1de16c54af4537fd567e77dcd20795d&chksm=84e42482b393ad94d218c8f9f339cf6220700177c5c1937a738f221ce23c3eab0de659274639#rd,2024-06-24 12:03:42,上海交通大学生成式人工智能实验室（GAIR Lab）的研究团队推出了OlympicArena，一个评估AI智力的测试平台，通过模拟奥林匹克学科竞赛来衡量模型的综合表现。团队首次使用“奥林匹克竞赛奖牌榜”对AI模型进行排名，分析了Claude-3.5-Sonnet、Gemini-1.5-Pro和OpenAI的GPT-4系列等模型。实验结果显示，Claude-3.5-Sonnet在某些科目上超过GPT-4o，但整体上两者表现接近。研究强调了不同模型在不同学科和推理类型上的优势，表明AI在某些领域的推理和知识整合能力仍有提升空间。
为什么都放弃了LangChain？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923209&idx=1&sn=841a47666e7052449572228cdeee9e04&chksm=84e424b7b393ada167417fbef2e9d6413d04976d06022c9c515085fd6caef1f4c89d90cccc74#rd,2024-06-23 12:25:29,这篇文章是一位名为Fabian Both的深度学习工程师分享的关于使用LangChain（一种AI工具链）的负面经验。Both在文章中提到，尽管LangChain在初期因其丰富的工具和易于集成的特点看似是最佳选择，但随着项目复杂性的增加，LangChain的不灵活性和抽象设计成为了问题。代码的复杂性增加，维护困难，且无法适应快速变化的人工智能领域。Both表示，LangChain的抽象方法没有带来明显的好处，反而增加了理解和调试的难度。他们最终决定放弃LangChain，转而采用更直接的编程方法。另一位开发者Tim Valishev则表示他仍然喜欢LangChain的一些功能，如可视化日志和Prompt playground。文章最后建议，在人工智能领域的开发中，有时保持简单可能更为有效。
从RLHF到DPO再到TDPO，大模型对齐算法已经是「token-level」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923209&idx=2&sn=1d5f4df7efcd7f4cda09b8adb591e713&chksm=84e424b7b393ada16516c052ccb625c850b46705519ce5e896fadc166e302c5b70b57151c0a0#rd,2024-06-23 12:25:29,这篇文章介绍了人工智能领域的一个新发展，即Token-level Direct Preference Optimization (TDPO)算法。该算法旨在更好地控制和优化大语言模型（LLM）的行为，确保其安全性和人类友好性。早期的方法如RLHF（强化学习人类反馈）虽有效，但资源消耗大。DPO（直接偏好优化）作为RLHF的简化版，减少了复杂度，但可能降低生成的多样性。TDPO由中科院和伦敦大学学院的研究团队提出，通过从token-level（单词级别）角度建模，引入细粒度的KL散度约束，解决了DPO的多样性问题。相比于DPO，TDPO能实现更好的对齐性能和生成多样性，并在多个数据集上的实验中显示出优势。
英伟达 Nemotron-4 340B 火了！合成数据能否将大模型带入下一个阶段？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923209&idx=3&sn=dbf867f7c5fb187e52d1cc7c90c01161&chksm=84e424b7b393ada1c525e7c37d07132915dbd749c9240c35dc8c30c838c0ec685f83ad92ac34#rd,2024-06-23 12:25:29,英伟达开源了Nemotron-4 340B系列模型，该模型可生成多种领域的大规模合成数据，用于预训练和微调特定的大模型，旨在解决大模型训练中的数据短缺问题。模型采用了Transformer架构和先进技术，如RoPE和MOE，以提高性能。合成数据在大模型训练中可以用于预训练的补充和对齐阶段的高效数据获取，但同时也面临着真实性、保真度、偏见和过拟合等挑战。目前，业内对于合成数据能否有效解决数据瓶颈存在不同看法。此外，文章还探讨了大模型的商业化策略和人形机器人Unitree G1的市场动态。
CVPR 24｜ETH Zurich等团队：重新定义小样本3D分割任务，新基准开启广阔提升潜力！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923209&idx=4&sn=a4107879c429720565b8694a9df061f8&chksm=84e424b7b393ada13e4c7bdbb99439d5e780d8736846145515bfdb7ff35c8a5cb4104e9083d0#rd,2024-06-23 12:25:29,这篇文章介绍了一种 Few-shot 学习方法在3D场景理解中的应用，该方法能提高模型在识别新类别时的性能，减少对大量标注数据的依赖。研究团队发现当前 Few-shot 3D Point Cloud Semantic Segmentation (FS-PCS) 任务中存在前景泄漏和稀疏点分布问题，这些问题影响了模型评估的准确性。为此，他们提出了一种新的标准化设置，采用均匀采样和增加采样点数，以及一个名为 COSeg 的新模型，该模型通过优化点云之间的相关性来提高泛化能力。实验显示，COSeg 在 Few-shot 任务中实现了最佳性能，为未来的研究提供了新方向。
LeCun学生、纽大助理教授Alfredo视频上新，跟他免费学本科AI课程,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923209&idx=5&sn=e398cebdfb66751cd2db92747ec9ffd3&chksm=84e424b7b393ada1a91b16cadcbe480f2fc9a9002077b0873d29d7aacd7d914d3a8e05762882#rd,2024-06-23 12:25:29,纽约大学计算机科学助理教授 Alfredo Canziani 开设的人工智能本科课程已放出在线视频，内容包括基于知识的 AI 和基于学习的 AI 及自然语言处理。课程分为两大部分，第一部分由 Ernest David 授课，涉及搜索、逻辑推理等；第二部分由 Alfredo Canziani 讲授，涵盖离散概率、神经网络等。Alfredo Canziani 是深度学习研究科学家，其研究集中在自动驾驶机器学习。课程视频可在 Youtube 上观看，详细信息可在课程主页查阅。
导师爆料：这篇CVPR最佳学生论文，从想法到成稿只用一个月，源自业余灵感,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923183&idx=1&sn=20294bcece727ec6b6439109daa3aa3b&chksm=84e424d1b393adc7ccb7842ae29cdae6ef262e20875161fbd7ffd6b87cc5a29e69d5f365a403#rd,2024-06-22 12:54:41,CVPR 2024 最佳学生论文“Mip-Splatting: Alias-free 3D Gaussian Splatting”仅用一个月时间完成。该论文由Zehao Yu撰写，他通过业余时间对高斯泼溅技术产生兴趣并进行研究，解决了3D图像渲染中的抗锯齿和缩放伪影问题。Zehao Yu的导师Andreas Geiger强调了研究的非线性和好奇心在科研中的重要性。这篇论文提出了一种用于3D图像渲染的抗锯齿方法，有助于提高图像质量。Zehao Yu是图宾根大学的博士生，此前已参与过多个项目并在NeurIPS 2022上发表过论文。
墙裂推荐！Karpathy大模型培训课LLM101n上线了，非常基础,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923183&idx=2&sn=72dcecc89f49a2a5a8bd266290547652&chksm=84e424d1b393adc70fd233d0e78d063ea0a306812ba3aca79a743b842605a0ca8806d781a8a3#rd,2024-06-22 12:54:41,Andrej Karpathy在GitHub上发布了一个新项目，名为LLM101n，目标是构建一个能够创作、提炼和解释小故事的大型语言模型。这个课程从语言建模和机器学习基础开始，涵盖多模态、强化学习（RLHF）、模型部署等方面，被比喻为类似CS231n的全面课程，旨在教授如何构建类似ChatGPT的模型。课程包括17章，从Bigram语言模型到多模态和模型部署，适合对AI和深度学习感兴趣的学生。项目已在GitHub上获得广泛关注和推荐。
华为盘古大模型5.0技术解密：更多模态，复杂推理,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923183&idx=3&sn=84f732d10320e9eeb5c7cfb4dfc8d061&chksm=84e424d1b393adc7d60c1c958ba01f9862c87c6ae5cbd4a885dddcc0f00e8f5787f5e5596c2c#rd,2024-06-22 12:54:41,华为发布了盘古大模型5.0，该模型能理解多种模态信息，包括文本、图片、视频等，并已在工业领域和具身智能领域落地应用。模型分为不同规模版本，最高达万亿级参数。盘古5.0通过数据合成技术提高训练效率，使用合成数据弥补高质量自然数据的不足。此外，模型采用了昇腾亲和的Transformer架构——π架构，解决特征坍塌问题，提升精度。大集群训练技术优化了模型计算算力利用率。模型在多模态能力和复杂推理能力上有所提升，特别是在动态分辨率表征和强思维任务上表现出色。华为还将这些技术集成到其AI框架中，以提高训练效率。
字节豆包全新图像Tokenizer：生成图像最低只需32个token，最高提速410倍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923183&idx=4&sn=8018157f98d657eb62bd38ce9705c295&chksm=84e424d1b393adc744970bf7adb6b9905956c7144fc2ff8e649a8feb2d9154b0526e0d43a5c2#rd,2024-06-22 12:54:41,字节跳动豆包大模型团队和慕尼黑工业大学合作提出了一种新的1D图像Tokenizer——TiTok，用于生成式模型。TiTok打破了传统2D Tokenizer的限制，能将图像压缩成更紧凑的Token序列，减少图像编码的冗余信息。对于256x256分辨率的图片，TiTok仅需32个Token，远少于常规2D Tokenizer的256或1024个Token。在512x512分辨率下，TiTok仅需64个Token，比Stable Diffusion的VAE Tokenizer减少64倍。在ImageNet图像生成任务上，使用TiTok的生成器在质量和速度上均有所提升，如在512分辨率下，TiTok的FID得分优于DiT且生成速度提高了410倍。实验表明，TiTok在减少Token数量的同时，保持了高质量图像生成和更快的推理速度。
《Python 机器学习》作者新作：从头开始构建大型语言模型，代码已开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650923183&idx=5&sn=4eaa868d5c37067209490d18a4a5426b&chksm=84e424d1b393adc7d8f3b7ed84f823569dce2170290d956fe3506463d93b6493f63beb0e9f28#rd,2024-06-22 12:54:41,机器学习和 AI 研究员 Sebastian Raschka 近期开源了一本新书《Build a Large Language Model (From Scratch)》的代码库，该书详述了从头构建大型语言模型的全过程，包括设计、创建、训练和调整。项目中特别介绍了指令微调的方法，如数据格式化、prompt-style 模板应用和掩码使用。书中的内容涵盖规划编码 LLM、准备训练数据集、微调 LLM 和应用指令调整等阶段。Sebastian Raschka 是一名专注于深度学习和机器学习的研究员，著有畅销书《Python Machine Learning》等，他致力于使 AI 和深度学习技术更易获取，并积极参与开源软件贡献。
抢疯了，腾讯给大模型人才，定了一个前所未有的标准,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922990&idx=1&sn=77254311533e85925256f397a9e4a0e9&chksm=84e41b90b3939286266add309cc191f572fa15c7ee6fa80beb642fa7107977610351ba3c427c#rd,2024-06-21 13:01:15,这篇文章讲述了科技公司对顶尖AI人才的争夺，以OpenAI的成功为例，强调了人才在公司持续发展中的关键作用。文章提到了腾讯在大模型领域的投入，特别是混元大模型团队的研发成果，例如推出了业内首个中文原生的DiT架构文生图模型混元-DiT，并开源给公众。另外，文章通过三位腾讯员工的故事，展示了他们如何在技术领域追求创新和进步，包括在游戏AI、文生图模型和蛋白质组学研究方面的贡献。腾讯还宣布加强大模型领域的人才招聘，扩大了其“青云计划”的规模，以吸引全球顶尖学子。
小红书这场大模型论文分享会，集齐了四大国际顶会的作者,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922990&idx=2&sn=596214587a29263bff1693c36a46d887&chksm=84e41b90b3939286c099e333cdedec684e16d16b9a50bc5deb69a8c1d757a6e25bba60b9e70e#rd,2024-06-21 13:01:15,小红书技术团队在大模型和自然语言处理领域取得多项研究成果，多篇论文入选ICLR、ACL、CVPR等国际顶会。6月27日，小红书将在线上直播分享2024年发表的6篇大模型研究论文，涵盖大模型解码与蒸馏技术、评测方法及平台应用。分享会将探讨如何降低多步推理的成本、提升自由格式生成任务的性能、实现类人水平的文本评测以及利用负样本进行模型蒸馏等问题。参与直播的观众将有机会与论文作者交流，并获取论文PDF合集。
Luma、Runway轮番炸场，视频生成卷出新高度，Sora还能称霸吗？来这场WAIC视频生成论坛寻找答案,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922990&idx=3&sn=741b51e5ba17cbec205d49cdf0cdec58&chksm=84e41b90b3939286f8c39e5b5df05d67c6c1070042b6cb98b39c6b8b23c282e32f0d0ff2f9f6#rd,2024-06-21 13:01:15,这篇文章提到了2024年被称作“人工智能电影”元年，随着Sora、Stable Video Diffusion、LTX Studio等AI视频应用的出现，视频生成技术迅速发展，推动了AI 2.0时代的到来。世界人工智能大会组委会将于2024年7月5日举办「2024 WAIC 视频生成前沿技术论坛」，该论坛将汇聚达摩院、美图公司、Morph AI等10余家AI视频领域的领先企业，展示最新技术成果和创新应用。论坛将深入探讨视频生成的前沿技术、产业实践以及未来趋势，同时提供专业书籍作为参会福利。
不做数值运算、纯靠嘴炮也能机器学习？基于自然语言的全新ML范式来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922990&idx=4&sn=677260c05737f294f7f11ac1e6f0660f&chksm=84e41b90b39392863106fc21d8345d610bcdd7f9c36ef2dd878cebf01e1b2a79873a04157014#rd,2024-06-21 13:01:15,这篇文章介绍了Verbalized Machine Learning (VML)——一种基于自然语言的机器学习新范式。在VML中，大语言模型（LLM）被用作自然语言空间中的通用近似函数，数据和参数都是字符串。推理和训练过程通过LLM进行，其中优化器和模型都以自然语言形式存在。VML的优势包括易于添加归纳偏置、自动选择模型函数族以及提供可解释的更新和推理。实验展示了VML在多项式回归、非线性二维平面分类和医疗图像二分类任务中的应用，证明了其有效性和可解释性。
无论真实还是AI视频，「摩斯卡」都能重建恢复4D动态可渲染场景,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922990&idx=5&sn=cdb4c802d5f859f213409b4120fbc22d&chksm=84e41b90b3939286316465540103e74b16aff5264d68e61b2c050e447a3d8d80b7ef518db72c#rd,2024-06-21 13:01:15,这篇文章介绍了美国宾夕法尼亚大学和斯坦福大学研究团队开发的一种名为摩斯卡(MoSca)的新型神经信息处理系统，该系统可以从单目视频中重建可渲染的动态场景。摩斯卡利用单目有尺度深度估计、视频跟踪、光流估计和预训练语义模型等基石模型的输出，结合四维运动脚手架(4D Motion Scaffold)的紧凑动态场景表示，解决了从二维视频中提取三维动态信息的难题。四维运动脚手架通过刚体运动轨迹的时空间插值来表示物体的变形，允许全局信息融合和高效优化。摩斯卡不需要相机内外参，能够直接从视频中优化相机位姿和内参。实验结果显示，摩斯卡在多个数据集上表现出色，能够处理具有挑战性的动态场景重建任务。
1342万考生填报志愿这件事 ，AI搜索可帮了大忙,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922829&idx=1&sn=ae4791241d62803a2d0543618371551a&chksm=84e41b33b3939225832429140f9c1a7dc2a106a5e45fd5b0a205daa086cf7699e695b8a6dfb3#rd,2024-06-20 13:16:08,本文介绍了阿里旗下夸克APP在2024年高考中推出的全新AI搜索功能，帮助数百万考生和家长应对新高考制度下的志愿填报。新高考改革赋予了考生更多选择，但也带来了信息获取和分析的挑战。夸克高考提供了模拟志愿选择、个性化问题解答等服务，利用AI搜索能力解答复杂问题，引用权威信息源，并增加了在校生的学习生活笔记和校园实景等信息，以帮助考生更全面地了解院校和专业。此外，夸克还提供了智能选志愿功能，根据考生信息给出志愿填报建议。夸克通过升级AI搜索，将大模型技术应用到高频应用场景，提升了用户体验，为高考信息服务提供了新的解决方案。
超越CVPR 2024方法，DynRefer在区域级多模态识别任务上，多项SOTA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922829&idx=2&sn=ed0ead2ac9aba01f799890facaf62035&chksm=84e41b33b3939225d08200d7c807fcda48d1811539237b6d601f217dcb9a4fe0b81deff7eaa0#rd,2024-06-20 13:16:08,这篇文章介绍了中国科学院大学LAMP实验室的研究成果，名为DynRefer的动态分辨率方案，该方案旨在模拟人类视觉认知系统，提升区域级多模态理解的精度。DynRefer通过引入动态分辨率机制，能够在单个模型中处理区域识别、属性检测和字幕生成任务，并在多个任务上达到SOTA性能。与传统方法相比，DynRefer利用多视图构造和随机动态视图嵌入来模拟人类对关注区域的高分辨率处理和非关注区域的低分辨率处理。实验结果显示，DynRefer在区域字幕生成、密集字幕生成、开放词汇属性检测和区域识别任务上都表现优秀。
从高考到奥林匹克竞技场：大模型与人类智能的终极较量,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922829&idx=3&sn=166a662a9a78a47b10a2fe3d2cb9a1ae&chksm=84e41b33b3939225c52c2e436ea8dc5128be48a3d800ee73a2a0c16921dfbf054be118a2e78e#rd,2024-06-20 13:16:08,上海交通大学生成式人工智能实验室的研究团队推出了一个名为OlympicArena的新基准，用于评估大模型（包括多模态大模型）的认知推理能力。该基准使用国际学科奥林匹克竞赛的高难度题目，涵盖数学、物理、化学等七大核心学科，旨在测试AI在跨学科问题上的智力水平。研究发现，当前大模型在学科奥赛上的表现不佳，即便是最先进的模型GPT-4o，正确率也只有39%，显示出模型在科学问题求解和推理能力上与人类存在差距。OlympicArena为评估和提高AI的科学推理能力提供了工具，并强调了在复杂推理和利用视觉信息方面的发展需求。
北大推出全新机器人多模态大模型！面向通用和机器人场景的高效推理和操作,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922829&idx=4&sn=940f7f787b8171ff9fbf20fab7687d1a&chksm=84e41b33b3939225c32468c44724ec9d890edb6f7e781cfd9bb16307b7150992403dd0ca5dc0#rd,2024-06-20 13:16:08,研究者提出了一种名为 RoboMamba 的多模态大模型，它将视觉编码器与高效的状态空间模型（Mamba）集成，以实现机器人推理和操纵能力。RoboMamba 能够处理视觉常识任务和机器人相关任务，并在这些任务上表现出先进的性能。此外，该模型可以通过极低的训练成本学习多种操纵位姿预测技能。这一成果改进了现有机器人多模态大模型在复杂任务推理和计算效率上的挑战。RoboMamba 在多个基准测试上表现出色，并在模拟和现实世界实验中展示了高效的操纵位姿预测能力。
ShareGPT4V作者团队又一力作！百万高质量视频-字幕数据助力社区提升多模态大模型视频理解及生成能力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922829&idx=5&sn=6b838991bf3b181628678f378027c0f7&chksm=84e41b33b3939225b9b0d98e2661b1738607b9ee2dd8983a30d567a3012276bc1fe6cd4ca6a2#rd,2024-06-20 13:16:08,来自中国科学技术大学、北京大学和上海 AI Lab 的研究人员发布了 ShareGPT4Video 系列，旨在提升视频理解和生成能力。该研究基于高质量的 ShareGPT4V 数据集，通过一种称为差分滑窗视频描述 (DiffSW) 的策略，为任意分辨率、宽高比和长度的视频生成高质量描述。研究者们创建了大型“视频-文本描述”数据集 ShareGPT4Video，包含4万条（291小时）由GPT-4V标注的视频数据，以及一个多功能多模态大模型ShareCaptioner-Video，用于视频描述生成。实验表明，ShareGPT4Video 数据集的使用可以显著提高视频理解模型的性能，并且详细的字幕数据对文生视频模型的视频生成质量有显著提升。
大模型如何破解数据困局，WAIC产学研专家共话突围之道,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922592&idx=1&sn=ff2b7d5ab2f96faaeb7ede2e59a2bbd1&chksm=84e41a1eb39393087d63ac73d201fa557117a6dec4c6a57c701c4e0b4bdd6b9a47a07b520693#rd,2024-06-19 12:44:23,这篇文章提到了即将到来的「2024 WAIC 隐私计算：助力大模型与数据可信融合发展论坛」，该论坛旨在探讨隐私计算如何在保障数据安全和隐私的同时，促进大模型技术的规模化应用和数据跨行业流通。随着大模型技术的发展，数据安全和隐私成为重要议题，论坛将聚集业界和学术界的专家，分享隐私计算的前沿技术和实践案例。论坛还将发布蚂蚁集团的“隐语 Cloud”大模型密态计算服务，展示如何在医疗等敏感领域应用密态计算技术。此外，论坛将涵盖隐私计算技术的学术前沿、数据可信流通的标准与技术体系以及产业发展实践等方面，并提供相关行业书籍给参会者。
英伟达成全球市值最高公司，黄仁勋加州理工演讲：年轻人抓住机会，要跑不要走,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922592&idx=2&sn=313cbe66a8d703f595cb25b09d973723&chksm=84e41a1eb3939308109a2285f98919f2104d531d0ac054d6173617f5a660ca90cb2e0b82b698#rd,2024-06-19 12:44:23,英伟达（NVIDIA）在6月18日超越微软，成为全球市值最高的公司，达到3.334万亿美元。这一里程碑是英伟达股价在过去一年飙升的结果，反映了华尔街对新兴生成式人工智能技术的乐观情绪。英伟达的市值在短短几个月内从两万亿美元升至三万亿美元，黄仁勋（Jensen Huang）的个人财富也因此增加，成为全球第11富有的人。在加州理工学院的毕业典礼上，黄仁勋鼓励毕业生投身人工智能革命，并分享了英伟达在AI领域的转型和成就。他强调，随着计算机行业从基础设施层面发生转变，人工智能正在引领一场深刻的技术革命，对每个行业都将产生影响。
英伟达摘两篇最佳论文、浙大周昆获时间检验奖，SIGGRAPH 2024奖项出炉,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922592&idx=3&sn=d9f47dca4da82ac3ab1591189f1ba8b2&chksm=84e41a1eb39393087efbf1ed24db1d70a3a731590212067e169421df4038dfbe500830dfbd47#rd,2024-06-19 12:44:23,ACM SIGGRAPH 2024 公布了今年的最佳论文、荣誉提名和时间检验奖。这些奖项表彰了在计算机图形学和交互技术方面做出突出贡献的研究。从数百篇论文中，评选出了5篇最佳论文、12篇荣誉提名和4篇时间检验奖论文。时间检验奖旨在奖励过去十年对领域有重大影响的论文。获奖研究涵盖了光传输理论、无网格蒙特卡罗方法、形状空间、快速边界积分方程求解和有理参数曲线的稳健分类等多个方面。这些论文来自不同机构，包括达特茅斯学院、英伟达、CMU等。此外，还有一系列荣誉提名论文，涉及固体编织、感知算法评估、生成3D资产和实时大型场景探索等主题。
吴恩达团队新作：多模态多样本上下文学习，无需微调快速适应新任务,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922592&idx=4&sn=1a68a08af87dd59e3357baf3f2bf268e&chksm=84e41a1eb393930842a2c4f4a8be611f9684e89316dec7a92d4c705c0dabbf449a6c386f9509#rd,2024-06-19 12:44:23,斯坦福吴恩达团队的最新研究ManyICL评估了多模态基础模型在大量样本（最高2000个）的上下文学习中的性能，发现多样本学习能显著提升模型在多个领域和任务上的表现。研究使用了GPT-4o、GPT4 (V)-Turbo和Gemini 1.5 Pro模型，并在10个不同领域和任务的数据集上进行实验。结果显示，增加示例数量能提高模型性能，尤其是Gemini 1.5 Pro，且批量查询可以在不牺牲性能的情况下降低推理成本和延迟。这项研究为多模态基础模型的快速适应新任务和领域提供了新思路。
ICLR 2024 Oral | 应对随时间变化的分布偏移，西安大略大学等提出学习时序轨迹方法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922592&idx=5&sn=dba0e71412408141a514ef4d78102555&chksm=84e41a1eb393930899535876ff999f0a839842754ee39093a1ae468f8edfc33152403478b2ee#rd,2024-06-19 12:44:23,本文介绍了SDE-EDG，一种解决时变域泛化问题的新方法。在现实世界中，数据分布随时间变化是常见的挑战，SDE-EDG通过构建无限细分网格演变轨迹（IFGET）来克服稀疏时间戳带来的过拟合问题。通过使用随机微分方程（SDEs）建模数据的连续轨迹动态，并通过路径对齐正则化器与IFGET对齐，SDE-EDG能够更好地捕获分布演变趋势。实验结果显示，SDE-EDG在多个数据集上的分类准确率优于其他基线方法，证实了其在捕捉数据随时间演变能力方面的优势。
单镜头16秒720p高清视频一键生成，开源版Sora又有新惊喜了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922381&idx=1&sn=9ef59aa1eddf2a12151f353f1855a47e&chksm=84e419f3b39390e59a3d431ff295de5b3eb9e43259fad16bc7f497db4c1955091334dc7457b3#rd,2024-06-18 12:14:43,潞晨 Open-Sora 团队在文生视频领域取得突破，能够生成任意风格的高质量720p短片，并全部开源。开源地址：https://github.com/hpcaitech/Open-Sora。模型能够生成各种场景，包括人物、动画和电影级别的镜头。Open-Sora 引入了视频压缩网络、优化的扩散模型算法和更多可控性，并训练出1.1B的扩散生成模型。团队通过创新压缩策略平衡了训练成本和质量。此外，他们还提供了训练解决方案、模型评估体系和一键部署的 Gradio 应用，支持参数调节和中文输入。这一开源举措将促进文生视频技术的发展和创新。
杀疯了！谷歌卷视频到语音，逼真音效让AI视频告别无声！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922381&idx=2&sn=c9a8b5f76f64d29900501ada9f0cde5f&chksm=84e419f3b39390e54a074c569dd1fd1f2ae7ae281132fa5bcf22bcb4161d18a14168d50cc26d#rd,2024-06-18 12:14:43,Google DeepMind发布了视频生成语音（V2A）技术的进展，该技术能根据视频像素和自然语言文本提示为视频生成配音。视频生成模型V2A可以与视频生成模型如Veo结合，创造出具有配乐、音效或匹配视频角色和风格的对话镜头。用户可以使用正向和负向提示来控制音频输出。研究团队采用了扩散方法以实现视频和音频信息的同步。虽然该技术仍面临一些挑战，如视频质量对音频输出的影响和唇形同步的准确性，但Google DeepMind承诺将负责任地开发和部署该技术，并在公开前进行安全评估。此外，他们还整合了SynthID工具包，为AI生成的内容添加水印以防止滥用。
大模型压缩量化方案怎么选？无问芯穹Qllm-Eval量化方案全面评估：多模型、多参数、多维度,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922381&idx=3&sn=f9385aa9420e8868c7cbb9b56342cdea&chksm=84e419f3b39390e5d72b13d1602e72c6f93e4d473fa3e640292dcecf86b552f9456a83e170fd#rd,2024-06-18 12:14:43,"这篇摘要可以是：

来自清华大学电子工程系、无问芯穹和上海交通大学的研究团队评估了大语言模型的量化方案，该工作被ICML'24接收。研究团队在《Evaluating Quantized Large Language Models》（Qllm-Eval）中探讨了不同模型、量化类型和方法对性能的影响，以实现大模型在资源受限场景下的压缩和高效推理。研究发现，权重、激活值和键值缓存的量化可以降低存储和计算开销，但量化通常会导致性能损失。评估涵盖了各种任务类型的能力，包括基本自然语言处理、涌现能力、可信度、对话和长文本处理。量化对不同模型和任务的容忍度不同，且对于长文本任务，权重和KV Cache的量化容忍度较低。研究还探讨了量化对推理速度的加速效果，并为未来的大模型量化工作提供了指导。"
字节打造大模型TTS：不仅能高保真合成，而且支持调整编辑,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922381&idx=4&sn=5166e21ddcbdaf521173535d1266ff35&chksm=84e419f3b39390e53bc7f043f023b332d492feb2c947cb4ac2ac56c5253d1d90dabd53b042a3#rd,2024-06-18 12:14:43,字节跳动Seed Team发布了一款名为Seed-TTS的AI模型，该模型能够生成与真人语音几乎无异的高保真合成语音。Seed-TTS不仅自然度和表现力达到人类水平，还能以零样本方式根据较短的录入语音片段生成可控的合成语音。该模型适用于语音助理、配音、辅助视障和有声书制作等多个领域。Seed-TTS基于自回归Transformer，包括语音token化器、token语言模型、token扩散模型和声学声码器四个主要模块。通过预训练、微调和后训练三个阶段，模型在多个任务上表现出色，解决了基于语言模型的TTS系统的不稳定性问题。此外，模型还支持多种任务，如语音上下文学习、可控式TTS等。实验结果显示，Seed-TTS在语音合成的自然度和表现力上与真人语音接近，且在零样本语音上下文学习等任务上表现出色。
清华等高校推出首个开源大模型水印工具包MarkLLM，支持近10种最新水印算法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922381&idx=5&sn=60ad93465ed1406d87eed569f02ec57b&chksm=84e419f3b39390e50537a35434ccdc9c98b5f07ec300ee7955cb83d36318ad7f8cfe82cabf4d#rd,2024-06-18 12:14:43,这篇文章介绍了清华大学、上海交通大学等多所高校联合开发的开源大模型水印工具包MarkLLM。MarkLLM提供了一个统一的框架来实现大模型水印算法，包括KGW和Christ家族的9种具体算法，旨在方便研究人员实验、理解和评估水印技术。工具包还包含了直观的算法可视化方案和全面的评估模块。该工具有望推动大模型水印领域的研究和应用，目前在GitHub上已经获得了广泛关注和贡献。作者鼓励社区成员提供反馈和贡献代码，以共同促进大模型水印技术的发展。
3D 版 SORA 来了！DreamTech 推出全球首个原生 3D-DiT 大模型 Direct3D,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922111&idx=1&sn=df42c1d07e5896c1510eea673c7dd2b3&chksm=84e41801b39391173d3d4fa8e59ae31ab0ccdffa736c319b89dc697e94f5598257874b8c1e0d#rd,2024-06-17 12:03:18,DreamTech公司发布了其创新的3D生成大模型Direct3D，该模型利用3D Diffusion Transformer (3D-DiT) 技术解决了高质量三维内容生成的挑战。Direct3D是首个公开的原生三维生成模型，避免了2D-to-3D lifting方法的局限性，如多头多面和空腔问题。3D-DiT架构和D3D-VAE技术的使用大大降低了3D数据的复杂性，提高了模型训练和生成的效率。此外，DreamTech的数据合成引擎为模型训练提供了大量高质量3D数据。Direct3D的推出标志着3D内容生成进入商用级别，其生成的3D模型质量高，适用于3D打印和其他商业应用。DreamTech还推出了基于Direct3D的两款产品，包括面向C端用户的Animeit!和面向创作者的3D内容创作平台。
AI研究的主要推动力会是什么？ChatGPT团队研究科学家：算力成本下降,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922111&idx=2&sn=69ae67a08b5ffd782d7bd25d94e6ed7a&chksm=84e41801b393911720f779edaa704cc703a4871b96dd75eff9b599470090e8eb5d50034cebe0#rd,2024-06-17 12:03:18,OpenAI研究科学家Hyung Won Chung认为，AI研究的主要推动力是计算成本指数级下降导致的规模扩展。他指出，AI研究者在过去常常通过增加结构和建模假设来解决问题，但随着算力的增加，更少结构的模型具有更好的扩展性。Chung以Transformer的发展为例，比较了编码器-解码器Transformer和仅解码器Transformer，强调了在特定计算量、数据、算法和架构下存在最优的归纳偏置或结构。随着未来算力的增加，这些结构可能需要被移除以实现进一步的规模扩展。Chung呼吁AI研究社区更多关注如何移除结构，以利用计算成本下降的趋势。
大模型+蒙特卡洛树搜索，一招让LLaMa-3 8B奥数水平直逼GPT-4,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922111&idx=3&sn=e3325cb7cb6cf091fd5aa1aeaec6c355&chksm=84e41801b3939117d0554e991d6a13df6cf1dc214d7f1ced1c7b22015da53129a5e26262ed37#rd,2024-06-17 12:03:18,复旦大学和上海AI Lab的研究者提出了一种名为MCT Self-Refine (MCTSr)的新方法，旨在提升大语言模型（LLM）在复杂数学推理任务中的性能。当前，LLM在逻辑推理和证明题上的能力较弱，尤其在需要准确性和可信度的数学问题中容易出错。MCTSr通过结合LLM与蒙特卡洛树搜索（MCTS）算法，增强了模型在解决复杂数学问题时的决策和推理能力。实验结果显示，MCTSr在多个数学问题数据集上显著提高了LLM的解题成功率，尤其是在较低复杂度的问题上。不过，对于高度复杂的挑战，该算法仍有改进空间。
字节豆包、武大提出 CAL：通过视觉相关的 token 增强多模态对齐效果,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922111&idx=4&sn=eecc73f800a4313cd68499ba0da82c91&chksm=84e41801b393911792144deafd8aff24d3243b929ebcb2ed44e64d25f99088644a2abd7fe13e#rd,2024-06-17 12:03:18,武汉大学、字节跳动豆包大模型团队和中国科学院大学的研究人员提出了一种基于对比学习的文本token筛选方法（CAL），用于改进视觉语言模型（VLM）的多模态对齐。当前VLM主要依赖大语言模型（LLM）微调，通过文本自回归进行模态对齐。CAL方法能识别与图像高度相关的文本token，加强它们在训练过程中的权重，从而实现更精确的对齐。该方法无需额外的预训练阶段，且在OCR和Caption benchmarks上表现出显著提升，增强了模型对噪声数据的抵抗力。实验表明，使用CAL的模型在各项基准测试中表现更优，并且具有更好的注意力分布和图像内容映射。
答案抽取正确率达96.88%，xFinder断了大模型「作弊」的小心思,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922111&idx=5&sn=2d419d85ff827fb03aeb26cbe133d98e&chksm=84e41801b39391177a659fbe56f28ea18bb12188093319eb1fa9bb898d4e9c8d292409519174#rd,2024-06-17 12:03:18,上海算法创新研究院和中国人民大学的研究团队针对大语言模型（LLM）评估框架中的答案抽取器组件的可靠性和一致性问题，发表了一篇名为《xFinder: Robust and Pinpoint Answer Extraction for Large Language Models》的论文。研究发现，现有的评估框架主要依赖正则表达式（RegEx）抽取答案，但这种方法准确率低且易被拟合，影响评估可靠性。为此，他们开发了xFinder模型，该模型答案抽取准确率高达95.18%，优于RegEx方法，并支持多样化题型，降低了拟合题型的可能性。xFinder通过关键答案查找（KAF）数据集进行训练，提高了评估的准确性和一致性。实验表明，xFinder在不同任务和现实世界场景中的评估中表现出色，显示出高鲁棒性和泛化能力。
ACL 2024论文盖棺定论：大语言模型≠世界模拟器，Yann LeCun：太对了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922008&idx=1&sn=e3c67ea724b8977cb13a0408a6f095f9&chksm=84e41866b3939170f7390eb95d0baf1d945d39eae1e79209122c48a584b73ac5b4d26c5873f3#rd,2024-06-16 12:13:02,一篇入选ACL 2024的论文讨论了大语言模型是否能作为世界模拟器的问题。研究发现，GPT-4在模拟基于常识任务的状态变化时准确率约为60%，这表明语言模型并不能可靠地作为世界模拟器使用。图灵奖得主Yann LeCun对此表示认同，认为没有世界模型就无法进行有效规划。论文提出了一个新的基准“ByteSized32-State-Prediction”来评估语言模型在模拟基于文本的世界的状态转换性能。实验结果显示，虽然GPT-4表现出了令人印象深刻的能力，但仍然存在显著的局限性。研究强调了这一工作对于理解当前LLM的能力和局限性以及未来进展的基准设定价值。
星环科技孙元浩：语料已经是大模型最大的挑战,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922008&idx=2&sn=c421574c1334bb3d3d23cc913312e5f3&chksm=84e41866b3939170ecd77c362f2a3dab27f4f50866f4ce9dad505ff23fedb2a3a950a5363db6#rd,2024-06-16 12:13:02,星环科技创始人及CEO孙元浩认为，尽管大模型已经在互联网数据上取得了进展，但企业内部的大量未充分利用的数据提供了进一步提升模型准确性的机会。企业数据存在非结构化、海量、多形式、小文件多等问题，同时专业数据标注的门槛也较高。为应对这些挑战，星环科技采取了多种策略，包括升级大数据平台以处理更多元化的数据，增加Python接口，推出分布式Python引擎，优化向量数据库，构建知识图谱，开发语料开发工具，提供大模型工具链，构建AI原生应用，以及支持多种模型和数据源。孙元浩强调，提升语料质量是目前大模型准确性提升的关键，而挑战在于语料的开发和整理是一个巨大的体力活。通过构建外挂知识库、微调模型、持续训练和提供语料开发工具，可以提高模型的准确率。星环科技的目标是将大模型训练成能够进行数学分析和理解自然科学的“理科生”。
新一轮「硬件彩票」：MatMul-free 会改变大模型的游戏规则吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922008&idx=3&sn=57d62fcf17032de75bd96b1bfc3c6a3e&chksm=84e41866b3939170804fe14baccdb13150df23fac940b9d1dc8e425ecdac48b37360c530353c#rd,2024-06-16 12:13:02,"这篇文章的摘要可以是：

本周的AI & Robotics业内要事包括：

1. 研究人员开发了一种无需矩阵乘法（MatMul-free）的大型语言模型，该模型在FPGA上运行，功耗接近人脑，内存消耗降低超过10倍。这项工作提出了移除MatMul的重要性，并引发了关于使用非GPU处理器训练模型的讨论。

2. 构建AI算力集群的逻辑被深入探讨，指出并非越大越好，存在一些关键的考虑因素，包括如何避免盲目扩大规模和理解AI算力集群的组成结构。

3. Aidan Gomez分享了他在大模型创业公司Cohere的盈利策略，讨论了如何通过差异化的服务实现盈利，并提出了对AI未来发展的看法。

此外，通讯还涵盖了其他28项本周的AI & Robotics领域重要动态，包括技术进展、国内外新闻等。会员可以获取完整版通讯以了解更多详细信息。"
AI将是数学家的得力助手，陶哲轩谈AI在证明过程中的潜力,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922008&idx=4&sn=c6987854e9728c45a52ac366e7903298&chksm=84e41866b393917038db7d4a09c8088885af67e684fd98ec5a6420f0d21daddf202319b21e9f#rd,2024-06-16 12:13:02,数学家陶哲轩在近期的采访中表示，未来数学研究将受益于AI技术，数学家可以通过向AI解释证明，AI会将其形式化并生成LaTeX文件，提高工作效率。AI的引入将改变数学领域的合作方式，通过计算机验证证明的各个部分，促进更大规模的项目合作。然而，这一观点也引起了一些争议，担忧可能降低数学证明的严谨性和创造力。陶哲轩强调，AI旨在减轻繁琐工作，让数学家专注解决更复杂的问题。他分享了与ChatGPT互动生成复分析问题证明的示例，展示了AI在协助数学证明上的潜力。尽管目前技术仍有局限，但陶哲轩认为未来AI将成为数学研究的重要助手。
高质量3D生成最有希望的一集？GaussianCube在三维生成中全面超越NeRF,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650922008&idx=5&sn=28a700bf26cab27505b6e433387c37b9&chksm=84e41866b3939170b98e0818326b24c9b2f44320a2cbec3514d99846a024220f12608a5779d4#rd,2024-06-16 12:13:02,来自中科大、清华和微软亚洲研究院的研究人员提出了GaussianCube，这是一种新型的结构化、显式的3D表示方法，可以用于3D扩散模型。GaussianCube通过高斯拟合算法实现对3D资产的高精度拟合，并使用最优传输算法将高斯重新排列到体素网格中，形成结构化表示，简化了3D生成建模的复杂性。这种方法在保持高质量3D表示的同时，显著减少了所需的参数量，提高了效率。实验结果显示，GaussianCube在3D对象生成、数字化身创建和文本到3D内容合成等方面表现出色，相比于基线算法有显著性能提升。
现在起，真正的强者敢于直面「扣子」的「模型广场」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921965&idx=1&sn=673a01a2ba5d31ddda4e3af575798c58&chksm=84e41f93b3939685f04b4bb7f3e9adc21af881ca63b51db61b59b2bbb4588fca0a618b8db4a2#rd,2024-06-15 12:10:32,本文介绍了字节跳动推出的大模型平台“扣子”新功能“模型广场”，该功能提供了一个在线大语言模型对比与评估系统，用户可以通过三种对战模式（指定Bot对战、随机Bot对战、纯模型对战）来比较不同模型在实际任务中的表现，并进行投票。这一功能旨在帮助开发者和用户在不同业务场景下选择最适合的大模型，且无需自己付费。此外，模型广场还将定期发布排行榜，以用户反馈为基础评估模型性能。扣子平台还推出了一个联合Intel的Bot征集活动，鼓励用户创作图文创作、实用工具和互动创意的Bot。通过降低开发和运营难度，扣子旨在推动AI应用的普及和生态发展。
仅存活三个月的Copilot GPTs，因无盈利希望，被微软强制「退休」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921965&idx=2&sn=531bc3add884eed96cdb4a829fe8c983&chksm=84e41f93b39396850007135ee020118f6f58fa5de2aa1f5ab4e6aa098163bd963ddb4e245ff1#rd,2024-06-15 12:10:32,微软宣布将于2024年7月10日起停止Copilot GPTs服务，并删除所有用户创建的GPT及相关数据，此举引发用户不满。微软表示原因是战略调整，将重点转向商业和企业场景。3月推出的Copilot GPT Builder也即将退休，所有定制的GPTs在7月14日后将无法访问。此外，出于安全考虑，微软推迟了Recall AI功能的发布。微软的这一决策可能与消费者AI产品市场反应不佳有关，公司将集中精力提升核心产品体验和支持开发者创新。
英伟达开源最强通用模型Nemotron-4 340B,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921965&idx=3&sn=d20e5e456077bfef06e7d6d2c656aab5&chksm=84e41f93b393968549391564b668026dc2a82c5dd125a71d4afe3df947de923a2aa82643a250#rd,2024-06-15 12:10:32,英伟达推出3400亿参数的Nemotron-4大模型，用于合成数据生成，以帮助开发人员训练和改进大语言模型。这个开源模型系列包括基础、Instruct和Reward模型，可用于医疗、金融等行业的商业应用。Nemotron-4 340B在Hugging Face上可供下载，并将打包为NVIDIA NIM微服务进行部署。该模型在多个基准测试中表现出色，其Instruct和Reward模型能生成高质量的合成数据并进行筛选，以提高自定义LLM的性能和鲁棒性。开发人员可以使用NVIDIA NeMo框架和TensorRT-LLM库进行优化和微调。
有望解决一个千禧年大奖难题，这个20多年前的猜想终于得到证明,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921965&idx=4&sn=b58aa4719cadef7af0d37b1f67656c00&chksm=84e41f93b3939685856b53611f3e3df23869830ccc57563cc06889b524d55d4e4eba08204869#rd,2024-06-15 12:10:32,数学家们证明了一类名为expander图的特定图总是包含哈密顿回路，这是图论中的一个重要问题。哈密顿回路是指在图中找到一条经过每个节点恰好一次并回到起点的路径。这个问题在大规模图中非常难以解决，但对于expander图，数学家Michael Krivelevich和Benny Sudakov在2002年提出了一个猜想，认为这类图包含哈密顿回路。今年，Sudakov与其他人一起成功证明了这个猜想。expander图具有高度连接性和稀疏性的特征，它们即使边的数量不多，也能在不同部分之间快速建立连接。这个证明不仅对图论有贡献，也可能在计算机科学和网络设计等领域产生应用。
SIGGRAPH2024｜上科大、影眸联合提出DressCode：从文本生成3D服装板片,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921965&idx=5&sn=0fd38adb747c77c54a1e1f4723c06e84&chksm=84e41f93b393968532e7f90d1cd8d4f83fce00caa034dc2d6aee0ed5e005853b73d74ab29732#rd,2024-06-15 12:10:32,上海科技大学、影眸科技与宾夕法尼亚大学的研究团队联合提出了DressCode，这是一个首个支持CG操作的3D服装生成框架，能够通过文本引导自动生成高质量、可编辑、可驱动、可仿真的3D服装。该框架解决了通用3D生成方法与实际服装生产流程不兼容的问题，通过自然语言交互简化了服装设计过程，适用于时尚设计、虚拟试穿和数字人创造。DressCode使用了SewingGPT模型来生成缝纫版片，并结合PBR纹理生成器创建3D服装的几何和纹理部分。此外，它还具备版片补全和纹理编辑能力，可无缝整合到工业软件中。该框架在3D内容创造领域展示了巨大的潜力和应用前景。
又一届「AI春晚」拉开序幕！智源大模型集体爆发了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921938&idx=1&sn=f12f284bb83d8982e8f6f88ada88b001&chksm=84e41facb39396ba1955b79449e471cc22b85204ad9204b859f73ac718b8faf7db39fb0391b3#rd,2024-06-14 22:11:30,2024年智源大会展示了人工智能的最新进展，特别是大模型在各个领域的应用和技术创新。大会发布了多个全球首个研究进展，包括低碳单体稠密万亿语言模型Tele-FLM-1T，该模型在性能和能效上实现了突破，且部分版本已开源。此外，智源研究院还推出了通用语义向量模型BGE和原生多模态世界模型Emu3，以及具身智能相关的大模型和应用，如智能心脏超声机器人。在生物计算领域，发布了全原子生物分子模型OpenComplex，有助于加速生命科学的研究。智源研究院通过FlagOpen大模型开源技术基座2.0，推动模型、数据、算法、评测和系统的全面发展，为AI开发者提供支持。
让鲁迅说绕口令、赫本玩嘻哈，又一视频模型火了，斯坦福华人博士创立,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921938&idx=2&sn=d66ea952d83e09a8316c3feec48690ce&chksm=84e41facb39396ba9f58e3b357feff86e1c8f0ecfaa87a253b454f41b5580926b14bd3bb60f0#rd,2024-06-14 22:11:30,斯坦福大学团队开发的AI视频工具Proteus引起了关注。Proteus是一款低延迟的基础模型，能够生成高度真实和富有表现力的人物形象，实现人类表情的实时生成。采用最先进的Transformer架构的潜在扩散模型，Proteus能以超过100 FPS的速度生成视频流，使得从静态照片创建的虚拟形象可以模仿各种表情和动作，如笑、说唱、歌唱等。该技术有望成为声音可控的视觉化身，用于人工智能对话实体的交互界面，并与多模态大语言模型兼容，适用于多种应用场景。Proteus的研发团队由6人组成，包括华人成员，他们来自斯坦福大学，并在计算机科学领域有深厚的学术背景。
从ALOHA迈向Humanplus，斯坦福开源人形机器人，「高配版人类」上线,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921938&idx=3&sn=1e6fb4e78a1099a54d751fc6482a80fe&chksm=84e41facb39396bacda773ed4b3aded398211d29bb9d052f3062235e6985ee7068f1e86d5b50#rd,2024-06-14 22:11:30,斯坦福大学的研究团队推出了一款名为HumanPlus的新机器人，这款机器人能够自主执行多种任务，如叠衣服、搬运物品、后跳、弹钢琴、打乒乓球和打字等。团队由Zipeng Fu和Chelsea Finn等人共同打造，他们之前还开发了全能家务机器人Mobile ALOHA。HumanPlus通过模仿人类动作来学习技能，首先在模拟环境中基于人体运动数据集进行强化学习，然后在现实世界中使用RGB相机跟踪人体运动，实现远程操作和数据收集。通过这种“Shadowing”系统，机器人可以学习并自主完成一系列任务，成功率在60%到100%之间。该研究团队提供了论文、机器人材料清单、数据集和代码，强调了开源科学在机器人研究领域的重要性。
只需几个演示就能对齐大模型，杨笛一团队提出的DITTO竟如此高效,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921938&idx=4&sn=71638505178372910aec76c2bc4c05df&chksm=84e41facb39396bac4100cafa011e98ffdfbd1761ee17f5c8ce32ad6601bbb4caa76b89d1a4a#rd,2024-06-14 22:11:30,研究人员提出了一种名为DITTO的新框架，旨在通过少量用户提供的演示来对大型语言模型（LLM）进行对齐和个性化。DITTO利用这些演示创建一个增强数据集，通过将演示与模型输出进行比较，进而使用对齐算法更新模型。这种方法减少了需要大量比较数据的需要，提高了模型适应用户偏好的效率。实验表明，DITTO在与其它方法的比较中表现出色，特别是在与用户的偏好对齐和泛化到自然任务的能力上。
Mobile-Agent-v2问世，自动化手机操作能力再上新台阶,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921938&idx=5&sn=df7b30637a2a5648f4b836044618df90&chksm=84e41facb39396bacdf23767f8fe74de214db8764bbf1e777a6364828a144a1485c0a9a9666c#rd,2024-06-14 22:11:30,这篇文章介绍了阿里通义实验室的高级算法专家徐海洋负责的多模态大模型mPLUG系列工作，包括mPLUG、mPLUG-Owl、mPLUG-DocOwl和Mobile-Agent等。Mobile-Agent是一个基于纯视觉方案的多模态智能体，能够自动化操作手机，不依赖UI文件。最近，Mobile-Agent发布了新版本v2，其特性包括纯视觉方案的保留、多智能体协作架构、增强的任务拆解和跨应用操作能力以及多语言支持。论文和代码已公开，Mobile-Agent-v2也接入了魔搭的ModelScope-Agent平台。文章展示了Mobile-Agent-v2在执行自动化打车任务、跨应用操作、社交媒体和视频平台操作等任务的演示，表明其具有强大的手机操作能力。Mobile-Agent-v2通过规划智能体、决策智能体和记忆单元来跟踪任务进度和处理屏幕信息。实验结果表明，Mobile-Agent-v2在各种指令和场景中表现出色，特别是在处理长序列任务时。
IDC最新报告，7大维度11家大模型厂商比拼，唯一全优是谁？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921726&idx=1&sn=20792816c56d279674d9a39d9acb9048&chksm=84e41e80b3939796ab65d68ec50874dc4a22abcc2380fd9c5757290ad4fed921cac2c501e744#rd,2024-06-13 19:12:33,IDC最新发布的大模型实测报告《中国大模型市场主流产品评估，2024》显示，百度文心大模型在7大维度上均表现出领先优势，是唯一一家在所有维度被评为优势厂商的企业。报告评估了11家大模型厂商的16款产品，包括基础能力和应用能力两大类，如问答理解、推理、创作表达、数学、代码等。其他厂商中，阿里获得6项优势维度，OpenAI GPT-4和商汤各有5项优势。百度文心一言和文心一格在多项能力上表现出色，显示出全面的竞争力。报告强调了测评的公平性和全面性，旨在更准确地评估大模型的真实水平。
被《AIGC体验派》硬控25分钟，大模型落地还能这么玩？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921726&idx=2&sn=9ba1368dcd1ae7490536b49ea7fbf507&chksm=84e41e80b39397967486466831cffd902c054c0c0299d9e2e38ac0e66146a138e91036eda0fa#rd,2024-06-13 19:12:33,这篇文章提到了2024年大模型厂商的关注焦点已从技术进展转向应用层，期望AIGC（人工智能生成内容）从娱乐性转向实用性。在各种行业中，AIGC展现出初步的影响力和潜力。营销领域被视为AIGC的重要应用场景，有望通过智能化升级加速发展。为此，火山引擎、英伟达与机器之心、CMO Club联合推出视频节目《AIGC体验派》，首期节目将于6月19日播出，主题为“从有趣到有用，AIGC如何促进营销增长”。节目将探讨AIGC在营销中的实际价值、应用案例以及衡量成效的方法。首期嘉宾包括CMO Club创始人班丽婵和火山引擎AI解决方案负责人骆怡航。此外，文章还邀请观众参与直播报名和有奖问卷调查。
万字综述大模型高效推理：无问芯穹与清华、上交最新联合研究全面解析大模型推理优化,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921726&idx=3&sn=1fd2e11957b550dd848019435671671f&chksm=84e41e80b3939796fbedd50b530159e1ee070bf929bbbf9c48a4d62d0549361c41a39676c6a1#rd,2024-06-13 19:12:33,这篇文章是关于大语言模型高效推理技术的综述。大语言模型在推理过程中存在效率瓶颈，如计算开销、访存开销和存储开销大，特别是在处理长序列时。研究团队将优化技术分为数据层、模型层和系统层三个层次进行分析。数据层优化包括输入压缩和输出规划，如提示词剪枝、软提示词压缩和输出结构规划。模型层优化涉及结构设计和模型压缩，如混合专家模型、模型量化和权重稀疏。系统层优化则关注推理引擎和服务系统的效率，包括图和算子优化、猜测解码以及服务系统的内存管理和调度策略。未来的研究方向包括智能体和多模型框架、长文本场景、边缘端部署以及安全-效率协同优化。
又一Sora级选手来炸街！我们拿它和Sora、可灵PK了下,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921726&idx=4&sn=1e744de6db788611d0871edf0d6c6221&chksm=84e41e80b3939796c34493663bd780b5f7b7ef21393a67d0d91c996d77c5eb0ee3af57afa3d6#rd,2024-06-13 19:12:33,初创公司Luma AI推出了新一代AI视频生成模型Dream Machine，该模型可以根据文本描述生成高质量、逼真的视频，效果可与OpenAI的Sora相媲美。Dream Machine的特点包括速度快、动作逼真、角色一致性高和自然的运镜。用户可以免费使用，但由于需求量大，许多用户在官网等待数小时才能生成视频。尽管受到了一些用户的高度评价，但也有人反馈有使用限制。Luma AI此前已推出文生3D模型Genie，公司已获得英伟达等投资者的融资。Dream Machine的推出使AI视频领域竞争加剧，其他如快手可灵也在该领域推出相关产品。
ACL 2024｜PsySafe：跨学科视角下的Agent系统安全性研究,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921726&idx=5&sn=7e418d633f11368b2aff86986b242a86&chksm=84e41e80b393979663485b599bd197362f084b709972adcb986ac8fe86d4f279e08225ee0e62#rd,2024-06-13 19:12:33,"这篇文章的摘要可以是：

这篇论文由上海人工智能实验室、大连理工大学和中国科技大学的研究人员完成，探讨了大型语言模型（LLM）在发展成智能Agent系统时的安全性问题。随着Agent系统的复杂性和互动性的增加，它们可能会形成类似微型社会的结构，但这也带来了潜在的安全隐患。研究团队提出了PsySafe Agent系统安全研究框架，关注如何评估和应对Agent系统的危险行为。他们发现，通过注入“黑暗”价值观的Prompt，Agent可以变得非常危险，并且Agent的心理状态与其行为的危险性有很强的相关性。此外，他们提出了输入端防御、心理防御和角色防御的方法来改善Agent系统的安全性。这项研究强调了AI对齐和社会科学交叉领域在未来研究中的重要性。"
快手「可灵」爆火：海外AI圈巨震，中国版Sora一号难求,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921562&idx=1&sn=7bd51fc42c6084cddaa3b3d8b3acabc6&chksm=84e41e24b3939732d908a65226cb33f99c025b58d0e96e214488e0abad378be67a5ffed9647e#rd,2024-06-12 20:26:31,快手推出了一款名为“可灵”（Kling）的文生视频大模型，该模型能够将文本转化为长达2分钟、30fps的1080P视频，主打一键转化功能。可灵已开放测试，吸引了很多用户，包括一些知名人士的称赞。该模型的生成效果被认为在某些方面超越了现有的类似模型，如Sora。视频生成技术的应用领域广泛，包括游戏开发和影视制作，有可能颠覆传统的工作流程，实现更高效和创新的创作方式。可灵的发布表明中国在AI技术，尤其是视频生成领域达到了新的高度，并在产品落地方面取得了领先。目前，可灵的测试资格需求旺盛，引发了大量的关注和兴趣。
苹果智能背后模型公布：3B模型优于Gemma-7B，服务器模型媲美GPT-3.5-Turbo,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921562&idx=2&sn=c7bd92b5a7538d4f41016528d55e58a1&chksm=84e41e24b39397329e65177cb051325e815ae4e0a9d59a0737361bf4af71af678418cb3a3591#rd,2024-06-12 20:26:31,苹果在最新的开发者大会上推出了Apple Intelligence，这是一个深度集成到iOS 18、iPadOS 18和macOS Sequoia中的个性化智能系统。系统包含多个高度智能的生成模型，其中两个模型被详细说明：一个拥有30亿参数的设备端语言模型和一个更大、基于服务器的云模型。苹果强调在训练模型时未使用用户私人数据，并采取措施保护隐私，如过滤个人可识别信息和低质量内容。他们还介绍了在训练、后训练阶段使用的优化算法，以及如何在设备端和服务器上实现模型的高效运行。此外，通过适配器技术，模型可以针对用户任务进行动态微调。苹果对模型性能进行了详尽的评估，强调了人类评估的重要性，并展示了其设备端和服务器模型在多种任务上的优越性能。
重磅！2024智源大会完整日程公布——全球大模型先锋集结,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921562&idx=3&sn=cdc668fe666c0bdcd1ed27d564c6c44e&chksm=84e41e24b393973298b88fb811bfdb1a7ab35e124afd73b6b80938aead13cd791f9f4610bebe#rd,2024-06-12 20:26:31,2024年北京智源大会将于6月14-15日召开，汇聚全球顶尖机构和AI领域重要项目作者，包括OpenAI、DeepMind、Meta、微软等。大会将采用线下与线上结合的形式，线下会场位于中关村国家自主创新示范区展示中心，全程线上直播。会议涵盖大语言模型、意识与通用人工智能、Agent、智慧医疗、AI安全等多个专题论坛。会上将有多个主题报告和圆桌讨论，探讨AI的最新进展和未来趋势。此外，现场参会者将有机会获得纪念品，并有机会抽取宇树机器狗。参会者需在官网预约收看或注册线下参会。
改变传统，吴恩达开源了一个机器翻译智能体项目,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921562&idx=4&sn=3106be5cc97a2687576ea390dcb19549&chksm=84e41e24b3939732b47b904fdf227f8db53b829a2fd444d077d671a8acd8e0a0d2294f0f9a3f#rd,2024-06-12 20:26:31,吴恩达开源了一个AI智能体机器翻译项目，他认为智能体在翻译方面具有巨大潜力但尚未被完全发掘。这个翻译智能体使用反思工作流进行翻译，能够根据用户的指令调整语气、地区变体和术语一致性。虽然在测试中表现有时可与商业提供商匹敌，但也有不足。吴恩达鼓励社区进行更多实验和研究，以提升翻译智能体的性能，并提出了包括尝试其他语言生成模型、创建和使用术语表、在不同语言和领域进行评估以及寻找更好的评估指标等发展建议。该项目以MIT许可证发布，可供自由使用和改进。
打通智能体「自我进化」全流程！复旦推出通用智能体平台AgentGym,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921562&idx=5&sn=2739575f2c7cddd01cca739372c80cc7&chksm=84e41e24b3939732b0768c1db37fdae250db91f4157526ede7888613e91081c6c2bd06c1e9b8#rd,2024-06-12 20:26:31,复旦大学语言与视觉团队推出了AgentGym平台，该平台允许大语言模型智能体进行数据采样、训练微调、自我进化和能力评测的全流程。基于该平台，研究团队提出了AgentEvol算法，首次探索了通用智能体的自我进化能力，使其在多种环境和任务上表现优秀，与SOTA模型如GPT-4和Claude相当。AgentGym提供了14个环境和89种任务，旨在促进通用智能体的自我学习和适应性。AgentEvol算法通过探索和学习过程优化智能体，使其在未见过的任务中提升性能，实现自我进化。
苹果智能炸裂登场：直接GPT-4o加持，全家桶都上生成式AI，Siri脱胎换骨,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921293&idx=1&sn=7dd34e37b5285f85000ddc98c17949b5&chksm=84e41d33b393942533f56d8d1b992bff28c4619416a0991383e08a7a9ccbdec7276e86141f39#rd,2024-06-11 06:18:08,在2024年的苹果全球开发者大会（WWDC）上，苹果公司宣布了一项重大更新，将生成式人工智能全面整合到其产品线中，包括iPhone、iPad和Mac。这一更新被称为Apple Intelligence，它是一个全新的个性化智能系统，能够理解并创造语言和图像，提供实用的智能服务。Siri作为Apple Intelligence的一部分，获得了重大改进，变得更加智能、自然和个性化，支持打字交互，能够处理更复杂的任务并在不同应用之间操作。此外，苹果还宣布与OpenAI合作，将ChatGPT集成到其操作系统中，提供图像和文档理解功能。苹果强调了其在保护用户隐私方面的努力，通过Private Cloud Compute技术在设备端和云端之间灵活处理计算任务，确保数据安全。这一系列更新将在秋季随iOS 18、iPadOS 18和macOS Sequoia发布。
这家世界模型公司发布中国版Sora级视频生成大模型，走向世界模型打造新一代数据引擎,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921293&idx=2&sn=c261914e3ae2c55a5ca23d43d5da5fe8&chksm=84e41d33b3939425104e0fd3c52aac3fb7202467b0bc03210f5cc9bd2adbc3e461bb92295e67#rd,2024-06-11 06:18:08,这篇文章介绍了中国首个超长时长、高性价比的视频生成大模型「视界一粟 YiSu」的发布，该模型由世界模型公司「极佳科技」和清华大学自动化系联合推出。YiSu 模型具有原生16秒的超长时长，可生成超过1分钟的视频，且具备超大运动、超强表现力和物理世界理解能力。与以往的视频生成技术不同，YiSu 采用自研融合架构，结合LLM和扩散模型，优化了多模态融合、训练和推理效率。团队目标是利用YiSu的性能和性价比推动长视频生成的大规模应用。此外，文章还提到极佳科技在世界模型技术上的领先，如自动驾驶世界模型 DriveDreamer，以及团队成员的丰富经验和成就。公司希望通过基础模型和超级应用的智能闭环飞轮，加速通用智能时代的发展。
视觉语言模型导论：这篇论文能成为你进军VLM的第一步,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921293&idx=3&sn=b8513157578094d9bc81a2129afc16bf&chksm=84e41d33b39394256edbda93456eb13ef3f40099e86f978b9bea8c442589d17225c1a16d3768#rd,2024-06-11 06:18:08,这篇论文介绍了视觉语言模型（VLM）的最新进展，这些模型能够处理和理解文本以及视觉信息。传统的大型语言模型已经扩展到处理视觉输入，但目前在理解空间关系、计数和属性等方面仍存在挑战。这篇导论由Meta和蒙特利尔大学等机构的研究人员撰写，详细阐述了VLM的定义、训练方法和评估标准。作者将VLM的训练范式分为对比式、掩码式、基于预训练骨干网络的方法和生成式，并提供了各种模型的示例。论文还讨论了训练数据的重要性、软件工具、定基提升技巧以及负责任的VLM评估方法。此外，文中还提到了将VLM应用于视频的挑战和进展。这篇论文旨在帮助读者理解VLM的基础知识和最佳实践，而不是全面覆盖所有研究。
用神经架构搜索给LLM瘦身，模型变小，准确度有时反而更高,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921293&idx=4&sn=20827cbd82826b38b970864a298768e0&chksm=84e41d33b3939425d9d538c694431ca611d8ee1d9ded490f28a4d117cc290585b2f6fa9197e7#rd,2024-06-11 06:18:08,Intel Labs 使用神经架构搜索（NAS）技术，成功地为大型语言模型（LLM）瘦身。在实验中，他们将 LLaMA2-7B 模型的大小减少了 2 倍，同时保持了同等的准确度。这项研究首次展示了 NAS 在 LLM 压缩方面的效率，表明 NAS 方法在某些标准基准任务上可能比传统的剪枝和稀疏化技术更有效，并且不需要额外的恢复微调步骤。通过 InstaTune 方法和 LINAS 算法，该团队在不牺牲性能的情况下优化了模型结构，并发现了一些任务的过度参数化现象。此外，他们还发现，对这些压缩模型进行量化处理可以在不降低准确度的情况下进一步减小模型大小。这项工作为 LLM 的高效部署和资源利用提供了新的途径。
CVPR 2024｜让图像扩散模型生成高质量360度场景，只需要一个语言模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921293&idx=5&sn=1ec3969d88d05be611ce7e9dc556620b&chksm=84e41d33b39394257039aa897895201d7a32d7e3c040a231c3b072142bfaac76425a74c634e7#rd,2024-06-11 06:18:08,这篇文章介绍了美国英特尔研究院研究员蔡志鹏博士及其团队提出的一种名为L-MAGIC（Language Model Assisted Generation of Images with Coherence）的新方法，用于生成高质量、多模态、零样本泛化的360度场景。L-MAGIC结合了语言模型和图像扩散模型，解决了现有方法在360度场景生成中出现的重复目标和闭环问题。该方法能够从不同模态的输入（如文字、草图、深度图）生成自然图像，并通过迭代扭曲和修复生成360度全景图。此外，L-MAGIC还能生成沉浸式视频和三维点云。其创新之处在于利用语言模型自动控制扩散模型，确保生成的场景结构符合输入描述。L-MAGIC在图像到360度场景和文字到360度场景生成任务中表现出优越性能，并在各种输入和场景下都能生成多样化的全景图。该论文已被CVPR 2024接收，并在ISC HPC 2024上展示。
独家专访Pika：Sora is not very hard to beat，我们的算法能够以小胜大｜AI Pioneers,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921189&idx=1&sn=f730ff92fc4c20d8c66fdbe002cae8ab&chksm=84e41c9bb393958d4d49b33c3c2dddf89fba3fa8cd069c92d2dd14b29d255ac4f0450d3e4d47#rd,2024-06-10 12:41:41,视频生成创业公司Pika获得8000万美元B轮融资，计划加速视频大模型的研发和团队扩张。在OpenAI的Sora引发视频生成赛道技术新标准后，Pika表示Sora的效果可通过规模化实现，并认为自己有能力超越。Pika强调团队实力，包括多名国际信息学奥赛金牌获得者和知名科学家，并透露年底将发布新产品，加强可控性。公司目标是打造服务创作者的产品，而非追求通用人工智能（AGI）。Pika认为视频生成行业目前处于60到70分阶段，关键待解决的问题包括准确性、可控性和效率。Pika正在招聘不同背景的人才，以增强其在视频生成领域的竞争力。
Karpathy最新四小时视频教程：从零复现GPT-2，通宵运行即搞定,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921189&idx=2&sn=7a8722741819f7cbbd711985f64869f3&chksm=84e41c9bb393958db1f186620e0be750cbc42150a5ff468738a9b3716152b8039569ceec30d9#rd,2024-06-10 12:41:41,AI大牛Andrej Karpathy发布了一部长达四个小时的视频，详细讲解如何从零开始复现GPT-2（1.24亿参数）模型。视频内容包括构建GPT-2网络、优化训练速度、设置训练运行和超参数，以及模型评估。Karpathy提供了完整的GitHub存储库“build-nanogpt”来辅助学习。视频分为建立网络、加快训练速度、设置运行和结果四部分，涵盖了从基础实现到优化技巧的全过程。
具身智能赋能机器人，「AI+人形机器人」论坛在浦东新区成功举行,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921189&idx=3&sn=b36d67bf25dc14face54c0748d9e3593&chksm=84e41c9bb393958df9dacc3a4eb15dc0605429e69bc3520461c26a4337a6d0f53fc9e3911a68#rd,2024-06-10 12:41:41,6月6日，「AI + 人形机器人」论坛暨张江机器人全球生态峰会在上海浦东举行，吸引了超过200位嘉宾和30000次在线观看。论坛汇集了具身智能、运动控制等领域的专家和企业代表，进行了技术交流和研究成果分享。浙江大学、上海人工智能实验室、香港中文大学（深圳）、上海理工大学等机构的学者和研究人员介绍了他们在机器人末端规划、具身智能、肌腱仿生驱动、自监督学习等方面的工作。此外，科大讯飞、百度智能云、OpenLoong开源社区等企业的代表也分享了他们在人形机器人技术、数据集构建、低成本具身平台等方面的努力。论坛为AI技术和产业的融合提供了交流平台，推动人形机器人领域的发展。
偏微分方程有了基础模型：样本需求数量级减少，14项任务表现最佳,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921189&idx=4&sn=c3b07c2e17a05fa3509eb2ef94fcb304&chksm=84e41c9bb393958ddd3f51b02385d498683a6eef3cf0c56f75b53437d430234894110b9d867d#rd,2024-06-10 12:41:41,苏黎世联邦理工学院等机构的研究者提出了一种名为Poseidon的新模型，用于学习偏微分方程（PDE）解算子。Poseidon基于多尺度Operator Transformer，能够在连续时间中进行评估，并在大规模数据集上预训练。在15个具有挑战性的下游任务上，Poseidon在样本效率和准确率上均优于基线方法，显示了在不同类型的PDE问题上的泛化能力。此外，Poseidon可以扩展以适应不同的模型和数据大小，并且其预训练模型和相关数据集都是开源的。该研究证明了PDE基础模型的潜力，并为高效通用PDE求解提供了新途径。
i人小助手：Meta推出多模态对话图，帮你轻松识别社交状态,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921189&idx=5&sn=8bd08b65e9dec2653c0082e428d23adc&chksm=84e41c9bb393958d645d378148b5ad513441283c1e577669f6c29f1b8c2dd576d4be8a835b9f#rd,2024-06-10 12:41:41,这篇文章介绍了来自佐治亚理工学院、Meta 和伊利诺伊香槟分校的研究者在 CVPR 上提出的新框架——音视频对话注意力（AV-CONV），用于识别第一人称视角下多人对话中的复杂社交行为。研究中，他们构建了一个有向的第一（Ego）——第三（Exo）人称对话图，通过建模跨时间、跨主体和全局-局部跨模态的表示来识别对话关系。AV-CONV 模型利用多模态特征，包括视觉和音频信号，通过自注意力机制进行增强，以预测不同社交对之间的对话状态。实验表明，AV-CONV 在并发对话数据集上显著优于基准模型。未来的研究可能将这一社交图概念扩展到其他人类行为分析，并探索更复杂的群体动态。
从LLM中完全消除矩阵乘法，效果出奇得好，10亿参数跑在FPGA上接近大脑功耗,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921106&idx=1&sn=8e78af28e7284eda29c2f0f7a670f170&chksm=84e41cecb39395fad0a1ac875b98f08e9fda05ae3b3bfbe971e726036daef0aecd41ddbf2beb#rd,2024-06-09 13:01:46,来自加州大学圣克鲁兹分校等机构的研究者证明了矩阵乘法（MatMul）操作可以完全从大型语言模型（LLM）中消除，同时在十亿参数规模下保持强大性能。他们提出的MatMul-free模型在推理期间需要的内存少于最先进的Transformer，且随着模型规模扩大，性能差距逐渐缩小。研究者还实现了高效的GPU模型，训练期间内存使用最多可减少61%，推理时内存消耗可减少超过10倍。此外，他们还在FPGA上构建了一个硬件解决方案，以低功耗处理十亿参数规模的模型，使LLM更接近大脑效率。该工作为减少LLM的计算资源需求和提高效率开辟了新途径。
大模型的高考数学成绩单：及格已经非常好了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921106&idx=2&sn=b2b4d8ffbbfe09ffd0c62d99accb6f20&chksm=84e41cecb39395fa497f4dc53e3afd25e27dfa55a70268189d168b3ae8a098820dcec44c8b00#rd,2024-06-09 13:01:46,这篇文章是关于一场让国内顶尖AI大模型参与的高考数学模拟考试的结果。在这次考试中，大模型的表现普遍不佳，只有GLM-4-0520模型超过了及格线。测试集中在高考数学的前14个客观题，包括单选、多选和填空题，涵盖基础数学知识和计算能力。在满分73分的情况下，GLM-4-0520以63分排在首位，而其他模型得分较低，甚至有部分模型得分在30分以下。模型在解决数学问题时需要理解数学概念、运用逻辑推理和抽象思维，这些似乎是当前大模型的挑战。文章还列举了每个模型在各个题目的回答情况，显示出在某些难题上的普遍错误。
SSM 能取代 Transformer 搞出更「牛」的大模型吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921106&idx=3&sn=4b47b6db7b40f34e47711928990193dc&chksm=84e41cecb39395fa8c3553b37e1c1abab8b60330d5e6a9938217fc3436410d0cc06dc7fea51b#rd,2024-06-09 13:01:46,"这篇文章讨论了人工智能和机器人领域内的三个重要议题。首先，它提到了Structured State Space Models (SSM)作为可能替代Transformer的大模型候选，因为SSM在处理长序列和计算效率方面展现出优势，尤其是在Mamba模型中的应用。研究发现，Transformer和SSM在数学上存在紧密联系，可以通过结合注意力机制和SSM来优化性能。

其次，文章探讨了自动驾驶领域中大模型的应用，特别是智能驾驶车企如何尝试将大模型“上车”，以解决无图化驾驶等问题。虽然大模型可能带来技术进步，但实现商业化盈利仍面临挑战。

最后，文章提到了硅谷的一次对话，涉及AI大模型市场变革，特别是Meta的Llama 3模型的影响，以及企业在选择开闭源模型和应对AI浪潮时的策略。此外，AI技术在个人应用和自动驾驶等领域的未来突破也进行了展望。

文章还包含了本周AI和Robotics领域的28项重要动态，涵盖技术、国内和国外的新闻。其中，对SSM与Transformer的比较和结合、大模型在自动驾驶中的应用，以及AI市场变革的讨论是本期通讯的三个专题解读重点。"
AI降噪耳机，可在嘈杂人群中单独通话，看一眼锁定目标,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921106&idx=4&sn=001d83107ceb42f0b3601cab07111dac&chksm=84e41cecb39395fa4497c1f4d174cc2e0706e1ed547c37ffe1b7f567ceb03fafc52ee3050748#rd,2024-06-09 13:01:46,华盛顿大学研究人员开发了一种名为“目标语音听觉”（Target Speech Hearing）的AI系统，可以让佩戴降噪耳机的用户通过注视说话者三到五秒来记录并锁定其声音。该系统能消除环境中的其他噪音，实时播放选定说话者的声音，即使用户和说话者的位置改变也能保持追踪。研究团队在ACM CHI计算机系统人因会议上展示了这项成果，并开源了概念验证设备的代码。此前，他们曾研发过允许用户选择听到特定声音类别的“语义听觉”系统。未来，这类技术可能扩展到耳塞和助听器等更多设备上。
可信度超越GPT-4V，清华&面壁揭秘「小钢炮」模型背后的高效对齐技术,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650921106&idx=5&sn=ac5ea0c3e91d5fc682936a53fcde2103&chksm=84e41cecb39395fa42d6820566dae349f5196bdf96ce3d1bc6834be264ea12d59a9a527cf9f2#rd,2024-06-09 13:01:46,这篇文章主要介绍了清华大学自然语言处理实验室和面壁智能合作推出的开源多模态大模型 MiniCPM-Llama3-V 2.5。该模型在发布后迅速登上Hugging Face、GitHub、Papers With Code的Trending榜首，且在可信度方面表现出色，超越了包括GPT-4V在内的闭源模型。模型的关键技术RLAIF-V是一种基于开源AI反馈进行多模态大模型对齐的方法，它通过无偏候选构造和分而治之的反馈收集策略实现了高性能和高可信度。此外，文章还提到了RLAIF-V的反馈数据集RLAIF-V Dataset和新的多模态评测集RefoMB，它们都显示出了优秀的泛用性和准确性。实验结果表明，RLAIF-V方法在减少模型幻觉和提升可信度方面取得了显著效果。
原作者带队，LSTM卷土重来之Vision-LSTM出世,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920943&idx=1&sn=7898a0e6176768f165f6570400ff6d0f&chksm=84e41391b3939a878c71086524410442bf95557acac0198bc9e073b87c851894be8bb56a8975#rd,2024-06-08 12:24:40,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
329篇图像、视频生成论文，今年CVPR最火的研究主题是这些,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920943&idx=2&sn=ad66875c8337732e67b0af83231892b0&chksm=84e41391b3939a87a6bc5be0623da0048ddf4663a211f804c2afd77147f16533d34e3496b343#rd,2024-06-08 12:24:40,这篇文章是对CVPR 2024会议论文录用情况的分析，展示了当前计算机视觉领域的研究热点。图像和视频合成与生成是论文最多的主题，共有329篇，其次是三维视觉（276篇）和人体行为识别（202篇）。视觉、语言与语言推理领域的论文数量为152篇，显示出多模态学习的重要性和关注度。底层视觉、自动驾驶、机器人技术以及视频中的动作和事件理解也是研究重点。此外，随着人形机器人的热潮，与机器人相关的研究，如机器人视觉、导航和操纵也受到关注。这些趋势反映了学界对视觉生成、三维感知、人机交互以及智能决策能力的重视。
支持合成一分钟高清视频，华科等提出人类跳舞视频生成新框架UniAnimate,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920943&idx=3&sn=486dceb31fd7f361d92c307baf62e664&chksm=84e41391b3939a8794b6e13943cc6e970382084742465929bd2824c9dcb2d0df91a1ce027fc1#rd,2024-06-08 12:24:40,华中科技大学、阿里巴巴和中国科学技术大学的研究团队提出了一种名为UniAnimate的框架，用于高效、长时间的人类跳舞视频生成。该框架解决了现有方法中的一些限制，如额外的参考网络需求、时序建模的复杂性和生成视频长度的限制。UniAnimate采用统一的视频扩散模型进行表观对齐和视频去噪，无需额外的参考网络，并通过统一的噪声输入支持长视频生成。此外，它利用状态空间模型（Mamba）替代时序Transformer，减少计算开销。实验表明，UniAnimate能生成高质量、连贯的视频，支持长达一分钟的视频合成，优于现有方法。这种方法有望在影视制作、虚拟现实和游戏等领域应用，提升人类形象动画的体验。
轻松构建聊天机器人、准确性新SOTA，RAG有了更强大的AI检索器,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920943&idx=4&sn=e207828f036988db08785d2aedd53b6d&chksm=84e41391b3939a87832cf3fb1e7c977f5c5aad4bce9345158c6a9dff6c6081f64cbb3b34914c#rd,2024-06-08 12:24:40,Denser.ai 团队推出了开源的 Denser Retriever，这是一个用于检索增强生成（RAG）的工具，旨在提高 AI 应用中生成内容的质量和相关性。Denser Retriever 支持异构检索器，包括关键词搜索、向量搜索和机器学习模型重排序，并在 MTEB 检索基准测试中实现了最先进的准确性。该工具设计为生产环境就绪，提供易用性和可扩展性，并且灵活适应不同行业的应用需求。用户可以通过简单的 Docker Compose 命令快速安装和使用。此外，Denser Retriever 还提供了构建检索索引和查询的示例，以及从文本文件和网页页面构建检索器的功能。
1.8B参数，阿里云首个联合DNA、RNA、蛋白质的生物大模型，涵盖16.9W物种,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920943&idx=5&sn=2c434135aa3c6eda80264e308e515526&chksm=84e41391b3939a87e286dc41f77c895cd50111ca95aaf8d306ce1531b05b1a448e7c8a308c92#rd,2024-06-08 12:24:40,"阿里云飞天实验室开源了业界首个联合DNA、RNA、蛋白质的生物大模型“LucaOne”，旨在综合学习遗传和蛋白质组语言，涵盖169,861个物种的数据。该模型通过自监督和半监督学习架构，能够在大量序列和注释信息上进行学习，参数规模约为1.8B，能够识别核酸与蛋白质之间的转化过程，有助于研究人员深入理解生物系统的内在逻辑。LucaOne在中心法则学习任务上取得了显著成效，预测准确率达到0.85，并在流感病毒的免疫逃逸风险预测中实现100%准确率。该模型的开源将为全球科研人员提供一个强大的生物计算工具，加速生命科学的探索与创新。"
英特尔放大招：新制程、能效核一起上，144核的至强6，性能成倍提升,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920913&idx=1&sn=bb2904653ce4e1d2fe797ed0fb477005&chksm=84e413afb3939ab93c4c88207dc79e30f415b0e3710d76bc950a7a670a4045010a684c4b734f#rd,2024-06-07 12:15:32,英特尔推出了全新的英特尔® 至强® 6能效核处理器，每个CPU拥有多达144个内核，旨在满足云级工作负载需求，提供高能效和低TCO。这款处理器特别适用于云原生应用和分布式计算，通过高密度设计提升机架密度达3倍，以应对企业对计算力、存储容量和网络带宽的增加需求。处理器内置加速引擎，支持高并行处理和大吞吐量工作负载，如Web托管、数据库和AI。同时，其高能效特性有助于数据中心降低运营成本和碳足迹，符合绿色低碳的发展目标。英特尔与生态合作伙伴共同推出基于该处理器的解决方案，以提升数据中心性能和效率。未来，英特尔还计划推出更高性能的性能核版本，以满足更多样化的AI工作负载需求。
Ilya参与，OpenAI给GPT-4搞可解释，提取了1600万个特征，还能看它怎么想,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920913&idx=2&sn=a19735f4f0a39966d3c7c7984e1b31bb&chksm=84e413afb3939ab9ee83e694044b6632d4192fdc4fa3e8d4cc8102089afe7cd642de0f275ce2#rd,2024-06-07 12:15:32,OpenAI开源了一种新的方法，可以解释大模型GPT-4的思路，这项技术涉及使用稀疏自动编码器来识别模型中的特征。该方法具有更好的可扩展性，使得研究团队在GPT-4中找到了1600万个特征。尽管仍处于早期阶段，且存在许多难以解释的特征，但这一进展有望提高模型的可信度和可操纵性，为监控和控制语言模型行为提供帮助，并最终增强对AI模型的信任。相关论文、代码和特征可视化工具已公开。
阿里Qwen2正式开源，性能全方位包围Llama-3,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920913&idx=3&sn=c6a60b3282b6fafef7f8273253df940e&chksm=84e413afb3939ab9210ac895efc678f7c617aa9d686bdef2974dce29aa1d18108540cb305f77#rd,2024-06-07 12:15:32,阿里云通义千问团队发布了Qwen2大模型，该模型在性能上超过了业界著名的开源模型Llama3-70B和多个国内闭源大模型。Qwen2系列包括五个尺寸的模型，所有尺寸都使用了Grouped-Query Attention（GQA），以提高推理速度和降低显存占用。在预训练和指令微调数据的规模和质量上进行了大量优化，提升了多语言能力。Qwen2-72B在多项评估中表现出色，包括自然语言理解、知识、代码、数学和多语言理解。此外，Qwen2-72B-Instruct在16个基准测试中取得了优异成绩，平衡了基础能力和人类价值观的对齐。Qwen2系列模型已在魔搭社区和Hugging Face上开源，供开发者免费下载。
ACL 2024 | 让纯LLM实现类人的符号逻辑推理能力，开源框架SymbCoT来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920913&idx=4&sn=31e0aa7a56d6114a70ca4824d796abf8&chksm=84e413afb3939ab98ccc866e0b7180aff093ef6b6e9c10111cbf1edaab318fc3be5b8f29da9f#rd,2024-06-07 12:15:32,新加坡国立大学、加州大学圣芭芭拉分校和奥克兰大学的研究人员提出了一种名为SymbCoT（Symbolic Chain-of-Thought）的新框架，旨在提高大语言模型（LLMs）的符号逻辑推理能力。当前的LLMs在严谨的逻辑推理方面存在不足，通常依赖于提示方法和外部符号推理工具。SymbCoT结合了符号化逻辑表达式和思维链，以增强推理质量、鲁棒性和可信度。与现有方法相比，SymbCoT在三个复杂逻辑推理数据集上的性能分别提高了22.08%、9.31%和7.88%。该框架包括翻译、规划、执行和验证四个步骤，能有效避免翻译错误和逻辑推理过程中的不准确。SymbCoT的实验结果表明，它在处理复杂推理任务、提高鲁棒性和确保推理过程可信度方面具有优势。
大模型时代，学习动手做AI Agent,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920913&idx=5&sn=19aa437e137e5d10dc5ef56f0f4f77e2&chksm=84e413afb3939ab9430168c45c7649f16b7f57f712f8e0f36c0cbc580d0762bc9ab136eab0dc#rd,2024-06-07 12:15:32,这篇文章提到人工智能行业的焦点已转向AI Agent，它们是能够理解和回应自然语言并执行任务的智能体。OpenAI的GPTs引发了对AI Agent的关注，而比尔·盖茨认为它们代表着AI的未来。黄佳，一位新加坡科技研究局的人工智能研究员，出版了新书《大模型应用开发—动手做AI Agent》，探讨了AI Agent的设计和实现，并将在6月11日的直播中分享如何利用大模型优化Agent的认知框架选型和应用。直播将介绍最新认知框架，如Function Calling、CoT、ToT、ReAct、Plan-and-Execute以及Self-ask，并通过案例和Demo展示其应用。这本书面向研究人员、开发人员、产品经理等对AI Agent感兴趣的人群。
辅导作业这么费劲的事，还是交给这个大模型吧,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920885&idx=1&sn=a85987ad0b0a1607a1d9a8a5447ca8be&chksm=84e413cbb3939add03ba5cdfc0a5d806f21e22a6ce8abc4e2ba8cb566b2c9197896b53c25f53#rd,2024-06-06 18:25:29,学而思学习机的AI助手“小思”近期进行了重大升级，新增了“小思作业模式”、“小思圈圈学”、“小思AI口语分级练”、“小思对话”和“小思建议”等功能。其中，“小思AI口语分级练”和“小思对话”基于九章大模型（MathGPT）技术，旨在提高孩子的自学效率和口语能力。学而思学习机在2024年一季度销量和销售额均位居市场第一，搭载九章大模型的旗舰款在高端市场占据主导。此外，“小思作业模式”通过摄像头监督孩子完成作业，并提供批改和答疑服务，帮助家长减轻辅导压力。学而思通过内置AI技术和教研内容，致力于在家庭教育中提供更智能、个性化的学习支持。
黎曼猜想突破作者首次公开讲解，陶哲轩送上总结,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920885&idx=2&sn=6d5d0b37a7b6e32ccee243d04ba7d8ff&chksm=84e413cbb3939add1ddfd441ee61d6e8a595613f502214e9831d3909206c940285dca4797463#rd,2024-06-06 18:25:29,MIT数学教授Larry Guth和牛津大学数学研究所教授James Maynard在新论文中对黎曼猜想的研究取得了重要进展。他们改进了关于黎曼ζ函数零点的经典界限，但表示离解决这一数学问题还有很长的路要走。两位作者分别进行了主题讲座，详细解释了他们的研究成果，特别是关于Dirichlet多项式大值问题的分析。这些研究在解析数论中具有重要意义。讲座中，Maynard和Guth通过板书和密集的内容输出，深入探讨了证明思路和关键细节。知名数学家陶哲轩对这项工作给予了积极评价。
这个团队做了OpenAI没Open的技术，开源OpenRLHF让对齐大模型超简单,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920885&idx=3&sn=94e5baeba95fc3a86de3357e98382d8c&chksm=84e413cbb3939add69df2218520680f92a1ac3149f49f9faf50d2ea858d92841f4470d899373#rd,2024-06-06 18:25:29,为解决大型语言模型（LLM）与人类价值观对齐的难题，强化学习（RLHF）是一种有效技术，但随着模型规模扩大，训练所需的内存和计算资源也在增加。现有的RLHF框架在处理超过700亿参数的模型时面临挑战。为应对这一问题，一个联合团队推出了OpenRLHF，这是一个易于使用、可扩展、高性能的RLHF框架，支持超过700亿参数的模型训练。OpenRLHF使用Ray、vLLM和DeepSpeed进行模型调度优化，能在多台GPU上高效分配模型组件，同时实现与Hugging Face的无缝整合和多种对齐算法的支持。此外，它还采用了一系列性能优化技术，如张量并行化和内存管理策略，以加快训练速度和提高训练稳定性。OpenRLHF的易用性使其能够简化大型LLM的RLHF训练过程。
Stability AI开源47秒音频生成模型，虫鸣鸟叫、摇滚、鼓点都能生成,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920885&idx=4&sn=45344ce92b50541bbee3be44bd366652&chksm=84e413cbb3939addd288702f3d08e690b1eba2a1cbd25d8d1cecaa2ca4f447dc12aa36e8d587#rd,2024-06-06 18:25:29,AI公司Stability AI推出了开放模型Stable Audio Open，该模型能够根据简单的文本提示生成长达47秒的高质量音频数据，适合创建鼓点、乐器片段、环境音等。该模型基于Transformer架构，由自编码器、文本嵌入和扩散模型组成。训练数据来自FreeSound和Free Music Archive，经过筛选以确保不包含受版权保护的材料。然而，该模型存在一些局限性，如无法生成逼真的声音，对非英语描述的支持有限，且在不同音乐风格和文化中的表现不一。Stable Audio Open遵循Stability AI的非商业研究社区协议许可证，不能用于商业用途。
ICML 2024 Oral｜外部引导的深度聚类新范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920885&idx=5&sn=e5c7f18841576386b14ab6b8efef57ef&chksm=84e413cbb3939addde5fcdb53375410168242b545bf0e8b2ee40d5c06d669162147ded8ef8cc#rd,2024-06-06 18:25:29,本文介绍了四川大学计算机学院李云帆发表的论文《Image Clustering with External Guidance》，该论文提出了一种新的图像聚类方法，利用外部知识库内容提升CLIP图像聚类的性能。传统聚类方法主要依赖数据内部信息，而该方法引入了外部文本模态的语义信息来引导聚类。通过预训练的CLIP模型和WordNet的名词，构建文本表征，并使用跨模态互蒸馏方法协同图像和文本模态，从而提高聚类准确性。实验结果表明，这种方法在多个图像聚类数据集上表现出优秀性能，甚至超越了依赖类别标签的CLIP Zero-shot分类。该研究为聚类任务提供了一种新的外部引导聚类范式，具有广阔的应用前景。
GLM-4开源版本终于来了：超越Llama3，多模态比肩GPT4V，MaaS平台也大升级,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920715&idx=1&sn=60f40d1f7210cdd1d3528fef43294d2a&chksm=84e41375b3939a638460e1808c0490827f8df2c71c9d33e12b8e7185ef700a071594d1c525b9#rd,2024-06-05 18:50:17,这篇文章是关于智谱AI在AI开放日上发布的一系列更新和成就。智谱AI的大模型开放平台已获得30万注册用户，日均调用量达到400亿Tokens，且过去6个月API每日消费量增长达50倍以上。最新版本的GLM-4-9B模型在性能上超越了Llama 3 8B，多模态模型GLM-4V-9B也已上线且保持开源。智谱AI降低了大模型服务的价格，最高折扣可达6折，GLM-4-9B版本的价格低至6分钱/100万Token。此外，他们推出了MaaS开放平台2.0，提高了模型微调平台的效率，并强调了通过技术创新降低应用成本的策略。在模型技术方面，GLM-4-9B在多项基准测试中表现出色，且支持多语言和长文本处理。智谱AI还致力于生态建设，是国产大模型技术的领军者，并参与制定AI安全标准。
黎曼猜想显著突破！陶哲轩强推MIT、牛津新论文，37岁菲尔兹奖得主参与,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920715&idx=2&sn=22bd850a132ec9dec300e836a9c27b74&chksm=84e41375b3939a631aed9b997d07a23d48f09f26875aebb2478e0c9d23b6f97929f698fc8b96#rd,2024-06-05 18:50:17,MIT 数学教授 Larry Guth 和牛津大学数学研究所教授 James Maynard 在黎曼猜想上取得新突破，他们对黎曼 zeta 函数零点的经典 1940 年 Ingham 界限进行了首次实质性改进。这一进展对解析数论领域有重要意义，但数学家陶哲轩表示，这离完全解决黎曼猜想还有很大距离。黎曼猜想是关于素数分布的一个未解决问题，与众多数学命题的成立密切相关。如果证明猜想正确，将对数学界产生深远影响。至今，黎曼猜想已提出超过 165 年，尽管有多次尝试，但尚未得到完全证明。
央国企需求场景发布，共议 AI 赋能产业融通，尽在WAIC这场论坛,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920715&idx=3&sn=aeb1e9d429b480d3a044c4ae562012a7&chksm=84e41375b3939a633a574d18e24df9dca4f20306b4ef0da8a56458d5834806cf6c9193c5025e#rd,2024-06-05 18:50:17,这篇文章提到了中国政府将深化大数据和人工智能的研发应用，开展“人工智能+”行动，以打造具有国际竞争力的数字产业集群。为推动这一进程，7月6日将举办「2024 WAIC 人工智能赋能产业融通发展论坛」，由机器之心主办。论坛将汇聚多家央国企和头部AI企业，发布和探讨人工智能在各产业的应用场景需求和落地策略。论坛将设置央国企应用场景需求发布环节，促进供需双方合作，并揭晓“人工智能+”标杆示范名单，展示和表彰在人工智能领域取得成就的企业。此外，活动还将通过主旨演讲和圆桌讨论，分享人工智能改造产业的经验和未来发展方向。
嘴炮王者Tyler1化身免费AI陪玩，帮你在英雄联盟中打爆三路，轻松上分,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920715&idx=4&sn=77d0538a710b73701b32fbe60baebf35&chksm=84e41375b3939a63879410e8e98f2fe5a795d35ec5e33c7f246532263f2dcd5add8f24aa1d70#rd,2024-06-05 18:50:17,很抱歉，您还未提供具体的文章。请您提供需要摘要的文章内容，我会尽忙为您生成摘要。
腾讯混元、北大发现Scaling law「浪涌现象」，解决学习率调参难题,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920715&idx=5&sn=8d15454ce74891f57be06b7cce1bd099&chksm=84e41375b3939a63c8b25d876ad30ad45ac6fe8386d936767c6ba91e36bc95084b0bbd9fcb3a#rd,2024-06-05 18:50:17,这篇论文摘要讨论了深度学习优化中学习率（Learning rate）和批量大小（Batch size）的调整问题。研究发现，对于基于SGD的优化器，应当遵循OpenAI 2018年的结论进行调整，而使用Adam风格的优化器时，学习率和批量大小的放缩规律为平方根关系。当批量大小超过某个阈值时，使用Adam优化器的最优学习率会下降，这是由于一阶动量除以二阶动量平方根的更新形式导致的。论文中还提出了“浪涌现象”，即学习率曲线在批量大小增加时先升高后下降，并且这个现象随着训练进行会更加明显。理论预测和实验证实了这个现象，并在腾讯Angel大模型训练框架中进行了应用。
再战Transformer！原作者带队的Mamba 2来了，新架构训练效率大幅提升,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920390&idx=1&sn=46a34c9edf886e58b6d18f28c8ec438a&chksm=84e411b8b39398aeb969f90b4a22821325c8974c1846ee91b853c0fa77b9f404b9f08b2a0e57#rd,2024-06-04 12:50:58,Mamba-2，一种新的序列模型架构，由Albert Gu和Tri Dao提出，解决了Transformer模型中自注意力机制计算量随上下文长度平方级增长的问题。Mamba-2通过状态空间对偶性（SSD）框架实现了线性扩展，速度提高了2-8倍，同时在语言建模任务上与Transformer竞争。相较于Mamba，Mamba-2具有更快的训练速度和更大的状态维度，且在MQAR任务上表现出显著改进。论文中提出的SSD框架为序列模型的理解和改进提供了新途径，并且Mamba-2的架构设计允许利用现有的Transformer生态系统进行扩展和优化。实验结果显示，Mamba-2在多个基准上与或超过了Mamba和Transformer++。
苏妈杀疯了：移动端最强NPU算力达50TOPS，最强AI芯片挑战英伟达,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920390&idx=2&sn=892232833819cdd0ae2c18933345c53f&chksm=84e411b8b39398ae60264e36ad585680de7098accce71b4b44bc02cc0465174c175e1c24eff0#rd,2024-06-04 12:50:58,AMD在Computex科技大会上展示了基于Zen 5架构的全新桌面端Ryzen 9000系列CPU，包括16核32线程的Ryzen 9 9950X，性能和能效提升显著，预计7月上市。此外，AMD还推出了AI PC芯片锐龙AI 300系列，拥有50TOPS的NPU算力，以及第五代EPYC霄龙数据中心芯片，最高192核384线程的Turin芯片，挑战英伟达在GPU领域的地位，公布了Instinct GPU的未来产品路线图。
Karpathy点赞，这份报告教你如何用 LLaMa 3创建高质量网络数据集,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920390&idx=3&sn=b46c35437f520e90d4b3c5b49186406a&chksm=84e411b8b39398ae4aa54356c2d97d62cea34e5ed94cded431be2086fcfe0d892badc1625c29#rd,2024-06-04 12:50:58,研究人员构建了一个名为FineWeb的大规模数据集，用于预训练大型语言模型。这个数据集包含15万亿个token，经过过滤和质量评估，旨在提供高质量的教育内容。AI专家Andrej Karpathy推荐了FineWeb-Edu，它是FineWeb的一个子集，专注于教科级内容，经过Llama 3 70B模型的评估，分为1.3万亿和5.4万亿token的两个版本。FineWeb-Edu在教育相关基准测试中表现出色，超过了其他公开可用的网络数据集。数据集的创建涉及对CommonCrawl的处理、重复数据删除和使用LLM进行质量注释等步骤。这是提高大语言模型性能的一个重要步骤，强调了高质量教育内容在训练中的价值。
单个4090可推理，2000亿稀疏大模型「天工MoE」开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920390&idx=4&sn=0bc7ce29e6bcff325da99316b20e377e&chksm=84e411b8b39398ae368f15554e3db1a2b16037e264124274a5599c184614e237b360847c972b#rd,2024-06-04 12:50:58,昆仑万维宣布开源2千亿稀疏大模型Skywork-MoE，该模型基于开源的Skywork-13B扩展而来，应用了MoE Upcycling技术，能够在单台4090服务器上进行推理，降低了推理成本。Skywork-MoE是首个支持这种推理的开源千亿MoE大模型，其模型权重、技术报告完全开源，免费用于商业。该模型总参数量为146B，激活参数量22B，具有16个Expert。在20B的激活参数量下，其性能接近70B的密集型模型，推理成本下降约3倍。模型还引入了Gating Logits归一化操作和自适应的Aux Loss以改进训练和泛化性能。此外，Skywork-MoE提出Expert Data Parallel和非均匀切分流水并行等并行优化设计，以提高大规模分布式训练的效率。
AI训练数据的版权保护:公地的悲剧还是合作的繁荣?,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920390&idx=5&sn=8adcd1f34022d79b38431f8002849ae8&chksm=84e411b8b39398aeba6e8c7f6734df1f2b6d27589cfb644e4165d9f898bf4c712686c99430b1#rd,2024-06-04 12:50:58,普林斯顿大学、哥伦比亚大学、哈佛大学和宾夕法尼亚大学的研究人员提出了一种新的方案，以解决生成式AI的版权保护问题。随着AI在艺术和内容创作中的应用日益广泛，版权争议逐渐增多。该方案基于经济学理论，提出使用Shapley值来公平地分配版权收益，缓解AI开发者和版权所有者之间的冲突。Shapley值是一种合作博弈论工具，可以评估每个数据来源对AI模型的贡献，并据此确定版权分成。该方法通过评估模型在不同数据子集上训练的效用来确定每个版权所有者的应得份额，但计算成本较高，需要通过蒙特卡洛方法或模型微调来降低计算负担。虽然此框架在实验中显示了有效性和可行性，但未来的研究还需要解决包括抗操纵机制、处理不愿意协商的版权所有者以及降低计算开销等问题。
清北爸爸李永乐都搞不定的事情，这个隐身的大模型在发起挑战,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920201&idx=1&sn=5f435218e4a3cbb07d68eac93de7e17a&chksm=84e41177b3939861aec0c49d9edeec771a8b2f6ee0b57a44eae27019b8f19bd8c11ff918eeae#rd,2024-06-03 13:21:42,这篇文章提到了猿辅导公司如何利用人工智能（AI）大模型来改进教育辅导。文章指出，即使是有顶尖学府背景的家长在辅导孩子作业时也会遇到困难，而AI辅导提供了一种新的解决方案。猿辅导旗下的飞象星球发布了一段视频，展示了一个大模型如何通过问答方式帮助孩子解决数学问题，这种方法强调启发式教学，鼓励孩子独立思考。猿辅导的大模型不是独立产品，而是作为技术底座支持其教育产品，提供个性化学习服务。该公司强调，大模型应注重启发和个性化，以适应不同学生的需求，而不是直接给出答案。猿辅导在AI领域的研究始于2014年，积累了大量的教育数据，这些数据有助于大模型理解教育规律和方法，提供更有效的辅导。未来，猿辅导计划在多模态大模型上进一步发展，以增强教育场景的应用。虽然教育大模型的应用仍处于早期阶段，但它们有潜力重塑教育方式，促进教育资源的公平分配。
斯坦福爆火Llama3-V竟抄袭国内开源项目，作者火速删库,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920201&idx=2&sn=17eb3f97e7f8c757d104c0102684283c&chksm=84e41177b3939861b089252c5ad2c305b816b7e3b49293141399d79c3e235085630b4d05394f#rd,2024-06-03 13:21:42,"这篇文章的摘要可以是：

斯坦福大学的一个研究团队发布了一个名为Llama3-V的多模态模型，声称只需500美元，就能达到与GPT-4o等高性能模型相当的水平，但模型规模小100倍。该模型在推特上迅速引起关注，但随后遭到质疑，被指可能抄袭了清华大学自然语言处理实验室与面壁智能合作的MiniCPM-Llama3-V-2.5模型。网友发现Llama3-V的代码和配置文件与MiniCPM-Llama3-V-2.5高度相似，且作者的解释存在时间线上的矛盾。在质疑声中，Llama3-V的项目链接被删除，作者也隐藏了相关模型和代码。"
全球最强GPU芯片已量产、下一代Rubin曝光，老黄继续打破摩尔定律,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920201&idx=3&sn=8eb6bd91a1d997dcee5df2cc27fbcfcc&chksm=84e41177b3939861b4b661780b01451dd3f0a1ac196cac3f669c6075aa010fcc11a1746bd4b4#rd,2024-06-03 13:21:42,在2024年的COMPUTEX科技大会上，英伟达创始人、CEO黄仁勋展示了最新量产版的Blackwell芯片，这是英伟达首个采用MCM设计的GPU，拥有强大的AI算力。黄仁勋表示，AI算力在短短八年里提升了1000倍，同时成本逐年下降。他还预告了未来三代芯片的路线图，包括Blackwell Ultra（2025年）、Rubin（2026年）和Rubin Ultra（2027年），并将保持一年一次的更新节奏。此外，英伟达还推出了游戏助手Project G-Assist，这是一个基于RTX的AI助手，能为PC游戏提供上下文感知的帮助。同时，NVIDIA NIM是一个新的推理微服务，简化了生成式AI应用的部署。在机器人技术方面，NVIDIA展示了Isaac平台和Omniverse在工业数字化变革中的应用。
物理传热启发的视觉表征模型vHeat来了，尝试突破注意力机制，兼具低复杂度、全局感受野,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920201&idx=4&sn=96a96028d8f4d9447ebb81d56423208f&chksm=84e41177b393986161e0ca790154fb7f6cbfb2b1dcfcae5696bf52e43b54534fd0cc108f6056#rd,2024-06-03 13:21:42,中国科学院大学和鹏城实验室的研究人员提出了一种新的视觉表征模型vHeat，该模型基于热传导原理，用以替代Transformer中的Attention机制。vHeat将图片特征视为热源，通过预测热传导率来提取图像特征，从而在保持较低计算复杂度（1.5次方）的同时，实现了全局感受野和物理可解释性。相比Swin Transformer，vHeat在高分辨率图像处理时具有更高的吞吐量、更低的GPU显存占用和更少的FLOPs。在ImageNet-1K图像分类、COCO目标检测和ADE20K语义/实例分割等任务上，vHeat展现了先进的性能。论文和代码已开源。
不同数据集有不同的Scaling law？而你可用一个压缩算法来预测它,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920201&idx=5&sn=f66b18d4148b2786e7840394ff013b90&chksm=84e41177b39398616cdd94ab577683c65a1aded7cd4f7cc51711d78364f53a8778261e50fc11#rd,2024-06-03 13:21:42,研究人员发现神经网络的Scaling law（规模定律）——即性能与模型参数和训练数据量之间的关系——受到训练数据集复杂度的影响。通过使用概率式上下文无关语法（PCFG）生成不同复杂度的文本数据集，研究发现随着数据复杂性的增加，Scaling law的计算最优边界更倾向于数据量而非模型参数量。通过gzip压缩率作为数据复杂性的度量，研究者发现数据的可压缩性可以预测Scaling law的行为，表明Scaling law对训练数据的属性有显著依赖。这一发现对于优化模型训练和资源分配有重要意义，表明在扩展模型时需要考虑数据集的特性。
上海交大卢策吾：具身智能与他的首个刮胡子机器人 | 智者访谈,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920090&idx=1&sn=d771f20cc122ca1c3b5bc31428965741&chksm=84e410e4b39399f2be553afe99d5b46cd97a9e2a028b6107b2b0a588b912ff012a0cfb59c4db#rd,2024-06-02 12:29:05,上海交通大学卢策吾教授成为了全球首位由机器人用刀片刮胡子的人，这一成就展示了其团队研发的具身智能大模型的高精度力反馈技术。机器人刮胡子需要行为泛化性和极致鲁棒性，即使在头部移动时也能动态调整压力和切向力，保证安全。卢策吾教授在「智者访谈」节目中深入探讨了具身智能的原理、挑战和落地应用，强调智能体与物理环境交互的重要性。他还提到了Scaling Law在具身智能领域的应用，并讨论了具身智能的评估、创业和人才问题。卢策吾教授是具身智能领域的知名专家，曾获得多项科技奖项，并在高水平期刊和会议上发表多篇论文，同时也是初创公司穹彻智能的首席科学家。
多模态大模型不够灵活，谷歌DeepMind创新架构Zipper：分开训练再「压缩」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920090&idx=2&sn=2b3bfd6c33f118785f5f506933d7d9b3&chksm=84e410e4b39399f2a1258c10f96dddb4ac170c9604c46a3f7f50513a67784ccc2844e310badb#rd,2024-06-02 12:29:05,Google DeepMind的研究人员提出了一种名为Zipper的新型架构，用于融合多种模态的生成任务。Zipper由多个单独预训练的单模态解码器模型组成，可以在预训练后利用交叉注意力将它们“压缩”在一起，通过有限的跨模态数据进行微调，实现多模态生成能力。这种方法比传统的多模态预训练模型更灵活，可以在新的多模态组合中重复使用和再利用预训练的纯解码器模型，而不需要大量对齐的跨模态数据。Zipper在语音到文本和文本到语音任务中的实验展示了其强大的跨模态生成能力，即使使用少量对齐数据也能取得良好效果。
搞定视频任务泛化，VLM 还有机会吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920090&idx=3&sn=5692b950293848bdb854295fd344a094&chksm=84e410e4b39399f25fe856376ddf48ed25aeb0502db4854e4b7833b7259d248fe3fff575f15e#rd,2024-06-02 12:29:05,"这篇文章是机器之心PRO的会员通讯，主要内容包括：

1. 视觉语言模型（VLM）在处理视频任务上的挑战和潜在机会：VLM在图像任务中表现出色，但在视频任务中仍处于初期阶段，需要解决数据标注、训练协议和合成数据等问题以实现泛化能力。视频数据对于模型的感知、理解和交互能力至关重要，尤其是在具身智能领域。

2. AI市场规模的激增：AI市场发展迅速，得益于多种因素，但也存在企业难以充分利用AI策略和实际应用难题的问题。

3. Scale AI的行业调查：通过对2000名AI从业者的研究，分析了2024年AI的准备情况，讨论了AI在技术和企业准备程度上的现状，以及开发者对AI模型的使用感受。

此外，通讯还包含了本周AI和Robotics领域的29项重要事件概览，涵盖了技术发展、国内外动态等多个方面。"
开源模型进展盘点：最新Mixtral、Llama 3、Phi-3、OpenELM到底有多好？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920090&idx=4&sn=ab80d2990b984dfa646c59ece930cf35&chksm=84e410e4b39399f26de87c1d6f7b78db95473a02aa5787caba4cebe0d0b778966dfd6c70ab16#rd,2024-06-02 12:29:05,这篇文章总结了4月份发布的四个主要的人工智能大模型：Mixtral 8x22B、Llama 3、Phi-3和苹果的OpenELM。Mixtral 8x22B是一个大规模的混合专家模型，表现出色。Llama 3在数据量大幅增加后性能显著提升，而Phi-3则强调数据质量而非数量。OpenELM是苹果发布的高效语言模型系列，专为移动设备设计。此外，文章还探讨了DPO和PPO两种强化学习方法在对齐大模型时的比较，以及4月份其他值得关注的AI研究进展。
高效、可泛化的高斯重建框架，只需3张视图即可快速推理，45秒便可完成优化,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920090&idx=5&sn=683e69ff80f6241b5d36316f7f6dd780&chksm=84e410e4b39399f2cb257e8c6ca47f4f171b48c5f9d10dbb0153323b1b2008ead11546f8e7ca#rd,2024-06-02 12:29:05,华中科技大学、南洋理工大学、大湾区大学和上海人工智能实验室的研究者提出了一种名为MVSGaussian的高效、可泛化的高斯重建模型，用于从稀疏多视角图像中学习场景的3D高斯表征，实现新视图合成。该模型结合了多视角立体（MVS）的几何推理和高斯溅射的实时渲染优势，能够在泛化推理和逐场景优化方面实现快速高质量的渲染。与现有方法相比，MVSGaussian在视图质量、渲染速度和优化时间上具有显著优势，仅需45秒即可完成高质量的实时渲染。该模型通过MVS推理几何，建立像素对齐的高斯表征，并采用混合高斯渲染方法增强泛化能力。此外，它还引入了一种多视图几何一致性聚合策略，实现快速逐场景优化。实验结果表明，MVSGaussian在多项指标上达到了最先进的水平。
给ChatGPT越狱，谈场赛博恋爱,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920070&idx=1&sn=c91e2164542c854fe8f13dcc3d019f51&chksm=84e410f8b39399eefe5c7abde981c84dc4560eab1f9d0f74b440e7daee44dd6af9e5b6a21318#rd,2024-06-01 12:43:08,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
Yann LeCun：ViT慢且效率低，实时图像处理还得看卷积,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920070&idx=2&sn=f88e78fbc290823d62a8680aefd31adb&chksm=84e410f8b39399ee00a150570dfb2c6b160ba63ff8c44443b9e31ca48ad0350dceb0fc5a50fe#rd,2024-06-01 12:43:08,图灵奖得主、Meta 首席科学家 Yann LeCun 近日加入了一场关于 Vision Transformer（ViT）与卷积神经网络（CNN）的讨论。起因是 Comma.ai CTO 展示了纯 ViT 在压缩器中的成功应用，但 LeCun 表示，虽然 ViT 很流行，但它在实时处理高分辨率图像和视频任务时效率低下。他主张在低级别使用卷积/步幅/池化，在高级别使用自注意力循环。LeCun 认为特斯拉的全自动驾驶（FSD）可能仍采用卷积，并认为在低级别 patch 嵌入上使用 Transformer 是浪费。这场争论反映了 ViT 和 CNN 在计算机视觉领域的持续竞争。
单GPU训练一天，Transformer在100位数字加法上就达能到99%准确率,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920070&idx=3&sn=027516aac75ebc2ec76f55aff57d66a9&chksm=84e410f8b39399ee51c794fb5ca59b73fa83d54b93621050481ace026286e8ca6d8c77950c49#rd,2024-06-01 12:43:08,研究者发现，Transformer 在算数任务中表现不佳，尤其是加法，主要因为它无法跟踪大范围数字中每个数字的确切位置。为解决这一问题，他们提出了Abacus嵌入，通过在每个数字中添加编码数字相对于开头位置的嵌入。使用Abacus嵌入，Transformer在20位数字的加法任务上训练一天后，就能达到99%的准确率，对于100位数字加法问题也能达到99%的准确率，实现了显著的泛化能力提升。结合输入注入和looped transformer架构，性能进一步提高，分布外准确率从92.9%提高到99.1%，误差降低了87%。这项研究还扩展到乘法和排序任务，同样表现出长度泛化能力。
超长小说可以用AI翻译了，新型多智能体协作系统媲美人工翻译,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920070&idx=4&sn=b874fcb04a24a6caf2c095f906a5e62d&chksm=84e410f8b39399ee28ae376742173985ab1878029d111f1a0ad8c8850fe30bc503f590f1d48d#rd,2024-06-01 12:43:08,研究人员提出了一种新的多智能体框架，用于翻译超长文学文本，称其可能超越人类翻译。这一框架名为TRANSAGENTS，模拟了一个虚拟出版公司的不同角色，如CEO、编辑、译员等，利用大型语言模型进行协作翻译。通过单语人类偏好（MHP）和双语LLM偏好（BLP）的评估策略，实验表明，TRANSAGENTS的翻译质量在某些情况下超过了人类参考翻译，特别是在需要领域知识时。虽然在d-BLEU指标上表现不突出，但人类评估和LLM偏好显示了对TRANSAGENTS翻译的更高满意度。
CVPR 2024 | 合成视频数据集里只有单人数据？M3Act破解人群行为标注难题,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650920070&idx=5&sn=28e55baa6f15dc9cc0baed9a259240c8&chksm=84e410f8b39399ee1adc66863ed950e3f217802bd38c3b54c07d80b67b754e1157afb97f1e4b#rd,2024-06-01 12:43:08,研究人员提出了一个名为M3Act的合成数据生成框架，用于生成多群组人群行为的视频，以促进视觉识别任务，如多人跟踪和群体活动识别。M3Act通过Unity引擎创建，包含多样化的3D场景、人物模型和动画，提供2D和3D标记以及个人和群组级别的标签。实验表明，M3Act可以显著提高模型在多人跟踪和群体活动识别任务上的性能，甚至可以替代部分真实数据，降低了数据标注成本。此外，M3Act还引入了可控3D群体活动生成任务，允许根据各种输入生成协调的群体活动。
AI内容创作开卷，为什么百度文库成为超强玩家？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919961&idx=1&sn=ef8c687a9005580ad74424546cf0a5d0&chksm=84e41067b3939971a637e1c6cf2fd95442b3e9579369437fee0da0983113ddcf8c0334f8b010#rd,2024-05-31 12:22:03,百度文库在2024百度移动生态万象大会上宣布已全面重构为一站式AI内容获取和创作平台，推出众多AI功能，如智能画本、智能PPT生成、文档生成、研究报告生成等，助力学习办公、家庭教育和兼职赚钱等场景。此外，百度文库还与多个IP合作，提供3D风格AI画本创作，如与“猪猪侠”IP合作。智能漫画和智能小说功能则让普通用户也能进行内容创作并实现商业变现。新产品“橙篇”是一个AI原生应用，提供专业知识检索、问答、超长图文理解和生成等服务，旨在满足更深层次的科研和学术需求。百度文库累计AI用户已超过1.4亿，AI新功能使用次数超过15亿，显示出AI在内容创作领域的广泛应用。
解决Transformer根本缺陷，CoPE论文爆火：所有大模型都能获得巨大改进,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919961&idx=2&sn=78456fd867b05195f558281bf6517402&chksm=84e41067b393997186b8c78851d5623e383de3d7a0966a16f75c162546397a25e2a8511998a0#rd,2024-05-31 12:22:03,这篇论文介绍了来自Meta FAIR的最新研究，提出了一种名为CoPE（Contextual Position Encoding）的新方法，用于改进Transformer模型的位置编码。传统位置编码基于token位置，而CoPE允许模型根据内容和上下文选择性地编码位置，解决了大模型在计数和复制任务上的挑战。这种方法使得模型能更好地处理需要精细理解输入数据结构和语义的任务，特别是在处理分布外数据和高泛化能力需求的任务上表现出优越性。CoPE为大型语言模型提供了更高效和灵活的位置编码方式，有望拓宽其在自然语言处理领域的应用。论文在短时间内成为了AI领域的热门文章，受到了广泛关注。
爆火ChatTTS突破开源语音天花板，3天斩获9k的Star量,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919961&idx=3&sn=5fbe8dbaa4e5889ad99db86cbd9b5de6&chksm=84e41067b39399714d6a0d5ad5bb926502ef4ea1c839fd1c68a1e9f2fe0a250fd1b469778110#rd,2024-05-31 12:22:03,一个名为ChatTTS的文本转语音项目在GitHub上迅速走红，三天内获得了9.2k的Star。该项目能够将文本转换成逼真的语音，支持中文和英文，甚至可以模拟特定人的声音，如乔布斯或Taylor Swift。ChatTTS还允许用户控制笑声、停顿和语气词等细粒度特征。尽管目前开源版本未经过SFT监督微调，但其韵律控制超越了大多数开源TTS模型。用户可以在HuggingFace上体验在线版本，但需要注意长文本的处理和分词问题。该项目引发了网友的兴趣，许多人尝试并赞赏其声音的真实性。
2D头像生成3D虚拟人开视频会，谷歌新作让人难绷,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919961&idx=4&sn=9f9ff84fd4b47cd081eef4dc836365d1&chksm=84e41067b3939971f1a7496c8b4f3fe5f5f6844c365a7ede5ee1fd645604742d0dff8d7a8711#rd,2024-05-31 12:22:03,谷歌提出了一项名为ChatDirector的技术，该技术使用静态的2D头像生成3D虚拟人，以增强远程视频会议的临场感。ChatDirector通过空间化视频头像、虚拟环境和自动布局转换，将传统的2D视频会议转变为3D体验，使参与者仿佛坐在同一间会议室中。虽然目前的虚拟人物看起来有些夸张，但其口型能准确对上，可能为在线会议营造轻松气氛。这项研究考虑了增强虚拟会议环境、提供语音驱动的协助、重现面对面互动的视觉效果、减少认知负荷和确保兼容性等因素。ChatDirector使用了深度学习和决策树算法来实现空间感知的场景渲染和语音驱动的布局转换。初步的用户研究表明，ChatDirector提高了注意力转移辅助的效率和参与者的共存感。然而，肖像安全和用户对自身肖像控制的问题是未来需要关注的焦点。
神笔马良画出三维世界，基于线稿的3D生成编辑方法SketchDream来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919961&idx=5&sn=6ff67f28c99f437a2a20e277fc0ad85b&chksm=84e41067b3939971725c3d2d4f9c25036fe7f31dd09c61226c446fc13a211ad80525859c2d15#rd,2024-05-31 12:22:03,中国科学院计算技术研究所、香港城市大学和卡迪夫大学的研究人员发表了一篇名为《SketchDream: Sketch-based Text-to-3D Generation and Editing》的论文，该论文提出了一种基于线稿和文本的三维内容生成和编辑方法，发表在SIGGRAPH 2024，并被收录于ACM Transactions on Graphics。SketchDream允许用户通过简单的线稿和文本描述来生成和编辑高质量的三维模型，无需复杂的三维建模软件。该系统支持对真实模型的修改和编辑，提高了用户对三维内容创建的可控性。线稿和文本输入使得用户可以生成多样化和定制化的三维模型，具有广泛的应用前景，如AR/VR、工业设计和游戏影视等领域。
大模型进入「实用」时代，亚马逊云科技已是Next Level,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919669&idx=1&sn=e0f44bf6f4d6e6df2ab6d0cec31f45e0&chksm=84e4168bb3939f9d0a15faccad73a9e5fd490182d855f819659cd2aacf2722e87daa14c30d94#rd,2024-05-30 12:41:29,这篇文章主要介绍了亚马逊云科技在生成式AI领域的进展和优势。亚马逊云科技的平台Amazon Bedrock提供了来自多个顶尖大模型厂商的30个基础模型，包括最新的Claude 3，该模型在成本和性能上都有优势。Amazon Bedrock强调的是灵活性和一站式服务，允许用户根据业务需求选择和定制模型，还提供了模型评估、安全控制和网页版开发体验（Amazon Bedrock Studio）等功能，以简化大模型的使用和集成。此外，文章提到了亚马逊云科技与AI芯片供应商的合作以及其生成式AI技术栈的全面性，强调了满足企业用户定制化需求的重要性。
清华「天眸芯」登Nature封面：全球首款类脑互补视觉芯片,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919669&idx=2&sn=041fa1e399dd0091332f98562a545862&chksm=84e4168bb3939f9d55c14cff9f921265bf47b90a8154cb0f1db96ca2747aea911c508bc1f21e#rd,2024-05-30 12:41:29,清华大学精密仪器系类脑计算研究中心在《自然》杂志上发表了一项关于类脑视觉感知芯片的新研究，推出了世界上首款类脑互补视觉芯片“天眸芯”。该芯片基于视觉原语的互补双通路新范式，模仿人类视觉系统处理视觉信息，能在低带宽和功耗条件下实现高速、高精度、高动态范围的视觉信息采集。这一创新解决了传统视觉感知芯片在处理复杂和极端场景时的性能瓶颈问题，具有在自动驾驶和智能无人系统领域的广泛应用潜力。该研究是继2019年“天机芯”之后，国内在类脑计算和类脑感知领域的又一基础性突破。
腾讯大模型App元宝上线，我们用它「单挑」了下GPT-4o,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919669&idx=3&sn=50dde12704f972004ac42d633619a11f&chksm=84e4168bb3939f9db103d551b0606568db8a5c84e6e88b44580ebb36f3e67ab3065d973ff013#rd,2024-05-30 12:41:29,腾讯推出了基于混元大模型的App“腾讯元宝”，该App提供AI搜索、AI总结、AI写作等功能，旨在提高工作效率。腾讯元宝在AI搜索方面表现出色，能够整合信息并提供引用来源的答案。在文档总结的较量中，虽然腾讯元宝的答案涵盖了更多内容，但在处理腾讯2024年第一季度财报时出现数据错误，而GPT-4o的数据全部正确。在网页总结和AI作图的测试中，腾讯元宝也展现了其功能，但GPT-4o在某些情况下无法访问特定链接的内容。此外，腾讯元宝还提供76款智能体，涵盖工作、娱乐等多个领域，用户可以创建自定义智能体。
速度秒掉GPT-4o、22B击败Llama 3 70B，Mistral AI开放首个代码模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919669&idx=4&sn=acc3cf01f120d3f46f4ffe2aa489bbf1&chksm=84e4168bb3939f9d5f1245b3d5a39ff601c55d437c0a1db48f790810c63afce8132e43560556#rd,2024-05-30 12:41:29,法国AI独角兽Mistral AI发布了首个代码大模型Codestral，这是一个专为代码生成任务设计的开放式生成AI模型，精通多种编程语言，包括Python、Java等。Codestral的参数规模为22B，遵循Mistral AI Non-Production License，可供研究和测试，但禁止商业使用。模型在多样化数据集上训练，能进行代码编写、测试编写和代码补全，有助于提高开发效率和代码质量。 Codestral在代码生成性能上优于其他模型，如CodeLlama和DeepSeek Coder，在Python、SQL和其他编程语言上的评估中表现出色。此外，Codestral还支持中间填充机制，能在代码片段缺失的情况下补全代码。用户可以通过HuggingFace下载模型或免费试用。
3D资产生成领域福音：自动化所、北邮团队联合打造材质生成新范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919669&idx=5&sn=d2311d2f3111ad095dd05317edeaecb8&chksm=84e4168bb3939f9dcf11f0ccee4575c98029a50aa282492f109560cabd77f0c53b55ab070367#rd,2024-05-30 12:41:29,这篇论文摘要介绍了一项由中国科学院自动化研究所、北京邮电大学和香港理工大学等机构的研究团队进行的研究，旨在提高3D资产生成的质量，特别是在元宇宙、数字孪生和VR/AR应用中的3D物体材质表现。现有的方法通常基于SVBRDF来推断材质属性，但忽略了人类对物体材质的先验知识。为此，研究团队构建了首个2D材质分割数据集MIO，包含了多种物体和视角的像素级材质标签，用于利用2D语义先验在UV空间中推断3D资产的材质。他们提出了MaterialSeg3D方法，该方法结合MIO数据集，能够预测3D资产的材质并生成PBR材质贴图，提高了渲染的真实性和一致性。实验结果表明MaterialSeg3D在生成真实感的3D资产方面优于现有方法。未来的研究方向包括扩大数据集和改进材质分割模型。
和GPT-4这些大模型玩狼人杀，人类因太蠢被票死，真·反向图灵测试,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919560&idx=1&sn=e4ad55558b0c20f78ae6942815a77c3c&chksm=84e416f6b3939fe018a0e72d3d6884b71754917a8bfb8610841a7f6e09e7f60c33858287c5b1#rd,2024-05-29 12:53:50,这篇文章描述了一个有趣的实验，被称为“反向图灵测试”，其中四个先进的人工智能NPC与一个人类参与者一起参与了一场游戏，目标是识别出人类。这些NPC由大型语言模型驱动，分别代表了历史上的著名人物，如亚里士多德、莫扎特、列奥纳多·达·芬奇和克利奥帕特拉七世，而人类则扮演成吉思汗。在游戏过程中，NPC们展示了深度的历史知识和洞察力，而人类扮演者因缺乏严谨的思维和深入的洞察能力被识别出来。这个实验展示了AI在对话和模拟人类行为方面的进步，引发了人们对AI在游戏行业中潜在应用的讨论。开发者和玩家对AI NPC持积极态度，认为它们可以增加游戏的可玩性和真实感，但也存在如游戏状态同步、幻觉问题和角色知识管理等挑战，这些需要解决才能在3A大作中广泛采用。
填补AlphaFold3空白，字节跳动提出物理引导的方法让蛋白质动起来,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919560&idx=2&sn=1a781c9aa76134bffcf3090cf404c7c3&chksm=84e416f6b3939fe07da01ca8a10501da09e8d92fd0cccc07aac5d7e5bfc8a41ebabd855424ea#rd,2024-05-29 12:53:50,研究人员提出了一种名为CONFDIFF的物理信息引导的蛋白质构象生成扩散模型，该模型能够预测蛋白质的动态构象分布。传统方法和深度学习模型如AlphaFold3在预测动态构象方面存在局限，而CONFDIFF通过预测中间时刻的力场和能量来引导生成低能量、多样化的构象，使其分布更符合玻尔兹曼分布。这一方法在快速折叠蛋白质和牛胰蛋白酶抑制剂数据集上的实验表明，CONFDIFF能有效生成低能且服从真实分布的蛋白质构象，优于现有的结构预测模型。这一研究有助于深入理解蛋白质功能和药物设计。
快速入门大模型技术与应用，推荐你从Stable Diffusion开始学起,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919560&idx=3&sn=2699ec482340670a23fe2d5a5966ee38&chksm=84e416f6b3939fe07e40eb86611ac8500be6a0ec60fc6e8c131ad587fbbca15cb1dad11892df#rd,2024-05-29 12:53:50,这篇文章介绍了Stable Diffusion这一开源视觉模型的广泛应用和潜力，特别是在艺术创作、设计和科学研究中的作用。随着人工智能技术的发展，学习和使用Stable Diffusion成为了许多人的需求。为此，机器之心和Datawhale合作推出了一门专门的课程，旨在帮助学习者从基础原理到实践操作掌握Stable Diffusion，包括图片生成、编辑、模型微调等内容。课程适合对大模型感兴趣的技术和非技术从业者，通过学习，参与者可以提升工作效率，体验AI创造力，并解决具体行业问题。课程由两位在Stable Diffusion领域有经验的讲师授课，提供理论与实践相结合的教学。课程共有33节视频，售价129元，购买后可加入学习交流群并获得讲师答疑支持。
奥特曼挂帅新团队，OpenAI新一代大模型开训，前任高管却「投敌」了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919560&idx=4&sn=52073c6e82fb5d6fe2fa1480235c50eb&chksm=84e416f6b3939fe09eab3f66d2f5ab83239b60792cf9cd1f5139e71f8e5f4898cc5ec3943a06#rd,2024-05-29 12:53:50,OpenAI宣布成立新的安全与保障委员会，由董事会成员领导，以评估和加强其项目和运营的安全性，特别是在其开始训练下一个前沿模型之际。该委员会将负责在90天内审查开发流程和保障措施，并向董事会提出建议。前安全负责人Jan Leike离职后加入了竞争对手Anthropic，继续进行超级对齐研究。此外，前董事会成员Helen Toner在播客中透露了董事会在Twitter上得知ChatGPT发布的消息，质疑了前董事会对OpenAI的监督。现任董事会主席Bret Taylor回应，指出前任董事会的决定并非基于安全或财务担忧，并强调公司将继续前进。
ACL 2024 | 提升大模型持续学习性能，哈工大、度小满提出共享注意力框架SAPT,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919560&idx=5&sn=26453c945582d9a530682d6babd24676&chksm=84e416f6b3939fe0313aa9d3cb03839dd89ac33de4ee4f5c79f12d932848fb24c1129e847ec6#rd,2024-05-29 12:53:50,哈尔滨工业大学和度小满合作的研究团队提出了SAPT，一个共享注意力持续学习框架，用于解决大语言模型的灾难性遗忘和知识迁移问题。SAPT在ACL 2024上被接收，其设计包含共享注意力学习与选择模块（SALS）和注意力反思模块（ARM）。SALS通过共享注意力操作对学习和选择模块进行对齐，而ARM则通过生成伪样本帮助模型回忆旧任务的注意力权重，防止遗忘。实验结果显示，SAPT在处理灾难性遗忘和知识迁移方面表现出色，适用于不同规模和架构的模型。该方法未来将应用于度小满的轩辕大模型。
清华接手，YOLOv10问世：性能大幅提升，登上GitHub热榜,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919477&idx=1&sn=f0691dd61cfd57113470434011cf3517&chksm=84e4164bb3939f5dcacb2926ac5516eb758987a5860c1b3ff3ff0c0e40dea2bedb9bebfdf51c#rd,2024-05-28 12:36:40,清华大学研究人员推出了YOLO系列的最新版本YOLOv10，该目标检测框架在保持相同性能的情况下，延迟减少了46%，参数减少了25%。YOLOv10首次实现了无非极大值抑制（NMS）训练的一致双重分配，以提高性能和减少推理延迟。此外，通过提出轻量级分类头、空间通道解耦下采样和排序指导的块设计等方法，YOLOv10在效率和准确率上都得到了全面优化。在COCO数据集上，YOLOv10-S在类似AP下比RT-DETR-R18快1.8倍，同时减少了参数和FLOP。与YOLOv9-C相比，YOLOv10-B在性能相同的情况下延迟降低了46%，参数减少了25%。
清华、华为等提出iVideoGPT：专攻交互式世界模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919477&idx=2&sn=c4d8330cd87bca8470e4c2cab2caacaa&chksm=84e4164bb3939f5d3a4e6b12faee0f14c1da89b7418aff5630f161f873041bd168e9c61c8582#rd,2024-05-28 12:36:40,这篇文章介绍了一个名为iVideoGPT的新型生成模型，它旨在满足视频生成和交互式世界模型的需求。iVideoGPT是一个可扩展的自回归Transformer框架，能够整合视觉观察、动作和奖励等多模态信号，通过预测下一个Token实现智能体的交互体验。研究者使用压缩tokenization技术减少了视频序列长度，同时通过条件编码保持时间一致性。模型在大规模视频数据上预训练，以学习广泛的世界知识，并在下游任务中进行交互式预测。实验结果显示，iVideoGPT在动作条件预测和奖励预测方面表现出竞争力，同时具有良好的交互性和可扩展性。
AI智能体的炒作与现实：GPT-4都撑不起，现实任务成功率不到15%,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919477&idx=3&sn=aa0c22454c35a0e49de30df5fbd754f4&chksm=84e4164bb3939f5da160b69850c22f8b6868f2d3ede2664d8567bef303f81cd5ba669354a459#rd,2024-05-28 12:36:40,尽管大语言模型在性能和准确度上有所提升，但AI智能体的实际应用仍面临挑战。WebArena的基准测试显示，最好的AI智能体成功率也只有35.8%。目前的AI智能体在可靠性、性能、成本、法律问题和用户信任方面存在问题，如容易产生幻觉和不一致性，成本高，且可能需要对错误负责。一些初创公司和大型科技公司正在探索AI智能体，但大多数仍处于实验阶段。作者建议，近期应专注于利用AI增强现有工具，并采用人机协同的方法，设定现实的期望。AI智能体在自动化简单任务方面有潜力，但在复杂的自主任务上还有很长的路要走。
适应多形态多任务，最强开源机器人学习系统「八爪鱼」诞生,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919477&idx=4&sn=a376d01791b85fe830a2372cec063148&chksm=84e4164bb3939f5dfa26da11e1dc9185bf0e90ba44ee10824cc3ea4d5036c6a50d7a99819a4f#rd,2024-05-28 12:36:40,研究人员近日发布了开源机器人学习系统Octo模型，这是一个基于Transformer的模型，能够控制不同形态的机器人执行多样化任务，无需额外训练，具有很好的泛化能力。Octo模型通过将输入和任务转换为token，用Transformer进行处理，然后输出动作，可以适应不同传感器配置、动作空间和机器人形态。它在大型机器人操控数据集上进行预训练，并且可以微调以适应新任务和机器人，而无需大规模重新训练。 Octo是首个可有效微调并完全开源的通用机器人策略，为机器人学习领域的研究和应用提供了新的工具和资源。
不影响输出质量还能追踪溯源，「大模型无偏水印」入选ICLR 2024 Spotlight,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919477&idx=5&sn=8f9d7ccb7582fd3283b65a3166904bf5&chksm=84e4164bb3939f5d64abf5aea4d2d0b6ae039a524f46e42241d528029d42231595ff5021a824#rd,2024-05-28 12:36:40,马里兰大学、匹兹堡大学和滑铁卢大学的研究者提出了一种新的大语言模型（LLM）水印方法——无偏水印（Unbiased Watermark），该方法可以在不牺牲生成文本质量的前提下，实现对LLM输出内容的可靠追踪和溯源。传统的水印方法在内容溯源和质量保证之间存在矛盾，而无偏水印通过使用多个水印分布并确保含水印分布的期望值与原始分布相匹配，解决了这一问题。该方法包括无偏重赋权（Unbiased Reweight）和独立水印码（Independent Watermark Codes）两个关键组件，并提供了基于似然和无需似然的两种检测方法。实验表明，无偏水印在文本质量、鲁棒性和检测性能上均表现良好。该研究为LLM内容的管理和追踪提供了一种有效解决方案，但也需要注意其可能引发的伦理问题。相关论文已被ICLR 2024接收为Spotlight论文。
换了30多种方言，我们竟然没能考倒中国电信的语音大模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919383&idx=1&sn=6539211b60a7a206877c2be64d68ee01&chksm=84e415a9b3939cbf917ff6f89e6247f8dd68116162b086f0174169deb54d4f33f29ca7a7ab8b#rd,2024-05-27 12:19:31,中国电信人工智能研究院发布了首个支持30种方言自由混说的「星辰超多方言语音识别大模型」，能同时识别粤语、上海话、四川话、温州话等方言，是国内支持最多方言的语音识别模型。这一模型通过「蒸馏 + 膨胀」联合训练算法解决了大规模多场景数据集和大规模参数条件下的预训练坍缩问题，实现单一模型支持多种方言的语音识别。该模型已在智能客服系统中应用，提高了方言用户的服务体验，并有望在保护和传承方言文化方面发挥作用。
全球首台生物计算机开放服务：16个人脑类器官，能耗节省百万倍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919383&idx=2&sn=cc3142d972d2872245130eed6214fbcf&chksm=84e415a9b3939cbff403aefed51b745ca7e4b93bb16510d87a974f79684bb8db2c6281f3cdc5#rd,2024-05-27 12:19:31,瑞士初创公司FinalSpark发布了全球首款生物处理器，它由人脑类器官的生物神经元驱动，号称比传统数字处理器的功耗低一百万倍。FinalSpark的Neuroplatform是世界上第一个提供体外生物神经元访问的在线平台，旨在学习和处理信息，减少计算对环境的影响。该平台允许研究人员远程进行电生理实验，控制和监测神经类器官，寿命可达100天。FinalSpark已经向多个机构开放了远程访问权限，并计划与更多大学合作。虽然生物处理器在实验运用中存在寿命限制，但其低功耗特性可能成为未来芯片技术的一个优势。公司提供了一个专门的API，通过Python库进行远程研究和操作。
大模型时代的计算机视觉！CVPR 2024线上分享会全日程公布,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919383&idx=3&sn=76e26b3dfc0fe16c9cda003b6facddf8&chksm=84e415a9b3939cbfbad19ef5526e8cf8a5719e11dfbecf1268e604066e0837736e61617b4291#rd,2024-05-27 12:19:31,机器之心将于2024年6月1日组织「CVPR 2024 线上论文分享会」，为CV社区提供学术交流平台。今年的CVPR共收到11532篇论文，录用2719篇，录用率为23.6%。分享会将包括Keynote演讲和论文分享环节，涉及数字人建模、创作者与生成模型的合作、视觉生成技术、多模态大模型与具身智能等主题。Keynote嘉宾包括浙江大学的金小刚教授、CMU的朱俊彦助理教授、腾讯的芦清林博士以及北京航空航天大学的盛律副教授。会议将在机器之心和黄大年茶思屋平台直播。
CoT提出者Jason Wei：大模型评估基准的「七宗罪」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919383&idx=4&sn=9d9fcd1d9ddcf5a5e70dbfe334980e17&chksm=84e415a9b3939cbf46a5f0a44be5b7bc654c9c2dfb04cf7a0a2ae838fe8e566af4a1f152dce9#rd,2024-05-27 12:19:31,Jason Wei，思维链提出者，探讨了评估大模型（LLM）性能的标准和现有基准的局限性。他提到成功的评估基准，如GLUE/SuperGLUE、MMLU、GSM8K、MATH和HumanEval，并指出不成功的基准可能存在的七个问题，包括样本量不足、质量问题、复杂性、运行难度、任务相关性、评分准确性以及性能饱和速度。文章还建议评估工具应具有易于使用、高质量和意义重大的任务，并提出了关于测试集污染和命名的考虑。Wei建议，评估工具应随着LLM的发展而进化，以适应它们的多任务能力和长回答生成。
模块化重构LLaVA，替换组件只需添加1-2个文件，开源TinyLLaVA Factory来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919383&idx=5&sn=4542f24057170ee2499127075446197f&chksm=84e415a9b3939cbfa8fdc3171ff707afa4d6ab4ecffd0427709cf4887ce7ffc3227a313ac2a6#rd,2024-05-27 12:19:31,这篇文章介绍了清华大学和北京航空航天大学联合开发的TinyLLaVA Factory，这是一个开源的代码库，旨在支持定制、训练和评估多模态大模型。TinyLLaVA Factory基于LLaVA项目重构，强调代码可读性、扩展性和实验可复现性，使得研究者和开发者更容易探索多模态大模型。该项目提供了简化的数据预处理、模型组件模块化以及评估工具，支持用户轻松替换语言模型、视觉编码器和连接器组件。此外，TinyLLaVA Factory还包括示例教程，帮助用户定制自己的多模态大模型。该代码库和相关模型已在GitHub和Hugging Face上开源。
全面超越DPO：陈丹琦团队提出简单偏好优化SimPO，还炼出最强8B开源模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919310&idx=1&sn=9ab3ae94974892f9d769af47aa7bcb51&chksm=84e415f0b3939ce6ebdffae30d59da982210000a5d997bca2169037184be5b267934fe0cfc82#rd,2024-05-26 12:29:01,研究人员提出了一个新的离线偏好优化算法SimPO，它简化了大型语言模型（LLM）的训练过程，使其更加简单和高效。SimPO通过直接对齐奖励函数和生成指标，解决了直接偏好优化（DPO）中训练和推理之间的差异问题，从而提升了模型的性能。与依赖参考模型的方法相比，SimPO更轻量且在多个基准测试中展现出优越的性能，同时减少了响应长度的过度利用。该算法的贡献在于其简单的设计和对偏好数据的更有效利用，有助于在训练LLM时更好地学习人类的价值和意图。
英伟达赢麻了！马斯克xAI超级算力工厂曝光，10万块H100、数十亿美元,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919310&idx=2&sn=4c019af3609ad3efd92f0a70d8a37519&chksm=84e415f0b3939ce66f41b9d6fd0d577082eb3b1fc5f8d53f4d2afb3683e2355ace5904702256#rd,2024-05-26 12:29:01,马斯克的人工智能初创公司xAI计划建造一个名为“Gigafactory of Compute”的超级计算机，该计算机将使用10万块H100专用GPU，规模是目前最大AI集群的四倍。这台超级计算机旨在为AI聊天机器人Grok的下一个版本提供算力支持，减少语音限制。xAI可能会与甲骨文公司合作建造该超级计算机，目前已经成为甲骨文最大的H100服务器芯片租赁客户。马斯克的目标是在2025年秋季前让超级计算机运行起来。该计划表明马斯克在大语言模型领域的巨大投入，同时也将有助于xAI追赶OpenAI和微软等竞争对手。
离散化、对齐文本还是预训练，哪个才是 LLM 处理时序数据的关键？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919310&idx=3&sn=0c86f359ad39fbfb00b8f6ae2c71ca5f&chksm=84e415f0b3939ce666a954da3465f1f75d78a01f78ed9a6e3c9fa70557f1939cb1d38e3ec96a#rd,2024-05-26 12:29:01,这篇文章是机器之心Pro的会员通讯，主要涵盖了三个AI和Robotics领域的重点话题。首先，文章讨论了大型语言模型（LLM）处理时序数据的方法，包括离散化、对齐文本和预训练，指出时序数据处理在ICML 2024上的热度上升，并分析了大模型在此类任务中的挑战。其次，文章探讨了大模型价格下降的现象，分析了不同厂商的价格策略、对企业用户成本的实际影响以及可能存在的问题。最后，提到了 Gemini 1.5 Pro 技术报告的亮点和值得关注的技术细节。通讯还包含了本周AI和Robotics领域的28项重要事件概览。
ICML 2024 | 脱离LoRA架构，训练参数大幅减少，新型傅立叶微调来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919310&idx=4&sn=0e62f46eeeafca1e2689502e180dccd4&chksm=84e415f0b3939ce6cd31f9d6d5c8808a6d462d1cae17a10315d73d88789008d9b9bcf6feedcf#rd,2024-05-26 12:29:01,这篇摘要介绍了香港科技大学（广州）的研究团队在ICML 2024上发表的论文「Parameter-Efficient Fine-Tuning with Discrete Fourier Transform」，该研究提出了一种名为傅立叶微调（FourierFT）的新方法，用于高效微调大型预训练模型。传统微调方法在面对大规模模型和多样化的下游任务时，计算和存储成本过高。论文中，研究人员利用傅立叶变换将模型权重增量表示为稀疏的频域信号，大幅减少了可训练参数，且在自然语言理解、自然语言生成和图像分类等任务上取得了与LoRA相当或更好的性能，参数量仅为LoRA的千分之一到十分之一。这种方法不仅降低了资源消耗，还展示了傅立叶变换在机器学习领域的潜力。论文和相关代码已开源。
ChatGPT如何「思考」？心理学和神经科学破解AI大模型，Nature发文,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919310&idx=5&sn=2e0d143711f1b5f59d37defb847f178a&chksm=84e415f0b3939ce6574c64c5e33e5b1b212b1e7a70d35f3cca0a7bd81d23afb05d0c1d394685#rd,2024-05-26 12:29:01,"研究人员正在努力解释人工智能（AI）特别是大型语言模型（LLM）的内部运作方式，因为这些系统在做出决策时可能变得难以理解。AI的黑盒性质使得追踪其决策过程极具挑战性，尤其是在涉及复杂的神经网络时。为解决这一问题，可解释人工智能（XAI）领域正在发展，以帮助理解和验证AI的行为。

大型语言模型如ChatGPT在各种任务中被广泛应用，但它们可能会产生错误信息、延续社会刻板印象，并可能泄露私人信息。因此，XAI工具的开发对于确保AI的安全性、准确性和可靠性至关重要。这些工具包括突出显示图像中的关键特征、构建简单的决策树以及使用特定技术来揭示AI如何利用其训练数据。

研究人员发现，尽管LLM可能表现出类人推理能力，但它们的行为也可能不稳定。通过让模型自我解释或使用“思维链提示”来展示其决策过程，研究人员正在逐渐揭示其工作原理。然而，这些解释并不总是准确的，模型可能会编造逻辑，就像人类有时会无意识地做的一样。

一些研究方法借鉴了神经科学的技巧，如通过观察和编辑模型的内部激活来理解其行为。例如，通过调整特定参数，可以编辑模型的知识，而不会影响整个模型的训练。此外，通过研究单个神经元的行为，研究人员发现这些模型的复杂性可能嵌套在多任务神经元中，每个神经元对多种概念都有反应。

尽管目前的进展令人鼓舞，但解释大型语言模型的全部功能仍然是一个挑战。研究人员呼吁AI公司提供更多的透明度，并确保XAI研究继续发展，以确保这些技术的安全和负责任的使用。"
披萨上涂胶水、建议用户吃石头、毒蘑菇……谷歌又被大模型带沟里,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919194&idx=1&sn=99c252d21b89648022b6aba280ee22fa&chksm=84e41564b3939c726cb462391cfda61d0e6a3b2903f26cb8f7efa7b4a7f697ba39417a76ee3a#rd,2024-05-25 13:32:41,谷歌的AI Overview功能近期引发争议，该功能在搜索结果中提供AI生成的答案，但被发现给出了许多不准确甚至有害的建议，如建议在披萨上涂胶水、吃石头等。这些离谱的回答在社交媒体上发酵，导致一些用户质疑谷歌AI的质量和可靠性。谷歌已开始手动禁用某些搜索的AI Overview功能，以修复和优化问题。此前，谷歌宣布AI Overview是其搜索引擎25年来最大的更新之一，旨在提供人工智能生成的答案以增强搜索体验。然而，这一事件暴露了大型语言模型在处理特定查询时可能出现的错误和误导性回答，促使谷歌采取紧急措施进行改进。
Bengio等人新作：注意力可被视为RNN，新模型媲美Transformer，但超级省内存,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919194&idx=2&sn=e305b94dc2f62184f4f8e427d17aaf77&chksm=84e41564b3939c72cd3f848337bb77fb89696b04c0225c1cb9605d907efa3deea4efd2db1091#rd,2024-05-25 13:32:41,研究者提出了一种名为Aaren的新模型，它解决了Transformer在处理长上下文时的内存和计算效率问题。Transformer虽然在并行训练中表现出色，但在推理时由于内存需求随token数量线性增长，限制了其在资源有限的环境中的应用。Aaren通过将注意力机制视为一种特殊的循环神经网络（RNN），并引入基于并行前缀扫描算法的多对多RNN计算方法，实现了高效更新。该模型在保持与Transformer相当的性能的同时，能够在时间和内存方面提供更高的效率，适用于长上下文的序列建模任务。
只需单卡RTX 3090，低比特量化训练就能实现LLaMA-3 8B全参微调,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919194&idx=3&sn=682dbe50c73713532c691f2a06aa6aaa&chksm=84e41564b3939c72814a052f2f28b505ae78cb0a04822e4ba8d6c59012ba99925cdaf60a569d#rd,2024-05-25 13:32:41,本文介绍了GreenBit.AI团队在开源大模型和低比特量化技术方面的工作，强调了开源模型在降低使用门槛和成本方面的重要性。随着大语言模型如ChatGPT的推出，生成式AI成为推动产业革新的关键，但高昂的商业化成本是一个挑战。开源模型通过提供性价比更高的解决方案，促进了技术的普及和快速发展。团队通过神经架构搜索（NAS）和量化技术，为社区贡献了超过200个从开源大模型压缩而来的低比特量化模型，覆盖了从110B到0.5B的不同规模，并优化了本地部署，使得模型能在消费级GPU上运行。此外，团队还开发了Bitorch Engine和green-bit-llm工具，支持低比特模型的高性能推理和全参数微调。这些工具和模型库的开源，旨在解决本地部署的资源限制问题，降低模型开发和部署成本，加速AI技术的商业化进程。
用基础模型指导特征传播，首个泛化型图像匹配器OmniGlue搞定未见过域,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919194&idx=4&sn=7a4d2976e8f4b64d042ffe819877c500&chksm=84e41564b3939c727997377885590bd8037469d98dd77170801f19b9a958916a33f52bcd5d40#rd,2024-05-25 13:32:41,德克萨斯大学奥斯汀分校和谷歌研究院的研究者提出了一种名为OmniGlue的新型可学习图像匹配器，这是第一个以泛化能力为核心设计原则的图像匹配器。传统的图像匹配模型在处理未见过的领域数据时性能会大幅下降，而OmniGlue通过引入基础模型指导和关键点位置注意力指导来提高匹配层的泛化性能。该方法在多种视觉领域上展示了出色的泛化能力，同时保持了在源领域内的高性能。实验表明，OmniGlue在多个数据集和任务上优于现有的可学习匹配器，尤其是在领域外数据上的表现。
可控核聚变新里程碑，AI首次实现双托卡马克3D场全自动优化，登Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919194&idx=5&sn=0d8c66b25f9b914f04507b6eb0fbbea5&chksm=84e41564b3939c728cb227f519249caad04657d26adf454298fe61b64099effa1bfe72c13a18#rd,2024-05-25 13:32:41,普林斯顿等离子体物理实验室（PPPL）的科学家正在利用人工智能（AI）来解决核聚变反应中的挑战，目标是通过聚变等离子体产生清洁、可靠的能源。研究团队使用机器学习来分析数据、推断特征关系，并优化反应控制，包括改进超热等离子体容器设计、优化加热方法和保持反应稳定。最近，他们使用机器学习成功避免了磁扰动对聚变等离子体稳定性的破坏，这一成果在两个不同的托卡马克装置上得到验证。通过实时利用边缘爆发的滞后来增强等离子体约束，同时扩展AI在核聚变技术中的应用，研究团队提高了聚变性能，并接近实现无边缘爆发操作，这对于未来反应堆的经济性和安全性至关重要。这一进展为国际热核聚变实验反应堆（ITER）等未来设备铺平了道路。
李飞飞亲自撰文：大模型不存在主观感觉能力，多少亿参数都不行,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919048&idx=1&sn=b06026bfd9935f979daaa8261d2f52dd&chksm=84e414f6b3939de0da3831a8c579fec16e623b52da721d2e8ad909f69af7313dba31992ca5b6#rd,2024-05-24 12:42:35,李飞飞和John Etchemendy教授撰文讨论AI是否具有感觉能力，他们认为大型语言模型（LLMs）并不具备感觉能力。尽管LLMs可以生成与人类类似的输出，如表达“我饿了”，但它们缺乏与这些感觉相关的生理状态和主观经验。李飞飞指出，人类的智能包括感觉，而LLMs只是数学模型，没有物理身体，无法体验饥饿、疼痛等感觉。他们强调，感觉是生物系统中产生的，目前的人工智能系统尚未实现这一点。文章反驳了基于LLMs能报告主观经验而认为其有感觉的论点，并指出要实现有感觉的人工智能，需要更好地理解生物系统的感觉产生机制。
通用世界模型问世：不学习就能生成新领域视频，可实时控制,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919048&idx=2&sn=78625e932632b74f8dec61aafd54bb8b&chksm=84e414f6b3939de04b3fec9da45996487a7efede747e1fdcd3d942557a28dd5519cc30a19e87#rd,2024-05-24 12:42:35,研究人员推出名为Pandora的通用世界模型，该模型能够通过自然语言命令实时操控并在视觉空间中进行推理。Pandora是一种混合自回归扩散模型，可以生成视频来模拟世界状态，并允许通过自由文本动作进行实时控制。通过预训练的大型语言模型和视频模型的集成，Pandora避免了从头训练的成本，展现出在不同领域（室内/室外、自然/城市等）的广泛输出能力。通过更大规模的训练，研究人员认为可以构建更强大的通用世界模型，这一进展对于交互式内容生成和增强推理能力具有重要意义。
2024「人工智能 +」标杆示范征集正式开启，7 月巅峰相见！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919048&idx=3&sn=ffaa61324b0d57a065347eddbb51b1e8&chksm=84e414f6b3939de068de7d7ae21bf2b527ca8d8541666ea4200a13fc53075f77209b46a8acc1#rd,2024-05-24 12:42:35,"为了推动人工智能行业的发展，机器之心发起了2024 ""人工智能 +"" 标杆示范征集活动。响应国务院对深化大数据和人工智能应用的号召，此次活动旨在寻找和展示具有市场竞争力和技术实力的AI产品、创新案例和隐形冠军企业。征集分为三个类别：产品标杆、创新案例标杆和隐形冠军企业标杆，共计划选出Top 20产品和Top 20案例，以及Top 10隐形冠军企业。参与机构可从5月17日至6月7日进行报名，评审结果将于7月在世界人工智能大会的 ""人工智能 +"" 论坛上公布并颁奖。入选标杆将获得权威认证、资源对接、媒体曝光等多重优势。报名可通过指定链接或联系机器之心工作人员进行。"
从80个模型中构建Scaling Law：华人博士生新作，思维链提出者力荐,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919048&idx=4&sn=7a2966b882bf11c1bce687a541712741&chksm=84e414f6b3939de0fcf8797efce7f42630af0bc1f20692b8a51e0d0d6cea070ea34a9a4dd30f#rd,2024-05-24 12:42:35,研究人员提出了一种新的方法，称为可观察的扩展定律（Observational Scaling Laws），用于理解语言模型（LM）的性能如何随规模变化，而无需从头开始构建扩展法则。这一方法利用大约 80 个公开可用的模型，建立起 LM 功能与下游性能之间的关系，绕过了模型训练的计算资源限制。研究发现，LM 的性能可以表示为低维度能力空间的函数，不同模型系列在将训练计算转换为能力的效率上有所差异。通过这种方法，研究者能够预测模型的涌现能力、智能体性能和后训练干预措施的效果，例如思维链（Chain-of-Thought）。这种方法成本低且预测准确，有助于扩展研究，并预注册了对未来模型的预测以验证其有效性。
腾讯PCG自研高性能大语言模型推理引擎「一念LLM」正式开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919048&idx=5&sn=700ee1366fe81a00a98af598cf4d37ef&chksm=84e414f6b3939de076dbaef4912731665a34977f3ddf9efea43449837f39c3a8689d43079d65#rd,2024-05-24 12:42:35,一念LLM是腾讯PCG机器学习平台中心自研的高性能大语言模型推理引擎，旨在解决大语言模型推理成本高的问题。相比其他著名开源框架如vLLM和TensorRT-LLM，一念LLM在相同精度下推理单价降低20%+，并且首次同时支持Nvidia GPU和华为NPU，以应对硬件供应问题。该框架通过显存优化、异步调度和计算复用技术提高性能，并已在QQ智能体等业务场景上线。一念LLM的开源代码可在github上获取。
OpenAI、微软、智谱AI等全球16家公司共同签署前沿人工智能安全承诺,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919007&idx=1&sn=5a11e2ccca0080d92fcf4e9efa8d92c2&chksm=84e41421b3939d37306bb5437e5cb96ba5ab1062731b616a3a4d74f8104e2bbe5fa99071cd94#rd,2024-05-23 21:00:00,这篇文章主要关注了人工智能（AI）安全问题的紧迫性，包括OpenAI的两位重要成员离职，他们认为OpenAI忽视了安全问题。图灵奖得主和其他专家在Science杂志上发文警告AI无节制发展可能带来的严重后果。文章提到了全球首部AI全面监管法规——欧盟的《人工智能法案》的批准，以及OpenAI、谷歌、微软和智谱AI等公司签署的前沿人工智能安全承诺，旨在确保AI的负责任治理和透明度。此外，智谱AI分享了它们在AI安全方面的具体做法，包括超级对齐技术，以提高大模型的安全性。这些动态表明，AI安全已成为全球关注的焦点，相关公司和政府正在采取行动以确保AI的健康发展。
世界模型也扩散！训练出的智能体竟然不错,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919007&idx=2&sn=f7c10b721768bfee21f83a6daf3716cb&chksm=84e41421b3939d371b33468fd204d625d38781d9661089810163359f377bdf8249f1125d971e#rd,2024-05-23 21:00:00,来自日内瓦大学、爱丁堡大学和微软研究院的研究者提出了一种名为DIAMOND（DIffusion As a Model Of eNvironment Dreams）的新方法，它使用扩散模型来训练强化学习智能体。在Atari 100k基准测试中，DIAMOND获得了1.46的平均人类归一化得分，表现与在世界模型中训练的智能体的SOTA水平相当。这种方法利用扩散模型在处理视觉细节方面的优势，允许智能体在图像空间中操作，提高了对关键视觉细节的建模能力。实验结果表明，DIAMOND在需要捕捉细节的游戏中表现出色。
WAIC · 云帆奖五周年：AI 青年，执掌未来十年的钥匙,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919007&idx=3&sn=6fc1f182202eea6ee88f19ef4bdd5912&chksm=84e41421b3939d372847504831e6191749464ecf071ff1b65cd86201638eadace78ea00595a1#rd,2024-05-23 21:00:00,WAIC·云帆奖是一项表彰在人工智能领域做出杰出贡献的青年人才的奖项，旨在推动AI技术的发展和创新。该奖项由多个机构联合评选和运营，今年以“超越与联结”为主题，继续发掘和表彰AI领域的先锋人物。历届获奖者在AI的不同领域展现出才华，有的在尖端技术上取得突破，有的推动技术应用到实际生活中。2024年WAIC·云帆奖的征集即将结束，活动还包括五周年嘉年华，将汇聚获奖者、科学家、商业领袖和投资人等，促进全球人工智能领域的交流与合作。
时隔一天，百川大模型拿下国产第一，AI助手「百小应」上线,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919007&idx=4&sn=2b134dd485fa183281d49b50212430df&chksm=84e41421b3939d37ae857bc5a77937a13cc4504ece9f0b93269fa6c6a47240c4bfcf7de1c65e#rd,2024-05-23 21:00:00,国内AI创业公司百川智能发布了最新一代基座大模型Baichuan 4和AI助手“百小应”。Baichuan 4在SuperCLUE评测中排名国内第一，各项能力相比前代有显著提升，特别是在通用、数学和代码能力上。新模型还引入了多模态能力，超越了其他多模态模型。百小应结合大模型的通用能力和搜索技术，能够进行多轮搜索、定向搜索，提供精准的问答和信息整理服务。此外，百川智能推出了MaaS+AaaS服务，并提供1000万免费token和Assistants API的免费试用。百川智能强调，大模型的核心是语言智能，未来将注重模型的自洽性和推理能力的提升。
具身智能体三维感知新链条，TeleAI &上海AI Lab提出多视角融合具身模型「SAM-E」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919007&idx=5&sn=ad6c88df7e174a2b98f5b69099ef45a6&chksm=84e41421b3939d374e503f412d2c260316aa263fd7eba25df52596c55eb10dd8c1d9a13fe4a5#rd,2024-05-23 21:00:00,中国电信人工智能研究院李学龙教授团队与上海人工智能实验室、清华大学等单位合作，提出了一种名为SAM-E的通用具身操作算法，该算法受到人类“感知-记忆-思维-想象”认知过程的启发。SAM-E利用视觉分割模型Segment Anything (SAM)的强大功能，结合多视角Transformer，理解和预测三维操作空间。该方法能够帮助机器人理解自然语言指令，进行长期规划和高效执行复杂任务。这项工作被ICML 2024录用，为构建通用三维具身策略奠定了基础。通过实验，SAM-E在机械臂操作任务中表现出高成功率和执行效率。
大模型与具身智能的火花，ICML 2024 MFM-EAI Workshop征稿和挑战赛启动,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650919007&idx=6&sn=4850c947aa237b41b03190c83ddc717b&chksm=84e41421b3939d374e627d7ece8430ac193e777abbe5e0755065dd738d4dcd629d71eb245b19#rd,2024-05-23 21:00:00,这篇文文章介绍了即将举行的多模态基础模型与具身智能（MFM-EAI）Workshop，这是一个关注于MFM（如CLIP和DALL・E 3）在人工智能和具身智能应用的论坛。工作坊将探讨MFM的泛化能力、在具身智能中的应用、世界模型、决策制定和评估标准等主题，并通过OpenReview平台进行双盲审稿的论文征集。此外，文章还提到了三个相关挑战赛，包括EgoPlan、Composable Generalization Agent和World Model挑战，旨在评估MFM在任务规划、执行和场景泛化等方面的能力。每个挑战都有具体的报名方式和奖励设置。工坊的组织者和联系方式也在文中给出。
微软颠覆生产力：Copilot推自定义版，AI PC原生支持PyTorch，奥特曼预告新模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918734&idx=1&sn=57295e8a0d344a50bcd336daf7b6fa10&chksm=84e40b30b39382268abc06527b0ede8b5cc33991f91fdb6a5e6b8b7fbd72ddc1d82bb9a1e6ca#rd,2024-05-22 04:39:07,在微软Build 2024开发者大会上，微软宣布了新一代的AI技术与工具，重点介绍了Copilot在PC和团队协作中的新应用。微软将在6月18日推出首批搭载高通Snapdragon X系列处理器的AI PC，这些设备将提供强大的AI性能，通过Windows Copilot Runtime对系统进行深度集成。此外，Windows 11将原生支持PyTorch和Web神经网络，提升开发人员在Windows上的AI开发体验。在团队协作方面，GitHub Copilot扩展了新功能，可以定制集成Azure等服务，并推出了Team Copilot，将AI助手引入团队协作，提高效率和创造力。微软还介绍了新的人工智能小模型 Phi-3系列，包括多模态模型Phi-3-vision，以及与OpenAI合作的最新进展。这些更新表明微软正在通过AI技术革新其操作系统和生产力工具。
Hinton万字访谈：用更大模型「预测下一个词」值得全力以赴,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918734&idx=2&sn=7ae3324bfcbd93bd242d4f2dc49366e4&chksm=84e40b30b3938226c7d3e2c6c5756ca70a7c668de981b7efad93a92e7e8685e2374dc99f8fa1#rd,2024-05-22 04:39:07,图灵奖得主 Geoffrey Hinton 在最近的访谈中讨论了大型语言模型的重要性，他认为大模型通过学习不同领域的共同结构，能够压缩信息并形成深层次的理解，展现出创造力。Hinton 还提到，模型通过预测下一个符号实际上执行了推理，随着模型规模的增加，推理能力将增强。此外，他还分享了与学生 Ilya Sutskever 的合作经历，Ilya 对大模型规模扩展的直觉最终被证明是正确的。Hinton 对多模态学习表达了乐观态度，认为它能够帮助模型更好地理解空间事物，提升推理能力。他还讨论了人类大脑与语言的关系，认为大脑利用符号与向量的结合进行理解。关于未来，Hinton 认为需要探索快速权重的概念，以模拟大脑中更复杂的认知过程。
从Claude 3中提取数百万特征，首次详细理解大模型的「思维」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918734&idx=3&sn=6d288f856987e575955658f07a3d030e&chksm=84e40b30b393822622ef4fdee3691584b9402f1d38204719ca2b0d4044162d29c48a3e59aae5#rd,2024-05-22 04:39:07,人工智能公司 Anthropic 在理解大型语言模型内部运作机制上取得重大突破，成功在模型 Claude Sonnet 中表征了数百万个概念，这是对现代生产级语言模型的首次详细理解。这一进展将有助于提高 AI 模型的安全性。当前 AI 模型被视为黑匣子，其决策过程难以解释，而 Anthropic 的研究通过一种称为“字典学习”的方法，分离出神经元激活模式，揭示了模型如何表征各种概念。研究人员在 Claude 3.0 Sonnet 中发现的特征涵盖了抽象概念、科学主题、情感等，甚至可以影响模型的输出。这些特征还可被操纵，改变了模型的行为，显示了它们在模型内部世界表征中的作用。这一成果对于确保 AI 安全性和可靠性具有重要意义，但目前仅揭示了模型学到的少量概念，进一步研究仍需大量工作。
简单通用：视觉基础网络最高3倍无损训练加速，清华EfficientTrain++入选TPAMI 2024,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918734&idx=4&sn=d6540b80257762d40b5a3386ad480b0d&chksm=84e40b30b3938226ca16911fcf19410e025d03f03c9a2d9ea3e351a3b7ba4e92615c03fc81f5#rd,2024-05-22 04:39:07,清华大学研究团队提出了一种名为EfficientTrain++的广义课程学习算法，旨在解决大规模深度学习模型训练的高成本问题。该算法不筛选数据，而是逐步揭示每个数据样本的难易特征或模式，实现视觉基础网络训练的加速，同时保证模型性能不受影响。EfficientTrain++可以即插即用，适用于不同的训练数据规模、学习方法和网络结构，且在实际应用中考虑了CPU/HDD效率和大规模并行训练的优化。实验结果显示，EfficientTrain++能实现1.5-3.0倍的训练加速，且在ImageNet-1K和ImageNet-22K数据集上均有良好表现，同时对较小模型还能提升性能。论文已发表在IEEE Transactions on Pattern Analysis and Machine Intelligence，代码和预训练模型已开源。
弥补中文短板，社区Llama3汉化微调版效果如何？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918734&idx=5&sn=1e7db94a6488100a246b916efa325e71&chksm=84e40b30b3938226aba2c5855cabbddcaf347416f8bc0bd79b13afbcb40711471448cfcde800#rd,2024-05-22 04:39:07,开源社区对Llama3进行了中文优化的微调，推出了多个模型，如Chinese-LLaMA-Alpaca-3的v1和v2版本，Llama3-ChineseSFT，DPO版本和LLama3-Chinese-Chat。这些模型通过不同方法增强了Llama3的中文处理能力，包括使用中文语料、增量训练和指令数据精调。从5月20日至5月24日，这些模型将在一个在线平台上开放，供用户测试其在不同场景下的性能，如常识推理、代码助手和物理公式证明。参与实测的用户可以了解中文汉化Llama3的性能，探讨模型能力、开发工具链生态和应用开发情况。此外，还安排了项目发起人的分享会，讨论使用DPO微调Llama3的实践。用户可以加入实测社群和预约直播，参与讨论和测试。
微软颠覆PC形态，Copilot+PC搭载GPT-4o，8688元起售,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918609&idx=1&sn=0aac6b716e73777fff25963b204348c1&chksm=84e40aafb39383b9c41abce9bf69abf885a99fd53ba4ad7f7e9e22cf2347dfe5b2d141044e64#rd,2024-05-21 12:06:19,微软发布了专为AI设计的新型Windows PC，名为Copilot+ PC，这是Windows平台几十年来最重大的变化。新设备拥有强大的AI算力，可实现40+ TOPS，具有实时交互能力，如实时字幕翻译、AI图像生成和优化等功能。每台Copilot+ PC都配备了一个AI Agent，用户可以通过新的Copilot按键与之交互。新设备还将支持OpenAI的最新模型，如GPT-4o，提供更自然的语音对话体验。微软宣布与多个合作伙伴，包括Adobe、DaVinci Resolve Studio等，共同打造多样化创意AI体验。Copilot+ PC将于6月18日起开始供应，起售价为999美元。
中国大模型头名易主：全球盲测榜单上，Yi-Large与GPT-4o中文并列第一,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918609&idx=2&sn=12b270160c82a3dfaf4da544ff53cd29&chksm=84e40aafb39383b93de556e63a156dc2e15ca87bce3a072de5218744d26781828dbb3686dc4b#rd,2024-05-21 12:06:19,"这篇文章的摘要可以是：

在大模型竞技场Chatbot Arena中，中国公司零一万物的千亿参数模型Yi-Large表现出色，总榜排名世界第7，成为中国第一，并在中文分榜上与GPT-4o并列第一。这一竞技场已成为国际大厂如OpenAI、Google等比拼的平台，采用真实用户盲测投票，以Elo评分系统保证公正性。Yi-Large在编程能力、长提问及艰难提示词等高难度评测中也有突出表现，展现了其在大模型领域的竞争力。Chatbot Arena的评测方式强调真实用户反馈和公平性，成为行业基准和风向标。"
CCF-阿里妈妈科技袋基金正式发布，第一期聚焦大模型方向,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918609&idx=3&sn=1433466a025f16fe90ec8c4794376fa9&chksm=84e40aafb39383b9e7f722fcd490bb50164f247846f198bd145051ea33777019b46eac6804eb#rd,2024-05-21 12:06:19,"在2024年5月18日的YEF 2024活动中，中国计算机学会（CCF）与阿里妈妈共同推出了“CCF - 阿里妈妈科技袋基金”。该基金旨在促进全球高校学者与产业界之间的合作，加强交流，特别是在人工智能领域的算法、模型和技术研发。基金的设立将支持新一代人工智能技术的研究，并期望将创新成果应用于社会和企业，推动科技进步。

CCF秘书长唐卫清强调了产学合作的重要性，并表示已有超过一千个项目通过CCF产学合作基金获得资助。淘天集团技术副总裁、阿里妈妈CTO郑波提到，大模型和多模态技术是当前的研究热点，科技袋基金将促进工业界和学术界的协作，以应对新的技术革命挑战。

科技袋基金第一期将专注于大模型领域，设立4个方向的10个研究课题，包括电商搜索、推荐系统、工具评价与任务规划以及电商内容风控应用等方面。每个课题将获得30万元人民币的资助，并提供学生实习机会。申请截止日期为2024年6月18日。"
寡姐怒了，GPT-4o系统配音强行模仿，OpenAI回应删除,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918609&idx=4&sn=6dc38c95144933e9d1f08a5d576eb6a6&chksm=84e40aafb39383b9998b1f07e9e4db88f183b98337e16c3d53bddd09dabc2fc734a99046af4f#rd,2024-05-21 12:06:19,OpenAI宣布将删除ChatGPT中一个被质疑模仿演员斯嘉丽·约翰逊声音的选项。在用户发现ChatGPT新模型GPT-4的语音交互功能中，一个名为Sky的配音与斯嘉丽·约翰逊的声音相似后，OpenAI决定暂停使用该声音。尽管OpenAI表示Sky的声音并非模仿名人，而是属于另一位专业女演员，但为了避免混淆和保护配音员隐私，他们选择移除这个声音。此前，OpenAI的CEO Sam Altman曾在社交平台暗示ChatGPT实现了电影《Her》中的场景，该电影讲述了一个男人与人工智能系统之间的爱情故事，斯嘉丽·约翰逊在电影中为人工智能配音。据称，斯嘉丽·约翰逊曾拒绝为ChatGPT配音，并对此次事件表达了震惊和愤怒，已聘请法律顾问与OpenAI沟通解决。
李飞飞「空间智能」系列新进展，吴佳俊团队新「BVS」套件评估计算机视觉模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918609&idx=5&sn=fdf369e46b508a9591c1f7fc1922ed24&chksm=84e40aafb39383b9be2616a06681b8ab6b79761cb0c7f3385f888a8def916a6706dc94bb8c73#rd,2024-05-21 12:06:19,研究人员发布了BEHAVIOR Vision Suite（BVS），这是一个为评估计算机视觉模型设计的工具和资源集合。BVS基于BEHAVIOR-1K基准，提供大量可调参数，覆盖场景、物体和相机级别的变化，以进行精确的控制实验。这个数据集包括8841个3D物体模型和1000个室内场景实例，具有丰富的语义类别和真实的物理属性。BVS可以用于评估模型在环境参数变化时的鲁棒性、系统评估场景理解模型以及训练新视觉任务模型。它还提供了全面的标注，如深度、语义分割和目标边界框，以促进多任务预测模型的发展。通过BVS生成的数据，研究人员能够发现现有模型在某些条件下的性能限制，并为改进模型提供依据。
大模型进入「实用」时代！腾讯助力「销冠」量产，5 分钟创建智能助手,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918471&idx=1&sn=602562fe9df87cad8aec6ca43a44f075&chksm=84e40a39b393832f0225577d45a9b0130ca4f868ea7653d4ad471fd4222f40da4c4c1149000b#rd,2024-05-20 12:35:41,腾讯云发布了多个基于大模型的产业应用产品，如一站式AI智能体创作与分发开放平台“腾讯元器”、大模型知识引擎、图像创作引擎和视频创作引擎等。这些平台降低了使用大模型的门槛，使得一线业务人员无需深入技术细节也能利用大模型解决实际问题。例如，知识引擎能让企业快速开发知识服务应用，5分钟内即可搭建，提高业务效率。此外，腾讯混元大模型的能力也得到提升，部分中文能力已追平GPT-4，支持16秒视频生成。这些产品体现了腾讯云“产业实用”的大模型战略，旨在简化应用实践，降低使用成本，推动大模型在产业中的实际应用。
Karpathy称赞，从零实现LLaMa3项目爆火，半天1.5k star,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918471&idx=2&sn=94f9f18ec841bcecbe478d09532abb82&chksm=84e40a39b393832fd24255cde7b7b9ee2e76a4556b5d5d1e5f352df00a1eaeec0890abeb8102#rd,2024-05-20 12:35:41,本文介绍了GitHub上一位名为“Nishant Aklecha”的开发者从零开始实现Llama3大模型的项目，该项目提供了详细的解释，包括注意力矩阵乘法、位置编码和每个层的实现。项目得到了大神Karpathy的称赞，并在短时间内获得了1.5k的star。作者逐步讲解了如何加载模型文件、分词、读取模型参数、构建transformer层、实现注意力机制、位置编码（RoPE）以及前馈神经网络等步骤。通过这个项目，开发者可以更好地理解Llama3模型的内部工作原理。
首个GPU高级语言，大规模并行就像写Python，已获8500 Star,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918471&idx=3&sn=2e55697ddc8b735a61fcc7131298c236&chksm=84e40a39b393832f7363e1b85e47036e30edc60230597c23239293bec56ec6778a8000f91dbc#rd,2024-05-20 12:35:41,Bend是一种新的开源编程语言，允许在GPU上运行高级语言代码，尤其适合大规模并行处理。它采用Python语法，提供快速对象分配、高阶函数和无限递归等特性，支持CPU和GPU的并行计算。Bend通过HVM2运行时运行，旨在简化多核硬件上的编程，避免低级语言如CUDA的复杂性。虽然目前不适用于现代机器学习算法，但在处理动态函数、闭包和不可预测内存分配的“真实应用程序”中具有优势。在性能测试中，Bend在某些任务上已经能够显著快于Node.js。安装Bend需要Rust和相应的编译器或CUDA工具包，并提供了C和CUDA解释器的运行选项。Bend的并行性基于表达式的并行逻辑，例如，通过分治方法实现的双调排序可以在GPU上并行运行。未来的版本有望在性能上进一步提升。
数据更多更好还是质量更高更好？这项研究能帮你做出选择,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918471&idx=4&sn=7833305598dc218af624a311489cd5db&chksm=84e40a39b393832f57f49ecbd8f04ff2170f5d0c26c13256af749ada75fc847d2a7d42e2bf10#rd,2024-05-20 12:35:41,卡内基梅隆大学和 Bosch Center for AI的研究人员探索了数据过滤的扩展定律，强调了质量与数量之间的权衡（QQT）。研究发现，当计算预算有限时，使用低质量数据可能比重复使用高质量数据更有效。他们提出了一个新的扩展模型，考虑了数据的质量维度，可以预测不同数据池组合在不同计算预算下的性能，从而指导最优的数据整编决策。研究还指出，数据整编不能脱离计算资源来考虑，并且在计算资源增加时，需要平衡数据质量和数量。实验结果表明，新提出的扩展定律能够准确预测不同计算规模下的数据过滤策略效果。
让大模型理解手机屏幕，苹果多模态Ferret-UI用自然语言操控手机,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918471&idx=5&sn=235b06f55f9ece6d3a1094f4ecf77d4f&chksm=84e40a39b393832f8759a1ed21dead8375f67cc3026a1e4fc1491b42f01196490cc2844423d3#rd,2024-05-20 12:35:41,苹果公司推出了一种名为Ferret-UI的多模态大语言模型，该模型专门优化了对移动用户界面（UI）屏幕的理解，具有引用、定位和推理能力。Ferret-UI能够理解屏幕内容，关注特定UI元素，并将自然语言指令映射到相应的动作，有助于自动化用户界面的感知和交互过程，适用于手机辅助功能、多步UI导航、应用测试和可用性研究。该模型改进了预训练的视觉编码器和语言模型，可以直接处理原始屏幕像素，无需外部检测模块，能够处理从基础到高级的11种任务。苹果还构建了一个数据集以训练和评估模型，包括UI屏幕元素标注和多种任务构建。实验表明，Ferret-UI在各种任务上的表现具有竞争力。
OpenAI CEO下场回应「封口协议」，争议还是到了股权利益上，奥特曼：我的锅,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918342&idx=1&sn=8c1b2960da90231d7dc34128398b518d&chksm=84e409b8b39380aefc9ec770ef2b63f56aab0cd237036c143f5ba56a5ebaf1bb1417bbe29669#rd,2024-05-19 12:34:11,OpenAI面临着内部动荡和员工离职的问题，最近的争议焦点在于一份严格的“封口协议”。前员工Kelsey Piper爆料，员工离职后需要在60天内签署包含“一般豁免”的文件，否则将失去股权收益。对此，OpenAI CEO Sam Altman回应，公司从未收回任何人的既得权益，并承诺既得股权就是既得股权。然而，爆料者提出疑问，要求明确的解决方案和政策改变。此外，OpenAI的安全和未来风险处理也引起了争议，超级对齐团队的解散和前成员对安全问题的批评引发了关注。OpenAI联合创始人Greg Brockman在回应中强调了公司在AI安全方面的努力和未来计划。尽管如此，批评和质疑仍然存在。
在对齐 AI 时，为什么在线方法总是优于离线方法？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918342&idx=2&sn=fce1ec2c385060600a5ceafc7215e748&chksm=84e409b8b39380ae6eb27b70212e2b82091c6f067bd72692528084215bd4f736681cd872a9bc#rd,2024-05-19 12:34:11,DeepMind的研究论文探讨了在线和离线对齐算法在AI强化学习中的性能差距。虽然离线方法如直接偏好优化（DPO）在效率上具有优势，但在线方法通常表现更好。研究团队通过实验发现，在同等优化预算下，基于人类反馈的在线RLHF（强化学习与人类反馈）策略通常优于离线算法。这符合古德哈特定律，即当指标成为目标时，其效用会下降。研究还提出了几个假设来解释这种差距，包括数据覆盖、次优离线数据集、分类能力等，但实验结果显示这些假设无法完全解释差距。研究强调了在线采样的动态性和生成质量在提升性能方面的重要性，并指出仅扩大模型规模可能不足以解决离线对齐的挑战。
GPT-4o 与 Gemini 能否用多模态撬开下一代 AI 的新进程？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918342&idx=3&sn=9928c851a88ea86c6ce112e3c6631c92&chksm=84e409b8b39380aee3577dbda1b2869d89ba7fb9b3a23723fffa51bdcf4f84323a99ff8ec177#rd,2024-05-19 12:34:11,抱歉，您还未提供文章内容。请您提供需要摘要的文章，我会尽力帮您提取关键信息。
替代MLP的KAN，被开源项目扩展到卷积了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918342&idx=4&sn=c303da9f57351b78ea2730eef7c1c0c4&chksm=84e409b8b39380ae1fe0cab7383860dc7a0ff3efc604841dd4beb41312848730f8979e765ec9#rd,2024-05-19 12:34:11,"来自 MIT 等机构的研究者提出了一种名为 KAN（Kolmogorov-Arnold Network）的新型网络结构，它在准确性和可解释性上优于 MLP，并且参数量更少。研究者表示，KAN 以约 200 个参数就能重现 DeepMind 使用 300,000 参数的 MLP 实现的结果。KAN 的架构基于 Kolmogorov-Arnold 表示定理，其每个层的参数效率高于 MLP。最近，这一理念被扩展到卷积神经网络，形成了 KAN 卷积（CKAN），用可学习的非线性激活函数替换经典卷积的线性变换。初步评估显示，KAN 卷积在 MNIST 数据集上达到了可接受的准确度，但参数数量仅为标准 ConvNet 的 7 倍。未来，研究者计划在更复杂的数据集上进一步实验，以探索 KAN 卷积的潜力。"
多功能RNA分析，百度团队基于Transformer的RNA语言模型登Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918342&idx=5&sn=978e4dad06f004a3545a57451a30adc1&chksm=84e409b8b39380ae5fa2d5e1e06985dadde765c8224a26b81803d6a37a6b7ac69e94d20790bf#rd,2024-05-19 12:34:11,百度大数据实验室和上海交通大学的研究团队开发了RNAErnie，这是一种基于Transformer架构的预训练模型，专门针对RNA序列分析。RNAErnie使用基序感知预训练策略和类型引导微调，能在多个RNA分析任务中展现优越性能。在七个数据集和五个任务的评估中，RNAErnie超越基线模型，提高了分类、交互预测和结构预测的准确性。该模型的性能和泛化性得到验证，为RNA序列分析提供了强大的工具。尽管存在处理长序列和扩展到其他任务的挑战，RNAErnie仍展示了在RNA分析领域的潜力。
OpenAI解散Ilya重要团队，前高管怒斥，宫斗第二季,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918321&idx=1&sn=0daa7a87eecb7dac8b1ab0500f63148a&chksm=84e409cfb39380d906c45350679c12837a02578f3a13eb5880cfe50a7da66124634e580fda87#rd,2024-05-18 12:57:12,OpenAI，知名人工智能研究实验室，近期遭遇了一系列高层人事动荡。联合创始人、首席科学家Ilya Sutskever和超级对齐团队共同领导者Jan Leike宣布离职，超级对齐团队据报已被解散。这一变动引发了外界对于OpenAI在人工智能安全方面的担忧，因为该团队专注于确保AI系统与人类目标一致，防止意外危害。离职的Jan Leike在社交平台表达了对OpenAI忽视安全的不满。有前员工指出，OpenAI在追求先进技术的同时，可能忽视了对强大AI系统可能带来的风险的管理。OpenAI的目标是构建通用人工智能（AGI），但一些员工对其领导层处理AGI安全的能力失去信心。此次动荡与去年11月的董事会风波有关，当时Ilya Sutskever曾试图解雇CEO Sam Altman，但最终Altman留任并重组了董事会。离职员工指称，Altman过于关注技术进步，而对安全性的重视不足。随着安全团队的关键人物离开，OpenAI的安全工作前景令人关注。
谷歌Gemini 1.5技术报告：轻松证明奥数题，Flash版比GPT-4 Turbo快5倍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918321&idx=2&sn=95646308a9cb687ba37c58e31dac1b09&chksm=84e409cfb39380d9b3589d6f6489f14deafeb6c3a175164fcf3fc79ea7ac9b70d5b8248a8cfe#rd,2024-05-18 12:57:12,谷歌DeepMind发布了多模态大模型Gemini 1.5的技术报告，该模型通过工程和基础设施优化、MoE架构等实现了性能和速度的提升。Gemini 1.5系列包括更新的Gemini 1.5 Pro和轻量级的Gemini 1.5 Flash，能处理长上下文和跨模态内容。报告显示，Gemini 1.5 Flash在所有测试语言中的生成速度最快，而Gemini 1.5 Pro在多个基准测试中表现出最先进的性能，尤其是在视频理解和音频理解任务上。此外，Gemini 1.5 Pro的数学增强版本在竞赛级数学问题上表现出色。该模型在现实世界的应用中也能节省专业人士的时间。
大模型研究获最佳论文，WWW 2024奖项出炉,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918321&idx=3&sn=0f6eca53520a6349378bd34f79385cee&chksm=84e409cfb39380d909bb9db6f660ddbdeba667067ea9e2821e26142c4ec9d0905c3a51ca3e90#rd,2024-05-18 12:57:12,The Web Conference 2024公布了最佳学生论文奖、最佳论文奖以及时间检验奖。最佳论文奖授予了一篇关于大型语言模型机制设计的研究，由Google Research和芝加哥大学的作者团队共同完成，其中包括华人科学家Haifeng Xu和Song Zuo。该研究探讨了如何以激励相容的方式聚合多个大型语言模型，特别是在AI生成广告创意的拍卖格式中的应用。最佳学生论文奖由爱丁堡大学的Weihe Li和Paul Patras获得，他们的论文提出了Stable-Sketch，一种用于准确、快速处理大规模数据流的通用技术。时间检验奖则授予了斯坦福大学的Taher H Haveliwala，以表彰他在Topic-Sensitive PageRank上的工作，该方法改进了原始PageRank算法，使其能更好地适应特定主题的搜索查询。
人物照片+文字 = 定制化视频，腾讯光子开源ID-Animator,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918321&idx=4&sn=b6583007f21c22b531c93b0aa41b18d1&chksm=84e409cfb39380d902b54b096e753afd148d9cdf7d2383c28651f1e19886917b0ccf9cedfec8#rd,2024-05-18 12:57:12,这篇文章介绍了腾讯光子工作室团队的最新工作 ID-Animator，这是一种文本驱动的人物视频生成框架。该框架能够根据给定的参考图片生成一致性的人物定制化视频。研究者解决了视频生成模型训练的算力需求和缺乏高质量文本-视频人脸数据集的问题。ID-Animator 由轻量级的人脸适配器模块和视频生成主干网络组成，能够在不微调主干网络权重的情况下实现人物一致性视频生成。通过面向 ID 的数据集重构、随机人脸参考训练方法，以及创新的文本重写策略，ID-Animator 提供了高质量的人物视频生成效果。论文和相关资源可在给出的链接中获取。
多模态AI是医学的未来，谷歌推出三个新模型，Med-Gemini迎来大升级,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918321&idx=5&sn=b968c488c6d8a24f3f9e0a70e0ef8cac&chksm=84e409cfb39380d9fa03394c59258387aecaffd247389722dd9720366a6413a482f30083372c#rd,2024-05-18 12:57:12,Google DeepMind发布了一篇关于Med-Gemini的论文，这是一个针对医疗用途优化的多模态模型系列，基于Gemini模型并在医疗数据上进行微调。Med-Gemini包括三个模型：Med-Gemini-2D处理2D放射学、病理学、皮肤科和眼科图像；Med-Gemini-3D处理3D CT图像；Med-Gemini-Polygenic处理基因组数据。这些模型在多个医学成像和基因组任务上表现出了优秀的性能，超越了通用的大型模型，如在胸部X射线报告生成和医学视觉问答任务中达到或超过了当前最优水平。研究还展示了Med-Gemini在多模态对话和健康结果预测方面的应用。
手机到汽车，这家老牌手机厂商跨界玩的真溜,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918292&idx=1&sn=8fee3d1d459bc121e8c43300ea607b9a&chksm=84e409eab39380fc5d315a89ed33a6d3ae41a333132faba7b16ddfa1113eeeceb01e173d872a#rd,2024-05-17 23:12:54,星纪魅族发布了全新的Flyme AIOS系统，该系统引入了一系列AI功能，提升了智能辅助和系统交互能力。此外，搭载Flyme Auto的领克07车型上市，加强了AI生态的跨设备应用。Flyme AIOS中的Aicy助手提供了接近真人的对话体验，AI电话助理、AI笔记、AI录音和AI搜索等功能也得到升级。系统级的AI能力扩展至手机以外的终端，如汽车，实现多终端互联。星纪魅族致力于构建全场景互联的AI生态，通过AI电话助理、AI笔记等功能提升生活和工作效率。Flyme AIOS的发布标志着星纪魅族在All in AI战略上的重要进展。
全球140+大模型全方位评测结果出炉，智源评测体系发布,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918292&idx=2&sn=305e540753330cafa96a78355c2dbae0&chksm=84e409eab39380fc9a0bc59399786cf675685e6e08f68b54abb177caf680e9876ccbe43e200e#rd,2024-05-17 23:12:54,智源研究院发布了大模型评测体系，评估了140多个国内外语言和多模态大模型的能力。评测涵盖了语言模型的七大能力，包括理解、知识运用、推理等，以及多模态模型的图文理解和生成能力。在中文语境下，国内头部语言模型接近国际一流水平，但在能力均衡性上有待提高。在多模态任务中，国产模型表现突出。在语言模型评测中，字节跳动的Skylark2和OpenAI的GPT-4表现出色。在多模态理解与生成方面，OpenAI和国产模型如阿里巴巴的Qwen-vl-max和智谱华章的CogView3等都有优秀表现。此外，评测还涉及大模型在K12学科测试中的性能，发现模型在人文和理科方面存在差异，且对图表理解能力不足。智源评测旨在推动模型性能提升和产业落地，未来将继续完善评测体系。
OpenAI又整活：ChatGPT再扛起数据分析大旗，Excel、Word全部拿下,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918292&idx=3&sn=119ccb707d8d918aefdfafd8bd394e95&chksm=84e409eab39380fc792866206f0d5103130eef4e2a23f638e434d271a64938c66e98b84b7e9e#rd,2024-05-17 23:12:54,OpenAI最近为ChatGPT添加了数据分析功能，用户可以直接上传文件，包括从Google Drive和Microsoft OneDrive，进行数据交互和图表创建。ChatGPT可以处理数据合并、清理、图表制作和提供分析见解。用户可以实时跟踪表格更新，通过交互式表格和图表进行深入分析，同时支持自定义和下载图表用于演示文稿。此功能将适用于GPT-4，服务于ChatGPT Plus、团队和企业用户，强调数据安全和隐私保护。这一更新将帮助用户更高效地处理和理解复杂数据集。
2024「人工智能 +」标杆示范征集正式开启，7 月巅峰相见！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918292&idx=4&sn=eaf0bb8c4a5f4a9e82bc243bd6182fdd&chksm=84e409eab39380fcddcab8611552c93ed3d8ca31f33ef197248eed6d482ad4a805d7b58c43b2#rd,2024-05-17 23:12:54,"这篇文章摘要如下：

机器之心发起了2024 ""人工智能 +\"" 标杆示范征集活动，响应国务院总理李强在政府工作报告中关于深化大数据和人工智能应用的号召。活动旨在寻找具有市场竞争力和技术实力的人工智能产品、创新案例和隐形冠军企业。征集分为三大类别：2024 ""人工智能 +"" 产品标杆、2024 ""人工智能 +"" 创新案例标杆和2024 人工智能隐形冠军企业标杆。报名时间从5月17日至6月7日，入选结果将于7月在世界人工智能大会 ""人工智能 +"" 论坛上公布并颁奖。入选机构将获得权威认证、资源对接、媒体曝光等机会。报名可以通过提供的链接或联系机器之心工作人员进行。"
吴恩达：四个步骤，让大模型变得更好,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918292&idx=5&sn=e2729775edd9382f95586b789f1a5542&chksm=84e409eab39380fcd603865fc1c1f6469b6c3c0ce85036bd770824813d3e1aeec590ef4064be#rd,2024-05-17 23:12:54,人工智能学者吴恩达总结了提升生成式AI模型能力的两个主要方式：1) 提升模型的推理能力，使AI能处理复杂的概念和指令；2) 扩展输入上下文窗口。谷歌和OpenAI近期分别通过扩大上下文窗口和提高生成速度来改进模型。吴恩达建议使用更详细的“mega-prompt”来引导LLM执行复杂任务，并指出随着上下文窗口变长，多样本学习成为有效策略。他还推荐了Medprompt论文中的一系列复杂prompt策略。
仅靠开源数据复刻出LLaMA3指令学习效果，在线迭代RLHF全流程解决方案来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918292&idx=6&sn=e3aabd9c9e3464926a5841c99945c510&chksm=84e409eab39380fc4ff1668d98bffbce8c5d0d66c009e5cf5283ac4fdbaeee8133bcd525ec85#rd,2024-05-17 23:12:54,这篇文章介绍了来自UIUC和Salesforce的研究人员实现的开源在线迭代强化学习与人类反馈（RLHF）的全流程解决方案。研究基于ICML 2024论文，实现了从有监督学习到奖励函数建模，再到基于DPO的迭代RLHF，并在LLaMA3-8B模型上得到最先进的开源RLHF模型。之前，开源社区主要依赖离线直接偏好优化（DPO），而在线迭代RLHF在性能上通常优于离线版本。研究者开发了一个奖励模型和偏好模型，用开源数据集训练，并提供了模型、代码、数据和超参数的选择以促进社区复现和进一步研究。实验结果显示，所得到的模型在指令跟随测试中显著优于其他开源模型。未来的研究方向包括改进奖励函数的准确性和稳定性、优化探索策略以及解决RLHF的长度偏见问题。
用GAI定义手机，联发科和朋友们在行动,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918148&idx=1&sn=f44f006ef09b4f19c6eed2789176569f&chksm=84e4097ab393806c286a1286148a16646ff043d9ddf68f74b9fc7fa005c43e28f8faf9c9db40#rd,2024-05-16 13:42:16,这篇文章报道了联发科技（MediaTek）在天玑开发者大会 2024 上发布的新一代芯片天玑 9300+，该芯片提升了端侧 AI 能力，支持多种先进 AI 大模型，旨在引领 AI 手机新时代。vivo 最新发布的 X100S 系列手机搭载了这款芯片，实现了 AI 视效和跨 App 的智能录音识别等功能。联发科推出的一系列新技术和工具，如 AI 开发套件，旨在简化开发者将大模型适配到移动端的过程，加速生成式 AI 在手机端的落地应用。文章还提到，随着技术发展，生成式 AI 手机将在交互体验、智能出行和游戏体验等方面带来新的变革。市场预测，生成式 AI 手机的规模将在未来几年迅速增长。
18个月，OpenAI这支团队搞出了GPT-4o,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918148&idx=2&sn=9d60f2eee6cd5dfd4a367da461ebf22d&chksm=84e4097ab393806c9db8de26900c0ccf7ef8a56c4f6a0c3725c800a9f6311670aae9af154c74#rd,2024-05-16 13:42:16,OpenAI发布新一代生成模型GPT-4o，团队负责人Prafulla Dhariwal对此表示，GPT-4o是OpenAI首个原生的全多模态模型，是整个组织共同努力的结果。Dhariwal特别感谢了包括James Betker、Rowan Zellers、Alexis Conneau、Gabriel Goh、Ishaan Gulrajani、Alex Nichol、Li JING、Casey Chu、Mark Chen、Jiahui Yu、Huiwen Chang、A. Jabri和Christine McLeavey等在内的团队成员，他们在模型的各个领域做出了重要贡献。这些成员在OpenAI的研究方向包括生成式模型、图像和音频生成、机器学习、可解释性等领域。OpenAI也提供了完整名单以供查阅。
专访文青松｜AI时代的教育革新：深度融合，驱动未来,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918148&idx=3&sn=b523c029ee95cd1ee0a6d6d7933c6768&chksm=84e4097ab393806cd060ff2c7b79fca5ed6722fc87d22f49142c13f558ba426c8e79b7a13827#rd,2024-05-16 13:42:16,"这篇文章的摘要可以是：

文青松博士作为松鼠 Ai 首席科学家，在深度学习领域有显著成就，其在 ICLR 会议上提交的七篇论文被收录。文博士的研究涉及大语言模型、时间序列分析等多个领域，尤其在时间序列预测任务中对大型语言模型的创新性重构，开辟了新的研究方向。他的工作在学术和实践领域都具有重大意义，对教育革新产生影响，通过 AI 技术实现个性化学习和高效的教学干预。文博士强调持续学习、专注研究和面向应用的重要性，并期待 AI 在教育公平和资源分配上的作用，致力于通过技术创新推动教育进步。"
李飞飞解读创业方向「空间智能」，让AI真正理解世界,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918148&idx=4&sn=ec769e59a50132752307a91e97dab09a&chksm=84e4097ab393806cb52a76525080a3f8d37057395667164a2ebc324611a7f8c35d618032c9ef#rd,2024-05-16 13:42:16,AI 教母李飞飞在 TED 演讲中提出了“空间智能”的概念，这是人工智能拼图中的关键一环。她解释，空间智能能够帮助计算机理解三维世界，像人类一样评估物体的形状、位置和关系，并做出预测和行动。李飞飞提到，她的斯坦福大学实验室正在教计算机如何在三维世界中行动，例如让机械臂根据口头指令执行任务。演讲中，李飞飞展示了如何通过算法将图像转化为三维形状，并介绍了在医疗保健领域的应用，如智能传感器和脑电波控制的机器人，强调空间智能将提升人工智能与现实世界的互动能力。
ICML 2024 | 大语言模型预训练新前沿：「最佳适配打包」重塑文档处理标准,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918148&idx=5&sn=e7ea26f62c4bdde6b0314905d589cf5c&chksm=84e4097ab393806c5aff6525749c8f17d987b92cc921297327fc918004643fee0d46097b3999#rd,2024-05-16 13:42:16,AWS AI Labs的研究人员发现，大型语言模型训练中常见的文本处理方式——文档截断，会损害数据完整性，影响模型的上下文理解和事实一致性，甚至导致模型产生幻觉。为解决这一问题，他们提出了“最佳适配打包”（Best-fit Packing）方法，通过优化文档组合减少不必要的文本截断，从而提高模型性能并减少幻觉。这一研究已获ICML 2024接收。实验表明，最佳适配打包在多项任务中提升了模型性能，特别是在阅读理解、自然语言推理和程序合成等方面，同时显著降低了幻觉的产生。
大模型价格进入“厘”时代，豆包大模型定价每千tokens仅0.8厘,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918090&idx=1&sn=3a921fcdfd5d7f0f19d0efc450c5f7b7&chksm=84e408b4b39381a264869469608120efee52d0feaa551b62fca329afbdabf19e0cf90b2051ad#rd,2024-05-15 17:16:36,字节跳动在2024火山引擎FORCE原动力大会上宣布，其内部自研的大模型“豆包”将在火山引擎上对外开放服务，主打“极致性价比”。豆包通用模型pro-32k版的推理输入价格仅为0.0008元/千tokens，较行业平均价格低99.3%。此外，火山方舟2.0版本推出，旨在解决企业大模型落地过程中的成本、效果和安全等问题，提供更高效的平台服务。豆包大模型已应用于字节跳动50余个业务场景，日调用量达1200亿tokens，处理能力经受了大流量验证。火山方舟还增强了系统承载力，实现了分钟级千卡伸缩，并丰富了插件生态，以支持更多元化的应用场景。预计2024年底或2025年初，企业对大模型的调用量将迎来显著增长。
Ilya官宣离职，超级对齐负责人Jan直接辞职，OpenAI还是走散了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918090&idx=2&sn=e71f08ed6978b7808965761ebc07933b&chksm=84e408b4b39381a21bf08c28d800df2b88b6619a5744aaa30412d0f99cd75e63f2c7382673d7#rd,2024-05-15 17:16:36,OpenAI的联合创始人和首席科学家Ilya Sutskever宣布离职，结束他在该机构近10年的任职。Sutskever表示，他相信OpenAI将在其他领导人的带领下继续发展安全有益的AGI。OpenAI的CEO Sam Altman对Sutskever的离开表示遗憾，并赞扬了他的贡献，同时宣布Jakub Pachocki将接任首席科学家一职。Sutskever对于AI的未来发展持有深刻的关注，特别是对于AI的可控性和超级智能的潜在风险。他之前负责的超级对齐团队的未来也因此变得不确定。
谷歌反击：Project Astra正面硬刚GPT-4o、Veo对抗Sora、新版Gemini变革搜索,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918090&idx=3&sn=43ae0669e67f0b4e61ff376bb0024cfd&chksm=84e408b4b39381a20629e5d53f72100e358952756fbbd6499787a75d84cf06bb8693dad21275#rd,2024-05-15 17:16:36,谷歌在2024年的I/O开发者大会上强调了人工智能的中心地位，宣布了新一代的多模态大模型Gemini的进展。这一模型将增强搜索引擎的能力，使其能更好地理解和回答复杂问题，并能规划和执行任务。谷歌还展示了与OpenAI的GPT-4o和Sora竞争的Project Astra和Veo。Project Astra是一个AI智能体原型，具有视觉和语音交互能力，而Veo是视频生成模型，能生成高质量、长时长的视频。此外，谷歌发布了更快、更高效的模型 Gemini 1.5 Flash和开源模型Gemma 2，以及新一代TPU Trillium，以支持更强大的AI计算需求。谷歌正在将其AI技术整合到搜索、生产力工具和安卓系统等多个方面，以提供更智能的用户体验。
首个中文原生DiT架构！腾讯混元文生图大模型全面开源，免费商用,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918090&idx=4&sn=053bcc2543a7b2961faaece188ea9c5e&chksm=84e408b4b39381a2a300c06a3c9be26ad87532270c3a502c2ba6e78f63ef7400286d31559319#rd,2024-05-15 17:16:36,腾讯宣布其混元文生图大模型全面升级并开源，成为业内首个中文原生的DiT架构文生图开源模型。该模型支持中英文双语输入和理解，参数量为15亿。采用Hunyuan-DiT架构的腾讯混元文生图模型在文本图像一致性、排除AI伪影、主题清晰度和审美等方面表现出色，超越开源的Stable Diffusion模型。模型采用了Transformer架构的扩散模型，支持多轮对话和图像调整，擅长细粒度文本提示生成，尤其在处理中国元素方面表现出色。腾讯混元选择全面开源这一模型，旨在促进开发者和创作者的参与，共建下一代视觉生成开源生态。
告别3D高斯Splatting算法，带神经补偿的频谱剪枝高斯场SUNDAE开源了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650918090&idx=5&sn=b01039b68c9d588007f95fd46c9cc783&chksm=84e408b4b39381a2b536bca14ea34399fc153e9fb2e97fc77e9d9ca0e97f82f5499b81869027#rd,2024-05-15 17:16:36,这篇论文介绍了一种名为SUNDAE的新方法，用于减少3D Gaussian Splatting方法的内存消耗。3D Gaussian Splatting在3D表示和渲染中表现出色，但内存需求高。SUNDAE通过结合频谱修剪和神经补偿解决了这一问题。研究者构建了一个图来模拟高斯基元之间的关系，并应用图信号处理进行降采样以剪枝。同时，他们设计了一个轻量级神经网络来补偿剪枝导致的质量损失。实验结果显示，SUNDAE在保持高质量渲染的同时，显著降低了内存使用，例如在Mip-NeRF360数据集上，使用104 MB内存即可达到26.80 PSNR和145 FPS，优于标准3D Gaussian Splatting。论文已开源，并受到了国际研究社区的关注。
OpenAI颠覆世界：GPT-4o完全免费，实时语音视频交互震撼全场，直接进入科幻时代,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917888&idx=1&sn=7d7cf9a41642541b5df64d0c8fb5b76a&chksm=84e4087eb3938168382fadd785ad8eb00602cda1863fbe811697c037508985dafb8558331058#rd,2024-05-14 04:19:17,OpenAI在春季新品发布会上发布了新一代旗舰生成模型GPT-4o，以及桌面版本的ChatGPT，实现了文本、音频和图像的多模态交互。GPT-4o是一款免费的全能模型，提供与GPT-4相当的智能水平，同时在文本、视觉和音频方面有所改进。这款模型的突出特点是能够实时处理输入的多种类型信息，并以自然、快速的方式生成输出。OpenAI还宣布未来将优先考虑免费服务，让更多用户能够使用其产品。新推出的桌面应用程序简化了用户的工作流程，用户可以通过键盘快捷键或语音与ChatGPT交互。此外，OpenAI首席执行官Sam Altman表示，公司将努力提供免费的人工智能服务，让所有人都能使用GPT的计算能力。
我是如何赢得GPT-4提示工程大赛冠军的,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917888&idx=2&sn=a822ab09ec20cd3ba83df8d70f77bbe1&chksm=84e4087eb3938168175f055b238ce1a13f5ea186b1e66f55dc675e98acad21ea67b061caca48#rd,2024-05-14 04:19:17,本文是数据科学家Sheila Teo分享的关于如何赢得新加坡GPT-4提示工程竞赛的经验总结。文章介绍了四个关键提示工程技术，包括使用CO-STAR框架构建提示结构、通过分隔符为提示设置节段、使用LLM防护围栏创建系统提示，以及仅使用LLM分析数据集。CO-STAR框架帮助明确任务的上下文、目标、风格、语气、受众和响应，确保LLM的输出更加相关和有效。通过分隔符，可以为提示提供结构，使LLM更好地理解输入。防护围栏则允许在对话过程中设置LLM的行为边界，确保其遵循特定规则。最后，文章通过实例展示了如何仅使用LLM对数据集进行分析，适合模式发现任务，而非定量计算。
零一万物Yi-1.5来了，国产开源大模型排行榜再次刷新,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917888&idx=3&sn=af5679d5184903d65408b83b87edb705&chksm=84e4087eb39381681cae3f0bfb3aecae1365fb8c6d6e2d673f1a5a4eb2a9a7480ca6408d2637#rd,2024-05-14 04:19:17,中国大模型公司零一万物发布了开源大模型Yi-1.5，包括6B、9B、34B三个版本，预训练和微调模型采用Apache 2.0许可证。Yi-1.5是Yi-1.0的后续版本，通过500B个token的训练提高了编码、推理和指令执行能力。该模型在多个基准测试中表现出色，部分指标超过其他知名模型。此外，零一万物还宣布了一周年纪念的一系列大模型API接口，包括千亿参数的Yi-Large等，适用于不同场景。Yi-Large在多项评测中展现出全球顶级大模型的性能，并在中文通用大模型基准SuperCLUE中排名第一。公司还透露正在训练下一代Yi-XLarge MoE模型，以挑战GPT-5的性能。零一万物强调了技术成本、产品市场契合度在大模型发展中的重要性，并致力于优化计算效率以降低训练成本。
微软让MoE长出多个头，大幅提升专家激活率,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917888&idx=4&sn=90c657686a0d4b7363686ec9588d04dd&chksm=84e4087eb393816826bd8a9f44fcad32d75822eaa731021c1893634ed387d31d7cedd1683e89#rd,2024-05-14 04:19:17,微软研究院和清华大学的研究人员提出了多头混合专家（MH-MoE）模型，解决了稀疏混合专家（SMoE）模型中专家激活率低和无法细粒度理解单个token的多重语义问题。MH-MoE通过多头机制将输入token分割成子token，分配给一组多样化的专家并行处理，然后重新整合，提高了专家激活率，增强了模型的上下文理解能力。相比于SMoE，MH-MoE具有更高的激活率和更好的扩展性，并能实现更细粒度的理解能力。实验结果显示，MH-MoE在语言建模、多语言建模和掩码式多模态建模等任务上表现出优越性能。此外，消融研究验证了MH-MoE组件的有效性，分析表明其具有更好的扩展性和细粒度理解能力。
西浦、利物浦大学提出：点云数据增强首个全面综述,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917888&idx=5&sn=1e652d8800e2f1c1240f58a0085d2237&chksm=84e4087eb393816889f11f880e47b9461212c5d4f778d3d65be13bc3d4856320ad858137b2f2#rd,2024-05-14 04:19:17,这篇综述论文由朱钦峰、范磊和翁宁馨完成，首次全面总结了点云数据增强的相关研究工作。点云数据增强在深度学习中对于减少过拟合和提高模型性能至关重要，特别是在训练数据有限的情况下。论文将点云增强方法分为基础和特定增强两类，并提出了一个分类框架。基础增强包括仿射变换、丢弃增强、抖动等，而特定增强涉及Mixup、域增强等技术。作者们还讨论了未来的研究方向，包括对抗性变形、上采样和生成增强等潜在方法的探索，以及评估、计算效率和一致性学习等方面的问题。这篇综述为点云数据增强的研究提供了全面的概述和指导。
除了一键启动Copilot，什么是AI PC本来该有的样子？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917698&idx=1&sn=b6065777d8317c6f7e47d0f20faa47ed&chksm=84e40f3cb393862a97c336c733c653e05c86e64e438441a8a6a70d4614fd3da584599e4ea0ab#rd,2024-05-13 12:47:13,这篇文章讨论了人工智能（AI）如何改变个人电脑（PC）行业，提出了“AI PC”这一概念，即具有内置AI功能的个人电脑。AI PC能够通过大模型协助用户快速完成任务，提高个人生产力。微软等公司正在推动在AI PC上添加一键召唤大模型的服务。文章指出，AI PC的硬件革新，如英特尔的酷睿™ Ultra 处理器，通过CPU、GPU和NPU的异构混合计算，实现了在不联网情况下运行大模型的能力。这种处理器可以提升AI性能，降低功耗，并已在多个行业应用中展现出商业价值。目前，AI PC的应用场景包括AI Chatbot、AI PC 助理、AI Office 助手等，未来有望在更多领域普及，实现更高效的生产力工具。
Sora是世界模拟器吗？全球首篇综述全面解析通用世界模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917698&idx=2&sn=4377de73f253063e346dbafd0209c01c&chksm=84e40f3cb393862ae52c868e0dfac7614e96281102b993559242669e7d8bc3247b4b3f1df62f#rd,2024-05-13 12:47:13,"这篇综述文章是由北京极佳视界科技有限公司及其合作单位联合发布的，探讨了通用世界模型在人工智能领域的最新进展，特别是在视频生成、自动驾驶和智能体应用方面的研究。世界模型通过预测未来来理解和模拟数字与物理世界，被认为是实现通用人工智能的关键。文章提到了OpenAI的Sora模型在视频生成中的仿真能力，以及特斯拉和Wayve在自动驾驶中利用世界模型进行预测。在智能体和机器人领域，世界模型也被用于学习和规划策略。

文章还回顾了视频生成模型的发展，包括基于GAN、自回归、扩散和掩码建模的不同方法。在自动驾驶领域，世界模型被用于构建动态环境的表示，并进行安全驾驶的预测。此外，通用世界模型在智能体和机器人领域的应用也日益增多，比如Dreamer系列和基于Transformer与扩散模型的智能体模型。

尽管取得了一些进展，但世界模型仍面临挑战，如因果和反事实推理、模拟物理定律、泛化能力、计算效率和性能评估。文章对未来发展方向进行了展望，并在GitHub上提供了相关研究进展的更新。该综述为通用世界模型的研究提供了参考，并强调了其在各领域的潜力和应用。"
培育发展智能汽车领域新质生产力，「AI+智能车」论坛在浦东新区成功举办,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917698&idx=3&sn=0154d92fa47126ff4621e690f74fdace&chksm=84e40f3cb393862a078514da0fee5e5e80f6d234d5609b24175c80b795da893521dca3beea16#rd,2024-05-13 12:47:13,5 月 11 日，AI + 智能车论坛在上海金桥成功举办，探讨了大模型在自动驾驶、智能座舱等领域的应用。浦东新区科技和经济委员会副主任夏玉忠表示，浦东将为大模型落地提供支持，推动新一代信息技术与汽车产业深度融合。论坛上，6 家企业签署了“金桥未来车产业链生态共建倡议书”，以加强产业链合作。同济大学汽车学院教授朱西产指出，AI 大模型在车端的落地是实现自动驾驶的重要路径。此外，嘉宾们还讨论了大模型在车路协同、智能云、AI 芯片等方面的机会与挑战。未来，大模型赋能产业系列活动将继续关注不同垂直领域的应用。
只需百行代码，让H100提速30%，斯坦福开源全新AI加速框架,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917698&idx=4&sn=a2001bd0e08b4b8573b60c9ba2f75114&chksm=84e40f3cb393862a93ef39e252b247d7d9791888fe266a1c1bbcd2158529529f5d3629447269#rd,2024-05-13 12:47:13,斯坦福大学的研究者在《GPUs Go Brrr》博客中介绍了如何提高GPU利用率，特别是针对AI计算效率。他们发布了一个名为ThunderKittens的库，用于在CUDA上编写快速的深度学习内核。ThunderKittens简单易用，具有可扩展性和高性能。通过ThunderKittens，研究者在RTX 4090上实现了一个GPU内核，达到大约122 TFLOP，相当于理论最大值的74%。对于英伟达的H100 GPU，研究者揭示了其一些特殊的硬件特性，如WGMMA指令、共享内存管理和地址生成等挑战。ThunderKittens通过简化这些复杂性，使得在现代硬件上实现高利用率变得更简单。
字节开源大模型量化新思路，2-bit量化模型精度齐平fp16,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917698&idx=5&sn=97c5a01d5fb1fe75ee526b942a01f342&chksm=84e40f3cb393862aa97c373ecba645cdb450b175b84af87528fd6cf3dc41c3815098f7e06eee#rd,2024-05-13 12:47:13,字节跳动语音团队提出了一种新的模型量化方法，称为decoupleQ，以解决深度学习大语言模型推理成本高的问题。传统量化方法在低比特下可能导致精度下降，而decoupleQ通过将模型参数分解为整数和浮点两部分，并从数学优化角度建模量化任务，能够在极低比特下保持高精度。这种方法避免了处理量化特定问题的复杂性，而是通过构建优化目标函数并求解来实现量化。论文已经发表在arXiv上，相关代码开源，实验结果显示，decoupleQ在保持高精度的同时，提供了更好的推理性能，并已在字节跳动的多个语音相关产品中得到应用。
DiT架构大一统：一个框架集成图像、视频、音频和3D生成，可编辑、能试玩,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917646&idx=1&sn=aa11bc4b5b2feab3e5a6319f94b3338c&chksm=84e40f70b3938666bd915c4b9518c2860f15c209d3b880eb33f8fefdc6af6a2818988e69ae7e#rd,2024-05-12 12:16:56,上海 AI Lab、港中文和英伟达的研究者联合推出了Lumina-T2X系列模型，通过基于流（Flow-based）的大型扩散 Transformers（Flag-DiT）实现图像、视频、多视图3D对象和基于文本描述的音频生成。这一系列模型中的最大模型包括70亿参数的Flag-DiT和130亿参数的多模态大语言模型SPHINX。Flag-DiT在稳定性、灵活性和可扩展性方面有所改进，能够生成任意分辨率和宽高比的高质量图像，并支持视频、3D和语音的生成。研究者还提供了Lumina-Next-T2I模型的试玩地址，供用户体验。
从零开始手搓GPU，照着英伟达CUDA来，只用两个星期,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917646&idx=2&sn=0ee11e42f920837765e34d8850103206&chksm=84e40f70b39386666be19c9721d5f29e77b854795551436f87fc6ac7f1126e36f1cf3ce7543e#rd,2024-05-12 12:16:56,一位美国web3开发公司的工程师Adam Majmudar在两周内从零开始构建了一块GPU，并将过程分享在Twitter和GitHub上，获得了广泛关注。他首先学习了GPU的基础知识和英伟达的CUDA框架，理解了GPU架构和编程模式。然后，他设计了一个简化版的GPU架构，强调并行化、内存访问和资源管理，并创建了自己的指令集架构（ISA）。通过Verilog编写代码时遇到了挑战，经过多次重写和优化，最终成功实现了GPU设计。这个项目目前正在进行物理形态的芯片流片过程。Adam Majmudar强调，这个项目简化了许多复杂性，旨在突出GPU的核心概念，让其他人更容易了解GPU。
空间智能：能否成为具身智能技术的下一个里程碑？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917646&idx=3&sn=716aa3be8624aa3c7f7015190d843299&chksm=84e40f70b3938666b8135399439f0e2e55b587679312278b8b87fc429783dde11860221693c7#rd,2024-05-12 12:16:56,很抱歉，您还未提供具体的文章内容。请您提供需要摘要的文章，我会尽忙为您生成摘要。
Flash Attention稳定吗？Meta、哈佛发现其模型权重偏差呈现数量级波动,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917646&idx=4&sn=322b7a89b08ec91eaa5bd58768316916&chksm=84e40f70b3938666abd5a5ac4334a08b22b969cd5ba7c7c992db4aa27758f06455293181ec7c#rd,2024-05-12 12:16:56,Meta FAIR 和哈佛大学的研究者合作开发了一个定量方法，用于理解和评估大规模机器学习训练中的数值偏差问题。在训练大型语言模型时，数值偏差可能导致训练不稳定，尤其是在使用优化技术如 Flash Attention 时。研究者通过微基准测试和数据驱动分析量化了 Flash Attention 的数值偏差，并发现其比 BF16 基线的数值偏差大一个数量级。他们使用 Wasserstein 距离来衡量这种偏差对模型权重变化的影响，结果显示，Flash Attention 引入的模型权重偏差大约是低精度训练的 1/2 至 1/5 倍。这项研究强调了量化训练优化对数值偏差影响的重要性，并为此提出了一种新的框架。
AlphaFold 3轻松应对核酸、脂类分子？科学家迫不及待地更新了评测,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917646&idx=5&sn=05cb6d2d121e603cf6ed9ec989ae73f5&chksm=84e40f70b3938666ba16231a0cb380600393b3b16215dc1b8dd74c3774a7d7a45ab389ee6b22#rd,2024-05-12 12:16:56,欧洲分子生物学实验室的科学家Jan Kosinski在AlphaFold 3发布后，使用该模型进行了一系列测试，发现AlphaFold 3能够准确预测未知转录因子的结构和序列特异性。Kosinski表示，这可能预示着功能建模新时代的开始，未来可能通过计算预测所有转录因子的序列特异性。他还测试了AlphaFold 3对启动子区域和限制性核酸酶的预测能力，结果喜忧参半。一些实验显示AlphaFold 3能够识别特定序列，但对某些限制性核酸酶的预测不准确。此外，Karel Krápník Berka使用AlphaFold 3预测了膜上脂质分子的位置。这些初步测试揭示了AlphaFold 3在生物学领域的潜在应用，但也表明了需要进一步验证和优化的领域。
坏了，我的RTX 3090 GPU在对我唱歌！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917605&idx=1&sn=9213906d70372187f6698a156af2026d&chksm=84e40e9bb393878daa2d679789c6b1fdc86ddb91d23fa97b1b71cb2125b49b735f9caa39a314#rd,2024-05-11 21:16:24,AI科学家Vrushank Desai发现RTX 3090 GPU在运行特定内核时，其电感线圈能发出声音，甚至可以“演奏”《一闪一闪亮晶晶》。Desai通过控制GPU内核的频率调节功耗，导致电感线圈振动发出声音。他在研究GPU编程和优化《Diffusion Policy》论文中的推理时，注意到Pytorch Eager模式比CUDA图形或自定义内核产生更大的线圈噪音，进而发现可以通过改变内核启动间隔来控制这种噪音，最终实现让GPU“唱歌”。Desai在博客中详细记录了这一过程，并分享了相关代码。
百万tokens低至1元！大模型越来越卷了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917605&idx=2&sn=4f9af1d345cc00194e67aaed365ea5c5&chksm=84e40e9bb393878df5b52293e18e7fd41dc49c55295131771ef6d90fdcacb7cc9c5f6f712464#rd,2024-05-11 21:16:24,智谱AI大模型开放平台降低了其入门级产品GLM-3 Turbo的调用价格，降幅达80%，现在价格为1元/百万tokens，旨在让更多企业和个人能够使用。新注册用户还将获得赠送的tokens额度，从500万提升至2500万。此外，企业级产品GLM-4/GLM-4V价格维持在0.1元/千tokens。智谱AI的这一举动旨在吸引更多的开发者和企业，促进大模型的广泛应用和商业化。平台上已有数十万企业和开发者，并且每日token消耗增长迅速。随着技术进步和成本优化，大模型的使用成本将进一步降低，推动AI应用和国产算力发展。GLM系列模型还将迎来更新，目前正处于灰度测试阶段。
OpenAI下周要有大动作，奥特曼在线剧透：不是GPT-5，不是搜索引擎,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917605&idx=3&sn=e122cbdd34adf86e96c41124e782632d&chksm=84e40e9bb393878d661d0d93080e3eea06a1f5281a8ac11d1c0b8dee8698c6c7ae93a2ee7d5c#rd,2024-05-11 21:16:24,OpenAI宣布将于美国时间5月13日进行直播，展示ChatGPT和最新模型GPT-4的更新。CEO Sam Altman表示，发布的内容不是GPT-5，也不是搜索引擎，但会是新东西，他将其比喻为魔法。有消息称OpenAI正在开发一款AI语音助手，它具有音频输入/输出和更好的推理能力，可能在直播中亮相。这款语音助手据称在某些方面超越了GPT-4，目标是成为类似于电影《她》中的虚拟助手。此外，OpenAI还计划推出AI搜索引擎和自动化软件，并可能在今年年底发布GPT-5。苹果公司也计划升级Siri，使其使用生成式AI技术以应对竞争。
人类偏好就是尺！SPPO对齐技术让大语言模型左右互搏、自我博弈,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917605&idx=4&sn=1be7b2a4993007794054100ceef5606f&chksm=84e40e9bb393878d699a4033acd0ea5291a9db41dbc019241b7062c5cc311d15953347e61329#rd,2024-05-11 21:16:24,"加州大学洛杉矶分校（UCLA）的顾全全教授团队与卡内基梅隆大学（CMU）Yiming Yang教授团队合作开发了一种名为「自我博弈偏好优化（Self-Play Preference Optimization, SPPO）」的技术，旨在通过自我博弈优化大语言模型的行为，使其更好地符合人类偏好。该方法将基于人类反馈的强化学习（RLHF）问题定义为一个两玩家常和博弈，并使用自我博弈机制和乘法权重的经典在线自适应算法来近似纳什均衡策略。实验结果显示，SPPO方法显著提升了大语言模型在多个评估平台上的性能，特别是在理解和遵循人类偏好方面。该技术有望促进大语言模型的对齐和优化，为构建更智能和负责任的AI系统做出贡献。"
跟着开源的InternVL，学习如何做自己的GPT-4V,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917605&idx=5&sn=efcce6070086b0b8e6d18e45992dc95e&chksm=84e40e9bb393878d5fac57598b0f8d9b0d27aceac693beba0d56f1520f6270963b8d4f42e831#rd,2024-05-11 21:16:24,这篇文章介绍了书生图像大模型InternVL的最新进展，旨在缩小开源模型与商业模型在多模态任务性能上的差距。InternVL 1.5模型通过三项创新设计提升了性能：1) 强大的视觉编码器通过连续学习增强视觉理解能力；2) 动态高分辨率处理适应不同大小的图像，最高支持4K分辨率；3) 高质量双语数据集用于增强OCR和中文任务性能。这些改进使得InternVL 1.5在多模态任务中表现出色。分享会将详细讨论这两个版本的模型以及它们在人工智能生成内容领域的应用和未来发展。
在ICLR 2024这场演讲中，智谱AI首次公开神秘项目「GLM-zero」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917554&idx=1&sn=2b320588aab5aec3b7ae2486e594e75d&chksm=84e40eccb39387dabf67b86f217cb1b50977b5c9af52857d8d98a9846f9fbbd7d7425492fb85#rd,2024-05-10 20:06:04,ICLR 2024，国际学习表征会议，在奥地利维也纳开幕，迎来热度提升，论文提交量和参会规模创新高。该会议已成为与 ICML、NeurIPS 并列的顶级机器学习盛会。开幕式上颁发了首届时间检验奖，授予对深度学习和生成模型领域有深远影响的《Auto-Encoding Variational Bayes》（VAE）研究。本次大会有七场特邀演讲，包括来自中国的 GLM 大模型团队，主题为《The ChatGLM's Road to AGI》。GLM 团队探讨了大模型技术如何推动人工智能发展，尤其是对于 AGI（人工通用智能）的期待，并提出模型的“涌现”现象和预训练损失在模型能力中的关键作用。GLM 大模型团队还分享了其在多模态建模、通用计算系统和无意识学习机制研究方面的探索，展示了其在大模型领域的进展和对 AGI 的前瞻性思考。
马斯克Neuralink植入物出故障：受试者接线脱落,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917554&idx=2&sn=71fe456bf4f52e7b40b34852bc461f5a&chksm=84e40eccb39387dab1a1925b6311fa505d30a68b8e47c8c11aa71e22bcb4024e7e04c092e34f#rd,2024-05-10 20:06:04,马斯克的脑机接口公司Neuralink透露，其植入人体的首个侵入式大脑芯片出现故障，神经元监视线似乎已从参与者的大脑中脱落。该公司在博客中确认了这一问题，但表示参与者的安全似乎没有受到影响。尽管如此，Neuralink已经修改了信号解码算法，以恢复和保持植入物的性能。此前，该设备被植入了一名因潜水事故导致瘫痪的男子，使他能够通过意念控制电脑。目前尚不清楚柔性线移位的具体原因和影响，但Neuralink计划在未来几个月进行更多次的人体试验。
苹果启动AI云服务器计划，芯片直接用M2 Ultra,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917554&idx=3&sn=bd43692375f38190861e9b68c90bf45c&chksm=84e40eccb39387dadb321b46f805764af8ce712b8578dd996c31f756efa97aca538a8d724ca6#rd,2024-05-10 20:06:04,苹果在春季新品发布活动中宣布了新的M4芯片，强调其在AI性能上的提升，特别是16核心神经引擎的先进设计。苹果还计划将M2 Ultra芯片用于云服务器，处理AI任务，这是其在AI领域的重大举措。苹果将在iOS 18中推出这些功能，同时结合设备端和云端处理，根据任务复杂度选择处理路径。这一转变代表苹果开始更多地依赖云端处理复杂AI任务，但仍会强调设备端的隐私和安全。苹果预计将使用自家数据中心，但未来可能也会依赖外部设施。苹果已经在云端计划上投入数亿美元，并与谷歌、OpenAI等进行讨论，计划将AI服务整合到其设备中。
3倍生成速度还降内存成本，超越Medusa2的高效解码框架终于来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917554&idx=4&sn=2dabc12a2ac1225f83d9f77e78976f7f&chksm=84e40eccb39387da7b799abc98f573491cd5aa86bd60c0122cb28fba67c822ba5701ce0d3b32#rd,2024-05-10 20:06:04,来自上海交通大学和加利福尼亚大学的研究团队提出了一种新的并行解码器族，称为一致性大语言模型（CLLMs），能够通过高效解码n-token序列来降低大型语言模型（LLMs）的推断延迟。这种方法模仿人类的思考过程，通过微调预训练的LLMs，使得模型能够并行地解码多个token，而不需要自回归解码的逐个生成。研究团队还介绍了Jacobi解码，一种基于迭代的方法，可以潜在地加速解码过程。实验结果显示，CLLMs在生成速度上相比传统方法提高了2.4到3.4倍，且不需要额外的内存成本。这种方法对于提高LLMs的效率和加速推断过程具有重要意义。
14 项任务测下来，GPT4V、Gemini等多模态大模型竟都没什么视觉感知能力？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917554&idx=5&sn=b16493eeb6801536215386d29f823384&chksm=84e40eccb39387da40e3886a79d24888eb7329138845c850580553aae6ccffd6b4f9ba536377#rd,2024-05-10 20:06:04,BLINK是一个新提出的基准测试，旨在评估多模态大模型（如GPT-4V、Gemini等）的视觉感知能力。当前的多模态模型在处理复杂的视觉任务上存在挑战，而BLINK包含14项需要核心视觉理解的任务，如相对视深、视觉对应和多视角推理等。人类在这个测试中的平均准确率是95.70%，但GPT-4V和Gemini的准确率分别只有51.26%和45.72%，远低于人类。BLINK与其他基准测试的区别在于它涵盖更全面的视觉感知能力，并使用多种视觉提示，而不是只依赖文本问题和答案。实验结果显示，即使是最大的多模态模型，其在某些任务上的表现甚至不如随机猜测，表明在视觉理解方面仍有显著改进空间。
闭源赶超GPT-4 Turbo、开源击败Llama-3-70B，歪果仁：这中国大模型真香,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917394&idx=1&sn=3060bce83107a4988690515d008f51bd&chksm=84e40e6cb393877a7b07b763fca347c6ab969bae342a3c350a3dc894318464c79759d8f6fb14#rd,2024-05-09 18:07:37,阿里云的通义千问大模型在开源和闭源领域取得显著成果，登顶HuggingFace开源大模型排行榜，超越Llama-3-70B。通义千问2.5成为地表最强中文大模型，其性能在中文场景中超过GPT-4 Turbo。在过去一年中，通义千问通过不同参数量级的模型满足了从端侧到服务器的部署需求，且在多项基准测试中表现优秀。此外，通义千问在文档处理、音视频理解和智能编码能力方面有独特优势，为用户和开发者提供了多样化和高效的生成式AI体验。该模型的开源策略促进了开发者社区的活跃反馈，加速了模型能力的提升。
原作者带队，LSTM真杀回来了！,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917394&idx=2&sn=be53466538b409ccf9980d85eff3fd9d&chksm=84e40e6cb393877a47bfa0d0a0e27f8cda6b01ce7b0c4bc8ed1a840498ca04fdb2ff11d6d982#rd,2024-05-09 18:07:37,LSTM的提出者Sepp Hochreiter在arXiv上发布了一篇关于xLSTM的预印本论文，这是一种改进的LSTM模型，旨在解决LSTM的局限性。Transformer的出现使得LSTM的使用减少，但xLSTM通过引入指数门控和矩阵内存解决了LSTM的存储决策不可修改、存储容量有限和可并行性差的问题。实验表明，xLSTM在验证复杂度上优于现有的语言建模方法，包括Transformer，并且在处理长序列和大规模模型时表现出色。
网传Ilya Sutskever的推荐清单火了，掌握当前AI 90%,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917394&idx=3&sn=4402a0e41b15306c7066b7f0b267eb71&chksm=84e40e6cb393877a6eb63724bf373196299616016b8c2ca6f3e51867ed1e9cf748b7a8c45160#rd,2024-05-09 18:07:37,OpenAI联合创始人Ilya Sutskever分享了一份机器学习研究文章清单，被认为是掌握人工智能领域90%重要内容的推荐读物。清单涵盖了transformer架构、循环神经网络（RNN）、长短期记忆网络（LSTM）和神经网络复杂度等相关主题。推荐的论文和博客文章包括《Attention Is All You Need》、《The Annotated Transformer》、Andrej Karpathy的RNN博客、Wojciech Zaremba和Ilya Sutskever的RNN正则化论文、Relational recurrent neural networks、Understanding LSTM Networks、《Kolmogorov Complexity and Algorithmic Randomness》等。此外，还有Geoffrey Hinton的AlexNet论文和DeepMind的神经图灵机（NTM）等经典工作。
10年前VAE经典论文获奖，ICLR 2024首个时间检验奖公布,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917394&idx=4&sn=8ec3b3b631e7e2123daf0053d2fca6ee&chksm=84e40e6cb393877ab1774de61d56579dffa25919588986efe5d6766a34dbce44a6404034d45b#rd,2024-05-09 18:07:37,ICLR 2024 首届时间检验奖颁发给两篇具有长期影响力的论文。获奖论文《Auto-Encoding Variational Bayes》由 Diederik P. Kingma 和 Max Welling 撰写，提出了变分自动编码器（VAE），将深度学习与概率推理结合，对深度学习和生成模型领域产生了重大影响。亚军论文《Intriguing properties of neural networks》由 Christian Szegedy 等七位作者合作完成，揭示了神经网络对微小输入变化的敏感性，为对抗性攻击和防御的研究奠定了基础。两篇论文均对深度学习领域的发展作出了重要贡献。
ICLR 2024 Oral｜用巧妙的「传送」技巧，让神经网络的训练更加高效,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917394&idx=5&sn=2ab8300e815213801f67e38ad5602b83&chksm=84e40e6cb393877a68cc1166356c450100c593764831bc31027e476f06a70446e2a368959840#rd,2024-05-09 18:07:37,这篇论文来自加州大学圣地亚哥分校、Flatiron Institute和美国东北大学等机构的研究人员，探讨了神经网络参数空间中的对称性如何影响优化和泛化。他们提出了一种名为“传送算法”的方法，利用这些对称变换加速寻找最优参数。研究发现，传送不仅能在短期内加快优化过程，还能总体上缩短收敛时间，并且可以改善模型的泛化能力。论文还展示了传送与其他优化算法以及基于优化的元学习的结合效果，强调了在优化过程中利用参数空间对称性的潜力。这项工作为理解神经网络优化提供了新的视角，并提出了改进泛化性能的策略。
2万块钱买平板：苹果新一代iPad Pro直接上M4芯片，最强也最贵,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917136&idx=1&sn=b71fea2cfabe6e3cde853f1574956088&chksm=84e40d6eb393847804cb764a671a62b82ebd0b4fb35703ab10e5b670b83f9ff8dd4f380edb15#rd,2024-05-08 00:27:18,苹果在春季新品发布活动中推出了新款iPad Pro，其中最引人注目的是搭载了全新的M4芯片。这款芯片采用280亿晶体管，基于第二代3nm技术，拥有10核心CPU（4个性能核心和6个能效核心）和10核心GPU。CPU性能相比M2提升了50%，GPU性能在专业渲染方面是M2的四倍，并支持硬件加速光线追踪。M4芯片还配备了16核心神经引擎，每秒可执行38万亿次操作。新款iPad Pro的显示引擎也得到提升，采用先进的OLED显示屏。此外，新款iPad Air也发布，搭载M2芯片。新款iPad Pro售价8999元起，新款iPad Air售价4799元起，将于5月9日接受订购，15日发售。
7262篇提交，ICLR 2024爆火，两篇国内论文获杰出论文提名,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917136&idx=2&sn=c762406e444e94a90d86c081693877e5&chksm=84e40d6eb39384784a3455a5e73135a2fd8dfbf1bdfb1659357e814c919dd5d0cb24e2675e0f#rd,2024-05-08 00:27:18,这篇文章是关于2024年国际学习表征会议(ICLR)的杰出论文奖和荣誉提名的报道。ICLR是一个重要的深度学习会议，今年在奥地利维也纳举行，共收到7262篇论文，接收率为31%。大会评选出5篇杰出论文和11篇荣誉提名。杰出论文涵盖了图像扩散模型的泛化、交互式真实世界模拟器、长期序列建模、蛋白质发现和Vision Transformer的改进等领域。这些获奖论文展示了深度学习和相关领域的最新进展和重要研究成果。
大模型时代的计算机视觉！CVPR 2024线上论文分享会启动,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917136&idx=3&sn=4d791518e304d0c4cef93fc252c35c0e&chksm=84e40d6eb3938478ab386a116a3d6b390755abbd234321cc14cbe1e567e53f7262a5b1097e5d#rd,2024-05-08 00:27:18,随着OpenAI的ChatGPT和Sora的发布，大模型和AI内容生成领域的热度持续升高。为了帮助AI社区及时了解最新的科研成果和趋势，机器之心宣布将于2024年6月1日举办「CVPR 2024 线上论文分享会」。CVPR是计算机视觉领域的顶级会议，今年收到了11532篇论文提交，录用率为23.6%。分享会旨在搭建一个学术交流平台，包括Keynote演讲、论文分享和企业招聘等环节，促进业界和学界的交流。活动将在机器之心和黄大年茶思屋平台直播，感兴趣的企业也可联系合作。
前特斯拉Optimus科学家跳槽HF，直接开源了一个机器人代码库,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917136&idx=4&sn=bd7acd66ab24e7094cf0921013602f80&chksm=84e40d6eb39384781f06af76093a6add2c991aaa34e79892d9275baf4dcdd1df0a165f40a542#rd,2024-05-08 00:27:18,AI初创公司Hugging Face推出了开源机器人项目LeRobot，这是一个基于大规模众包机器人数据集的工具包，被誉为机器人领域的“Transformers”。LeRobot提供了一个全面的平台，包括用于共享、可视化数据和训练SOTA模型的库，支持预训练模型以加速项目启动，并与物理模拟器集成，允许开发者在虚拟环境中测试AI模型。该项目旨在创建一个适应和控制各种形态机器人的AI系统，促进机器人技术的多功能性和可扩展性。通过LeRobot，用户可以训练机器人执行抓取物体、导航等任务。Hugging Face希望通过降低入门门槛和促进资源共享，构建一个重新定义AI机器人领域的社区。
低质多模态数据融合，多家机构联合出了篇综述论文,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917136&idx=5&sn=ee3e45e8b091783e9016b8a8ba0cbce4&chksm=84e40d6eb39384787ce8d63850e0fe7d487a87c304cf307ee3a2f39ace99ea9a5b59d94c1e17#rd,2024-05-08 00:27:18,该文章是关于多模态数据融合的综述，特别是关注低质量多模态数据的融合问题。多模态融合旨在利用不同模态的信息提升任务性能，但在现实场景中，数据往往存在噪声、缺失、不平衡和动态质量变化等挑战。文章详细介绍了针对这些挑战的现有方法，包括去噪、缺失数据融合、平衡多模态融合和动态多模态融合，并对未来的研究方向进行了展望。具体方法包括加权融合、联合变分去噪、模型过滤、基于补全的融合、无需补全的融合、注意力机制和不确定性感知的动态融合等。
智能计算加速搜索，中国天眼FAST寻获球状星团中迄今最长周期脉冲星,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917057&idx=1&sn=2a214fe6274c12fb23b1f44379865f80&chksm=84e40cbfb39385a955d507d1924ad737690353c4dd44eaf7165d25a915243fd7782a54f4597e#rd,2024-05-07 13:03:36,研究人员使用中国天眼FAST望远镜在球状星团M15中发现两颗长周期脉冲星，自转周期分别为1.9秒和3.9秒，其中M15L是目前球状星团中已知自转周期最长的脉冲星。这一发现揭示了球状星团脉冲星的新的演化路径，并补全了对球状星团长周期脉冲星搜索的了解，对于研究星族演化具有重要意义。此前，长周期脉冲星的探测极具挑战性，因为它们的信噪比低且易受红噪声干扰。研究团队通过新的搜索方案和数据处理技术，包括优化的消色散软件和AI视觉模型，成功筛选出这些脉冲星。这一成果已发表在《中国科学：物理学 力学 天文学》期刊上。
速读60万字《马斯克传》、手机一键生成PPT，零一万物上线AI生产力工具「万知」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917057&idx=2&sn=ab043ec09e71efd758de40faf366fb2e&chksm=84e40cbfb39385a9e3dfb05acb7c798aeef754a82ec92555adfc50f0cc56d47a0266c38e3be0#rd,2024-05-07 13:03:36,零一万物推出了一款名为“万知”的AI工作平台，该平台提供会议纪要、周报、写作助手以及文件解读和PPT制作等功能，支持中英双语，完全免费。万知利用AI技术解决用户在工作中“找、读、写”的需求，具备AI知识问答、AI读文档和AI创作PPT三大秘技，能快速处理大量信息并生成内容。万知还邀请李开复博士担任首席体验官，收集用户反馈并提供使用教程。该平台旨在提高个人工作效率，尤其在知识检索、文档整理和撰写方面，平均能提升效率五成以上。万知已为国内职场量身定制，支持移动和PC端协同使用，目标用户包括职业白领和大学生。
爆火后反转？「一夜干掉MLP」的KAN：其实我也是MLP,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917057&idx=3&sn=220ba3ef065ae7422b9e1fae05c69c98&chksm=84e40cbfb39385a9ee534fe0bcea9356df311bc669b51b8978b82c8238109295f677ddef71d6#rd,2024-05-07 13:03:36,多层感知器（MLP）是深度学习的基础，但近期来自MIT等机构的研究者提出了一种名为KAN（Kernelized Attention Networks）的替代方案，它在准确性和可解释性上表现出色，且能以更少的参数量超越MLP。然而，一篇名为《KAN is just MLP》的Colab文档引发争议，指出KAN可以通过在ReLU前添加重复和移位操作转换为MLP。尽管KAN的可解释性受到认可，但其方法和MLP之间的关系引发讨论，一些研究者认为KAN并非全新的架构，而是已有思想的重新包装。论文作者强调KAN的初衷在于可解释性，并欢迎对其的批评和讨论，认为实验是检验技术有效性的关键。
一块钱100万token，超强MoE模型开源，性能直逼GPT-4-Turbo,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917057&idx=4&sn=2d3225438117cdea15e417b6aa6b3d1e&chksm=84e40cbfb39385a9f367174f0721a69e4cacb0eb88a7ccc960029abe75285eb677ac938f87d7#rd,2024-05-07 13:03:36,DeepSeek AI公司开源了一款名为DeepSeek-V2的混合专家（MoE）语言模型，特点是训练成本低、推理效率高。该模型拥有236B参数，每个token激活21B参数，支持128K token的上下文长度。与前代DeepSeek 67B相比，DeepSeek-V2在性能增强的同时，训练成本降低了42.5%，KV缓存减少了93.3%，最大生成吞吐量提升5.76倍。在AlignBench基准上，DeepSeek-V2超过GPT-4，接近GPT-4-turbo；在MT-Bench中与LLaMA3-70B相当，并优于Mixtral 8x22B。此外，DeepSeek-V2在数学、代码和推理方面的表现也十分出色。在价格方面，DeepSeek-V2 API的定价比GPT-4-Turbo低约百分之一。模型采用创新的多层注意力（MLA）和DeepSeekMoE架构，以实现高效推理和经济的训练成本。DeepSeek-V2在多项英文和中文基准测试中表现出色，成为最强的开源MoE语言模型。
让机器准确「看懂」手物交互动作，清华大学等提出GeneOH Diffusion方法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917057&idx=5&sn=28c4c1f15e277068d6c5229351c0b883&chksm=84e40cbfb39385a94b87ef39f454aa03e7b8c5fbc98165c363fe52bdb1f33769e8ed51678f6c#rd,2024-05-07 13:03:36,清华大学、上海人工智能实验室和上海期智研究院的研究人员提出了一种名为GeneOH Diffusion的新方法，用于改善手和物体交互（HOI）过程中的噪声问题。该论文已被ICLR 2024接收。GeneOH Diffusion是一种去噪技术，旨在减少机器理解手物交互时因遮挡、光线变化等产生的误差。研究中，他们设计了一种名为GeneOH的序列表征，以广义接触点为中心参数化交互信息，增强了模型的泛化能力。此外，他们使用扩散模型进行先扩散后去噪的处理，提高了模型对复杂噪声的适应性。GeneOH Diffusion仅在有限的数据上训练，但能有效泛化到新的交互序列和真实世界的复杂噪声中。该技术有潜力应用于AR、VR和机器人等领域，提升数据质量和下游任务的性能。
特斯拉Optimus人形机器人进厂打工，娴熟分装电池、自我矫正，还能走更远了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916895&idx=1&sn=afa5259c2cf2e33854d443b7ee567bdf&chksm=84e40c61b393857771ff285696afa29afadf5f20ba489fde272dc344cba3ad3cf18b1221e924#rd,2024-05-06 11:52:04,特斯拉Optimus人形机器人展示了新的进步，开始在特斯拉电池工厂进行工作，学会了分装电池。二代Optimus使用端到端神经网络进行实时操作，能准确插入电池并具备自主恢复能力。通过人类远程操作收集训练数据，Optimus在工厂中的人工干预率持续下降，行走速度和稳定性也有所提高。目前，Optimus正在执行更复杂的任务，如分类物体，且其手部将增加到22个自由度。特斯拉计划让Optimus在今年底具备完成有用工厂任务的能力，并可能在2025年底前对外销售。
2024年WAIC·云帆奖启航：擎启AGI时代，集结超越边界的探索者,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916895&idx=2&sn=6a0b16275ac5ceeb4c62b16d10d087ff&chksm=84e40c61b39385770d1ceb8d67b501c8ec8ab76f868f3d963da9faff0dd9425c31f676fe9a98#rd,2024-05-06 11:52:04,2024年WAIC·云帆奖旨在全球范围内寻觅和表彰人工智能领域的杰出青年技术人才，聚焦通用人工智能（AGI）领域的创新者。该奖项由机器之心等机构负责评选，自2020年设立以来已评选出98位获奖者，对AI发展作出积极贡献。今年的主题为「超越与联结」，设置「璀璨明星」和「明日之星」两大榜单，分别评选出35岁以下的杰出技术人员和30岁以下的潜力人才。评选流程从即日起至5月24日接受报名和提名，颁奖典礼将于2024年7月6日在世界人工智能大会期间举行。此外，还将举办五周年嘉年华等活动，促进全球AI领域的交流与合作。
LeCun上月球？南开、字节开源StoryDiffusion让多图漫画和长视频更连贯,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916895&idx=3&sn=ae97d566213de7a5260b812e50395ed2&chksm=84e40c61b39385774fbbaecef762224f935c72c0861034c35050218e1207a60c2c0fcef55731#rd,2024-05-06 11:52:04,南开大学、字节跳动等机构的研究团队提出了一种名为 StoryDiffusion 的新方法，用于生成一致的图像和视频以讲述复杂故事。该方法通过一致性自注意力（Consistent Self-Attention）在生成图像时建立批内图像之间的联系，保持人物一致性。此外，语义运动预测器 (Semantic Motion Predictor) 被用于预测语义空间中的运动，生成高质量的视频。StoryDiffusion 可以生成主题一致的图像和视频，相比现有方法，其视频生成更流畅、连贯。该研究已在 GitHub 上开源。
仅用250美元，Hugging Face技术主管手把手教你微调Llama 3,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916895&idx=4&sn=64a4924517528a21f58a0d08ac1593d2&chksm=84e40c61b39385773603232734b097c8b5920ac7aa3bd19ced5802083d0c7aa15e566846b898#rd,2024-05-06 11:52:04,本文介绍了如何利用Hugging Face的库和fsdp以及Q-Lora对大语言模型，如Llama 3，进行微调。Hugging Face技术主管Philipp Schmid详细阐述了微调步骤，包括设置开发环境、创建和加载数据集、使用PyTorch FSDP、Q-Lora和SDPA进行微调，以及测试模型和推理。Q-Lora是一种微调方法，结合FSDP可以有效减少计算需求和内存占用，使得在消费级GPU上对大型模型进行微调成为可能。文章还提供了代码示例和配置文件，帮助读者实践这一过程。
看透物体的3D表示和生成模型：NUS团队提出X-Ray,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916895&idx=5&sn=58e029cae7097a6de369c73d23d55ef9&chksm=84e40c61b39385779dfe1aa5a5a312c4ce9a27b2235e1074321b0fc4d126d1964b1f192fd7cb#rd,2024-05-06 11:52:04,新加坡国立大学的研究团队开发了一种名为X-Ray的新型3D表示方法，它能够序列化地表示物体的逐层次表面形状和纹理，从而实现3D物体的高效生成，同时展示物体的内外结构。这一技术受到X射线穿透记录物体信息的启发，可以利用视频生成模型的优势来创建3D模型，克服了现有3D模型生成技术的复杂性和局限性。X-Ray表示将3D模型转化为与视频格式相似的序列，可以被现有视频生成模型处理，简化了3D生成过程。通过X-Ray编码和解码，可以将3D模型和X-Ray互相转换。研究团队使用视频扩散模型和上采样技术来生成高分辨率的3D模型，实验结果表明这种方法在3D模型生成中具有潜力。未来，X-Ray技术有望在AR/VR、教育、医疗影像等领域有广泛应用。
12年前上手深度学习，Karpathy掀起一波AlexNet时代回忆杀，LeCun、Goodfellow等都下场,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916807&idx=1&sn=c8ef8b74800944f3afcd04701a8ec16d&chksm=84e403b9b3938aaf7c9835178f41bf193721e5f8be08d8f278a195b9a4cce482301111d6f9dc#rd,2024-05-05 12:22:48,这篇 文章 回顾了深度学习历史上的重要事件——2012年AlexNet在ImageNet竞赛中的胜利，这场胜利开启了深度学习革命。AlexNet的代码是由Alex Krizhevsky用CUDA/C++从头编写的，这是深度学习利用GPU加速计算的一个早期例子。这个帖子引起了AI界许多知名人士的共鸣，他们分享了自己在2012年前使用各种工具进行深度学习研究的经历，包括Torch、Theano和Matlab。文章强调了AlexNet的成功如何预示了深度学习向更大规模和更强计算能力发展的趋势，并指出在需要最优性能时，研究人员仍可能需要回到基础，用低级语言如CUDA/C++编写代码。
LeCun哈佛演讲PPT放出：唱衰自回归LLM，指明下一代AI方向,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916807&idx=2&sn=75db0431064c449a6215a88de89c2a7c&chksm=84e403b9b3938aafc9535b471983ce9138e6ba1aa5c184851349a12e55adb0e5e236a26bfdb4#rd,2024-05-05 12:22:48,知名AI学者Yann LeCun在哈佛大学的演讲中表达了对自回归大语言模型（LLM）的批评，认为它们存在事实错误、逻辑错误、不一致性和有限的推理能力，且无法理解世界运作方式和进行规划。LeCun提出一个模块化的认知架构，其核心是可预测的世界模型，通过自监督学习训练的分层联合嵌入预测架构（H-JEPA）来实现。他主张放弃自回归模型，转向联合嵌入架构，支持基于能量的模型（EBM）和模型-预测控制。演讲中，LeCun强调AI应朝着学习、记忆、推理、规划、有常识和安全的方向发展，并认为开源AI是必要的，但需要监管以确保安全。
告别偏科，能玩转多模态、多任务、多领域的强化智能体终于来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916807&idx=3&sn=4ab713744efefcd584c91fe0fcb60885&chksm=84e403b9b3938aaf2740fac2e59a0d4ea297cc4f02a6e3a18bcc89b598f3942c33c7aa7f4a1c#rd,2024-05-05 12:22:48,研究人员提出了一个名为Jack of All Trades (JAT)的多模态通用强化学习智能体框架，旨在解决创建能够处理多种任务和数据类型的全能型智能体的问题。JAT基于Transformer架构，能够适应不同的数据类型，如图像和文本，并在多个任务中表现良好，包括Atari游戏、BabyAI、Meta-World和MuJoCo环境。研究团队还发布了JAT智能体的开源代码、数据集和专家策略，为通用智能体研究提供了新资源。实验表明，通过适当平衡预测观察嵌入和行动嵌入的损失函数，可以提高智能体的学习效率。未来的研究方向包括改进数据质量、使用离线强化学习和优化多任务采样策略。
CVPR 2024 | 借助神经结构光，浙大实现动态三维现象的实时采集重建,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916807&idx=4&sn=09863132d28dbee730ea0d3c85231595&chksm=84e403b9b3938aaf26307b4ee93cb301e297acabc1523a0c0e34c2eed5f29a3cd9a9310bb2e8#rd,2024-05-05 12:22:48,浙江大学计算机辅助设计与图形系统全国重点实验室的研究团队开发了一种新方法，使用AI来优化物理采集和计算重建，实现动态三维密度场的高效高质量重建。该方法通过神经结构光设计，仅使用单个投影仪和少量相机（1或3台）的轻量级硬件原型，将建模单个三维密度场所需的结构光图案数量降至6张，并实现每秒40个三维密度场的采集。研究团队还提出了一种轻量级一维解码器，以提高计算速度，重建单个三维密度场仅需9.2毫秒，比现有技术快2-3个数量级。相关论文已被CVPR 2024接收。
AI可以改写人类基因组吗？首次由AI从头设计的基因编辑器成功编辑人类细胞中DNA,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916807&idx=5&sn=d3c51c27811f498515d2c642f2ba8635&chksm=84e403b9b3938aaf26cde02bf522aa088daee9aa43ec8ee1f7c5faede12cbc7a502efe050cfd#rd,2024-05-05 12:22:48,美国AI蛋白质设计公司Profluence推出了OpenCRISPRTM计划，发布了世界上第一个由AI生成的开源基因编辑器。该技术基于AI分析大量生物数据，包括已有的基因编辑机制，创造出新的、定制化的基因编辑工具。Profluence展示了其AI设计的基因编辑器OpenCRISPR-1成功精确编辑人类基因组的案例。这一技术扩展了CRISPR家族的多样性，通过高效搜索蛋白质序列变异，AI可以在几小时内完成自然进化需要很长时间的任务。OpenCRISPR-1的脱靶编辑率显著降低，提高了基因编辑的特异性。该公司开源了OpenCRISPR-1，以促进基因编辑技术的研究和广泛应用。
斯坦福李飞飞首次创业：学术休假两年，瞄准「空间智能」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916787&idx=1&sn=2f16dc51a9d68e5695259fecc2121bc3&chksm=84e403cdb3938adb7ef37175c7e4f02f5a8ccee98bddbb61b39b6434d26bf52bbefdd23674c2#rd,2024-05-04 12:11:02,知名AI专家李飞飞创立了一家初创公司，利用类似人类的视觉数据处理方式提升AI的高级推理能力。据悉，李飞飞已完成种子轮融资，投资者包括Andreessen Horowitz和 Radical Ventures。李飞飞以开发ImageNet数据集而知名，曾任斯坦福大学以人为中心人工智能研究所联合主任和谷歌云AI部门负责人。她的新公司专注于空间智能，即让算法能够理解并预测三维环境中的图像和文字，并据此采取行动。此方向与她近期关于教计算机在三维世界中行动的研究工作相符。
瑜伽球上遛「狗」！入选英伟达十大项目之一的Eureka有了新突破,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916787&idx=2&sn=823b0a92cff343a2194874f1de87d5a0&chksm=84e403cdb3938adbf68cf48448842d6f298d8059b228d88f485110d9dd610bfd533022b27b50#rd,2024-05-04 12:11:02,研究人员提出了一种名为DrEureka的新算法，利用大型语言模型（LLM）实现奖励设计和域随机化参数配置，以实现模拟到现实的机器人技能迁移。该算法能够解决四足机器人在瑜伽球上行走等复杂任务，无需手动设计和调整。DrEureka基于Eureka，并在模拟环境中训练机器狗，然后直接将其技能迁移到现实世界，无需微调。通过利用LLM的物理直觉，DrEureka可以自动调整模拟参数，实现对各种地形的适应。实验结果显示，这种方法比使用人工设计的奖励和DR配置的策略更具鲁棒性。论文和相关项目已经开源。
ChatGPT们的幕后先驱，斯坦福教授Manning的四十年NLP生涯,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916787&idx=3&sn=7d568ce5b03dfb1e21a9e576756e30a7&chksm=84e403cdb3938adbb3d94ac8fd7111ffc5474267bccaf67a505bac18cddd1fa2465053f0874a#rd,2024-05-04 12:11:02,这篇文章介绍了自然语言处理（NLP）领域的著名学者Christopher Manning，他因其在深度学习应用于NLP方面的开创性工作获得了2024年度IEEE冯诺伊曼奖项。Manning教授在词向量模型、注意力机制、机器翻译等多个领域做出了重要贡献，并专注于让计算机能智能处理人类语言。他的研究对NLP领域产生了深远影响，包括预训练自监督模型，他也是斯坦福大学Human-Centered人工智能研究所的共同创始人。文章还提到，Manning教授早期就预见到了从语言数据中学习的重要性，并在统计机器学习和神经网络方面做出了关键的早期工作，这些为现代大语言模型的发展奠定了基础。此外，他还致力于创建可访问的NLP软件，推动了开源NLP软件库的发展。
ICLR 2024 Spotlight | 无惧中间步骤，MUSTARD可生成高质量数学推理数据,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916787&idx=4&sn=cd0a3be1bf60b9ee4c6245839ead428f&chksm=84e403cdb3938adbe3ff7a3854479b262207f046ebd86213ae2c7cdf025a7cbf0646d489a1b1#rd,2024-05-04 12:11:02,研究人员提出了一个名为MUSTARD的框架，用于自动合成大量、正确且人类可读的数学推理数据，以促进大型语言模型在数学应用题和定理证明等任务上的能力。该框架包含概念采集、数据生成和形式化验证三个阶段，利用形式化证明器来验证和修正生成的数据。通过人工评价和模型微调实验，MUSTARD生成的数据被证明能有效提高模型的数学推理性能。此外，研究团队还基于MUSTARD数据集组织了自动形式化和非形式化等挑战赛。
平均准确率达96.4%，中山大学&重庆大学开发基于Transformer的单细胞注释方法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916787&idx=5&sn=63f7dbc57284146eff4ee2a8ae6095f6&chksm=84e403cdb3938adb1b61c629544cb25fd9dd20b4746d7fd325d02b16b15b8267d41e9158e41c#rd,2024-05-04 12:11:02,研究人员提出了一种名为SANGO的新方法，用于通过整合单细胞ATAC-seq（scATAC-seq）数据中的开放染色质峰及其周围基因组序列信息来准确地注释单细胞类型。SANGO利用深度学习模型和图Transformer网络，考虑了每个开放染色质峰的基因组上下文，提高了细胞注释的准确性。在多种数据集上，SANGO的表现优于其他竞争方法，证明了其在单细胞类型识别任务上的优越性。此外，SANGO还能检测未知的肿瘤细胞，为研究肿瘤微环境提供了新工具。该研究已发表在《Nature Computational Science》上。
终于有人调查了小模型过拟合：三分之二都有数据污染，微软Phi-3、Mixtral 8x22B被点名,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916751&idx=1&sn=688a42c1b4eb012436134a2af5a10259&chksm=84e403f1b3938ae719c2a59a30576d409ea6b484d584a0a643c50775b4e0cf39a9c7befa35a5#rd,2024-05-03 12:40:33,Scale AI的一项新研究表明，许多大型语言模型（LLM）存在过拟合问题，这意味着它们在基准测试中的表现可能被高估。研究发现，包括OpenAI的GPT-4和一些知名的小型模型在内，在未经污染的新数据集GSM1k上的表现显著下降。GSM1k是一个由人工注释的小学数学题目集，旨在避免数据污染。结果表明，某些模型在GSM1k上的性能比在GSM8k上低13%，其中Mistral和Phi系列模型显示出明显的过拟合证据。然而，Gemini、GPT、Claude和Llama2系列的过拟合迹象较轻。研究者呼吁更多关注模型的泛化能力和避免数据污染的方法。
2023 IBM博士生奖学金华人占六成：Vicuna作者吴章昊、清华特奖得主高天宇入选,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916751&idx=2&sn=d1f6ecd11d330345e6c405e95bb52977&chksm=84e403f1b3938ae7ba8c844fd8ea50a0b0088d91624303fdd392e4666cd4cfb133e46bd05c15#rd,2024-05-03 12:40:33,这篇文章报道了2023年IBM博士生奖学金计划的获奖情况，共有10位优秀博士生获奖，其中6位是华人。这些获奖者在人工智能、混合云技术、量子计算和负责任及包容性技术等领域有突出研究。文章列举了6位华人获奖者的个人信息和研究方向，包括他们在顶尖大学的学习和研究成果。这些博士生在人工智能、自然语言处理、机器学习、可视化和人机交互等交叉领域展现出卓越的才华。
小模型性能饱和、表现不佳，根源是因为Softmax?,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916751&idx=3&sn=e52fdf770476246f601857b2c2cb97cd&chksm=84e403f1b3938ae7a9ffe916c6fa3c766dda6625330f20bfdd59d1ce390728acc04f8ffe271e#rd,2024-05-03 12:40:33,这篇论文探讨了小语言模型在训练到一定阶段后性能下降（饱和现象）的原因。研究发现，这种现象可以归因于小模型的隐藏维度与目标上下文概率分布的高秩之间的不匹配，以及softmax瓶颈问题。softmax瓶颈影响了小模型中线性预测头的性能，特别是在隐藏维度小于1000时，模型在预训练后期可能出现退化的潜在表征，导致性能降低。论文通过理论和实证分析证明了线性语言建模头成为了小隐藏维度架构的性能瓶颈，并提出了相关证据和实验结果来支持这些发现。
CVPR 2024 Highlight | 基于单曝光压缩成像，不依赖生成模型也能从单张图像中重建三维场景,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916751&idx=4&sn=ae72bae97c0a7a971fac145560c80725&chksm=84e403f1b3938ae78e8eef675355b84913927b83a6fdb7b83f074a6b9b3967bdb264afd537bf#rd,2024-05-03 12:40:33,"本文介绍了一种新的三维场景重建方法，名为SCINeRF，它结合了单曝光压缩成像（Snapshot Compressive Imaging, SCI）和神经辐射场（NeRF）技术。传统的3D重建算法需要多张图片，而SCINeRF仅需一张压缩图像就能重建3D场景，无需依赖预训练的生成模型。它利用SCI系统在单次测量中记录多视角图像信息，然后通过NeRF进行3D重建。这种方法提高了重建的准确性、稳定性和泛化性，能够生成高质量的3D场景和高帧率图像。实验表明，SCINeRF在合成和真实数据集上的表现优于现有方法，具有广泛的应用前景，如高速3D摄像和图像压缩。"
辉瑞 AI 方法登 Science，揭示数以万计的配体-蛋白质相互作用,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916751&idx=5&sn=d9f79470b278b95cac0444aebd3a4eba&chksm=84e403f1b3938ae7f75084edf6a4500db39688852f00e5ecd70bb6a6608239bc57d13b74643f#rd,2024-05-03 12:40:33,奥地利科学院分子医学研究中心CeMM的研究人员与辉瑞合作，开发了一种新方法，可以预测数百种小分子与数千种人类蛋白质的结合活性。这项大规模研究揭示了数以万计的配体-蛋白质相互作用，为开发化学工具和治疗方法提供了可能。利用化学蛋白质组学方法，研究人员绘制了人类蛋白质组中蛋白质-配体相互作用的图谱，并通过机器学习和人工智能模型预测其他小分子与活细胞中蛋白质的相互作用。所有数据和模型都通过开源网络应用程序免费提供，以促进药物发现研究。这项研究发表在《Science》杂志上。
跨越300多年的接力：受陶哲轩启发，数学家决定用AI形式化费马大定理的证明,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916710&idx=1&sn=d57026e4b00e740fe8519f89e85d4550&chksm=84e40318b3938a0ebacab509dadf3a7d479319bacc7642df8bfae6d3644fbe8d6b8869cb6689#rd,2024-05-02 16:34:23,数学家正在尝试使用人工智能（AI）来形式化费马大定理的证明。费马大定理是世界十大最顶尖数学难题之一，由17世纪数学家皮耶·德·费马提出，直到1995年才由安德鲁·怀尔斯教授证明。形式化证明意味着将证明转换为可以在计算机上理解和验证的形式语言。数学家Kevin Buzzard计划使用交互式定理证明器Lean来完成这一任务，旨在将现代数学的这一重要成就数字化，以便于计算机理解和应用，同时也为未来AI在数学研究中的应用打下基础。该工作将涉及将复杂的数学概念如自守形式、伽罗瓦表示和模性提升定理等在Lean中实现。该项目已经启动，并且是众包性质的，任何人都可以贡献自己对证明中部分小引理的形式化。
Transformer要变Kansformer？用了几十年的MLP迎来挑战者KAN,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916710&idx=2&sn=28024640e081228cc5887ad8c4aae8a3&chksm=84e40318b3938a0e59322f7218226155f5ad6fdee7e128774f909b8385ed05a9ad419e84d15e#rd,2024-05-02 16:34:23,本文介绍了一种名为Kolmogorov-Arnold Networks（KANs）的新型神经网络结构。KANs的灵感来源于Kolmogorov-Arnold表示定理，与传统的多层感知器（MLP）不同，KAN在边（权重）上放置可学习的激活函数而非节点上，从而避免了线性权重矩阵的使用。尽管每个MLP权重参数在KAN中被一个样条函数替代，但KAN的计算图比MLP更小，参数效率更高。研究表明，KAN在某些任务中比MLP更准确且具有更好的可解释性。尽管KAN的训练速度较慢，但其在准确性和可解释性方面的优势使其成为深度学习领域的一个有前景的替代选择。
热归热，Groq离取代英伟达GPU有多远？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916710&idx=3&sn=8aed48ad3c2723293f9ce56e3d2b5a1b&chksm=84e40318b3938a0e09e80aa85bb396b28ee889669efa8297ca207f4df9819bf4d3c2f8ada547#rd,2024-05-02 16:34:23,本文提到初创公司Groq在2024年4月20日宣布，其LPU推理引擎已部署Meta的Llama 3的8B和70B版本，每秒输出token数提升至800，远超英伟达GPU的性能且成本更低。Groq的LPU在运行开源模型Mixtral时展示出高效能，能在1秒内提供数百个单词的事实性答案。与GPT-4和Genimi相比，Groq在简单代码调试问题上的速度更快。LPU是一种专为计算密集型应用设计的处理单元，采用张量流处理器架构，提供高效能和能源效率。尽管一些专家指出Groq硬件的成本和能耗可能高于英伟达GPU，但也有观点认为Groq在特定场景下可能更具成本效益。这引发了关于Groq是否可能取代GPU的讨论，并可能预示着AI芯片市场正从训练转向推理。文章并未提及英伟达股价是否受此影响。
邮件曝光，微软为追谷歌脚步才投资了OpenAI，纳德拉回应：才不是,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916710&idx=4&sn=e58e432f3188ea3831bfb90544246a10&chksm=84e40318b3938a0e1626022a68b2a2e3b8ce80bc2d11e1038384bcf01c0284f7afb3b2a27570#rd,2024-05-02 16:34:23,微软与OpenAI之间的关系密切，微软曾向OpenAI投资超过130亿美元。微软首席技术官Kevin Scott在2019年的内部邮件中警告，谷歌在人工智能方面已大幅领先，如果不投资OpenAI，微软可能无法追赶。这封邮件促使微软不久后投资OpenAI。微软与OpenAI的合作有助于其在AI领域保持竞争力，但同时也引发内部资源倾斜和员工不满，甚至有高管因此离职。目前，欧盟曾疑虑微软对OpenAI的控制，但已撤销调查。在谷歌的反垄断案中，微软与OpenAI的合作被提及，微软表示与OpenAI合作是为了加速AI创新，而谷歌认为其垄断地位阻碍了OpenAI等公司的创新。
Meta 联合纽约大学和华盛顿大学提出MetaCLIP，带你揭开CLIP的高质量数据之谜。,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916710&idx=5&sn=0ea56c5f3bc279e61988dfd7d4331924&chksm=84e40318b3938a0eab594026efe256e1ea2e4ce112d949228040419bfb678ff4b8c893d3a8a1#rd,2024-05-02 16:34:23,这篇论文介绍了MetaCLIP，一个元数据导向的CLIP预训练方法，旨在揭示CLIP模型成功的数据质量因素。研究发现，CLIP的高质量源于其数据处理，而不是模型或损失函数本身。MetaCLIP提出了一种数据算法，通过元数据字符串匹配和平衡数据分布来提取高质量的人类监督文本，同时保留长尾数据的信号并减少噪声。实验表明，这种方法在不同数据规模上都能生成高性能的模型，且优于已有的CLIP实现。论文提供了数据处理的透明度，为研究社区提供了更深入理解CLIP数据处理的途径。
爆款生成式AI硬件，销量突破10万台，拆完一看只是安卓app？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916644&idx=1&sn=32208e45f63139af4d03204c6a1b5fb6&chksm=84e4035ab3938a4c035e86fe44c2f98d54ee1dd65ab47a84b2de9d881def67d6059d3c646c23#rd,2024-05-01 13:04:12,这篇报道介绍了美国记者Mishaal Rahman如何在Pixel 6a手机上成功运行了疑似基于Android的Rabbit R1应用程序。Rabbit R1是一款由Rabbit公司推出的AI智能设备，它运行在被称为Rabbit OS的操作系统上，该系统基于大型动作模型（LAM）。尽管设备设计独特，但有人指出R1的功能大部分可以通过智能手机和应用程序实现。最近的发现显示，Rabbit R1的操作界面可能只是一个在Android系统上的应用程序，可以在其他手机上安装使用。Rabbit公司的创始人回应称，Rabbit R1并非简单的Android应用，并强调其操作系统和云服务的定制性。尽管存在争议，Rabbit R1自发布以来销量已超过10万台，其便捷性和AI功能仍受到部分用户的欢迎。
余承东卸任华为终端BG CEO，何刚将接任,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916644&idx=2&sn=d830730ef63ecafe85df6ee036caeb72&chksm=84e4035ab3938a4c524239ed0c162d6c87799aab24759cf6f0218c8fdb2b09b2372d2ea80532#rd,2024-05-01 13:04:12,华为内部发布人事调整文件，余承东卸任华为终端 BG CEO，但仍保留终端 BG 董事长职位。何刚将接任华为终端 BG CEO，他此前担任华为终端 BG 首席运营官。余承东自 2011 年开始担任华为终端公司的 CEO，此次调整被视为常规业务架构调整，以便余承东能更专注于打造消费者精品。华为第一季度营业收入约 1784.5 亿元，同比增长 36.66%，归母净利润约 196.5 亿元，同比增长约 564%。在新年信中，余承东提到 2024 年是原生鸿蒙关键一年，将加快推进鸿蒙原生应用开发。
「用 AI 训 AI」这事靠谱吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916644&idx=3&sn=a390e2507da0f97ada3815da33326540&chksm=84e4035ab3938a4c230627e417f94feba12bc68e7abf42065d5cc21792e4e04706babeb301a7#rd,2024-05-01 13:04:12,"这篇文章讨论了大语言模型领域的一个新进展，即自我奖励语言模型（Self-Rewarding Language Models, SRLMs）。传统上，强化学习中的奖励模型需要外部反馈，但SRLMs能够生成并评估自己的微调数据，从而减少对外部模型的依赖。这个方法在微调Llama 2 70B模型后，在AlpacaEval 2.0排行榜上表现优于其他大模型。SRLMs的创新之处在于它们在训练过程中同时进行指令跟随和自指令创建，通过“LLM-as-a-Judge”机制实现自我评估。与依赖人类反馈的RLHF不同，SRLMs在训练中不断更新，提升了自我改进的能力。此外，文章还提到了与RLAIF（Reinforcement Learning from AI Feedback）的比较，RLAIF使用AI反馈来扩展强化学习，但SRLMs更侧重于模型的自我迭代和对齐。虽然使用AI生成的数据存在风险，如“哈布斯堡诅咒”，但这种方法为训练更大规模和更高效的模型提供了可能性。"
参数量不到10亿的OctopusV3，如何媲美GPT-4V和GPT-4？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916644&idx=4&sn=4b2049cea45e8581ed95922858e33a1d&chksm=84e4035ab3938a4c4a1fa0f1b9d885df4ad5ab8d89df38f3d3bb70dafe49b67c181a6ce7df47#rd,2024-05-01 13:04:12,这篇论文介绍了一个名为Octopus v3的多模态AI模型，该模型设计用于边缘设备，参数量优化至10亿以内，能够同时处理英文和中文。模型引入了“functional token”的概念，用于将图像信息转化为可执行动作。通过多阶段训练，Octopus v3能够整合视觉和语言信息，并在资源受限的设备如树莓派上高效运行。实验表明，该模型在处理智能手机API等任务时表现出与GPT-4V和GPT-4组合相媲美的性能。该模型的开发对于实现小型、高效的多模态AI系统具有重要意义，可应用于各种领域，包括智能家居、虚拟助手和自动驾驶等。研究者鼓励开发者在遵守许可协议的条件下使用和创新该框架。
登Nature子刊，「机器人+AI+MD模拟」加速材料发现和设计，发现全天然塑料替代品,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916644&idx=5&sn=9e26866f022ba035fdbb86d90708fe84&chksm=84e4035ab3938a4c33c8b90c0af31706e5f567a23c664733fb59d7976bfd0c3a981c890a53ca#rd,2024-05-01 13:04:12,马里兰大学的研究人员结合机器人技术和机器学习，提出了一种集成工作流程，加速环保塑料替代品的发现和设计。他们开发的机器学习模型与自动化机器人技术相结合，通过主动学习循环提高了预测材料特性的准确性，减少了寻找可生物降解且性能理想的全天然塑料替代品所需的时间和资源。研究中，模型成功预测了多种纳米复合材料的性能，并用于设计特定性能的塑料替代品。这一方法有助于减少塑料污染，为解决环境问题提供了新途径。
神秘GPT模型引爆社区，GPT-4.5、GPT-5谣言满天飞，奥特曼在线围观,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916474&idx=1&sn=97ab1ac4e6d19761a50872efd9d32f09&chksm=84e40204b3938b127a35e4bf8c0b2c7faff69788c60b2b1a9c7c20ebc8c1e70fd45590d06977#rd,2024-04-30 12:28:03,近日，AI领域热议的GPT-5模型引发关注，但OpenAI的首席执行官奥特曼表示，OpenAI采用迭代部署的方式进行研发，而不是秘密开发直到完成才公布。目前，一个名为“gpt2-chatbot”的神秘模型在LMSYS Chatbot Arena出现，引发广泛关注。该模型自称基于GPT-4架构，由OpenAI创建。虽然其在一些任务上的表现甚至优于GPT-4，但奥特曼的评论暗示它可能与GPT-2有关。网友们对gpt2-chatbot的能力表示赞赏，但也有人认为它可能是GPT-2的微调版本。目前，gpt2-chatbot已达到速率上限，无法立即体验。同时，OpenAI宣布Memory功能现已对ChatGPT Plus付费用户开放。
具身智能最佳形态是什么？它是通往AGI必由之路？八位头部玩家、学者现身说法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916474&idx=2&sn=b62064cc48467370e2ed6aab1a90cb3c&chksm=84e40204b3938b1250c00351639ef57c77330a469f376090a57fc675afc4c9fa217063c2acf7#rd,2024-04-30 12:28:03,这篇文章是关于具身智能的讨论，由北京智源人工智能研究院院长王仲远与七位行业专家进行的对话。他们探讨了具身智能是否是实现通用人工智能（AGI）的必要途径，具身智能是否必须通过人形机器人实现，硬件与软件的发展顺序，数据采集的真实数据与仿真数据的使用，以及具身智能在短期和长期的可能性。专家们还分享了对具身智能未来落地场景的预测，认为工业场景可能是初期的主要应用领域。最后，他们鼓励对具身智能感兴趣的青年才俊加入这一领域，共同推动其发展。
「非常接近GPT-4」的WizardLM-2被微软紧急撤回，有什么内幕？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916474&idx=3&sn=ef93a70cd495a6408f12357f2179a831&chksm=84e40204b3938b12134e4153efea759158c8a319b9b8ae860cc705e6cc1a875999d664deb122#rd,2024-04-30 12:28:03,微软此前开源了一个名为WizardLM-2的大模型，声称其性能可媲美GPT-4，包括三个不同规模的模型。然而，不久后微软撤回了所有相关发布，包括博客、GitHub和HuggingFace上的内容，原因是遗漏了毒性测试。社区对此有多个疑点，如为何删除所有Wizard系列项目，是否因性能接近GPT-4或与OpenAI技术路线冲突。微软团队表示是由于规定要求，且否认了团队被解雇的猜测。该模型的训练采用了人工智能驱动的合成训练系统，包括数据预处理、加权采样和协同教学等步骤。目前，WizardLM-2正在重新进行毒性测试，预计会尽快重新发布。
Python团队还没解散完，谷歌又对Flutter、Dart动手了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916474&idx=4&sn=e9694ab606de208b426f9f956485c825&chksm=84e40204b3938b126d977721fa4b448e775f1a6a511fb6c4137c40663d517c2e86b104439284#rd,2024-04-30 12:28:03,谷歌在开发者大会前裁员，包括Python基础团队、Flutter、Dart等关键团队的员工受到影响。虽然谷歌确认了裁员，但没有提供具体涉及的团队、角色或人数。公司表示，这是为了提高效率和资源对齐，同时减少官僚主义。受影响的员工可以申请谷歌的其他职位。Python团队的裁员特别引起关注，但据报道，被裁的是管理内部Python运行时、工具链和OSS Python相关团队的人员。谷歌强调Python仍将在I/O大会上发布更新，而裁员是为了更好地专注于公司的最大优先事项。
在12个视频理解任务中，Mamba先打败了Transformer,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916474&idx=5&sn=bb719473f265af54f94adba692167859&chksm=84e40204b3938b1266080189fb8004d49140694c6d52db7e667e98a997f93f2f97300478ff57#rd,2024-04-30 12:28:03,南京大学、上海人工智能实验室、复旦大学和浙江大学的研究团队提出了一种名为Mamba的状态空间模型，该模型在处理长序列视频数据方面具有优势，为视频理解领域带来了变革。研究团队构建了Video Mamba Suite，包括14个模型/模块，用于12项视频理解任务的评估。结果显示，Mamba在视频理解和视频-语言任务中展现出强大的潜力，同时实现了效率和性能的理想平衡。这一工作扩展了对状态空间模型在视频理解中应用的探索，为未来的研究提供了新的视角和资源。
人大系多模态模型迈向AGI：首次实现自主更新，写真视频生成力压Sora,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916313&idx=1&sn=25b6caa0ef31e81c24b5079c1be4be61&chksm=84e401a7b39388b15028681ad9c07d55dbc9370a08d5ffa8134e4b992710565108c023e4792b#rd,2024-04-29 12:21:10,这篇文章介绍了人大系初创公司智子引擎在中关村论坛上发布的全新多模态大模型 Awaker 1.0。Awaker 1.0 采用 MOE 架构，具备自主更新能力，是业界首个实现真正自主更新的多模态大模型。在视觉生成方面，它使用了自研的视频生成底座 VDT，打破了大模型落地难的问题。 Awaker 1.0 在多模态理解和生成方面都有显著提升，尤其在视觉问答和业务应用任务上超过了其他先进模型。此外，Awaker 1.0 的自主更新机制包括数据主动生成、模型反思评估和模型连续更新，使其适用于更广泛的行业场景，如具身智能、综合治理和安防巡检。视频生成底座 VDT 展现了 Transformer 在视频生成的潜力，能够模拟物理过程和生成高质量的写真视频。Awaker 1.0 的发布被认为是向通用人工智能（AGI）迈出的重要一步。
首届AI方程式大赛，8圈开了一个小时,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916313&idx=2&sn=9c16f258b81efd4e96a29115888a7584&chksm=84e401a7b39388b1fa2f667553bee07047c3e12594205ff07a181bffc33ee9aeb162bc4c278a#rd,2024-04-29 12:21:10,全球首场自动驾驶大奖赛在阿布扎比的F1赛道举行，8辆拥有相同硬件、仅凭自动驾驶代码差异竞技的赛车参与比赛。尽管在资格赛中，AI赛车展现了一些不熟练和意外情况，如过早刹车、撞墙和偏离赛道，但赛事仍然继续。在正赛中，领先的赛车在第四圈打滑，后续车辆因黄旗禁止超车而停下，最终德国慕尼黑工业大学的TUM赛车在最后一圈完成超车，赢得比赛。这场赛事展示了自动驾驶技术在赛车领域的应用，尽管仍处于早期阶段，但已取得长足进步。
Sora爆红视频幕后：被骗了，用了成吨的后期才有这效果,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916313&idx=3&sn=51d0b18579962e145dc62d6db007b326&chksm=84e401a7b39388b193dd604a452a247ff8fbd76144bfdeaedd624879c3e9cdf94c9d10b8e63f#rd,2024-04-29 12:21:10,加拿大多媒体制作公司 Shy Kids 使用 OpenAI 的人工智能视频大模型 Sora 制作了一段短片《Air Head》，该短片在社交媒体上引起广泛关注。Sora 是一个强大的文本到视频生成模型，但目前仍处于测试阶段，存在一些问题，如颜色一致性、镜头瑕疵等，需要大量后期制作来完善。Sora 的用户界面目前只能通过文本输入触发视频生成，没有实现多模态输入，且每次生成的结果可能不同，难以确保内容一致性。《Air Head》的制作过程中，团队通过编写详细的描述来尽量保持角色和场景的一致性。短片中的视频片段经过后期处理、提高分辨率等步骤，以增强视觉效果。尽管 Sora 在视频生成上展现出潜力，但它在理解摄像机运动、镜头控制等方面还有待改进，且需要大量尝试和后期编辑来完成最终作品。OpenAI 表示，Sora 目前的技术水平相当于视觉模型新范式的 GPT-1 阶段，还有很长的路要走。
亚马逊研究奖获奖名单出炉：谢赛宁、Mamba作者Albert Gu等入选,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916313&idx=4&sn=4cf2f30729a17e55c3728c6c21adedb5&chksm=84e401a7b39388b151797e7e6e2fbe0be459570d6e351591f0c030027121a57aa652a0a00172#rd,2024-04-29 12:21:10,"2023年亚马逊研究奖（Amazon Research Awards, ARA）揭晓，共有98位来自15个国家51所大学的学者获奖，相比去年的79位有所增加。该奖项旨在为学术研究人员在多个学科研究主题上提供不受限制的资金支持。获奖者可以访问亚马逊的公共数据集、使用AI/ML服务和工具，并有机会与亚马逊专家合作。获奖者的研究领域包括人工智能信息安全、自动推理、AWS人工智能等。今年的获奖者名单中还包括多位华人学者，他们在网络安全、大规模机器学习等领域有杰出贡献。"
CVPR 2024 | 文本一键转3D数字人骨骼动画，阿尔伯塔大学提出MoMask框架,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916313&idx=5&sn=656ea91c78e2e663c34ab4402efa4f58&chksm=84e401a7b39388b1db2c07a1c3ad8782892f98eeeff3f00cf5e69e90276da8d9e9e8b476550f#rd,2024-04-29 12:21:10,这篇文章介绍了来自阿尔伯塔大学研究团队提出的新一代Text2Motion框架MoMask，该框架可以基于文本描述生成高质量的3D人体动作骨骼动画。MoMask利用生成式掩码技术和多层离散化动作表示，能够在没有昂贵动作捕捉设备或专业动画师的情况下，根据文本生成精细的3D动作。该模型在HumanML3D数据集上达到了优秀的生成质量，FID值为0.045，超过现有最优工作。MoMask已被CVPR 2024收录，其代码和模型已在GitHub上开源。该框架包含残差量化模型、Masked Transformer和Residual Transformer三个关键模块，通过多层量化减少信息损失，并采用随机比例的掩码进行建模。实验结果显示，MoMask在动作生成和文本匹配方面表现出色，且推断效率高，仅需10步即可达到最优生成质量。此外，MoMask还可以用于动作序列的时序补齐。
半年涨粉1000万，这个AI聊天搭子是怎么火的,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916229&idx=1&sn=97eb694915a565b3fa89846c243da119&chksm=84e401fbb39388ed9962fb427e8c5633845409b43ca29b8d2a8a3c007c67f12a80b20a9d93aa#rd,2024-04-28 12:57:59,这篇文章介绍了快手平台上的一款名为「AI小快」的AI互动小助手，它作为官方账号，拥有超过1000万粉丝，以其幽默、有帮助的回复在评论区走红。AI小快能够进行文本问答、多轮对话、文生图和图片编辑等任务，为用户提供信息解答、情绪安慰和创意内容。其能力来自于快手自主研发的大语言模型「快意」和文生图大模型「可图」。AI小快的成功展现了大模型在社交媒体互动中的应用潜力，并且已经在快手的商业化、电商场景中发挥价值，未来可能成为全域的「AI Copilot」。
谷歌员工爆料Python基础团队原地解散,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916229&idx=2&sn=0c0fceb26d3b51df20a9ff3f76b9c7f2&chksm=84e401fbb39388ede839165b933289748bccfe09fc5dedcc0513653e83deef7e3db0f04a5b0e#rd,2024-04-28 12:57:59,谷歌进行了一次重组，解雇了其在美国的 Python 基础团队，并计划在德国慕尼黑重建该团队，此举被认为可能是出于成本考虑。谷歌的这一决定在开发者社区中引起了关注和讨论。虽然谷歌的 Python 团队完成了许多对公司内部至关重要的工作，但有人认为，这种裁员可能是由于工作效率低下或认为这些工作可以由更小的团队完成。此外，有人指出，谷歌内部对 Python 的使用可能与外部社区的使用存在差异，这可能会产生与外部 Python 社区对齐的长期影响。同时，Meta（前身为 Facebook）在 CPython 的效率提升方面发挥了重要作用，这可能对该公司产生积极影响。
全日程发布｜AI 大模型如何赋能智能网联车技术创新与产业应用？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916229&idx=3&sn=3aaedb1a485cb0c72475a0a6a05e2055&chksm=84e401fbb39388ed2df50d958d454386523c2d643ca25b5765f888732a3765b9cc196ab3c3b0#rd,2024-04-28 12:57:59,AI + 智能网联车论坛将于5月11日在上海金桥举办，探讨大模型在智能汽车产业中的应用和影响。论坛将聚焦大模型如何赋能自动驾驶、智能座舱和车路城协同发展，邀请了行业专家和企业代表分享高质量内容。活动由上海市浦东新区相关部门主办，同济大学汽车学院教授朱西产、上海金桥智能网联汽车发展有限公司总经理林瑜等嘉宾确认出席。论坛将深入讨论大模型对数据闭环、AI芯片性能和5G基础设施的需求，以及产业面临的机遇和挑战。现场参会和线上直播预约已开放。
Diffusion Policy 做具身控制会比 VLM 更有前途吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916229&idx=4&sn=68f574490134d8eff448c75bf5f390fb&chksm=84e401fbb39388edd1af17c88ea9ee04fb06d2f4ef20f49d7c0536c0ac224e00a63a4c007485#rd,2024-04-28 12:57:59,很抱歉，由于您没有提供文章内容，我无法直接生成摘要。请您提供文章的详细信息或文本，我会尽忙为您生成摘要。
让大模型不再「巨无霸」，这是一份最新的大模型参数高效微调综述,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916229&idx=5&sn=ff1279958a164c110a06dbad3d5a2bf2&chksm=84e401fbb39388ed15da0e46a4db82937fdc890d21052f44a377e3d48043a3c7c817946ad155#rd,2024-04-28 12:57:59,"这篇综述论文总结了参数高效微调（PEFT）技术在大模型上的应用和最新进展。随着大语言模型和文生图模型的快速发展，如何在有限的计算资源下高效地微调这些模型以适应各种下游任务成为挑战。传统的全参数微调方法不再适用，因此PEFT技术应运而生，它通过微调模型的一小部分参数来快速适配任务，降低了对计算资源的需求。

论文对PEFT技术进行了分类，包括加性微调（如Adapter和Soft Prompt）、选择性微调（如非结构化掩码和结构化掩码）、重参数化微调（如LoRA和DoRA）以及混合微调。此外，论文还探讨了如何提高PEFT的效率、其在不同领域的应用，例如在LLM、ViT、视觉文本模型和扩散模型中的应用，以及PEFT在系统设计和部署中面临的挑战。

论文对未来的研究方向提出了建议，如建立统一的评测基准、增强训练效率、探索扩展定律以适应更大模型、服务更多模型和任务，以及增强数据隐私和PEFT与模型压缩的结合研究。这篇综述为PEFT领域的从业者和初学者提供了全面的学习指南。"
当前最强国产Sora！清华团队突破16秒长视频，懂多镜头语言，会模拟物理规律,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916159&idx=1&sn=75f155043f058e00db261f9d66c31e0d&chksm=84e40141b393885732ece64ecb272dc40b9dcb92cb7d691175eaca961e24a6309a56667efbd9#rd,2024-04-27 12:46:31,生数科技发布了国内首个全面对标 Adobe Sora 的视频大模型“Vidu”，该模型能够生成长达十几秒的视频片段，并在多镜头语言、时间和空间一致性、物理规律遵循及超现实主义画面生成方面表现出色。Vidu 的推出标志着国内在视频生成领域的重要进步，特别是在长视频生成方面。这款模型基于生数科技自研的 U-ViT 架构，该架构早于 Sora 采用的 DiT 架构，且团队在图文任务上的成果为其视频模型的研发提供了基础。生数科技的核心团队来自清华大学人工智能研究院，有着深厚的技术积累。
一键换装，让奥特曼、黄仁勋穿上机器之心的文化衫,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916159&idx=2&sn=e84db4a6bffd5e9fbdc3c096e7221c0f&chksm=84e40141b3938857468347074ceda8e43feb3814b19a082a753e86ab72a14f026a856ed9af14#rd,2024-04-27 12:46:31,这篇文章介绍了韩国科学技术院 (KAIST) 和 OMNIOUS.AI 共同开发的一种新型扩散模型——𝐈𝐃𝐌-𝐕𝐓𝐎𝐍，该模型能够实现高保真度的虚拟试衣效果。该技术可以精准捕捉服装细节，即使在户外或有遮挡的情况下也能准确展示试穿效果。通过试衣演示，显示了将黄仁勋、奥特曼、霉霉等名人“穿上”机器之心文化衫的有趣应用。虽然存在一些小瑕疵，如手臂或字体还原不理想，但整体效果良好。论文链接和试用地址也已提供，以便读者进一步了解和体验这一技术。
旅行者1号「复活」：世界最慢的电脑，被成功修复了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916159&idx=3&sn=5d6d748ccebd12d86e9a169947125e96&chksm=84e40141b3938857c59d886861846caa43b0f91bee9966eb4196809094e5713255865fa5d228#rd,2024-04-27 12:46:31,NASA的旅行者1号宇宙飞船在经历了5个月的通信故障后，成功被修复并重新发送了数据。这艘46年前发射的飞船在距离地球240亿公里的星际空间中，由于飞行数据子系统（FDS）的单个芯片故障，自去年11月以来无法向地球发送可读数据。NASA工程师通过创新的远程操作，定位了问题并重写了部分受影响的代码，使FDS能够再次打包和发送工程数据。虽然自11月14日以来收集的所有科学数据已经丢失，但工程师计划在未来几周内继续修复，恢复科学数据的传输。旅行者1号是目前最遥远的人造物体，仍在继续向我们提供太阳系外的珍贵信息。
苹果OpenAI合作，力争今年生成式AI登陆iPhone,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916159&idx=4&sn=d895c2bd680f430fc048753281a3d161&chksm=84e40141b3938857de91155f5af33c32ada2fbc8e581b9ae3f153db61329d32449366c038231#rd,2024-04-27 12:46:31,在即将举行的WWDC24上，Apple可能会在下一代iOS操作系统中集成生成式AI技术。Apple正在与多个AI公司进行合作谈判，包括OpenAI、Google和Anthropic，以将聊天机器人和其他AI功能引入iPhone。在中国市场，Apple已宣布与百度合作，为国行版iPhone提供AI技术支持，包括语音识别、自然语言处理和图像识别。同时，Apple也在开发自己的生成式AI模型，发布了名为OpenELM的系列小型语言模型，并计划在iOS 18中包含基于大型语言模型的新功能。不过，Apple尚未决定最终的合作伙伴，可能与多家公司达成协议，或选择其他提供商。新款iPhone的AI功能将强调无缝集成和更好的隐私保护。
ICLR 2024 | 跨领域准确进行零样本异常检测，浙大等提出AnomalyCLIP,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916159&idx=5&sn=25f9657cad33594a434e080f5b020656&chksm=84e40141b39388574b8532020e2414302373054c2c5df14037363bbe9504ad196493c96ea651#rd,2024-04-27 12:46:31,来自浙江大学、新加坡管理大学和哈佛大学的研究者提出了AnomalyCLIP，这是一种改进的CLIP模型，用于零样本异常检测（ZSAD）。AnomalyCLIP通过学习对象不相关的文本提示技术，能捕捉图像中的通用正常和异常特征，从而实现跨领域的泛化异常检测。在17个不同领域的真实世界异常检测数据集上进行的实验表明，AnomalyCLIP在跨域和高度多样化类别语义的数据中表现出了出色的零样本异常检测和分割能力。这种方法通过一次微调，就能泛化地识别不同对象和场景的异常，提高了在工业检测和医学成像等领域的应用潜力。
为什么要做长文本、长图文、长语音的大模型？深度解读讯飞星火V3.5春季上新,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916046&idx=1&sn=47f90fe487047e717bf74d42ba54a9d8&chksm=84e400b0b39389a67e3c0be6abad53ced0cb1a8c7f1a627cac5596b91d3951b9becc2d271908#rd,2024-04-26 12:26:22,科大讯飞发布了其大模型讯飞星火的最新版本V3.5，该版本首次支持长文本、长图文、长语音的处理，旨在帮助用户高效获取和理解各种信息来源，包括文档、图文资料和会议录音等。新功能通过稀疏剪枝技术和大模型知识蒸馏技术提升了处理长文本的能力，其在长文本、长图文和长语音的处理能力上达到了行业领先水平。此外，讯飞星火还能实现超拟人对话和“一句话声音复刻”功能，提供更自然、生动的语音交互体验。目前，讯飞星火APP在安卓端的下载量已经超过9600万次，受到用户的广泛认可。未来，科大讯飞计划在6月27日推出讯飞星火大模型V4.0，继续对标GPT-4 Turbo。
会颠勺的国产机器人来了：大模型加持，家务能力满分,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916046&idx=2&sn=569ab5c579a7a1c6281c522623037777&chksm=84e400b0b39389a6b64c18ae08f74fde84bf85fe9653973eb78fb877a61b042580bde2a6137c#rd,2024-04-26 12:26:22,这篇文章介绍了星尘智能公司推出的AI机器人Astribot S1，该机器人展示了出色的家居和工作场景操作性能，包括叠衣、分拣物品、炒菜、清洁和竞技叠杯等复杂任务。S1通过模仿学习能敏捷灵活地执行任务，接近成年人的执行水平，建立新的AI机器人标准。预计该机器人将在2024年完成商业化。星尘智能团队在软硬件协同上取得突破，机器人软件支持强化学习和模仿学习，硬件则拥有高性能电机传动系统，保证其敏捷和精度。此外，S1强调安全交互，能够精准控制力量，避免伤害。公司创始人来杰拥有丰富的机器人研发经验，目标是让AI机器人走进千家万户。
奥特曼斯坦福演讲：专注当前AI局限性没用，GPT-5让一切努力过时,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916046&idx=3&sn=27a2554e136e09aa01347ebef13cd662&chksm=84e400b0b39389a6b5a2ad3d06d165637016aca086c6329834b71940e92363b217c7039736c3#rd,2024-04-26 12:26:22,OpenAI的CEO Sam Altman在斯坦福大学发表演讲，分享了他对AI未来发展的见解。主要内容包括：1) AI进展迅速，GPT-4之后的模型（如GPT-5）将更强大，但真正的创新在于定义AI能力的下一个范式转变；2) OpenAI致力于实现AGI，开源可能不是最佳途径，ChatGPT是积极影响社会的方式，重点是消除AI使用的不平等；3) AI创业公司应关注创新，因为未来模型可能会使当前局限性变得过时；4) AI可以增强人类能力，如在教育、医疗、娱乐等领域产生影响，但也需要负责任的开发和迭代部署。Altman强调，尽管AGI可能带来恐惧，但它有潜力解决社会问题并推动人类进步。
吴恩达：多智能体协作是新关键，软件开发等任务将更高效,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916046&idx=4&sn=e5a8bd962ffc2874f04d4951b82eee7b&chksm=84e400b0b39389a60e76abcd39a8fe1b561b1d8a5a86b412e1a8f305dccc21f71431db1d059b#rd,2024-04-26 12:26:22,本文介绍了斯坦福大学教授吴恩达关于智能体在软件开发中应用的观点。吴恩达提到，基于GPT-3.5的智能体工作流在实践中可能比GPT-4更有效，显示了智能体可能超越其基础模型的能力。多智能体系统在处理复杂任务时，如代码审查和生成，能够协同工作，互补能力，从而提高软件开发效率。吴恩达的文章提到了AutoGen和LangGraph等工具，这些工具旨在帮助开发者更容易地部署和管理AI智能体，使得非专业编程人员也能利用AI自动化开发流程。多智能体方法通过将任务分解为不同角色的子任务，提供了一个框架来组织复杂的任务。尽管这种方法在某些情况下表现出色，但多智能体系统的稳定性和可预测性仍有待进一步研究。
CVPR 2024 | 擅长处理复杂场景和语言表达，清华&博世提出全新实例分割网络架构MagNet,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650916046&idx=5&sn=0c44398ab6743fe97015588a7198eba5&chksm=84e400b0b39389a6ea125bc50c7bb1e6f26edfa24de110a829ce17f54077119cb5b219296abe#rd,2024-04-26 12:26:22,"清华大学和博世中央研究院的联合研究团队在CVPR 2024上提出了一种新的方法，名为MagNet，用于提升指代图像分割（Referring Image Segmentation, RIS）任务的性能。RIS要求模型能理解文本和图像信息，将句子所指的物体进行像素级分割。现有方法在处理复杂的语言表达和细粒度对齐时存在挑战。MagNet通过引入辅助任务Mask Grounding，学习文本与视觉对象的细粒度对应，以及Cross-modal Alignment Module和Cross-modal Alignment Loss来减小模态差异。这些创新使得MagNet在RefCOCO、RefCOCO+和G-Ref数据集上的性能显著超越了先前的最佳算法，提高了2.48个百分点的oIoU指标。实验和可视化结果证明了MagNet在处理复杂场景和语言表达时的优越性。"
国内销量持续领跑，荣耀告诉你切入AI手机的正确姿势,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915902&idx=1&sn=60c45edffeabaac761feacb02121feaa&chksm=84e40040b39389564aa1991b5744ad3a5ff007ba41de692ce6b8e6dd4f4d14236953f6ef6644#rd,2024-04-25 12:57:34,"这篇文章讨论了""AI手机""的定义和未来发展方向。随着ChatGPT等技术的出现，手机厂商开始在旗舰手机中引入AI大模型，提供各种AI功能，如新一代AI助理、图像生成和语音翻译等。然而，接入大模型并不等同于AI手机，真正的AI手机应能通过学习和理解用户行为，提供自动化和个性化的服务。苹果在即将举行的WWDC大会上可能会展示新的AI能力，而荣耀等国产手机厂商已经在这一领域取得进展，通过AI使能的全场景操作系统，如MagicOS，实现意图识别和人机交互的创新。荣耀认为，AI手机的核心是重构操作系统和应用，让AI无处不在，并通过智能体驱动大模型，实现更复杂任务的处理和交互体验的升级。未来，AI手机可能会发展成为持续学习和进化、更懂用户需求的设备。"
Open-Sora全面开源升级：支持16s视频生成和720p分辨率,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915902&idx=2&sn=73eaa128e0cfcf275fda0d60a40777f6&chksm=84e40040b3938956ecab8d6ac7d58b0540b121bd0e0ce025e9020eedcf7f8e35e5e2461fa410#rd,2024-04-25 12:57:34,Open-Sora，一个开源的文本到视频生成模型，已更新支持单镜头16秒的视频生成，最高分辨率达到720p，并能处理各种宽高比的生成需求。新版本的Open-Sora引入了更稳定的模型架构ST-DiT-2，采用多阶段训练方法以提高视频质量，并支持多时间、分辨率、长宽比和帧率的训练。模型还采用了旋转位置编码和QK归一化技术，以增强训练稳定性和性能。此外，Open-Sora提供了一个统一的框架来支持图像到视频和视频到视频的生成任务，以及多种视频编辑功能。所有这些新功能和完整的数据处理流程都在GitHub上开源。尽管目前的视频生成仍存在一些局限，如噪声、时间一致性等问题，但作者团队计划在后续版本中进行改进。
黄仁勋亲自给OpenAI送货，全球首台DGX H200开箱了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915902&idx=3&sn=157a841843dcec311faa0096e2ebf6e7&chksm=84e40040b3938956069b9e7170cf866305a06d972b4f2787e1fbc0649bb129dfd79739235365#rd,2024-04-25 12:57:34,英伟达创始人黄仁勋向OpenAI赠送了全球首台Nvidia DGX H200超级计算机，以支持双方共同推进AI和计算的发展。这台超级计算机配备了H200 Tensor Core GPU，具有强大的性能和内存功能，适用于生成式AI和高性能计算工作负载。此前，英伟达也曾向OpenAI捐赠过AI超级计算机DGX-1。此外，英伟达还宣布有意收购AI基础设施管理平台Run:ai，以进一步扩展其在AI领域的影响力。
视频生成技术与应用 AI 技术论坛圆满收官,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915902&idx=4&sn=3ea5ca7de01b084a5e231646ab8f28c2&chksm=84e40040b39389561f9d812b0386926994034c2a1b3b1b719d903807db827914230717e8ced8#rd,2024-04-25 12:57:34,机器之心主办的“视频生成技术与应用 — Sora 时代”论坛圆满结束，吸引了近 200 名参会者。论坛中，10 位视频生成领域的专家分享了关键技术、创新方案和研究成果。张俊林、朱思语、曾妍、杨欢、王耀晖、卞正达、童同等嘉宾分别就Sora技术、视频生成模型、数据集构建、多模态内容生成等主题进行了深入讲解。此外，圆桌讨论环节探讨了Sora发布后的行业影响和未来发展方向。未能到场的观众可以在机器之心官网知识站购买论坛视频，以继续学习和了解大模型技术。未来，机器之心将继续举办类似活动，助力开发者提升技术实践和创新能力。
仅需Llama3 1/17的训练成本，Snowflake开源128x3B MoE模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915902&idx=5&sn=fb98b8217dfde38c27b230f4fbc12d16&chksm=84e40040b3938956c80bbcc9e113ffdbaf138ae80cf54e818978b683cc42a865c6a4ee6b6958#rd,2024-04-25 12:57:34,Snowflake，一家数据管理和仓库提供商，宣布推出了专注于企业级应用的大型语言模型（LLM）——Snowflake Arctic。Arctic在企业任务如SQL生成、编程和指令遵循方面表现出色，其训练成本低于其他开源模型，为经济高效的训练设定了新标准。此外，Arctic模型是开源的，提供权重和代码的开放访问，并将在多个平台包括Hugging Face上可用。通过独特的Dense-MoE混合transformer架构，Arctic实现了高训练效率和推理效率，尤其在企业智能指标上与成本更高的模型相比表现强劲。Arctic采用了三阶段的课程学习方法，以提高在代码生成和SQL等企业相关任务中的性能。
8B文字多模态大模型指标逼近GPT4V，字节、华师、华科联合提出TextSquare,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915902&idx=6&sn=3d0740b23b8cb8ee1a207a6442b7f7a3&chksm=84e40040b3938956aa0526d5153f49ecfd59cc3316ca0c5bdc6554e7a6082aec6eec9c2a4a96#rd,2024-04-25 12:57:34,来自字节跳动、华东师范大学和华中科技大学的研究员提出了一种新策略——Square，用于生成大规模的文本中心的视觉指令微调数据集，以提升多模态大模型在文本相关视觉问答 (VQA) 任务上的性能。研究者通过一个四步过程（自问、自答、自推理和自评估）从先进的闭源模型中获取高质量VQA数据，构建了包含1000万个数据点的Square-10M数据集。基于此，他们训练了一个名为TextSquare-8B的模型，该模型在多个VQA基准测试中表现出了与闭源模型（如GPT4V和Gemini）相当或更优的结果，并显著超越了其他开源模型。TextSquare-8B的实验结果验证了大規模数据对VQA任务的积极影响，并揭示了指令微调数据规模、训练收敛损失与模型性能之间的关系。
MiniMax不声不响出了款让人惊喜的生产力产品：「海螺AI」大测评,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915761&idx=1&sn=c016d65218604f0e05bbfbf34bf08f9b&chksm=84e407cfb3938ed9442ac2b95767630b05e86a9e2518df1721dfb56b0da6930d77dddcafe48c#rd,2024-04-24 17:55:13,本文介绍了中国通用人工智能创业公司MiniMax推出了万亿参数量的MoE大语言模型abab 6.5，该模型在各类核心能力测试中表现接近世界领先水平。MiniMax还基于此开发了名为“海螺AI”的生产力产品，具备语音交互功能，支持速读长文、智能搜索、免费查数据、识图、创作文案和语音通话。海螺AI在与领先大语言模型的对比中表现出色，尤其在语音交互和长文本处理方面。MiniMax的业务布局包括自研大模型技术、面向企业和开发者的开放平台，以及多款面向消费者的AI原生应用。公司计划在今年实现用户规模和产品DAU的显著增长。
加速扩散模型，最快1步生成SOTA级图片，字节Hyper-SD开源了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915761&idx=2&sn=50ba74140b8d8c9663b64860e7a87e6e&chksm=84e407cfb3938ed9735387698d25f83af0e90fac57ba3762ff8d2a8258a82f0d3a048ac4dd23#rd,2024-04-24 17:55:13,字节跳动技术团队提出了Hyper-SD，这是一种新型的扩散模型蒸馏框架，旨在加速扩散模型的推理过程，同时保持高质量的图像生成。Hyper-SD结合了轨迹保持蒸馏和轨迹重构蒸馏两种策略，解决了现有方法的效果限制和输出域变化问题。该模型通过轨迹分段一致性蒸馏和人类反馈学习提高性能，并使用分数蒸馏增强一步生成能力。实验表明，Hyper-SD在SDXL和SD1.5架构上实现了1到8步生成的SOTA性能，且开源了相关模型和插件，促进了生成式AI社区的发展。
苹果卷开源大模型，公开代码、权重、数据集、训练全过程，OpenELM亮相,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915761&idx=3&sn=d233f9cb4e687f98a70dd834a7635ec4&chksm=84e407cfb3938ed9315e0daeff0c896ce671b856aec944bfba9a097c47e11090bd8349440a87#rd,2024-04-24 17:55:13,苹果发布了OpenELM，这是一个基于开源训练和推理框架的高效语言模型族，包括四种变体，参数量分别为270M、450M、1.1B和3B。OpenELM采用逐层缩放技术，使得每个Transformer层有不同的配置，以实现更有效的跨层参数分配。苹果提供了完整的框架，包括数据准备、训练、微调和评估程序，以及预训练的checkpoint和训练日志，促进开源研究。OpenELM在零样本和少样本设置下的性能优于其他开源LLM，如PyThia和OLMo。然而，尽管准确度更高，但OpenELM的推理速度比OLMo慢，未来将探索优化策略以提高推理效率。
硬控设计人一分钟，加持大模型的Adobe，PS起来更香了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915761&idx=4&sn=27d76cb3f269a19d9ab0c5504e37938b&chksm=84e407cfb3938ed92e36dd7bf1b5aea476f0c3a5a0c70ec7ef6e33dc105d3efb6448a7a5769e#rd,2024-04-24 17:55:13,Adobe发布了新的图像生成模型Firefly Image 3，提供在Firefly Web应用、Photoshop和InDesign中的测试版，计划今年晚些时候全面上市。该模型提升了图像的逼真度、光照和细节处理，能更好地理解长文本提示并生成清晰文本。Firefly Image 3的一大特点是允许用户上传参考图像来指导AI生成结果，匹配样式和颜色。此外，Photoshop中的测试版还支持自动生成图像背景和增强细节。Adobe还强调，上传的参考图像不会用于训练模型，并为生成的内容添加水印，确保商业使用的安全性。新工具旨在帮助创作者提高效率，产出高质量图像。
AI信任危机之后，揭秘预训练如何塑造机器的「可信灵魂」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915761&idx=5&sn=33aa176e799909c7ec63dc70c2a4d794&chksm=84e407cfb3938ed95e2d3df6cea447c3484cce9d95e47f7e158fe4e2f8b0d128ede9c98d342c#rd,2024-04-24 17:55:13,该文章介绍了人工智能领域中大语言模型（LLMs）的预训练阶段的重要性，预训练占据了大部分的计算资源，并且对于模型能力的构建至关重要。研究发现，LLMs在预训练早期就能建立关于可信概念的线性表征，且预训练过程呈现出类似信息瓶颈的学习动态，先拟合后压缩。此外，通过使用预训练切片的表征干预技术，可以提升最终模型的可信能力。这项工作强调了预训练阶段在理解和提升LLMs可信性方面的重要性，并为未来的研究提供了新视角。
首批中文版Llama3模型来了，解释成语、答弱智吧问题,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915761&idx=6&sn=2e81d65a4398909e6bc0271f18cb6950&chksm=84e407cfb3938ed9aa069b53e7d59fd27237d93a73ec1859354bc8482389d8ff70965a59372f#rd,2024-04-24 17:55:13,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
挑战拯救痴心“舔狗”，我和大模型都尽力了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915526&idx=1&sn=691be8028c2a3fe2f0fb4a6b0f4b1cce&chksm=84e406b8b3938fae802f2890eab23eb81727f4fabffac34047239ddfef0abdb6aa6633b8b765#rd,2024-04-23 19:06:08,这篇文章介绍了一款名为“拯救舔狗”的小游戏，该游戏基于商汤科技的大模型“SenseChat-Character”打造，玩家需要劝说模型放弃追求不感兴趣的女神。游戏展示了大模型的拟人化特点，具有长对话记忆和自我攻略属性，增加了游戏的趣味性和挑战性。此外，文章还提到了商汤科技的“日日新 SenseNova 5.0”大模型体系的升级，强调了其在多模态交互和性能上的提升，可以用于对话、文档处理、代码编写等多种场景。模型支持长对话记忆和跨模态任务，展示了在问答、文字创作、逻辑推理、文件处理等方面的能力。商汤科技通过尺度定律探索大模型的性能边界，并在数据和算力方面进行了突破。
这就是OpenAI神秘的Q*？斯坦福：语言模型就是Q函数,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915526&idx=2&sn=1218e4612e6155527030f7ed7b61fcbe&chksm=84e406b8b3938fae1381190a7bcef69b4f9e3bbf830235938bdf17de964394b7a6b8279d5f0f#rd,2024-04-23 19:06:08,斯坦福大学的研究团队发现大型语言模型（LLM）可以被表示为Q函数，这为OpenAI的神秘项目Q*提供了潜在的支持。研究团队在LLM中应用二元偏好反馈的直接偏好优化（DPO），结果显示DPO训练能够隐含地学习到一个基于token的奖励函数，其中语言模型的logit定义了最优Q函数或预期的总未来奖励。DPO能够在token层面上建模任意可能的密集奖励函数，这意味着它可以与隐含的人类奖励对齐。实验表明，DPO模型能够执行credit assignment并进行组合泛化，且经典的基于搜索的算法在DPO策略上等价于基于似然的搜索。初始策略和参考分布的选择对训练期间隐性奖励的轨迹有显著影响。这些发现为强化学习在LLM中的应用提供了新视角，但仍需要更大规模的实验验证。
微软发布Phi-3，性能超Llama-3，可手机端运行,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915526&idx=3&sn=55b4a4cb01b7dcc4b71044cc415877b0&chksm=84e406b8b3938faef4556c3f2983be13d990162a97eef13541d6492750d7360f734e4cf470fb#rd,2024-04-23 19:06:08,微软发布了新的小尺寸语言模型Phi-3，其中Phi-3 mini拥有38亿参数，经过3.3万亿token的训练，性能与Mixtral 8x7B和GPT-3.5等大模型相当，但优化后可在手机上运行。该模型在MMLU和MT-bench等基准测试中表现出色。微软强调，模型的高性能源于高质量的训练数据集，并且Phi-3系列模型与Llama-2使用相同架构，方便社区开发。此外，模型还经过了安全性和稳定性的调整，以符合微软的负责任人工智能原则。尽管规模较小，但Phi-3 mini在某些任务上仍受限于其参数量，例如事实知识存储，但可以通过搜索引擎增强来解决。
Llama3后，Meta又开放自家头显操作系统，打造元宇宙时代新安卓,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915526&idx=4&sn=51e54bcdc8e5aa24c3287ebcfaa68def&chksm=84e406b8b3938faefc637bfb51a8f281afa6d753a7af18805335b962499ed63b47ff128b77bd#rd,2024-04-23 19:06:08,Meta（前身为Facebook）宣布将其虚拟现实（VR）头显Quest的操作系统“Meta Horizon OS”向第三方硬件制造商开放，包括华硕、联想和微软等公司。这一举措是为了推动元宇宙成为一个更开放的计算平台。Meta希望通过开放操作系统，让更多的公司能够在上面构建创新产品，为消费者提供更多选择，并促进开发者生态系统的建设。Meta Horizon OS结合了MR的核心技术和社交功能，目前是基于安卓开源项目构建的。华硕、联想和微软等公司将基于该系统开发新的硬件设备，包括游戏、生产力和娱乐设备。此外，Meta还计划扩展其应用程序商店的开放性，使开发者更容易发布软件，并引入新的空间应用程序框架，帮助移动开发者创建MR体验。这一开放策略旨在消除平台限制，让用户通过多种途径访问内容。
CVPR 2024 | 基于MoE的通用图像融合模型，添加2.8%参数完成多项任务,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915526&idx=5&sn=78f3444380c9ca6e7146a881a7231215&chksm=84e406b8b3938fae7f47b441828fff2d259251938f0ac8bab4df6e9b198688710b3ec8013033#rd,2024-04-23 19:06:08,该文介绍了《Task-Customized Mixture of Adapters for General Image Fusion》的论文，该研究关注于通用图像融合，即整合来自多个源图像的互补信息。当前方法大多针对单一图像融合任务设计，而新方法TC-MoA引入了基座模型和混合专家（MoE）思想，使用任务定制的混合适配器来自适应地融合不同任务的图像。通过互信息正则化，模型能更好地识别和融合不同源图像的重要信息。实验表明，TC-MoA在多模态、多曝光和多焦点图像融合任务上表现出优越性能，并具有对未知任务的泛化性和可控性。
24GB单卡全量微调Llama 3-8B，仅需添加一行代码,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915526&idx=6&sn=d6e06a5f35f7aebbee2a0c1f6f213938&chksm=84e406b8b3938fae90892a6160292e007ef18d75b4246948e07cc0d85d96cd030776f6999ff8#rd,2024-04-23 19:06:08,研究人员提出了一种名为BAdam的优化算法，该算法减少了训练大型语言模型所需的显存开销，使得在一张24GB显存的RTX 3090显卡上可以全参数微调Llama 2-7b和Llama 3-8b模型。BAdam算法结合了块坐标下降法和大模型优化，其内存使用量减少了约六分之一，且损失函数收敛速度比LoRA快，单次迭代时间也更短。在性能方面，BAdam训练的模型在MT bench score和SUPERGLUE基准测试中表现出色，与使用Adam的全参数微调相当或更优。这项工作由香港中文大学（深圳）的数据科学学院博士生罗琪竣进行，并将在机器之心的线上分享中进行详细解读。
Sora之后，OpenAI Lilian Weng亲自撰文教你从头设计视频生成扩散模型,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915338&idx=1&sn=ec8402e95052fd2a21d7024be06ac01b&chksm=84e40674b3938f629a86e37751d7a1b5afa69088da0ffe093421d2b7160ba0152f6d7c5a24c1#rd,2024-04-22 12:16:42,这篇文章讨论了扩散模型在视频生成任务中的应用。视频生成比图像合成更具挑战性，因为它需要保持时间一致性，并且收集大量高质量视频数据更困难。作者介绍了不同方法，包括从头建模视频生成和调整预训练的图像生成模型以适应视频任务。这些方法涉及参数化、采样策略、模型架构（如3D U-Net和Transformer）以及时间一致性的处理。文章还提到了多个具体研究，如OpenAI的Sora模型、Imagen Video、Make-A-Video和Text2Video-Zero，这些研究展示了在视频生成领域取得的进展。
Linux之父讽刺AI炒作：很搞笑，大概我也会被大模型取代,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915338&idx=2&sn=1df0635690d21c965e03cfe783d66bc4&chksm=84e40674b3938f624a07a1b104bf12258502aa82e9503b8a95f6ee77163085508d75e16574d5#rd,2024-04-22 12:16:42,在北美开源峰会上，Linux 之父 Linus Torvalds 和 Dirk Hohndel 进行了对话。Torvalds 对用空格替换制表符的提议表示反对，并在最新 Linux 版本中特意加入了制表符来应对不兼容问题。他表示即将发布的 Linux 6.9 内核版本是“平静、稳定且无聊”的，这是成熟软件项目应有的状态。硬件错误是令人沮丧的，尤其是因为它们不易修复，但 Torvalds 认为开源硬件如 RISC-V 也会犯同样的错误。他谈到了开源项目中的安全问题，强调健康的社区是防御恶意行为的最佳防线。对于人工智能，Torvalds 认为不应过分炒作，虽然 AI 在某些领域有帮助，但不应期待它解决所有问题。最后，他表示会继续致力于 Linux 和 Git 的改进，因为它们对其他人有实际意义。
时代2024最具影响力100人：黄仁勋、Bengio、纳德拉 、王传福等人入选,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915338&idx=3&sn=55f474c72aead7dc7900b0b22da6e705&chksm=84e40674b3938f6217abac6d56ff3222065ef76dfa32784ceb484793d467417f8342f5dfd00a#rd,2024-04-22 12:16:42,《时代》杂志发布了2024年度最具影响力的100人名单，其中包括科技界多位知名人士。微软公司CEO兼董事长萨蒂亚·纳德拉、比亚迪创始人王传福、英伟达创始人兼首席执行官黄仁勋以及图灵奖得主Yoshua Bengio等入选。黄仁勋因其在AI和芯片行业的贡献受到认可，英伟达市值曾达到1万亿美元。Yoshua Bengio因深度学习研究奠定AI革命基础而知名。纳德拉领导微软转型成功，成为全球最有价值的上市公司之一，并注重AI的负责任发展。王传福带领比亚迪在电动汽车领域取得显著成就。
首个基于Mamba的MLLM来了！模型权重、训练代码等已全部开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915338&idx=4&sn=8894c42630bd90146a0bec5aab3168ea&chksm=84e40674b3938f6225794f815676e3495680d23404d939f5df4fb43405aa9dc04bb2b8dbd8f2#rd,2024-04-22 12:16:42,这篇文章介绍了Cobra，一种新型的多模态大型语言模型，旨在解决基于Transformer的模型计算效率低下的问题。Cobra采用线性计算复杂度的状态空间模型（SSM）作为基础，以提高推理效率。与现有方法相比，Cobra在保持竞争力的性能同时，具有更快的推理速度。实验表明，Cobra在参数量仅为LLaVA模型43%的情况下，仍能在多个基准测试上实现与其相当的性能。此外，Cobra在克服视觉错觉和空间关系判断方面表现出色。这项工作为提高多模态语言模型的效率和实用性提供了新的视角。
AI重建粒子轨迹，发现新物理学,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915338&idx=5&sn=a75d4c9c69f88f0bc50bf9164fb7f91e&chksm=84e40674b3938f621f5b5f58849f3cbf31e6a759372ec2e5a2f60fb223b0b36b16a5f9fd9de3#rd,2024-04-22 12:16:42,波兰科学院核物理研究所的研究人员发现，人工智能工具可能成为当前粒子轨迹快速重建方法的有效替代。传统方法在处理大型强子对撞机等高能物理实验中的大量数据时面临挑战，而AI算法在识别模式和重建粒子轨迹方面展现出潜力。研究团队设计了一个深度神经网络，经过训练后，能够准确重建二次粒子轨迹，其速度和精度都令人满意。这项技术已经在MUonE实验中实施和测试，该实验旨在通过研究μ子与电子的散射来寻找新物理学的迹象。未来，这种基于AI的轨迹重建方法可能在粒子检测技术中发挥重要作用。
AI Pioneers｜星海图高继扬：人形机器人不是具身智能的唯一答案,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915305&idx=1&sn=50370e07f577eb743f54fb1a47f0a2ba&chksm=84e40597b3938c819e41b056acddf1c7f8f12ba40e84192a9e1a77af593cb4cc396ac444b064#rd,2024-04-21 12:01:48,这篇文章讨论了人工智能领域中的具身智能，特别是机器人的发展。星海图是一家由清华系创始人创立的公司，他们提出在设计具身智能产品时，智能（大脑）比执行（身体）更重要。他们认为，应该根据具体场景推出适合的产品，通过商业闭环收集更多数据以提升机器人的智能水平，而不是一味追求完整的人形机器人。星海图提出了“一脑多形”的愿景，即一个智能系统可以适应不同形态的机器人，而人形只是可能的形态之一。公司还强调关注产品的失效成本和数据获取成本。星海图计划在今年下半年公布其具身智能产品的具体场景和产品设计。
史上首次！AI驾驶战机成功与人类飞行员空中「狗斗」,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915305&idx=2&sn=000d7c5f2994a42475f5880d5cbcc8ab&chksm=84e40597b3938c8125e2e45494d3a832e1f6d2d6a3ee96596e68a1466df3859744d88500ebc6#rd,2024-04-21 12:01:48,美国DARPA的AI验证机X-62A VISTA，一架由F-16改装的飞机，去年9月成功与人类飞行员进行视距内的空中缠斗，即“狗斗”。这是AI在空战领域的重大进展。在对抗中，AI驾驶的战机展示了防御机动和攻击等战斗技能，但胜负未公布。X-62A VISTA是DARPA空战进化(ACE)计划的一部分，已经完成了21次试飞，包括超过10万行飞行关键软件代码的修改。这次测试证明了AI在安全执行战斗任务方面的潜力。
VAR 会是 Scaling Law 在视觉生成的新起点吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915305&idx=3&sn=1ee155b66d1b8ea999b09bacecf5a034&chksm=84e40597b3938c812d42a810163be55e939f40cc881bf81c8306fdb9eff5acf4a4260a1bc9d8#rd,2024-04-21 12:01:48,非常抱歉，您还未提供具体的文章内容。请您提供一篇文章，我将为您生成摘要。
CVPR 2024 | 跳舞时飞扬的裙摆，AI也能高度还原了，南洋理工提出动态人体渲染新范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915305&idx=4&sn=d47a58c35be12fce757ff041da62edc3&chksm=84e40597b3938c81be44bf268886958910b31ede42863b86576cca7bcb7756e82a553d68d8c9#rd,2024-04-21 12:01:48,南洋理工大学 S-Lab 团队提出运动—外观联合学习的动态人体重建新范式 SurMo，通过基于人体表面的三平面运动表征 (surface-based triplane) 对运动物理建模和外观建模统一在一个框架中，提升了动态人体渲染质量。这一方法可以有效建模衣服附属运动，适用于从快速运动的视频中学习动态人体重建，且在渲染效率和图像质量上表现出色。SurMo 的运动—外观联合学习范式包括运动编码器、运动解码器和外观解码器，通过连续性建模改进了运动的表示。实验结果显示，SurMo 在新视点渲染、运动相关阴影和衣服附属运动的重建上优于其他方法。
4000万蛋白结构训练，西湖大学开发基于结构词表的蛋白质通用大模型，已开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915305&idx=5&sn=c693a983c34e078fa265f99104b5c35f&chksm=84e40597b3938c81a53e8e8121b0bfb803c620a479b0bbe0c9c42da1c294e4c7a2e11660e85d#rd,2024-04-21 12:01:48,西湖大学研究人员开发了一种新的蛋白质语言模型SaProt，它利用结构感知词表将蛋白质结构编码成一维离散token，结合氨基酸序列，以增强模型的表征能力。该模型在4000万个蛋白质结构上进行预训练，表现出优于先前序列和结构模型的性能。SaProt在各种蛋白质任务上的实验结果表明其具有强大的通用性，包括在突变预测和下游任务微调中的优秀表现。此外，SaProt在结构预测任务和结构信息学习上也显示出优势。尽管有这些成就，研究者也指出了模型改进的潜在方向，如扩大结构词表和增加模型规模。
Llama 3超大杯有何惊喜？Meta会一直开源吗？当初为何笃信元宇宙？扎克伯格新访谈回应一切,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915283&idx=1&sn=9b16363de3bad3bb7f66ba0698139861&chksm=84e405adb3938cbb88b181664700d24f1078d40f16b87676c37ca0b75bb6867ad143abc2c3fe#rd,2024-04-20 13:49:29,Meta 发布了三个版本的 Llama 3 大规模语言模型，其中 8B 和 70B 参数版本已开源，405B 参数版本预计年末发布，性能接近 GPT-4。Meta 计划年底拥有约 35 万块 GPU，正在建立大型集群以支持模型训练。Meta CEO 马克·扎克伯格表达了对开源的积极态度，认为不应让少数公司控制闭源模型，希望构建一个开放的 AI 生态系统。他提到 Llama 3 405B 将是一个密集模型，能进行高质量图像生成和动画化功能，而且在推理和编程能力上有所提升。此外，扎克伯格还讨论了元宇宙、基础设施投资和未来技术发展方向。
Transformer本可以深谋远虑，但就是不做,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915283&idx=2&sn=b762b8bdbbae4ab828337409f8de6846&chksm=84e405adb3938cbba4ca479978be8d0b4db4273bf21dfd4a6333804aee88f565c765530e293d#rd,2024-04-20 13:49:29,这篇论文探讨了Transformer语言模型是否会预先规划未来的token。研究发现，Transformer有能力这样做，但在实践中并不会。尽管之前的研究所示，可以从模型隐藏状态预测未来token，但新研究发现，这可能是数据的属性，而不是模型刻意为未来步骤准备信息。研究者提出了预缓存假设和面包屑假设，并通过短视型训练方案进行实验。实验结果显示，Transformer更倾向于根据当前位置优化预测下一个token，而不是预先计算未来信息。因此，Transformer在处理自然语言时并不显著地规划未来，而是专注于当前token的预测。
大模型一定就比小模型好？谷歌的这项研究说不一定,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915283&idx=3&sn=b0430e5f0d670c30ab29e8671424e703&chksm=84e405adb3938cbbd2a96a8931fc1add7baf8efa5d8546fa55e84beb2b2792c1e845ca0050dd#rd,2024-04-20 13:49:29,Google Research 的一个团队对隐扩散模型（LDM）进行了研究，发现模型的大小并不总是决定性能的关键因素，特别是在预算有限时。研究发现，较小的LDM在有限的采样预算下可能优于较大的模型。团队训练了12个不同规模的文生图LDM，参数量从39M到5B不等，结果显示，预训练性能和模型规模呈正相关，但较小模型在采样效率上更优。即使使用扩散蒸馏，较小模型在有限采样预算时仍能与较大模型竞争。这些发现对于优化LDM的实际应用和提高采样效率具有重要意义。
CVPR 2024 | 字节提出新一代数据集COCONut，比COCO粒度分割更密集,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915283&idx=4&sn=de89aaae0e09e21e5cfefc2677372c36&chksm=84e405adb3938cbbc8cb09777f75ffd65f5b96058147e404d7943f37ab6c224924f4b37f6aff#rd,2024-04-20 13:49:29,这篇文章介绍了字节跳动推出的新一代细粒度理解数据集COCONut，该数据集针对深度学习模型设计需求，对383K张图片进行了全景分割的精确人工标注，总包含5.18M张mask，是目前最大规模的人工标注全景分割理解数据集。COCONut支持多种理解任务，如全景分割、实例分割等，并在替换数据集后显示出了明显的性能提升。为了解决标注成本和效率问题，研究者提出了一种结合人工的半自动标签生成方法，实现了高精度标注和成本节省。与现有数据集对比，COCONut的标注更为精细，且在多个任务上表现出优越性能。此外，研究者还创建了一个更具挑战性的测试集COCONut-val，以更好地评估模型改进。该数据集和相关模型将在GitHub上公开。
药物分子设计新策略，微软条件扩散模型DiffLinker登Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915283&idx=5&sn=fecdd5b5e39b9e953a1d7c9609774301&chksm=84e405adb3938cbbad128011826f5af3f9edbefa2121745d6c2f472ed28e6bbb79e40d790a33#rd,2024-04-20 13:49:29,研究人员提出了一种名为DiffLinker的E(3)等变三维条件扩散模型，用于分子linker设计。这个模型可以连接任意数量的分子片段，自动确定linker的原子数量和连接点，且能考虑靶标蛋白口袋的条件。DiffLinker在标准数据集上的表现优于其他方法，能生成更多样化和可合成的分子。在实际应用中，它成功生成了针对目标蛋白口袋的有效linker，展示出在药物设计中的潜力。该研究发表在《Nature Machine Intelligence》上。
下接万卡集群、上连AI原生应用，操作系统的进化超出你的想象,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915099&idx=1&sn=8b2866306ce459f709079c3980df914c&chksm=84e40565b3938c73849de61aafbb4a8d814cfe76ef1e0c7760d8fa0411a92c9434876308ddab#rd,2024-04-19 14:05:06,在2024百度Create AI开发者大会上，百度智能云发布了新一代智能计算操作系统——万源。万源由内核层、外壳层和工具层组成，内核层包括百度百舸·AI异构计算平台和文心大模型，外壳层提供千帆ModelBuilder以定制和精调模型，工具层的千帆AppBuilder和AgentBuilder支持快速开发应用和智能体。万源旨在简化AI原生应用开发，提供高效的异构算力和智能化操作体验，推动AI技术在应用层面的发展。通过万源，百度智能云整合了其在算力、模型和应用开发工具方面的积累，以支持AI原生时代的加速布局。
开源大模型Llama 3王者归来！最大底牌4000亿参数，性能直逼GPT-4,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915099&idx=2&sn=2e05393935775a3c7fc9e86a590afe91&chksm=84e40565b3938c737548e6a7254ac3976d24c267c8e9f4b7ec6510ad09e544dd42af4bb380f6#rd,2024-04-19 14:05:06,Meta 发布了开源大模型 Llama 3，该模型在多个关键基准测试中表现出最先进的性能，尤其在代码生成等任务上领先。Llama 3 基于超过 15T token 训练，支持 8K 长文本，且在指令遵循、推理能力和多样性上有所增强。该模型已应用于 Meta 的 AI 助手，覆盖 Instagram、WhatsApp、Facebook 等应用，并提供了一个图像生成器。此外，Llama 3 还引入了新的信任和安全工具，如 Llama Guard 2、Code Shield 和 CyberSec Eval 2。8B 和 70B 参数版本的 Llama 3 已开源，更大的多模态版本将在未来几个月发布。
CVPR 2024高分论文：全新生成式编辑框架GenN2N，统一NeRF转换任务,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915099&idx=3&sn=f6832bdbb8b2a2c107e5c5d7cd92c1f6&chksm=84e40565b3938c731d0f3cb9fad789f3b825e094c63c436cd1aa7c22cb9431c4765c8764444b#rd,2024-04-19 14:05:06,研究人员提出了一个名为GenN2N的统一生成式NeRF-to-NeRF转换框架，适用于各种NeRF转换任务，如文本驱动的NeRF编辑、着色、超分辨率和修复等。GenN2N利用3D VAE-GAN来学习与2D编辑图像对应的所有可能的3D NeRF编辑分布，并通过对比学习确保不同视角的编辑内容一致性。这种方法能生成高质量、多视角一致性的3D编辑结果，并且效率和多样性均优于现有的NeRF编辑技术。论文、主页和代码链接已提供。
5亿个token之后，我们得出关于GPT的七条宝贵经验,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915099&idx=4&sn=3216461647631a25c37310214732dd08&chksm=84e40565b3938c739c5518255dee52714f7cac055666285496fd2c68431ed689617f580fb8f3#rd,2024-04-19 14:05:06,一位名为Ken Kantzer的初创公司CTO在博客中分享了他在使用OpenAI的GPT模型（主要是GPT-4和GPT-3.5）处理5亿个token后的七大经验。1. 提示（prompt）应简洁，因为模型已经具备常识，过多的细节可能会导致混乱。2. 只需要使用Chat API，无需Langchain或其他额外工具。3. 通过流式API改善延迟，实现变速输入，提升用户体验。4. GPT在生成零假设内容时可能出错，经常返回空白。5. “上下文窗口”命名不准确，输入窗口大（128k token），输出窗口小（4k token）。6. 向量数据库和RAG（检索式自动完成功能）在实际应用中效果有限。7. 幻觉现象很少发生，只要用例清晰明确，GPT的输出通常是可靠的。
MLLM真能看懂数学吗？MathVerse来了次摸底测评，放出当天登热榜,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915099&idx=5&sn=2868d73c205cfd4fd82cac36287c6a10&chksm=84e40565b3938c730a979db12a73b079b7123ac2a9163b996935a11bbbe327246aa3a0d85686#rd,2024-04-19 14:05:06,这篇文章介绍了多模态大语言模型（MLLMs）在数学问题求解能力测评方面存在的问题，并推出一个新的测评基准——MathVerse。当前的多模态数学benchmark可能过度依赖题目文本中的重复信息，导致评估不准确。MathVerse通过设计不同版本的题目，逐步移除文本信息，强制模型依赖图表理解，以评估其真正理解视觉图像的能力。此外，它还提出了一种称为Chain-of-Thought（CoT）的评估策略，以细致评估模型的中间解题步骤和推理能力。实验结果显示，许多MLLMs主要依赖文本而非图像解题，并且开源模型与闭源模型在数学问题解决能力上存在差距。MathVerse为评估MLLMs的多模态数学推理能力提供了一个更全面和深度的框架。
港股IPO招股异常火爆，唯一盈利的「AIGC第一股」是怎么炼成的？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915028&idx=1&sn=a16a26ae8a1aa0b04669866b9f4e0324&chksm=84e404aab3938dbc10c0dde33d06b9ed38c47c884490b6c2738b3b645a1761b15784cdf93e4d#rd,2024-04-18 20:24:27,出门问问，一家以生成式AI和语音交互技术为核心的AI公司，已在香港交易所招股，受到投资者热烈追捧，首日超额认购超过8倍，目前近30倍覆盖。公司预计24日上市，成为“AIGC第一股”。出门问问的商业模式清晰，2022年实现盈利，打破了市场对AI公司盈利的担忧。其AI软件业务增长迅速，特别是AIGC解决方案，2021年至2023年复合年增长率超过300%。公司提供包括AI配音助手、虚拟直播数字人和短视频生成平台等C端解决方案，以及为企业定制的AI语音交互解决方案。创始人李志飞是自然语言处理专家，公司在AI语音和AIGC领域有深厚积累。出门问问通过“产模结合”的模式，即AI产品与大模型的结合，构建了独特的核心竞争力，实现了数据飞轮效应，促进产品和模型的持续迭代和优化。公司自2012年成立以来，历经深度学习和生成式AI两波浪潮，成功穿越周期，成为AI领域内的创新者和领导者。
谁才是最强的？清华给海内外知名大模型做了场综合能力评测,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915028&idx=2&sn=ec8dbddb5ff7c9d802a0852b40500dc5&chksm=84e404aab3938dbcc97c12a0c18b43b66de5fdd52717efb36b721c2c8ca547bb5ab0cc8709d5#rd,2024-04-18 20:24:27,SuperBench 是由清华大学基础模型研究中心和中关村实验室联合研制的大模型综合能力评测框架，旨在推动大模型技术、应用和生态的健康发展。在 2024 年 3 月的评测报告中，14 个海内外代表性模型进行了测试，其中包括 GPT-4 系列、GLM-4 和文心一言 4.0 等。结果显示，GPT-4 系列和 Claude-3 在多个能力上领先，而 GLM-4 和文心一言 4.0 表现出色，接近国际一流水平，但国内模型在代码编写和作为智能体的能力上与国际一流模型仍有差距。评测涵盖了语义、代码、对齐、智能体和安全五个方面，评估了模型的综合性能。在安全能力方面，文心一言 4.0 的表现最佳。整体来看，国内模型在某些领域已接近国际一流水平，但仍需在特定能力上进行提升。
2024谷歌研究学者计划名单公布：清华、北大、上交ACM班等校友在列,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915028&idx=3&sn=0cf209a9a3bef97ed8ef752924af19b9&chksm=84e404aab3938dbc8329479327581de9c6a621f05f70bbaf37ec11f47834a33259c34b411cfe#rd,2024-04-18 20:24:27,谷歌公布了2024年研究学者计划的获奖名单，该计划涵盖12个领域，包括算法与优化、应用科学、人机交互等，旨在资助获奖者的学术研究。多位华人学者在不同领域获奖，将获得最高6万美元的奖金。获奖的华人学者包括研究图挖掘算法的顾研和Yihan Sun（夫妻关系）、在半导体可靠性和机器学习领域工作的Shu-han Hsu和Eric Y. Ma、研究人机交互的Hong Shen、以及在健康研究、机器学习和数据挖掘等领域有所建树的其他学者。这些学者来自加州大学河滨分校、台湾成功大学、UC伯克利、CMU等机构。
华为Pura70系列发布：麒麟9010+可伸缩镜头，上线秒抢光,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915028&idx=4&sn=9852edd0d4ff0202e066228f8e0b4608&chksm=84e404aab3938dbc7bae957e1b6be82f1e9a707ce31ceef9aca3e148f3810760fda653cc41c3#rd,2024-04-18 20:24:27,华为推出了新款Pura 70系列手机，包括Pura 70 Ultra、Pura 70 Pro、Pura 70 Pro+和Pura 70，其中前两个型号在开售后迅速售罄。该系列主打全新影像功能，采用独特的三角造型主摄像头模组设计，配备最高端的影像系统。Pura 70 Ultra的主摄具有超聚光伸缩摄像头，支持200倍变焦。手机搭载了未公开发布的麒麟9010芯片，预计性能比麒麟9000S提升约10%。新手机运行HarmonyOS 4.2，并集成了生成式AI技术，提供多项智能化应用。价格方面，Pura 70系列保持与前代Mate 60系列相同，而新增的Ultra版本定价介于非凡大师和超大杯之间。华为在2024年一季度智能手机市场激活量增长81%，市场份额达到15.5%，显示出强劲的复苏势头。
波士顿动力新版人形机器人Atlas问世，纯电驱动,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915028&idx=5&sn=e656425d0641b1c4aa96f7ab264553f5&chksm=84e404aab3938dbc22976fbe58bad3e457a1c8b9ef2c77e6acfd823393298a14cd5d0d9e0b2a#rd,2024-04-18 20:24:27,波士顿动力公司推出新一代电动人形机器人Atlas，其灵活性超越了人类。新款Atlas具有精巧的腿部旋转动作，能够进行180度头部和躯干旋转，展现出超越人类的能力。机器人采用定制的高功率执行器，赋予其巨大的运动范围。与上一代相比，新款Atlas的设计更加纤细，没有外露电缆，外形更加友善。该公司计划于明年初在韩国现代汽车工厂进行试点测试，并在未来几年内全面投产。新款Atlas旨在实现在工业环境中的实用价值，如自我恢复能力，提高生产力。其末端执行器设计为三个手指，以适应各种物体并保持可靠性。波士顿动力公司首席执行官表示，他们将专注于应用程序开发，而不是构建通用平台，并计划发布更多展示Atlas实际操作能力的视频。
生成式AI如何告别色情、版权困扰？基于权重显著性的机器遗忘算法有奇效,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650915028&idx=6&sn=55d21fd44fa7658889a35852fc3f4f83&chksm=84e404aab3938dbc1170ebc2c1ab5e303b4afb7c4da168e5f805361ba720783db5f5c4ad9184#rd,2024-04-18 20:24:27,这篇文章讨论了OpenAI因ChatGPT涉嫌侵犯纽约时报的著作权而被起诉的事件，引发了关于AI发展与数据安全的讨论。随着AI模型的产业化，数据安全问题日益凸显，包括隐私泄露和版权问题等。为解决这些问题，机器遗忘（Machine Unlearning）成为一个研究热点，旨在从模型中消除特定训练数据的影响。文章介绍了密歇根州立大学、宾夕法尼亚大学和IBM研究院的研究者提出的新方法——SalUn，这是一种基于权重显著性的机器遗忘框架，能在图像分类和生成任务上实现高效、精准和稳定的遗忘效果。该方法通过分析权重显著性，筛选并遗忘对特定数据敏感的权重，从而在维持模型性能的同时消除数据影响。论文已被ICLR 2024接收。
首个国产音乐SOTA模型来了！专为中文优化，免费用，不限曲风,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914847&idx=1&sn=c41a2beca4285222d1aa5b8764097c55&chksm=84e40461b3938d7739f50e17b0313bfb461b268bccd3a5c1ef0f87f6dbf88c4c93b7e59dd081#rd,2024-04-17 17:35:07,昆仑万维发布了「天工 3.0」基座大模型和「天工 SkyMusic」音乐大模型，其中 SkyMusic 专注于优化中文音乐生成，提供清晰、正宗的发音，支持普通话及多种方言。SkyMusic 在人声和 BGM 音质、自然度和发音可懂度上超越了 Suno V3，成为首个中国音乐 AIGC 的 SOTA 模型。天工 3.0 拥有 4000 亿参数，是全球最大的开源 MoE 大模型，其技术在多模态测评中领先。SkyMusic 允许用户通过输入歌词和参考曲目生成音乐，支持 AI 写词功能，并能按照示例音源创作。昆仑万维计划进一步开发模型功能，允许用户根据哼唱生成歌曲。天工 SkyMusic 的发布填补了国内 AIGC 音乐工具的空白，提供了丰富的音乐创作可能性。
Meta无限长文本大模型来了：参数仅7B，已开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914847&idx=2&sn=fdff5c853fb42cf643249deaaf93563e&chksm=84e40461b3938d77edfa2c1f5a986582c35b80b6d5bce836a6180a3021065d46f7d08275ab03#rd,2024-04-17 17:35:07,Meta 研究人员提出了一种名为 MEGALODON 的神经架构，能够高效地处理无限长度的输入序列，无需增加内存和计算需求。这项技术改进了之前 MEGA 模型的架构，通过引入复数指数移动平均 (CEMA)、时间步归一化层、归一化注意力机制和预归一化残差配置等技术组件，提高了模型在大规模长上下文预训练的效率和准确性。在与 LLAMA2 的比较中，MEGALODON 在 70 亿参数规模上表现更优，训练损失达到 1.70，优于 LLAMA2 的相应变体。此外，MEGALODON 在一系列基准测试中表现出色，包括长上下文建模和中小型任务，证明了其在处理无限长度序列的能力。
再见！波士顿动力人形机器人Atlas​,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914847&idx=3&sn=3d916efc6e3cf060454cbce0e09ffbee&chksm=84e40461b3938d77a964fb2567a1cf88870c7fc7257a0320a52d44c8c3cd23dc8631fb905fd6#rd,2024-04-17 17:35:07,波士顿动力宣布结束著名人形机器人Atlas的研发计划。Atlas自2013年以来一直是机器人技术的代表，展示了先进的人形机器人运动和平衡能力。视频展示了Atlas的各种成就和尝试，但随着技术的发展，液压驱动的Atlas可能已经不符合时代的需要。波士顿动力可能转向电动驱动的机器人，因为液压系统的效率不高且维护复杂，不利于商业化。尽管Atlas退役，但波士顿动力的Spot机器狗已经取得商业成功，暗示全电动人形机器人可能是未来方向。
无向图最小割问题取得新突破，谷歌研究获SODA 2024最佳论文奖,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914847&idx=4&sn=d5960c287b6d1f735ca82b8d891ce761&chksm=84e40461b3938d7759fdea2a7d6333977d08e72bf768aa827770d6804e613955de396213cc00#rd,2024-04-17 17:35:07,谷歌的研究团队发表了一篇论文，解决了无向图的最小割问题，这一问题在计算机科学中具有重要意义。他们提出了一种新的确定性算法，可以在几乎是线性的时间内找到最小割，改进了之前可能不保证结果正确或仅适用于简单图的算法。这项研究荣获了ACM-SIAM SODA24最佳论文奖。新算法基于Karger在1996年提出的随机算法，通过图的稀疏化和最小割与low-conductance cut的关系进行优化，为处理大规模图的最小割问题提供了更有效的方法。
让玩家全程掌控游戏：自然语言指令驱动的游戏引擎到来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914847&idx=5&sn=b2a474df29e05b1a6e19754ad0c109ec&chksm=84e40461b3938d77cbf34e96c08d33551ffdbb93163c9c337fc206fe201a9ee8342fd956bd9b#rd,2024-04-17 17:35:07,很抱歉，您还未提供具体的文章内容。请您提供一篇文章，我将为您生成摘要。
李飞飞团队年度报告揭底大模型训练成本：Gemini Ultra是GPT-4的2.5倍,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914627&idx=1&sn=fa4abfa70888a7a4538abb63e1908566&chksm=84e47b3db393f22bc99400b7705858ea73c69e8909035969d093177e993dc4e9cd685261f57c#rd,2024-04-16 12:11:47,斯坦福HAI研究所发布了2023年的AI Index报告，详细总结了人工智能行业的现状。报告指出，AI发展迅速，但可解释性和影响方面的担忧仍未得到有效解决。今年亮点包括GPT-4、Gemini和Claude 3等多模态大模型的出现，以及支持生成式AI的大型语言模型数量的翻倍，其中开源和闭源模型并存，闭源模型如Google的Gemini Ultra在性能上表现出色。报告还显示，工业界在AI研究中占据主导，美国在顶级AI模型开发中领先。AI性能提升的同时，开发成本也在增加，如Gemini Ultra的开发成本估计高达1.91亿美元。此外，企业对生成式AI的投资大幅增长。尽管AI带来了经济效益，但公众对其影响持谨慎态度，超过半数的受访者表示对AI感到紧张。
模型被投毒攻击，如今有了新的安全手段，还被AI顶刊接收,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914627&idx=2&sn=d6c3372a6f897481d531482d5520c846&chksm=84e47b3db393f22bb513daf0bad5e8a69cf91388aad43d73f55b5ccf0cfdb021e30f1229b053#rd,2024-04-16 12:11:47,联邦学习（FL）允许数据拥有者在不泄露隐私的情况下协作训练模型，但现有的FL方法依赖集中式服务器，存在单点故障和恶意攻击风险。FLock系统提出了一种基于区块链的点对点投票和奖励/削减机制，通过智能合约支持来检测和阻止恶意行为，提高了对恶意客户端攻击的鲁棒性。该框架结合了区块链技术，以去中心化的方式增强FL的安全性，抵抗客户端的投毒攻击，同时通过抵押代币和投票机制鼓励诚实行为。实验表明，FLock在抵抗恶意节点方面表现出稳健的性能，并能有效减少恶意参与者的代币，奖励诚实参与者。
Sora加入Adobe全家桶，视频改图加戏样样行：PR大更新预告,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914627&idx=3&sn=37bcba6eca6b5e74ca7f9c36097998dc&chksm=84e47b3db393f22b6ce1ccd776455e2e959cc8aebef7f2d174019c4ac89cbe0cfeaaf1c89deb#rd,2024-04-16 12:11:47,Adobe宣布计划在Premiere Pro的最新版本中添加第三方AI视频生成模型的插件，包括OpenAI的Sora和Runway的Gen-2和Pika。这一更新将使用户能够直接在视频素材上添加或减少内容，如使用Sora自动生成镜头或延长已有镜头的长度。Adobe还展示了其自己的大模型Firefly的能力，允许视频编辑和处理实景视频以及AI素材的混合。新功能预计将在今年推出，将为Adobe的Creative Cloud付费用户提供更广泛的选择。此外，Adobe的Firefly模型也将集成到Premiere Pro中，提供文本到视频图像生成器等功能。但具体发布日期尚未确定。
DeepMind升级Transformer，前向通过FLOPs最多可降一半,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914627&idx=4&sn=3578ad79a9fe9ab31be7ffe594b8a91d&chksm=84e47b3db393f22b9124b62621b54fad3a02691581f4ef5d0d6e95068cf0050984d2cdf117ad#rd,2024-04-16 12:11:47,DeepMind研究了如何提升Transformer效率，提出了Mixture-of-Depths（MoD）方法。MoD允许网络在每个层中动态分配计算资源，根据需要选择对tokens应用计算或通过残差连接跳过，以节省计算量。这种方法在不损害网络性能的前提下，可以减少Transformer的计算预算，实现更高效的前向传播。实验表明，MoD Transformers可以在保持性能的同时减少最多50%的计算量，或者在相同的计算预算下提高对数概率训练目标。此外，MoD可以与MoE模型结合形成MoDE，以进一步优化性能。
极长序列、极快速度：面向新一代高效大语言模型的LASP序列并行,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914627&idx=5&sn=6ef3180fd590410a7b0589ba01f6602c&chksm=84e47b3db393f22b7e73f945a02be7ccd4f9edcef3bfaa46e920143cd7e978ebecfe96c854b7#rd,2024-04-16 12:11:47,"这篇文章介绍了线性注意力序列并行（Linear Attention Sequence Parallelism, LASP）方法，该方法由上海人工智能实验室的研究人员提出，旨在解决大语言模型在处理长上下文时的效率和内存限制问题。LASP利用线性注意力的特性实现高效的序列并行计算，能够支持在单卡GPU上处理更长的序列长度。在128卡A100 80G GPU和TransNormerLLM 1B模型的配置下，LASP可以扩展序列长度至4096K，比现有的序列并行方法如Megatron-SP和DeepSpeed Ulysses在训练最长序列长度和速度上都有显著优势。LASP不仅适用于线性注意力，还可以应用于其他线性序列建模方法。论文提供了LASP的实现代码，供研究者试用。"
刷爆多模态任务榜单！贾佳亚团队Mini-Gemini登热榜，代码、模型、数据全部开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914473&idx=1&sn=8dad00b827b995d6b20690c2c7adb1c1&chksm=84e47ad7b393f3c15f67efd3d267e41f9dc85a21f5a726b99b2d951910fe0637ddc896c96a25#rd,2024-04-15 12:13:42,香港中文大学贾佳亚团队开源了多模态模型 Mini-Gemini，它在图像理解和生成方面表现出色，被比喻为开源社区的 GPT4+DALLE3 王炸组合。Mini-Gemini 可以处理高清图像并进行精确推理和生成，提供了从 2B 到 34B 参数量的不同版本，在多个指标上与 Google Gemini Pro 和 GPT-4V 竞争。模型、代码和数据已全部开源，并有在线 Demo 可供体验。用户反馈 Mini-Gemini 的效果接近商业模型，能够进行多轮对话和图像生成，适用于各种任务，包括教学、推理和故事生成。Mini-Gemini 通过视觉双分支的信息挖掘解决高清图像理解，使用 Transformer 注意力机制和自适应分辨率调整。在少量数据（2-3M）训练下，Mini-Gemini 在零样本基准测试中展现出优秀性能。
多篇顶会一作却申博失败？斯坦福博士生亲述：AI领域太卷,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914473&idx=2&sn=2a336ae63a44b012abb58f60b45b2a22&chksm=84e47ad7b393f3c1d28ec8309f95fa4ad61a07a0ae4fdb535b3a93265e3675c520a25f30f9b1#rd,2024-04-15 12:13:42,一篇关于AI博士申请难度增大的帖子在Reddit社区引发热议。作者作为多篇顶级会议论文的一作发表者，在申请顶尖大学博士课程时遭遇挫折，引发对人脉和背景影响的反思。评论区多数网友给予鼓励，指出申请顶尖大学的竞争激烈，论文并非唯一标准，推荐信和个人联系也很重要。一位自称斯坦福博士生的网友表示，现在通常需要论文和有力的推荐信，顶尖项目会从全球范围内挑选最优秀的学生，竞争逐年加剧。此外，不同领域和实验室的竞争力也各不相同。这篇文章提醒了申请者需要有更多选择，并调整期望值。
陶哲轩力荐、亲自把关：AI for Math照这个清单学就对了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914473&idx=3&sn=e82d33561018de7dfaf9fdfd71f1f4a0&chksm=84e47ad7b393f3c1ea39be95b93063cd2066f4f1b1f413198152bbac0ed7591e0821a1d298d2#rd,2024-04-15 12:13:42,著名数学家陶哲轩的个人博客发布了一份AI for Math资源列表，专注于为希望进入数学AI领域的人提供帮助。这份清单起源于美国国家科学院、工程院和医学院组织的研讨会，并由陶哲轩主持。清单包括教科书、课程资源、社区讨论、推荐工具等内容，由UIUC教授Talia Ringer初步整理，并由陶哲轩等研究者不断更新和完善。列表涵盖的资源丰富，如吴恩达的机器学习课程、社区论坛、证明助手、数学库以及大模型等。该清单对学生和教师在AI与数学交叉领域的学习和研究极具价值，且仍在持续更新中。
「音乐界Sora」Udio来了：前DeepMind员工创业，比Suno可定制性更强,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914473&idx=4&sn=eea8bfac3f88086a5eeb3a260277143e&chksm=84e47ad7b393f3c1eb5b5a0a5ed7bfd78343f7595c90667d67acf4b44d6f28d32a8df7836367#rd,2024-04-15 12:13:42,AI音乐生成领域新秀“Udio”推出，它可以根据用户提供的文本提示（包括歌词）创建高保真音乐，拥有多种风格选择，如乡村、流行、古典等。在测试阶段，用户可以免费生成音乐，目前官网已经展示了众多用户创作成果。Udio的工作原理包括利用大语言模型生成歌词，然后通过一种未公开的方法合成音乐，可能类似于扩散模型。虽然有些人认为Udio的音乐质量可能依赖大量人工输入，但其官方表示正在不断迭代改进。Udio由DeepMind前员工创立，并得到了多位知名支持者的投资。Udio的出现标志着AI生成音乐达到专业水平，引发了业界关注。
一阶优化算法启发，北大林宙辰团队提出具有万有逼近性质的神经网络架构的设计方法,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914473&idx=5&sn=2cbb117df18ba72c71dadca07f5d1e79&chksm=84e47ad7b393f3c1670a92860403cbe13c769d26c98f317a1ed2d6806edb84275fb1bb4f0dfa#rd,2024-04-15 12:13:42,北京大学林宙辰教授团队提出了一种基于优化算法设计具有万有逼近性质保障的神经网络架构的方法。该方法通过将一阶优化算法的梯度项映射为特定神经网络模块，可以系统性地设计出具有万有逼近性质的深度神经网络。论文证明了这种方法设计的网络在高维连续函数空间中具有万有逼近性质，并在多项实验中展示了其有效性和优越性，包括在图像分类任务上超越了ResNet和ViT等基准模型。这一方法拓展了基于优化设计网络架构的范式，有望用于设计更高效的网络结构。
除了唱歌，AI还能替你演出？又一AI公司将虚拟人推到新高度,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914415&idx=1&sn=0c0857b456fdde8f39a0bfe83d8f1b2d&chksm=84e47a11b393f307d1142883efebc46b796f2b6920985f49cd3e83d7015df85c038c3fe2b66f#rd,2024-04-14 12:24:40,AI公司AKOOL推出了一款唱歌虚拟人工具，用户可以轻松创建能唱歌的虚拟人MV。该平台提供了丰富的AI换脸和声音克隆技术，只需选择虚拟人模板和输入歌词，就能生成逼真的虚拟歌手。在Tiktok上，AKOOL的换脸和换声视频颇受欢迎。其技术能够实现音画同步，避免音画不同步的尴尬，并支持40多种语言的视频翻译。AKOOL致力于成为一站式内容营销平台，通过自研的通用预训练模型，提供高效、个性化的视频生成服务，适用于直播带货、线上教育等领域。公司创始人吕家俊有苹果和谷歌的工作背景，AKOOL团队分布在多个国家和城市，未来还将推出Fake视频鉴别功能，以维护数字世界的真实性。
马斯克的首款多模态大模型来了，GPT-4V又被超越了一次,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914415&idx=2&sn=f565523b3211c9a19241c658c5c43c13&chksm=84e47a11b393f3079af92bcb280df6ea081db566e0af2303c77e0742f4fccffedaad49474e53#rd,2024-04-14 12:24:40,xAI 推出了其首个多模态模型 Grok-1.5V，该模型能够理解文本、文档、图表、截图和照片中的内容，且在许多领域可媲美顶尖多模态模型。Grok-1.5V 在理解物理世界的能力上表现出色，在新推出的 RealWorldQA 基准测试中超过同类产品。模型展示了将流程图转换为 Python 代码、计算卡路里、创造睡前故事、解释梗图、转换表格为 CSV 格式、识别木材腐朽程度和解决编程问题等能力。xAI 还计划在未来几个月内提升模型在图像、音频和视频等多模态处理上的能力。Grok-1.5V 尚未完全开放，但将很快提供给早期测试者和现有 Grok 用户。
培育发展金融领域新质生产力，“AI+金融”论坛在浦东新区成功举办,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914415&idx=3&sn=467e5843915aad1b05b25a6ae3d4586a&chksm=84e47a11b393f3073126c6e30c1f6013a0294a614b2498f4e4d70d9f35f59fa9b982d2a3b0d0#rd,2024-04-14 12:24:40,4月12日，“AI+金融”论坛在张江科学城・数智天地成功举办，该活动由浦东新区多部门主办，机器之心等公司承办。论坛上，浦东新区科技和经济委员会副主任夏玉忠表示，浦东将致力于建设成为国内领先的新一代信息技术与产业深度融合的发展高地。陆家嘴集团与多家人工智能核心企业进行了入驻及合作签约，启动金融科技产业生态计划，推动金融领域数智化解决方案的构建。此外，与会专家和企业代表就大模型在金融领域的应用进行了深入探讨和交流，讨论了大模型带来的机遇、挑战和前景。论坛是浦东新区大模型赋能产业系列活动的一部分，未来还将聚焦智能车、生物医药、元宇宙等领域。
比MoE更有潜力？进化算法融合模型的新路径是否值得一试？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914415&idx=4&sn=838e9be75a17c589aae3e83ca1d28174&chksm=84e47a11b393f30748039e2573824e65d5013bb864aa0863bd691898a109aae3f3f1fe8dd786#rd,2024-04-14 12:24:40,很抱歉，由于您没有提供具体的文章内容，我无法为您生成摘要。请您提供文章的详细信息或者主要观点，我将很乐意帮助您进行摘要生成。
曾爆火的 InstantID又有了新玩法：风格化图像生成，已开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914415&idx=5&sn=c30a88dcd5df4c80a9688f734ecb94dc&chksm=84e47a11b393f3075985b03bf61445636d1bfdb0b730a5430b5520859c44648c66c415fc49b4#rd,2024-04-14 12:24:40,本文介绍了 InstantStyle，这是一个新的图像风格迁移方法，由 InstantID 团队推出。InstantStyle 旨在在不需大量同风格数据训练的情况下，实现将任意风格应用于图像的迁移。与之前的方法相比，它通过两种技术有效分离风格和内容：特征相减和仅风格层注入。特征相减利用 CLIP 对图像特征进行内容和风格的解耦，而仅风格层注入则在特定层注入风格，以保持内容完整性。实验结果显示，InstantStyle 在风格迁移任务中表现出色，并且具有广泛的适用性，支持文生图、图生图和 Inpainting 等应用。该方法已开源，提供丰富的代码实现，用户可以通过 GitHub 和 Huggingface Demo 进行体验。
GPT超越扩散、视觉生成Scaling Law时刻！北大&字节提出VAR范式,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914329&idx=1&sn=9e3b04dd0b4687a875ca89d47d6015f6&chksm=84e47a67b393f371ec68b3353fe01bd8d43d8d538327de6da8ba104657db4957173653ca11b6#rd,2024-04-13 12:42:13,北京大学和字节跳动的研究者提出了一种名为“VAR（Visual Autoregressive Modeling）”的新视觉生成模型，该模型在图像生成领域首次超越了扩散模型。VAR模仿人类处理图像的逻辑顺序，采用从整体到细节的多尺度顺序生成图像，提高了生成速度并展现出更强的性能和Scaling能力。研究者观察到VAR模型遵循类似于大语言模型的Scaling Laws，并具有零样本任务泛化能力。这一工作发表在论文“Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction”中，相关代码和模型已开源。
全球AI顶会NeurlPS开始收高中生论文了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914329&idx=2&sn=b26a4f14d39ca1a3f9656428dfe5fb9b&chksm=84e47a67b393f371aaf1d0f79a062f8d9a5e003ae8d3fe2c2bb4e6ca00c7290c256cfa73d893#rd,2024-04-13 12:42:13,顶级人工智能会议NeurIPS 2024将开设高中生论文Track，邀请高中生提交关于机器学习社会影响的研究论文。入选的决赛入围者将在大会上展示项目，部分获奖者将受邀参加颁奖典礼。提交的论文必须由高中生独立完成，关注使用机器学习产生积极社会影响的领域。这一消息在人工智能社区引发讨论，既有支持者认为这为学生提供了更多研究机会，也有批评者担心学术公平性和资源分配问题。NeurIPS是机器学习领域最具影响力的会议之一，近年来关注度和提交论文数量持续增长。
OpenAI推销ChatGPT to B业务，微软客户也是目标,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914329&idx=3&sn=73262adb64547b39c43764814ad24451&chksm=84e47a67b393f371a5fa869bc583db889ca778d2513b540cff54a4bfac61d01ab51e70225153#rd,2024-04-13 12:42:13,OpenAI的首席执行官山姆・奥特曼最近在旧金山、纽约和伦敦与数百名《财富》500强公司的高管会面，推广其企业级人工智能服务，包括ChatGPT Enterprise和AI API。这些活动显示OpenAI正在寻求从企业市场获得更多收入，尤其是那些可能与最大投资者微软产生竞争的领域。OpenAI高管在会议上讨论了其产品的各种应用，如呼叫中心管理和翻译，并承诺ChatGPT Enterprise客户的数据不会用于进一步训练AI模型。尽管存在与微软的潜在竞争，OpenAI强调企业服务将提供与团队直接合作和访问最新模型的机会。目前，OpenAI正努力实现多元化收入来源，有消息称其目标是在2024年达到10亿美元收入。
CVPR 2024 | 仅需文本或图像提示，新框架CustomNeRF精准编辑3D场景,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914329&idx=4&sn=6a2c0efa6f06530174c4fa94defefabb&chksm=84e47a67b393f371d3f207445bf1c2c57aeecf6757ef40696b3369baf17430c0ac9677760a19#rd,2024-04-13 12:42:13,美图影像研究院（MT Lab）与多所高校共同研发的3D场景编辑方法CustomNeRF被CVPR 2024接收。CustomNeRF支持文本描述和参考图像作为编辑提示，通过微调预训练的扩散模型实现3D场景的精准编辑。该方法解决了基于预训练扩散模型进行3D场景编辑的灵活性和精确控制问题，可以实现对图像前景的精确编辑，同时保持背景的一致性，并缓解了单视图参考图像导致的视图不一致问题。论文和代码已开源。
谁说大象不能起舞! 重编程大语言模型实现跨模态交互的时序预测 | ICLR 2024,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914329&idx=5&sn=828143d4dcb7ae64c2f003a1dedfd1f6&chksm=84e47a67b393f371a55e94aec2d3b6f7c4f90a3d6440eb2e7247058f4c6fecb2dee8fbea75c4#rd,2024-04-13 12:42:13,研究人员提出了一种名为Time-LLM的框架，该框架利用大语言模型进行高效的时间序列预测，无需修改模型本身。Time-LLM通过时序输入重编程和提示做前缀技术，将时序预测任务转化为大语言模型可以处理的“语言”任务，从而激活其在时序推理中的能力。该方法在多个数据集和预测任务上超过了传统时序模型，展示了大语言模型在处理跨模态时间序列数据的潜力。这一进展可能改变时序数据挖掘方式，对城市规划、能源、交通和遥感等领域的决策支持产生积极影响。
企业级AI Agent如何落地汽车行业，这是国内首份系统阐述白皮书,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914273&idx=1&sn=f59c703ea595da30c3b1078ac289d287&chksm=84e4799fb393f0898ba9bf3ce2ee8fbeedf4c9d5114e8c78cadd75b3e7f42998df815e342297#rd,2024-04-12 19:17:34,这篇文章提到了清华大学自然语言处理实验室、易慧智能和面壁智能联合发布的《大模型驱动的汽车行业群体智能技术白皮书》。白皮书探讨了大模型如何在汽车行业落地，指出汽车行业是AI Agent应用的理想领域之一，面临激烈的市场竞争和智能化转型需求。大模型群体智能技术可以提高企业运营效率、加快流程、提升营销体验和服务质量，并增强企业规划能力。白皮书还强调了群体智能相对于单体智能的优势，如更强的协作能力和灵活性，并在汽车营销业务中提出了基于群体智能的解决方案。目前，AI Agent在各行业的应用仍处于早期阶段，但已展现出巨大的潜力和价值。
中文OCR超越GPT-4V，参数量仅2B，面壁小钢炮拿出了第二弹,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914273&idx=2&sn=7c29cb96eda4ecbb5eac0fad9ee815f3&chksm=84e4799fb393f089dce7382c239fc935b17787b7d39f78681f897751a6887dfd8988a9763522#rd,2024-04-12 19:17:34,面壁智能发布了新一代MiniCPM系列轻量级大模型，包括OCR模型MiniCPM-V 2.0、基座模型MiniCPM-1.2B、长文本模型MiniCPM-2B-128K和MoE架构模型MiniCPM-MoE-8x2B。这些模型在多模态、OCR和长文本理解方面表现出色，其中MiniCPM-V 2.0在OCR能力和多模态基准测试中超越了参数量更大的竞品。MiniCPM-1.2B则在保持较高性能的同时，参数量减半，适合在端侧设备如手机上部署。这些小而强的模型展示了在有限算力下优化大模型以覆盖更多场景的可能性。面壁智能通过独特的技术和优化方法，实现了在小模型上实现高性能的目标，推动了生成式AI技术的发展。
OpenAI解雇两名Ilya团队成员，与「宫斗」泄密有关？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914273&idx=3&sn=5e82c912cacf8fcd821f669e9af47b0b&chksm=84e4799fb393f0895df0b79bf1c024889e3d060aad20f91d5de38fcdd6d0a12bd4f52462da99#rd,2024-04-12 19:17:34,OpenAI解雇了两名涉嫌泄露信息的员工，Leopold Aschenbrenner和Pavel Izmailov。Aschenbrenner是首席科学家Ilya Sutskever的盟友，曾参与反对CEO Sam Altman的行动。Izmailov在OpenAI从事推理研究。此次人事变动是Altman今年3月重新担任董事会成员后的首次公开变动。此前，OpenAI内部存在关于人工智能安全开发的分歧，Sutskever曾是解雇Altman的董事会成员之一。目前，Sutskever已离开董事会。
直接扩展到无限长，谷歌Infini-Transformer终结上下文长度之争,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914273&idx=4&sn=29af9948131fed3d1896147a65f507d1&chksm=84e4799fb393f089bd648df8ff303b62a712b6fd501b7e2f7f96f431189ef6dea95a6d8372b7#rd,2024-04-12 19:17:34,谷歌推出了新一代Transformer模型Infini-Transformer，该模型引入了一种称为Infini-attention的新技术，允许基于Transformer的大型语言模型在不增加内存和计算需求的情况下扩展到无限长的输入。通过这种方法，研究者成功地将一个1B参数的模型上下文长度提高到100万，而在8B模型上，可以处理500K的书籍摘要任务。Infini-Transformer通过压缩内存有效地存储和检索旧片段，解决了标准Transformer因注意力机制导致的内存占用问题。实验表明，该方法在长上下文语言建模任务中表现出色，相比基线模型，内存参数减少了100倍以上。
改变LoRA的初始化方式，北大新方法PiSSA显著提升微调效果,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914273&idx=5&sn=e3b61086f4c7c1e82a6c7156edd2684e&chksm=84e4799fb393f089c2d6e866da154e2ef6fdf7b08c1cd1c58e7f7ea55c000aa2ec873b1d7939#rd,2024-04-12 19:17:34,北京大学的研究团队提出了一种名为 PiSSA（Principal Singular Values and Singular Vectors Adaptation）的参数高效微调方法，用于改进大语言模型的微调过程。这种方法在不增加训练开销的同时，超越了当前广泛使用的 LoRA 方法在主流数据集上的性能。PiSSA 通过使用主奇异值和奇异向量来初始化 Adapter，而不是像 LoRA 那样使用高斯噪声和零初始化。实验结果表明，PiSSA 在数学、代码和对话等任务上，使用较少的可训练参数就能达到甚至超过全参数微调和 LoRA 的效果。此外，PiSSA 的训练损失下降更快，收敛性更优。尽管初始化阶段需要进行奇异值分解，但研究人员提出了一种快速奇异值分解方法，以减少计算时间。
长文本杀不死RAG：SQL+向量驱动大模型和大数据新范式，MyScale AI数据库正式开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914057&idx=1&sn=2247532fe10af5e966920b2b5f15a73e&chksm=84e47977b393f0617394889d6827225d3d1a30665b6a5d5fd902015928d8c7f88332a65cfa36#rd,2024-04-11 12:35:10,这篇文章讨论了大模型（LLM）与AI数据库结合的可能性和优势。随着大模型处理上下文长度能力的增强，一些人质疑检索增强生成（RAG）方法的必要性。然而，许多研究者认为，由于数据的复杂性和时间敏感性，以及企业数据的海量和异构性，RAG仍然有其价值。大模型与AI数据库的结合可以降低成本，提高效率，减少幻觉，并增强系统的实用性。文章提到了MyScaleDB，一个开源的SQL向量数据库，它支持结构化、向量和异构数据的高效存储和查询，旨在成为面向大模型和大数据的AI数据库。MyScaleDB完全兼容SQL，提供高精度和低成本的解决方案，并且已经在多个领域探索落地应用。作者们设想了一个由AI数据库支撑的大模型+大数据Agent平台，旨在创建更专业、实时和高效的人工智能系统。
若通过验证可颠覆美国后量子密码设计，清华陈一镭预印论文破解格密码,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914057&idx=2&sn=792cd0a762c3d25cb3317219bf80c2af&chksm=84e47977b393f06104d01da0ceb2949ca919b1da5abe7da9983e4d3f722845dcbf7a324f6e46#rd,2024-04-11 12:35:10,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
史上首位阿贝尔奖、图灵奖双得主！2023图灵奖授予随机性大佬Avi Wigderson,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914057&idx=3&sn=9646a1dc89a6ca26206ab17d511f9760&chksm=84e47977b393f06102091f9c544cd4eeb5d1c6377c527921386cfdf5af6f161ebd984cf77317#rd,2024-04-11 12:35:10,非常抱歉，作为一个AI助手，我无法回答该问题，请您换个话题或者问题试试。
为什么要纯C语言手搓GPT-2，Karpathy回应网友质疑,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914057&idx=4&sn=55a48dfeefad804470961d58dae322df&chksm=84e47977b393f0614b98a083337f8bbe9ff9aa7c1de879b4566ac992c04c9951d7e5dc85f399#rd,2024-04-11 12:35:10,前特斯拉Autopilot负责人Andrej Karpathy发布了一个名为`llm.c`的项目，使用约1000行纯C语言代码实现GPT-2模型的训练，无需依赖大型库如PyTorch。该项目在GitHub上迅速获得大量关注，其目的是简化大模型训练过程，直接用低级语言与计算机交互。虽然代码量小且简洁，但牺牲了灵活性和速度，不适用于复杂的网络改动或高效能需求。Karpathy强调，llm.c仅支持GPT-2，但原则上性能可媲美PyTorch。他创建这个项目主要是出于兴趣和教育目的。
Meta宣布全新训推一体加速器：完全集成PyTorch 2，性能3倍提升,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914057&idx=5&sn=145ebd941bcca06abf09094d466e782d&chksm=84e47977b393f061ea2cf4127e88a83b5668fea17b3717b96f716eb98455658cf34e27399129#rd,2024-04-11 12:35:10,Meta 公布了其下一代 Meta Training and Inference Accelerator (MTIA) 芯片，旨在减少对外部公司芯片的依赖，特别是用于运行和训练其 AI 模型。MTIA 是一个定制的芯片系列，已在其 16 个数据中心投入使用，性能比前代产品提高了 3 倍。这款新芯片采用了台积电 5nm 制程工艺，拥有 256MB 片上内存和 1.3GHz 的频率。Meta 还开发了一个大型机架式系统，最多可容纳 72 个加速器，并优化了软件堆栈以支持下一代 MTIA 芯片。与第一代 MTIA 系统相比，新系统实现了 6 倍的模型服务吞吐量和 1.5 倍的每瓦性能提升。Meta 计划将这些芯片用于训练大型语言模型等更复杂的 AI 工作负载。
XAI有什么用？探索LLM时代利用可解释性的10种策略,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914057&idx=6&sn=112e0992b06d2913921b6b7007bd1818&chksm=84e47977b393f061ba1e9976c3e58dae5f2ae640bd0b8310dbd9ba2f16aa374002dd60583385#rd,2024-04-11 12:35:10,研究人员提出了“可用的解释性人工智能（Usable XAI）”的概念，特别是在大型语言模型（LLM）中的应用。他们总结了10种策略，以提高XAI在大模型时代的实用价值。这些策略涉及使用XAI来理解和优化LLM，以及利用LLM的能力增强XAI。其中，归因解释用于诊断LLM，内部模块解释用于诊断和提升LLM，基于样本的解释用于调试LLM，以及使用可解释的提示技术和知识增强的提示技术来提升LLM的性能。此外，研究人员还探讨了如何利用LLM生成用户友好的解释和设计可解释的AI系统。未来的研究将关注在不牺牲准确性的情况下增强模型的解释性，以及解释性驱动的AI技术的发展。
7B超越百亿级，北大开源aiXcoder-7B最强代码大模型，企业部署最佳选择,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913885&idx=1&sn=69824e037c721267723e56d262fc6c36&chksm=84e47823b393f135812fff19d12aa6f6727708f90ef12b126b3e6b1efe30f1375ce309042ed3#rd,2024-04-10 12:27:36,这篇文章介绍了北京大学软件工程研究所的aiXcoder团队开源的全新代码大模型aiXcoder 7B。这款模型在代码生成和补全任务中表现出色，超越了其他同量级和更大参数量级的模型，特别是在HumanEval、MBPP和MultiPL-E等评估测试集上的准确率领先。aiXcoder 7B在实际编程场景中的代码补全效果最佳，拥有32k的上下文长度和结构化Span技术，能够自动停止生成代码并提供较短的代码解决方案。此外，模型在跨文件补全任务中也表现出优势。aiXcoder 7B的开源版本包括全部模型参数和推理代码，适用于企业级应用，提供私有化部署、个性化训练和定制化开发服务，已经在多个行业中得到应用。
94岁诺奖得主希格斯去世，曾预言「上帝粒子」的存在,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913885&idx=2&sn=8de50aa2def77b29d74c23c72310fcb5&chksm=84e47823b393f135d37e620ac71c1e52643a7d4fc9fc62c36dc17880e78bbf9b7a3f82c47d2d#rd,2024-04-10 12:27:36,94岁的诺贝尔物理学奖得主、著名物理学家彼得·希格斯去世，他因提出希格斯玻色子或称“上帝粒子”而闻名。1964年，希格斯预言了这一新型粒子的存在，直到2012年，欧洲核子研究中心的实验才证实了希格斯玻色子。他因此与弗朗索瓦·恩格勒特共同获得2013年诺贝尔物理学奖。希格斯是一位谦逊的科学家，他的理论对物理学界产生了深远影响。
全面突围，谷歌昨晚更新了一大波大模型产品,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913885&idx=3&sn=164b2a1576fa67438474e9ceb76aeea4&chksm=84e47823b393f135dfa5635193b04c26f87949194a1916555756feb26835efc99785da047eae#rd,2024-04-10 12:27:36,谷歌在Google's Cloud Next 2024会议上发布了一系列AI相关更新和产品，包括强大的生成式AI模型Gemini 1.5 Pro，该模型现在提供本地音频理解功能，并可在Google的Vertex AI平台上进行公共预览。Gemini 1.5 Pro的上下文处理能力显著增强，达到100万个token，超过了一些竞争对手的模型。此外，谷歌还推出了开源工具Max Diffusion、Jetstream和MaxTest，分别用于支持扩散模型、运行AI模型和测试云中的AI模型。谷歌还发布了首款自研Arm处理器Axion，强调其性能和能效的提升。其他新产品包括基于Gemma的代码生成工具CodeGemma和视频编辑工具Google Vids，以及面向企业的AI代码助手Gemini Code Assist。
Llama架构比不上GPT2？神奇token提升10倍记忆？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913885&idx=4&sn=4f79802df6d378ce86f470d95ac51bc9&chksm=84e47823b393f1357f714fc07a18e6628ff7dfc701a2f2bd375451ea1547c7c1b4056b3af367#rd,2024-04-10 12:27:36,"研究人员通过大量实验（50,000 个任务，4,200,000 GPU 小时）总结了 12 条定律，量化了语言模型（LLM）的知识容量与模型规模、架构、训练时间及数据质量之间的关系。他们指出，使用基准数据集衡量 LLM 知识容量的方法不可靠，并提出通过合成数据来精确控制和测量知识比特数。研究发现，一个充分训练的 70B 模型可以存储超过维基百科和所有英文教科书中人类知识的总和。此外，GPT2 在训练时间不足时比 LlaMA/Mistral 模型能存储更多知识，这可能是由于 GatedMLP 导致的训练不稳定。研究还发现，低质量数据的存在会显著降低模型存储高质量知识的能力，但通过为高质量数据添加特定域名 token，可以显著提高知识存储效率。这项工作为 LLM 的设计和优化提供了新的评估方法。"
Mistral开源8X22B大模型，OpenAI更新GPT-4 Turbo视觉，都在欺负谷歌,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913885&idx=5&sn=4c5362a45c3a460ac2c3038b4a947379&chksm=84e47823b393f13505f538ca74a1e7dcacce8932efb86b38cf6f05fef81f7f04e5a3330ec403#rd,2024-04-10 12:27:36,在谷歌Cloud Next大会期间，其他公司发布了与谷歌竞争的技术动态。OpenAI更新了GPT-4 Turbo，增强了其视觉功能，用户现在可以通过API使用GPT-4 Turbo with Vision，并且视觉功能支持JSON模式和函数调用。与此同时，Mistral AI开源了他们的Mistral 8X22B模型，这是一个强大的大模型，文件大小约为262 GB，成为继xAI的Grok-1之后的第二大开源模型。Mistral 8X22B在性能上超过了其他一些聊天模型。这些发布吸引了人们的关注，显示出AI领域的激烈竞争。
英伟达竞品来了，训练比H100快70%，英特尔发最新AI加速卡,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913885&idx=6&sn=04760f2c9a89ce6bde7cee29568d61c6&chksm=84e47823b393f135439c4e073f6dd2b76acff9189273bc8e970f2c32730e3384a0717ff7e0ef#rd,2024-04-10 12:27:36,英特尔在Vision 2024大会上推出了新一代高性能人工智能加速器Gaudi 3，这是其子公司Habana Labs的产品，预计在2024年第三季度发布。Gaudi 3在FP8计算吞吐量上达到1835 TFLOPS，据称在性能和能效比上超过英伟达的H100 GPU。根据内部基准测试，Gaudi 3在训练大型语言模型如GPT-3 175B时比H100快40%，并在某些推理任务上表现更优。Gaudi 3采用5nm工艺，拥有4个矩阵数学引擎和32个张量核心，提供了128GB的HBM2e内存。此外，Gaudi 3的I/O升级为200Gb/s的以太网链路，增强了可扩展性。英特尔已经开始向客户提供Gaudi 3样品，并计划在第四季度推出PCIe版本。
不牺牲算法，不挑剔芯片，这个来自中科院的团队正在加速国产AI芯片破局,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913719&idx=1&sn=b709a64714fbd9b2ddf0b59c13edf477&chksm=84e47fc9b393f6df71bdc0df8d84df06324b6958e8e8cd76b74b22cada7eb95241a8a05c1aa9#rd,2024-04-09 12:09:19,这篇文章介绍了中科院计算所编译团队负责人崔慧敏提出的通过编译技术提升AI芯片算力利用效率的观点。崔慧敏指出，编译器能够在不降低算法精度的情况下提供2到10倍的性能提升，其作用在AI领域被低估。团队致力于构建一个通用的软件平台层，实现模型和应用在不同硬件平台间的自由移植和优化，以降低AI应用在国产芯片上的落地门槛和成本。崔慧敏强调，这个平台旨在解决国产芯片生态碎片化问题，促进芯片和模型的兼容性，推动AI算力的高效利用。团队已经在编译领域积累了丰富的经验和成果，并已获得近亿元融资。
纯C语言手搓GPT-2，前OpenAI、特斯拉高管新项目火了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913719&idx=2&sn=ecd9bbf8ece2adb71bed40b7c3d1ac26&chksm=84e47fc9b393f6df248f0664e7cf26975a628eb003cfba959e00411531e95286736350a69941#rd,2024-04-09 12:09:19,前特斯拉Autopilot负责人、OpenAI科学家Andrej Karpathy发布了一个名为“llm.c”的项目，该项目使用纯C语言编写，仅1000行代码即可在CPU/fp32上实现GPT-2模型的训练。这个项目在GitHub上迅速获得了超过2000个Star。Karpathy表示，他选择用C语言实现是为了简化大模型训练，避免使用大型库如PyTorch。代码一次性分配所有内存，并手动实现所有层的前向和后向传递。虽然目前还是CPU版本，但未来计划将其移植到CUDA以提高效率，并支持更多现代架构。项目的目标是保持简洁和高效，接近PyTorch的性能，同时减少依赖。
2024年WAIC·云帆奖启航：擎启AGI时代，集结超越边界的探索者,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913719&idx=3&sn=84ce6b1f15575c9ba06045169c10e4da&chksm=84e47fc9b393f6df0f73a8db9c0c288f998dcd7e423b597ae096de02bf23057753389926ad4c#rd,2024-04-09 12:09:19,2024年WAIC·云帆奖启动全球征选，旨在发掘和表彰人工智能领域的青年技术人才，特别是那些在通用人工智能（AGI）领域有所贡献的创新者。该奖项自2020年设立以来，已评选出98位获奖者，他们通过研究成果、开源项目和产业实践推动了AI领域的发展。今年的云帆奖以“超越与联结”为主题，设置“璀璨明星”和“明日之星”两大榜单，分别针对35岁以下和30岁以下的杰出AI人才。评选流程将在5月24日截止，随后进行初审和终审，颁奖典礼将于7月5日举行。此外，世界人工智能大会期间还将举办“WAIC·云帆奖五周年嘉年华”等相关活动，促进全球人工智能领域的交流与合作。
杨笛一新作：社恐有救了，AI大模型一对一陪聊，帮i人变成e人,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913719&idx=4&sn=e98782b184570cdddcabf4d4d9a864ab&chksm=84e47fc9b393f6dfbd3ebfe9ea09a4e0bdcd7df579b0cb6efda95d9472a16be089925cc65eaa#rd,2024-04-09 12:09:19,研究人员提出了一种使用大语言模型进行社交技能训练的方法，该方法包括AI Partner和AI Mentor两个框架。AI Partner通过模拟对话帮助用户练习社交场景，而AI Mentor则提供基于知识的个性化反馈。该框架旨在使社交技能训练变得更加容易、安全和可扩展，尤其适用于缺乏专业训练资源的情况。研究强调了跨学科创新在解决这种方法的广泛影响方面的重要性，并提到了一些评估AI Partner和AI Mentor性能的挑战和方法。
CVPR 2024 | 分割一切模型SAM泛化能力差？域适应策略给解决了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913719&idx=5&sn=65ca6afaf0df51087d4da10db2c1d53a&chksm=84e47fc9b393f6df5c2f932c352b7c687e6b0eb54d14950396d39d77a7588bb48346679cede4#rd,2024-04-09 12:09:19,研究人员提出了一个针对Segment Anything Model（SAM）的弱监督自适应方法，以解决SAM在多领域任务中泛化性不佳的问题。该方法使用无源域的自训练策略，避免依赖源数据，通过引入冻结的source model作为锚定网络来规范模型更新，减少错误伪标签的影响。同时，通过低秩权重分解和弱监督（如稀疏点注释）来提高计算效率和适应性。实验表明，这种方法在多个下游任务中提高了SAM的泛化能力，解决了域适应的挑战。论文和项目代码已公开。
千元级AI 模盒，云天励飞率先打响大模型「平民化」之战,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913555&idx=1&sn=9a3122090a59b5ba61458b84379acf6c&chksm=84e47f6db393f67b386fbae5ad1c594dc861ebf8508ff335b260a29b6335700f7aebb2290d61#rd,2024-04-08 12:12:47,这篇文章提到了AI大模型的落地挑战和云天励飞的解决方案。云天励飞致力于成为物理世界的解码者，通过“深目”AI模盒来促进大模型在长尾场景中的应用。AI行业经历了从技术找场景到场景找技术的阶段，云天励飞在其中发挥了重要作用，其动态人像识别系统“深目”在智能安防领域取得突破。为解决长尾场景的算法难题，云天励飞推出了“深目”AI模盒，它覆盖了90%以上的场景，算法精度超过90%，使用成本降低了90%，并且售价亲民，使得大模型应用更加普及。此外，云天励飞还加速推进AI产品化，与智慧互通合作推动AI在智慧交通等领域的落地，并通过收购智能穿戴方案设计公司，探索大模型与智能穿戴设备的融合。
N-S方程问题有解了？与黎曼猜想并列，千禧年数学难题胜利在望,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913555&idx=2&sn=52b50c9de17448ebfd9fe1ac181f2abd&chksm=84e47f6db393f67b5e7058a69f207589f6044ef4435b8ef90ee7a7375d913bd98f56a68658c5#rd,2024-04-08 12:12:47,数学界正在热议一项可能解决纳维-斯托克斯问题的新工作，这是一个被称为千禧年七大难题之一的未解问题。纳维-斯托克斯方程描述了流体的运动，对于航空航天、天气预测等多个领域至关重要。这个问题的解决一直极具挑战性，因为它涉及到极其复杂的偏微分方程。最近发表在《Journal of Fluid Mechanics》上的论文提出了一种新的正则哈密顿公式，为解决这一难题提供了新的途径。这篇论文通过了同行评审，但是否能完全解决纳维-斯托克斯问题并获得百万美元的悬赏，还需要进一步的验证。
超10秒高分辨率，北大Open Sora视频生成更强了，还支持华为芯片,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913555&idx=3&sn=cda29f54783037b2666067d36c47b83c&chksm=84e47f6db393f67b53392e3e17ff70f8555f313b07e46435b93f0b3490bf26d33751135f0c42#rd,2024-04-08 12:12:47,北大团队联合兔展发起的 Sora 复现计划——Open Sora Plan，已取得新成果，发布了 Open-Sora-Plan v1.0.0。这个项目旨在复现 OpenAI 的视频生成研究 Sora，并通过开源社区的力量增强视频生成质量和文本控制能力。新版本可以生成1024×1024分辨率的视频和10秒、24 FPS的高清视频，支持国产AI芯片华为昇腾910b进行推理。模型架构基于 CausalVideoVAE，从文本到视频、图像的生成效果有所展示，但目前存在运动模糊和网格效果的问题，团队正努力改进。项目已耗费2048 A800 GPU 小时进行多阶段级联训练。
多模态大模型有了统一分割框架，华科PSALM多任务登顶，模型代码全开源,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913555&idx=4&sn=fde435695f2cf8eb28206c0b8709dbd3&chksm=84e47f6db393f67b698d431c66d5c06be42aaa4018bd3f24081d8c27a151d458c1f0932be31a#rd,2024-04-08 12:12:47,华中科技大学的研究团队推出了一种名为PSALM的模型，旨在解决多模态大模型在处理图像分割任务时的局限性。PSALM设计了一个统一的框架，可以处理多种类型的图像分割任务，包括语义分割、实例分割和指代分割等。该模型通过将任务指令提示和任务条件提示结合到大语言模型的输入中，实现了不同分割任务的统一处理。PSALM在多个分割任务上表现出色，甚至在未训练过的开放场景任务中展现出强大的零样本泛化能力。模型的代码和相关资源已开源。
无需训练，这个新方法实现了生成图像尺寸、分辨率自由,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913555&idx=5&sn=ed64a700ddff9ddace546b756b366523&chksm=84e47f6db393f67b0495e02ffcc4c79f87b2e97920998cf657f83dfeb7a0b87a1202cda0be01#rd,2024-04-08 12:12:47,研究者提出了FouriScale，一种用于预训练扩散模型生成高分辨率图像的新方法，以解决模式重复和人工伪影问题。扩散模型已超越GAN和自回归模型，成为生成式模型的主流，但超出训练分辨率生成图像时会出现问题。FouriScale通过空洞卷积和低通滤波保证了跨分辨率的结构和尺度一致性，无需重新训练即可生成高质量图像。实验结果表明，FouriScale在不同预训练模型和分辨率下都提升了图像生成质量。论文和开源代码已发布。
超越GPT-4，斯坦福团队手机可跑的大模型火了，一夜下载量超2k,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913479&idx=1&sn=09876ffdc69f824a38d904dd6e281e71&chksm=84e47eb9b393f7afdb9783c448f3aa7b0336ca0e93019347adad9ab758182b5c632b88f00c20#rd,2024-04-07 12:59:39,斯坦福大学研究人员推出了一个名为Octopus v2的20亿参数语言模型，该模型专为在智能手机、汽车和个人电脑等端侧设备上运行而设计。Octopus v2在准确性和延迟方面超越了GPT-4，并将上下文长度减少了95%。相比Llama7B + RAG方案，它快36倍。此模型的创新之处在于其独特的函数token策略，使得它在推理速度和效率上具有优势，适合边缘计算设备。该模型已经在Android设备上进行了优化，能够在各种复杂场景中生成函数调用。评估结果显示，Octopus v2在速度和函数调用准确性上均表现出色，与GPT-4相当。
谷歌DeepMind发布Gecko：专攻检索，与大7倍模型相抗衡,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913479&idx=2&sn=e564b834a820294a83ee5a5fc9973075&chksm=84e47eb9b393f7af363e8bfe342de50b3c990e40658e6887ce43a609ad928b22478bcf0d7a26#rd,2024-04-07 12:59:39,谷歌DeepMind的研究人员提出了Gecko，这是一种通用的文本嵌入模型，通过从大型语言模型（LLM）中蒸馏知识来训练。Gecko在大规模文本嵌入基准MTEB上表现出色，即使在256个嵌入维度下，也优于具有768个嵌入维度的现有模型。通过使用LLM生成的合成数据集FRet进行预微调和微调，Gecko能够在各种文本相关任务中实现强大的性能，包括文档检索、语义相似度和分类。这种方法避免了依赖大量手动标记数据的挑战，提高了模型的多样性和泛化能力。
Scaling Law 又一次性感了吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913479&idx=3&sn=96c5ffec4e8548bc4ca251d301898030&chksm=84e47eb9b393f7affcb88be984f3d7bf891264bc3693f4e8d94c2de166819b2f162490df2927#rd,2024-04-07 12:59:39,Sora的发布引发了对OpenAI的Scaling Law的讨论，该理论认为模型的性能随着模型大小、数据集大小和训练计算量的增加而改善，具有幂律关系。Scaling Law允许研究人员预测模型性能的变化趋势，有助于优化资源分配。然而，围绕Scaling Law的争议包括数据需求是否会耗尽、模型性能的实质性提升以及大模型是否真正理解世界。尽管存在质疑，但OpenAI的成果表明Scaling Law在实践中可能有效，但也有人指出需要关注模型的泛化能力和智能水平。
揭秘AI幻觉：GPT-4V存在视觉编码漏洞，清华联合NUS提出LLaVA-UHD,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913479&idx=4&sn=2d3a86a1534990c05e16aff9f5143e38&chksm=84e47eb9b393f7af9666b25da13eafb77f7de390b07941b74a2848a2d02f69ce4c866f141d25#rd,2024-04-07 12:59:39,研究人员发现多模态大模型GPT-4V在图像处理上存在视觉编码漏洞，导致它在数图像中的对象时出现错误。具体问题包括：1) GPT-4V将图像切片处理时有重叠，影响计数准确性，例如在高分辨率图像中可能出现数量翻倍或四倍的错误；2) LLaVA-1.5模型在处理非正方形图像时进行大范围填充，导致计算资源浪费和模型能力受限。为解决这些问题，清华大学、新加坡国立大学和中国科学院大学的研究人员提出了LLaVA-UHD模型，它可以高效地处理任意长宽比的高分辨率图像，并在多个基准测试中取得性能提升。LLaVA-UHD采用图像模块化策略、压缩模块和空间装饰模式，改进了对图像的编码方式，提升了模型的效率和可扩展性。
二次元专用超分AI模型APISR：在线可用，入选CVPR,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913479&idx=5&sn=d0c761935b3bd6507acb80e98092146a&chksm=84e47eb9b393f7afbef2432ada4f7096ea00217c63cd474cdd77b2b157ad727247badc8208c2#rd,2024-04-07 12:59:39,联合密西根大学、耶鲁大学和浙江大学的研究团队为动漫超分辨率任务提出了一套新方法，包括数据集、模型和改进措施，论文已被 CVPR 2024 接收。团队开源了相关代码并在 Huggingface 上线试用模型。他们分析了动漫制作过程，发现可以使用基于图像的方法和数据集来创建适用于图像和视频的超分辨率和恢复框架，而不是依赖视频模型和视频数据集。团队创建了名为 API SR 的数据集，用于训练超分辨率模型。此外，他们设计了一个动漫实用退化模型，以恢复扭曲的手绘线条和压缩伪影。实验结果表明，新方法在性能和视觉效果上优于现有最佳方法。
拒绝白人与亚洲人同框，Meta图像生成器的「歧视」，被人挖出来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913452&idx=1&sn=228cadb5c00cb41b8354a13b4fcbf3eb&chksm=84e47ed2b393f7c416b430521cf0b9ee032ade8b2a40c9524005ff816eec974356847cfba2f1#rd,2024-04-06 12:30:08,Meta的AI图像生成器被发现存在偏见，无法准确地根据提示生成“亚洲男性和白人妻子”或“亚洲女性和白人丈夫”的图像，经常生成两个亚洲人的图像。即使调整文本提示，结果仍然不准确。这一问题揭示了AI系统中可能存在的偏见和刻板印象，可能是由于训练数据不足或有偏差。此前，Meta的AI生成贴纸工具也曾因创建不恰当图像而引发争议。
苹果终止电车项目后大裁员，押注家用机器人，这会是Next Big Thing吗？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913452&idx=2&sn=9f90ee43773af0c06d1c6de95da38dca&chksm=84e47ed2b393f7c44047a4ade760d6772fa49be167b326f5ad8562244ee47ac1dde6b05595d3#rd,2024-04-06 12:30:08,苹果公司放弃了电动汽车项目和Apple Watch下一代屏幕的自主生产计划，转向机器人技术的研发。据彭博社报道，苹果工程师正在研究一种能够跟随用户在家中移动的机器人，但该项目仍处于初期阶段，未来是否会上市还不确定。苹果在机器人技术上的工作由硬件工程部门和人工智能与机器学习组合作进行，但公司尚未决定是否将机器人作为正式产品线。此消息公布后，投资者反应冷淡，苹果股票上涨不足1%，而iRobot公司的股票短暂上涨后回落在2%以下。此前，苹果将汽车、家居和混合现实视为未来发展的重点，但现在可能会更多地关注智能家居市场。
Up主已经开始鬼畜，腾讯开源「AniPortrait」让照片唱歌说话,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913452&idx=3&sn=59641ad08d7a17ce96178535a9ddbc0f&chksm=84e47ed2b393f7c44f99d3d8086a18462a0d69549bf33aaca07e8f2e49cd0b94b25e60442c6d#rd,2024-04-06 12:30:08,腾讯开源了一个新项目AniPortrait，它可以基于音频和一张参考图像生成高质量动画人像。该模型包含两个模块：Audio2Lmk用于从音频中提取Landmark序列，捕捉面部表情和嘴唇动作；Lmk2Video则利用这些Landmark序列生成时间上稳定一致的高质量人像视频。AniPortrait的创新之处在于使用预训练的wav2vec模型来提取音频特征，并通过简单的架构转换成3D人脸网格和姿势序列。实验结果显示，生成的动画在质量和真实度上表现出色，用户还可以编辑3D表征进行面部重现。该项目在GitHub上的Star数已经突破2800。
ICLR 2024 | 联邦学习后门攻击的模型关键层,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913452&idx=4&sn=ff7fd70caa96dc39590cdde7eb92dc5f&chksm=84e47ed2b393f7c40f3f9479a91353f6085ad9540935d7d6997484597a0f987f33e32b878b66#rd,2024-04-06 12:30:08,本文关注在有防御保护的训练框架下对联邦学习发起后门攻击。研究发现后门攻击与神经网络的某些特定层密切相关，这些层被称为后门攻击关键层。通过识别和攻击这些关键层，攻击者可以控制少量参与者进行高效的后门攻击，绕过现有防御算法的检测。文章提出了一种层替换方法来识别后门关键层，并在CIFAR-10和MNIST数据集上验证了基于这些关键层的攻击的有效性。实验表明，即使在少量恶意客户端的情况下，也能实现高成功率的后门攻击，揭示了当前防御方法的漏洞，强调了需要更精细的防御算法来保护联邦学习安全。
从300亿分子中筛出6款，结构新且易合成，斯坦福抗生素设计AI模型登Nature子刊,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913452&idx=5&sn=fbcee3bf0ae1595335c017c6cfcfc5df&chksm=84e47ed2b393f7c4e6e621f0136db0b9c5416473ffd5648c6a5c606e362de8100b81a182d321#rd,2024-04-06 12:30:08,研究人员开发了一种名为SyntheMol的生成式AI模型，该模型能够设计数十亿种新的抗生素分子，这些分子价格低廉且易于合成，以对抗抗生素耐药性问题。该模型使用蒙特卡洛树搜索和化学反应组合，从大型化学空间中生成具有潜在抗菌特性的新分子。在实验中，SyntheMol设计的6个分子显示了对鲍曼不动杆菌的抗菌活性，且无毒。这一成果发表在《Nature Machine Intelligence》上，为抗生素发现带来了新希望。
李飞飞主讲，斯坦福2024 CS231n开课，依旧座无虚席,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913422&idx=1&sn=d87f55d35b726c143f689c38d8cdd7af&chksm=84e47ef0b393f7e6f5d4e95cbcd0f15d87630d55421e099df09adf543ddc975f644ab200bca2#rd,2024-04-05 12:13:32,知名AI科学家李飞飞的计算机视觉课程CS231n再次开课，已有600多名学生报名。这门课程自2015年起已经连续九年，成为计算机视觉领域广受欢迎的课程。尽管课程代码保持不变，但预计2024年的课程将包含视觉生成技术在过去三年中的新进展。李飞飞在年初的预测中提到，计算机视觉正处在技术进步的边缘，生成式AI和扩散模型等技术即将迎来突破。课程将深入探讨深度学习架构，特别是图像分类任务，并通过实践作业和期末项目让学生掌握深度学习工具和技巧。此外，斯坦福大学的另一热门课程CS25：Transformers United V4也将更新，探讨Transformer在各个领域的应用，并邀请前沿专家进行客座讲座。该课程将开放给所有人参与，并涵盖NLP和视觉Transformer等内容。
AI无人商店背后，是上千个印度人通过摄像头看美国人买西蓝花？,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913422&idx=2&sn=dcfbc86ea895d22bdaf8f7b83971a209&chksm=84e47ef0b393f7e667ab2a2b9d729a4cae9b677ce72f818719b704fc45fef089e8b15fe553a0#rd,2024-04-05 12:13:32,亚马逊的“Just Walk Out”无人结账技术被曝出实际上依赖于一个在印度的上千人团队来观看和标记视频以确保准确结算。这项技术本应通过计算机视觉和深度学习自动识别商品，但在实际操作中，每1000笔交易有700笔需要人工审核，远高于亚马逊预期的20-50笔。尽管亚马逊表示印度员工主要负责机器学习数据的辅助工作，包括注释视频以训练模型，但这一消息引发了关于该技术实际智能化程度的质疑。最近，亚马逊决定在新开的杂货店中放弃Just Walk Out，转而使用带有屏幕和扫描仪的Dash Carts智能购物车进行结账。这一事件突显了许多高科技解决方案背后仍然需要大量人工支持的事实。
攻陷短视频后，Sora将需要72万块H100 GPU,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913422&idx=3&sn=b66a3f68b0a2366e5d3d0fdc4caeb4e3&chksm=84e47ef0b393f7e62385984c523fb02a1c8300547b35c6aa16867159f1bf1b10c95a6812d873#rd,2024-04-05 12:13:32,OpenAI的Sora模型在视频生成领域取得重大进展，其推理成本可能超过训练成本。Sora基于扩散Transformer和潜在扩散模型，通过扩大视频模型以实现性能提升，类似于大语言模型的扩展。该模型需要大量计算资源训练，估计在4200至10500块英伟达H100 GPU上训练一个月。推理阶段，每个H100 GPU每小时能生成约5分钟视频，推理成本比基于扩散的模型如Sora高几个数量级。随着类Sora模型的广泛应用，推理计算需求将超过训练计算。如果在TikTok和YouTube等平台上广泛应用，可能需要72万块Nvidia H100 GPU来应对计算峰值需求，这将显著增加对GPU推理计算的需求。Sora的出现也预示着视频生成模型的实用性和对GPU计算能力的影响将日益增大。
值得你花时间看的扩散模型教程，来自普渡大学,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913422&idx=4&sn=e2f663d795c771fd7df77e684ef81615&chksm=84e47ef0b393f7e63719dc0c027c4ca0ea282885b955ff7bfcb98705b51e855fdb193648078d#rd,2024-04-05 12:13:32,普渡大学的Stanley H. Chan发布了一份50页的教程《Tutorial on Diffusion Models for Imaging and Vision》，详细解释了扩散模型在图像和视觉领域的基本思想。扩散模型是一种图像生成技术，通过逐步去除噪声来生成图像。教程分为四个部分，涵盖了变分自编码器、Denoising Diffusion Probabilistic Models、Score Matching with Langevin Dynamics和Stochastic Differential Equations等概念，旨在帮助本科生和研究生理解并应用扩散模型。作者Stanley Chan是普渡大学的电气与计算机工程和统计学副教授，专注于计算成像研究。
让智能体像孩子一样观察别人学习动作，跨视角技能学习数据集EgoExoLearn来了,http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650913422&idx=5&sn=b5f9e7f56462fdd16bbc6b13fd17a205&chksm=84e47ef0b393f7e61f24a3e1d84fc86c6cab1298a936815e3835d6f4752e85fabad7bc1cbf54#rd,2024-04-05 12:13:32,研究人员发布了新的数据集EgoExoLearn，旨在让机器人通过观察他人来学习新动作。这个数据集包含第一视角和第三视角的视频，模拟人类的学习过程，并涵盖了日常生活和实验室环境中的任务。数据集还附带高质量的注视数据和多模态标注，以帮助解决不同视角下异步动作的建模问题。研究人员提出了跨视角关联、跨视角行动规划等基准测试，以评估数据集的效果，并期望EgoExoLearn能推动AI向更高阶的学习能力和智能发展。
