Paper ID,Title,URL,Summary,First Author,Publish Date,Update Date,Code URL,Stars
2410.18980v1,Very massive stars and Nitrogen-emitting galaxies,http://arxiv.org/abs/2410.18980v1,"Recent studies of high-redshift galaxies using JWST, such as GN-z11 revealedhighly elevated levels of nitrogen (N). This phenomenon extends togravitationally-lensed galaxies like the Sunburst Arc at z = 2.37, as well asto globular clusters (GCs). We propose that this originates from the presenceof very massive stars (VMSs) with masses ranging from 100 to 1000\,\Msun. TheHe {\sc ii} observed in the Sunburst Arc could also stem from thedisproportionately large contribution of VMSs. We build an entirely newFramework for massive star evolution which is no longer set by Dutch or othermass-loss ""recipes"" but which take the physics of $\Gamma$ or $L/M$-dependentwinds into account. We discuss the mass-loss kink and the transition mass-lossrate between optically thin and thick winds, before we study the evaporativemass-loss history of VMSs. Our novel evolution models exhibit verticalevolution in the HR-diagram from the zero-age main sequence due to aself-regulatory effect driven by their wind-dominated nature, and we discusswhat wind physics sets the stellar upper-mass limit. Our estimate for theSunburst Arc in Vink (2023) suggests that the significant amounts of N found instar-forming galaxies likely arise from VMSs. We evaluate the strengths andweaknesses of previous hypotheses, including fast rotating massive stars andsupermassive stars (SMSs), and we conclude that only our VMS model satisfiesthe relevant criteria. Finally, we advocate for the inclusion of VMSs inpopulation synthesis and chemical evolution models, emphasizing the need for aself-consistent wind approach, which currently does not exist. Even minorinaccuracies in mass-loss rates dramatically impact the stellar evolution ofVMS, as well as their ionizing and chemical feedback.",Jorick S. Vink,2024-10-24,2024-10-24,,N/A
2410.18979v1,PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views,http://arxiv.org/abs/2410.18979v1,"We propose PixelGaussian, an efficient feed-forward framework for learninggeneralizable 3D Gaussian reconstruction from arbitrary views. Most existingmethods rely on uniform pixel-wise Gaussian representations, which learn afixed number of 3D Gaussians for each view and cannot generalize well to moreinput views. Differently, our PixelGaussian dynamically adapts both theGaussian distribution and quantity based on geometric complexity, leading tomore efficient representations and significant improvements in reconstructionquality. Specifically, we introduce a Cascade Gaussian Adapter to adjustGaussian distribution according to local geometry complexity identified by akeypoint scorer. CGA leverages deformable attention in context-awarehypernetworks to guide Gaussian pruning and splitting, ensuring accuraterepresentation in complex regions while reducing redundancy. Furthermore, wedesign a transformer-based Iterative Gaussian Refiner module that refinesGaussian representations through direct image-Gaussian interactions. OurPixelGaussian can effectively reduce Gaussian redundancy as input viewsincrease. We conduct extensive experiments on the large-scale ACID andRealEstate10K datasets, where our method achieves state-of-the-art performancewith good generalization to various numbers of views. Code:https://github.com/Barrybarry-Smith/PixelGaussian.",Xin Fei,2024-10-24,2024-10-24,https://github.com/barrybarry-smith/pixelgaussian,0
2410.18978v1,Framer: Interactive Frame Interpolation,http://arxiv.org/abs/2410.18978v1,"We propose Framer for interactive frame interpolation, which targetsproducing smoothly transitioning frames between two images as per usercreativity. Concretely, besides taking the start and end frames as inputs, ourapproach supports customizing the transition process by tailoring thetrajectory of some selected keypoints. Such a design enjoys two clear benefits.First, incorporating human interaction mitigates the issue arising fromnumerous possibilities of transforming one image to another, and in turnenables finer control of local motions. Second, as the most basic form ofinteraction, keypoints help establish the correspondence across frames,enhancing the model to handle challenging cases (e.g., objects on the start andend frames are of different shapes and styles). It is noteworthy that oursystem also offers an ""autopilot"" mode, where we introduce a module to estimatethe keypoints and refine the trajectory automatically, to simplify the usage inpractice. Extensive experimental results demonstrate the appealing performanceof Framer on various applications, such as image morphing, time-lapse videogeneration, cartoon interpolation, etc. The code, the model, and the interfacewill be released to facilitate further research.",Wen Wang,2024-10-24,2024-10-24,,N/A
2410.18977v1,MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms,http://arxiv.org/abs/2410.18977v1,"This research delves into the problem of interactive editing of human motiongeneration. Previous motion diffusion models lack explicit modeling of theword-level text-motion correspondence and good explainability, hencerestricting their fine-grained editing ability. To address this issue, wepropose an attention-based motion diffusion model, namely MotionCLR, with CLeaRmodeling of attention mechanisms. Technically, MotionCLR models the in-modalityand cross-modality interactions with self-attention and cross-attention,respectively. More specifically, the self-attention mechanism aims to measurethe sequential similarity between frames and impacts the order of motionfeatures. By contrast, the cross-attention mechanism works to find thefine-grained word-sequence correspondence and activate the correspondingtimesteps in the motion sequence. Based on these key properties, we develop aversatile set of simple yet effective motion editing methods via manipulatingattention maps, such as motion (de-)emphasizing, in-place motion replacement,and example-based motion generation, etc. For further verification of theexplainability of the attention mechanism, we additionally explore thepotential of action-counting and grounded motion generation ability viaattention maps. Our experimental results show that our method enjoys goodgeneration and editing ability with good explainability.",Ling-Hao Chen,2024-10-24,2024-10-24,,N/A
2410.18976v1,CAMEL-Bench: A Comprehensive Arabic LMM Benchmark,http://arxiv.org/abs/2410.18976v1,"Recent years have witnessed a significant interest in developing largemultimodal models (LMMs) capable of performing various visual reasoning andunderstanding tasks. This has led to the introduction of multiple LMMbenchmarks to evaluate LMMs on different tasks. However, most existing LMMevaluation benchmarks are predominantly English-centric. In this work, wedevelop a comprehensive LMM evaluation benchmark for the Arabic language torepresent a large population of over 400 million speakers. The proposedbenchmark, named CAMEL-Bench, comprises eight diverse domains and 38sub-domains including, multi-image understanding, complex visual perception,handwritten document understanding, video understanding, medical imaging, plantdiseases, and remote sensing-based land use understanding to evaluate broadscenario generalizability. Our CAMEL-Bench comprises around 29,036 questionsthat are filtered from a larger pool of samples, where the quality is manuallyverified by native speakers to ensure reliable model assessment. We conductevaluations of both closed-source, including GPT-4 series, and open-sourceLMMs. Our analysis reveals the need for substantial improvement, especiallyamong the best open-source models, with even the closed-source GPT-4o achievingan overall score of 62%. Our benchmark and evaluation scripts are open-sourced.",Sara Ghaboura,2024-10-24,2024-10-24,,N/A
2410.18975v1,Unbounded: A Generative Infinite Game of Character Life Simulation,http://arxiv.org/abs/2410.18975v1,"We introduce the concept of a generative infinite game, a video game thattranscends the traditional boundaries of finite, hard-coded systems by usinggenerative models. Inspired by James P. Carse's distinction between finite andinfinite games, we leverage recent advances in generative AI to createUnbounded: a game of character life simulation that is fully encapsulated ingenerative models. Specifically, Unbounded draws inspiration from sandbox lifesimulations and allows you to interact with your autonomous virtual characterin a virtual world by feeding, playing with and guiding it - with open-endedmechanics generated by an LLM, some of which can be emergent. In order todevelop Unbounded, we propose technical innovations in both the LLM and visualgeneration domains. Specifically, we present: (1) a specialized, distilledlarge language model (LLM) that dynamically generates game mechanics,narratives, and character interactions in real-time, and (2) a new dynamicregional image prompt Adapter (IP-Adapter) for vision models that ensuresconsistent yet flexible visual generation of a character across multipleenvironments. We evaluate our system through both qualitative and quantitativeanalysis, showing significant improvements in character life simulation, userinstruction following, narrative coherence, and visual consistency for bothcharacters and the environments compared to traditional related approaches.",Jialu Li,2024-10-24,2024-10-24,,N/A
2410.18974v1,3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation,http://arxiv.org/abs/2410.18974v1,"Multi-view image diffusion models have significantly advanced open-domain 3Dobject generation. However, most existing models rely on 2D networkarchitectures that lack inherent 3D biases, resulting in compromised geometricconsistency. To address this challenge, we introduce 3D-Adapter, a plug-inmodule designed to infuse 3D geometry awareness into pretrained image diffusionmodels. Central to our approach is the idea of 3D feedback augmentation: foreach denoising step in the sampling loop, 3D-Adapter decodes intermediatemulti-view features into a coherent 3D representation, then re-encodes therendered RGBD views to augment the pretrained base model through featureaddition. We study two variants of 3D-Adapter: a fast feed-forward versionbased on Gaussian splatting and a versatile training-free version utilizingneural fields and meshes. Our extensive experiments demonstrate that 3D-Adapternot only greatly enhances the geometry quality of text-to-multi-view modelssuch as Instant3D and Zero123++, but also enables high-quality 3D generationusing the plain text-to-image Stable Diffusion. Furthermore, we showcase thebroad application potential of 3D-Adapter by presenting high quality results intext-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks.",Hansheng Chen,2024-10-24,2024-10-24,https://github.com/Lakonik/MVEdit,0
2410.18972v1,Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques,http://arxiv.org/abs/2410.18972v1,"Cognitive decline is a natural part of aging, often resulting in reducedcognitive abilities. In some cases, however, this decline is more pronounced,typically due to disorders such as Alzheimer's disease. Early detection ofanomalous cognitive decline is crucial, as it can facilitate timelyprofessional intervention. While medical data can help in this detection, itoften involves invasive procedures. An alternative approach is to employnon-intrusive techniques such as speech or handwriting analysis, which do notnecessarily affect daily activities. This survey reviews the most relevantmethodologies that use deep learning techniques to automate the cognitivedecline estimation task, including audio, text, and visual processing. Wediscuss the key features and advantages of each modality and methodology,including state-of-the-art approaches like Transformer architecture andfoundation models. In addition, we present works that integrate differentmodalities to develop multimodal models. We also highlight the most significantdatasets and the quantitative results from studies using these resources. Fromthis review, several conclusions emerge. In most cases, the textual modalityachieves the best results and is the most relevant for detecting cognitivedecline. Moreover, combining various approaches from individual modalities intoa multimodal model consistently enhances performance across nearly allscenarios.",David Ortiz-Perez,2024-10-24,2024-10-24,,N/A
2410.18970v1,ConceptDrift: Uncovering Biases through the Lens of Foundational Models,http://arxiv.org/abs/2410.18970v1,"Datasets and pre-trained models come with intrinsic biases. Most methods relyon spotting them by analysing misclassified samples, in a semi-automatedhuman-computer validation. In contrast, we propose ConceptDrift, a method whichanalyzes the weights of a linear probe, learned on top a foundational model. Wecapitalize on the weight update trajectory, which starts from the embedding ofthe textual representation of the class, and proceeds to drift towardsembeddings that disclose hidden biases. Different from prior work, with thisapproach we can pin-point unwanted correlations from a dataset, providing morethan just possible explanations for the wrong predictions. We empirically provethe efficacy of our method, by significantly improving zero-shot performancewith biased-augmented prompting. Our method is not bounded to a singlemodality, and we experiment in this work with both image (Waterbirds, CelebA,Nico++) and text datasets (CivilComments).",Cristian Daniel Păduraru,2024-10-24,2024-10-24,,N/A
2410.18968v1,Stimulated Emission of Dark Matter via Thermal Scattering: Novel Limits for Freeze-In and eV Cold Dark Matter,http://arxiv.org/abs/2410.18968v1,"Recently, one of the present authors noticed a stimulated emission process ofbosonic dark matter via the two-body decay of a mother particle in a thermalplasma similar to the operation principle of a laser in 2301.08735. In thispaper, we show that in a $2 \to 2$ process, including a bosonic final particle(e.g., an axion or dark photon), the stimulated emission occurs as well due toa small angle scattering of the thermal mother particles and thus thephenomenon is more universal. Two important conclusions follow: (1) Care mustbe taken when studying the freeze-in production of a bosonic dark matter, asthe abundance and momentum distribution of dark matter can differ significantlydue to this effect. (2) eV-mass-range bosonic dark matter is special andtheoretically well-motivated because models for freeze-in or other thermalproduction of dark matter include the parameter region of cold eV dark matter.We also study the dark matter mass effect for the stimulated emission.",Kodai Sakurai,2024-10-24,2024-10-24,,N/A
2410.18967v1,Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms,http://arxiv.org/abs/2410.18967v1,"Building a generalist model for user interface (UI) understanding ischallenging due to various foundational issues, such as platform diversity,resolution variation, and data limitation. In this paper, we introduceFerret-UI 2, a multimodal large language model (MLLM) designed for universal UIunderstanding across a wide range of platforms, including iPhone, Android,iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI2 introduces three key innovations: support for multiple platform types,high-resolution perception through adaptive scaling, and advanced task trainingdata generation powered by GPT-4o with set-of-mark visual prompting. Theseadvancements enable Ferret-UI 2 to perform complex, user-centered interactions,making it highly versatile and adaptable for the expanding diversity ofplatform ecosystems. Extensive empirical experiments on referring, grounding,user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDEnext-action prediction dataset, and GUI-World multi-platform benchmarkdemonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and alsoshows strong cross-platform transfer capabilities.",Zhangheng Li,2024-10-24,2024-10-24,,N/A
2410.18966v1,Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions,http://arxiv.org/abs/2410.18966v1,"Large language models (LLMs) have demonstrated great performance acrossvarious benchmarks, showing potential as general-purpose task solvers. However,as LLMs are typically trained on vast amounts of data, a significant concern intheir evaluation is data contamination, where overlap between training data andevaluation datasets inflates performance assessments. While multiple approacheshave been developed to identify data contamination, these approaches rely onspecific assumptions that may not hold universally across different settings.To bridge this gap, we systematically review 47 papers on data contaminationdetection, categorize the underlying assumptions, and assess whether they havebeen rigorously validated. We identify and analyze eight categories ofassumptions and test three of them as case studies. Our analysis reveals thatwhen classifying instances used for pretraining LLMs, detection approachesbased on these three assumptions perform close to random guessing, suggestingthat current LLMs learn data distributions rather than memorizing individualinstances. Overall, this work underscores the importance of approaches clearlystating their underlying assumptions and testing their validity across variousscenarios.",Yujuan Fu,2024-10-24,2024-10-24,,N/A
2410.18965v1,On the Crucial Role of Initialization for Matrix Factorization,http://arxiv.org/abs/2410.18965v1,"This work revisits the classical low-rank matrix factorization problem andunveils the critical role of initialization in shaping convergence rates forsuch nonconvex and nonsmooth optimization. We introduce Nystrom initialization,which significantly improves the global convergence of Scaled Gradient Descent(ScaledGD) in both symmetric and asymmetric matrix factorization tasks.Specifically, we prove that ScaledGD with Nystrom initialization achievesquadratic convergence in cases where only linear rates were previously known.Furthermore, we extend this initialization to low-rank adapters (LoRA) commonlyused for finetuning foundation models. Our approach, NoRA, i.e., LoRA withNystrom initialization, demonstrates superior performance across variousdownstream tasks and model scales, from 1B to 7B parameters, in large languageand diffusion models.",Bingcong Li,2024-10-24,2024-10-24,,N/A
2410.18963v1,OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning,http://arxiv.org/abs/2410.18963v1,"Large language models (LLMs) and large multimodal models (LMMs) have showngreat potential in automating complex tasks like web browsing and gaming.However, their ability to generalize across diverse applications remainslimited, hindering broader utility. To address this challenge, we presentOSCAR: Operating System Control via state-Aware reasoning and Re-planning.OSCAR is a generalist agent designed to autonomously navigate and interact withvarious desktop and mobile applications through standardized controls, such asmouse and keyboard inputs, while processing screen images to fulfill usercommands. OSCAR translates human instructions into executable Python code,enabling precise control over graphical user interfaces (GUIs). To enhancestability and adaptability, OSCAR operates as a state machine, equipped witherror-handling mechanisms and dynamic task re-planning, allowing it toefficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR'seffectiveness through extensive experiments on diverse benchmarks acrossdesktop and mobile platforms, where it transforms complex workflows into simplenatural language commands, significantly boosting user productivity. Our codewill be open-source upon publication.",Xiaoqiang Wang,2024-10-24,2024-10-24,,N/A
2410.18962v1,Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction,http://arxiv.org/abs/2410.18962v1,"Spatial intelligence is the ability of a machine to perceive, reason, and actin three dimensions within space and time. Recent advancements in large-scaleauto-regressive models have demonstrated remarkable capabilities across variousreasoning tasks. However, these models often struggle with fundamental aspectsof spatial reasoning, particularly in answering questions like ""Where am I?""and ""What will I see?"". While some attempts have been done, existing approachestypically treat them as separate tasks, failing to capture their interconnectednature. In this paper, we present Generative Spatial Transformer (GST), a novelauto-regressive framework that jointly addresses spatial localization and viewprediction. Our model simultaneously estimates the camera pose from a singleimage and predicts the view from a new camera pose, effectively bridging thegap between spatial awareness and visual prediction. The proposed innovativecamera tokenization method enables the model to learn the joint distribution of2D projections and their corresponding spatial perspectives in anauto-regressive manner. This unified training paradigm demonstrates that jointoptimization of pose estimation and novel view synthesis leads to improvedperformance in both tasks, for the first time, highlighting the inherentrelationship between spatial awareness and visual prediction.",Junyi Chen,2024-10-24,2024-10-24,,N/A
