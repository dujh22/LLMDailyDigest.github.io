+++
title = '新趋势'
date = 2025-08-08T00:00:00+08:00
draft = false
toc = true
+++

# 新趋势

## 通用验证器

1. OpenAI正在通过一种名为「Universal Verifier」的技术，让GPT-5在全领域实现稳步提升。翻译过来就是：通用验证器。这项技术的核心思想是：让一个AI 模型充当「验证者」，检查另一个模型的输出质量。
2. 去年下半年，代号为Orion的模型本应成为GPT-5，但其性能提升远低于预期，最终只能以GPT-4.5的身份发布。原因在于三大技术瓶颈同时出现：**高质量训练数据枯竭、强化学习过程不稳定、模型扩展时的性能退化。**
3. 这个系统的工作原理类似于生成对抗网络（GAN）：**一个模型负责生成答案，另一个模型负责评判质量。**
4. OpenAI此前的论文「**Prover-Verifier Games Improve Legibility of LLM Outputs**」详细展示了这种方法的威力。

   1. 当时的超级对齐研究团队设计了一个巧妙的游戏：「**证明者**」模型被赋予两种角色：「helpful」（提供正确答案）和「sneaky」（故意制造错误）。「**验证者**」模型则需要学会识别哪些答案是正确的。

#### [CompassVerifier: llm评估和结果奖励的统一鲁棒验证器（24▲） ](https://huggingface.co/papers/2508.03686?utm_source=digest-papers&utm_medium=email&utm_campaign=2025-08-06)

1. CompassVerifier 是一个轻量级、稳健的模型，用于跨多个领域验证 LLM 输出，支持该模型的是 VerifierBench，一个全面的基准数据集。
2. 答案验证不仅对于通过将大型语言模型（LLMs）的非结构化输出与标准答案进行匹配来评估其性能至关重要，同时也作为奖励模型指导 LLM 的优化。大多数评估框架依赖正则化匹配或使用通用 LLMs 进行答案验证，这需要对正则表达式规则或评估提示进行大量且重复的定制。
   1. 目前方法存在两个根本性限制：1）缺乏系统评估不同 LLMs 验证能力的综合基准；2）验证器开发尚处于初期阶段，现有方法既缺乏处理复杂边缘案例的鲁棒性，也缺乏跨领域的泛化能力。
   2. 在本工作中，我们开发了 CompassVerifier，一种准确且鲁棒的轻量级验证模型，用于评估和结果奖励。它展现了涵盖数学、知识及多样推理任务的多领域能力，能够处理多种答案类型，包括多子问题、公式和序列答案，同时有效识别异常/无效响应。
   3. 我们介绍了 VerifierBench 基准测试，该测试包含从多个数据源收集的模型输出，并通过对元错误模式的人工分析进行增强，以提升 CompassVerifier 的性能。
   4. 我们期望 CompassVerifier 和 VerifierBench 能够促进答案验证、评估协议和强化学习研究。代码和数据集可在 https://github.com/open-compass/CompassVerifier 获取。
3. [3B模型性能小钢炮，“AI下半场应该训练+验证两条腿跑步”丨上海AI Lab&amp;澳门大学](https://mp.weixin.qq.com/s/nzEQ86jx4hEJMUnzj8Mu5A)
   1. **训练AI解决某个任务的难易程度与该任务的可验证性成正比。所有可解决且易于验证的任务，都将被AI解决** 。
   2. VerifierBench：针对验证模型的多领域、高难度基准
   3. 论文地址：https://arxiv.org/abs/2508.03686
      项目主页：https://open-compass.github.io/CompassVerifier
      Github：https://github.com/open-compass/CompassVerifier
      Model & Dataset：https://huggingface.co/collections/opencompass/compassverifier-686e5a25e8672e603b17c666

## dLLM 扩散语言模型

本综述系统梳理了离散扩散方向的研究图谱，呈现了离散扩散语言模型（dLLMs）与离散扩散多模态语言模型（dMLLMs）的理论基础、代表模型、训练与推理技术，以及在推理、视觉、生物等多个领域的应用进展。[https://mp.weixin.qq.com/s/hcIUmS-jUIVLOIfS7-1gtQ](https://mp.weixin.qq.com/s/hcIUmS-jUIVLOIfS7-1gtQ)

### Diffusion + 文本

2025-06-28 18:43:50 Saturday 这个扩散LLM太快了！没有「请稍后」，实测倍速于Gemini 2.5 Flash

Mercury 就是为此诞生的，其是首个基于扩散模型的 LLM。与自回归（AR）模型相比，Mercury 模型在性能和效率上都达到了最先进的水平。

在性能表现上，根据第三方测评机构 Artificial Anlys 的基准测试数据显示，Mercury 可媲美 GPT-4.1 Nano 和 Claude 3.5 Haiku 等速度经过优化的前沿模型，同时运行速度提升超过 7 倍。 https://mp.weixin.qq.com/s/dSEkdYHOQbaiRN3O4D-hKg

2. 2025-06-27 14:24:28 Friday

[#21](https://arxiv.org/abs/2506.21170) **[用于文本扩散建模的压缩和平滑潜在空间](https://papers.cool/arxiv/2506.21170)** **[PDF(1)]** **[Copy]** **[Kimi(1)]** **[REL]**

作者：维亚切斯拉夫·梅沙尼诺夫、叶戈尔·奇姆布拉托夫、亚历山大·沙巴林、亚历山大·阿布拉莫夫、德米特里·维特罗夫

自回归语言模型在现代文本生成中占主导地位，但它们的顺序性引入了基本限制：解码速度很慢，保持全局连贯性仍然具有挑战性。扩散模型通过实现并行生成和灵活控制提供了一种有前途的替代方案;然而，它们应用于文本生成的原因是 token-level 表示的高维性。我们介绍了 Cosmos，这是一种新颖的文本生成方法，它完全在专为扩散量身定制的压缩、平滑的潜在空间中运行。这个空间是使用自动编码器学习的，该自动编码器同时训练用于令牌级重建和与来自预训练语言编码器的冻结激活对齐，提供强大的语义基础并实现有效的基于扰动的增强。根据经验，我们证明了文本表示可以通过以下方式压缩 8×8× 同时保持与 Token 级扩散模型相当的生成质量。此外，增加潜在序列长度使 Cosmos 能够超越基于扩散和自回归的基线。我们在四个不同的生成任务上评估 Cosmos，包括故事生成、问题生成、总结和解毒，并将其与各种生成范式进行比较。Cosmos 实现了相当或卓越的发电质量，同时提供超过2×2× 更快的推理。

### Diffusion + RL

🌈🌈🌈🌈🌈（可以借鉴这个里面的训练全流程工作）2025-06-28 18:36:21 Saturday ｜ 苹果与港大出手！改进GRPO，让dLLM也能高效强化学习 https://mp.weixin.qq.com/s/akWoBx1F8sEvi_IxMQpJbg

此前的 Mercury Coder 和 Gemini Diffusion 已经表明：基于扩散的代码生成器可以与顶尖自回归代码模型相媲美。

首先研究了 dLLM 的解码行为，然后建立了一种用于扩散 LLM 的原生强化学习 (RL) 方法。这是该研究一作、香港大学博士生 Shansan Gong 在苹果实习期间的研究成果。

论文标题：DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation

论文地址：https://arxiv.org/pdf/2506.20639

项目地址：https://github.com/apple/ml-diffucoder

2. **🌈🌈🌈 #3 DiffuCoder：理解并改进用于代码生成的掩码扩散模型 [PDF** **(6)** **] [复制] [Kimi** **(7)**  **] [相关] ** **[#3](https://arxiv.org/abs/2506.20639)****[DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation](https://papers.cool/arxiv/2506.20639)**** [PDF(6)] [Copy] [Kimi(7)] [REL]**

作者：龚珊珊、张瑞祥、郑黄杰、顾家涛、Navdeep Jaitly、孔令鹏、张一哲

扩散大语言模型（dLLMs）因其去噪模型作用于整个序列而成为自回归（AR）模型极具吸引力的替代方案。dLLMs 的全局规划和迭代优化特性尤其适用于代码生成任务。然而，当前 dLLMs 在代码领域的训练与推理机制仍待深入探索。为揭示 dLLMs 的解码行为并释放其在编程领域的潜力，我们系统研究了其去噪过程与强化学习（RL）方法。我们在 1300 亿代码标记上训练了 70 亿参数的\textbf{DiffuCoder}模型，并以其为测试平台分析解码行为，发现其与 AR 模型的关键差异：(1) dLLMs 无需依赖半自回归解码即可自主决定生成过程的因果性程度；(2) 提高采样温度不仅会多样化标记选择，还会改变其生成顺序。这种多样性为 RL 推演创造了丰富的搜索空间。 在强化学习训练中，为降低词元对数似然估计的方差并保持训练效率，我们提出\textbf{耦合 GRPO}方案——通过为训练用补全样本构建互补掩码噪声的新型采样方法。实验表明，耦合 GRPO 显著提升了 DiffuCoder 在代码生成基准上的性能（EvalPlus 指标提升 4.4%），同时降低了解码过程对自回归因果的依赖。本研究深入揭示了扩散语言模型生成机制，并提供了一种高效的、原生支持扩散的强化学习训练框架。项目地址：https://github.com/apple/ml-diffucoder。

主题：计算与语言

https://arxiv.org/abs/2506.20639

### Diffusion + 推理

#### [种子扩散：具有高速推理的大规模扩散语言模型（64▲） ](https://huggingface.co/papers/2508.02193?utm_source=digest-papers&utm_medium=email&utm_campaign=2025-08-06)

我们提出了 Seed Diffusion Preview，一种基于离散状态扩散的大规模语言模型，提供了显著快速的推理速度。得益于非顺序的并行生成，离散扩散模型显著加快了速度，缓解了逐令牌解码固有的延迟，正如最近的研究所示（例如，Mercury Coder，Gemini Diffusion）。Seed Diffusion Preview 在 H20 GPU 上实现了 2146 令牌/秒的推理速度，同时在一系列标准代码评估基准测试中保持了有竞争力的性能，速度远超当代的 Mercury 和 Gemini Diffusion，在代码模型的速度-质量帕累托前沿上树立了新的最先进水平。

### Diffusion + 数据合成

2025-06-27 12:08:15 Friday ｜具身世界模型新突破，地平线 & 极佳提出几何一致视频世界模型增强机器人策略学习  https://mp.weixin.qq.com/s/Hj2h3nxO8XxPeqd3OhctKA
