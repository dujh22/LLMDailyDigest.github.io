+++
title = '新模型'
date = 2025-08-12T00:00:00+08:00
draft = false
toc = true
+++

# 新模型

## 2025-08011

#### 智谱GLM-4.5V

1. 相关素材
   1. 体验地址：https://chat.z.ai/
   2. HuggingFace 开源地址：https://huggingface.co/zai-org/GLM-4.5V
   3. GitHub 开源地址：https://github.com/zai-org/GLM-V
   4. 桌面助手下载地址：https://huggingface.co/spaces/zai-org/GLM-4.5V-Demo-App
   5. 魔搭社区：https://modelscope.cn/collections/GLM-45V-8b471c8f97154e
2. 对图像的识别与推理、视频理解：GLM-4.5V 在涵盖图像理解、视频理解、GUI、文档理解等任务的 41 个公开视觉多模态榜单中综合效果达到了开源 SOTA 水平，这和我们在实测中体验到的结果是一致的。

## 2025-08-08

#### GPT-5：博士生水平

1. 官方介绍：https://openai.com/index/introducing-gpt-5/

   1. **gpt-5** ：专注逻辑推理和多步骤任务
   2. **gpt-5-mini** ：轻量级版本，成本敏感型应用
   3. **gpt-5-nano** ：速度优化版，超低延迟
   4. **gpt-5-chat** ：企业级多模态对话，支持上下文感知
2. GPT-5 是一个一体化系统，包含三个核心部分：

   1. 一个智能高效的基础模型，可解答大多数问题
   2. 一个深度推理模型（即GPT-5思维模块），用于处理更复杂的难题
   3. 以及一个实时路由模块，能够基于对话类型、问题复杂度、工具需求及用户显式指令（如prompt含“仔细思考这个问题”）智能调度模型
3. [快来看看GPT-5第一波实测](https://mp.weixin.qq.com/s/bKo5zwqCxdDXTch187tc2g)

   1. ARC-AGI的成绩单表示GPT-5不如Grok 4
   2. SimpleBench上，GPT-5的水平已经超过了人类平均水平，在大模型中尚属首次。这是一个简单常识推理类的数据集，主要特点就是对于人类非常简单，但对大模型比较困难。
4. [GPT-5来了！人人都能免费用，最强大模型只需最傻瓜式使用](https://mp.weixin.qq.com/s/ktVhcQ2gjbUMh5zX260ynA)
5. [GPT-5编程成绩有猫腻！自删23道测试题，关键基准还是自己提的](https://mp.weixin.qq.com/s/gVvvkiIFFT8GWZcVwhWS9Q)

## 2025-08-07

1. [端侧｜Qwen紧追OpenAI开源4B端侧大模型，AIME25得分超越Claude 4 Opus](https://mp.weixin.qq.com/s/No7YJsxrIWaVbFZXGd0pbQ)
   * Qwen3-4B-Instruct-2507：非推理模型，大幅提升通用能力
   * Qwen3-4B-Thinking-2507：高级推理模型，专为专家级任务设计，逻辑、数学、科学及代码中的高级推理能力——专为专家级任务设计。
   * 更智能、更精准，并且支持256k上下文，更具上下文感知能力。
   * 抱抱脸直通车：
     * [1]https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507
     * [2]https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507
   * 魔搭社区直通车：
     * ttps://modelscope.cn/models/Qwen/Qwen3-4B-Instruct-2507
     * https://modelscope.cn/models/Qwen/Qwen3-4B-Thinking-2507
2. 智能体｜Reflection AI已经发布了他们的首款AI智能体Asimov，较Claude Code Sonnet 4等模型，得到了用户更多偏好。
   1. Asimov是一款专为代码理解打造的，它能对代码仓库、架构文档、GitHub讨论串、对话历史等多种信息进行索引，从而形成对代码库结构、历史及团队知识的全面认知。
   2. Asimov **并非单一智能体** ，而是 **由几个小型智能体协同工作** 。

## 2025-08-06

1. **Claude Opus 4.1**
   1. [Claude Opus 4.1火速发布！坐稳编程之王，官方：马上还有大更新](https://mp.weixin.qq.com/s/objwQLTeGWyrYnuy93aZFw)
      1. **编程性能**再次突破天花板，超越Claude Opus 4，拿下SOTA。
         1. **在SWE-bench上，Opus 4.1超越Opus 4、Gemini 2.5 Pro、o3，将性能提升至74.5%，拿下新SOTA。**
      2. **Blog：**[https://www.anthropic.com/news/claude-opus-4-1](https://www.anthropic.com/news/claude-opus-4-1)
      3. **System Card：**[https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf](https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf)
2. **谷歌DeepMind发布了****新一代通用世界模型Genie 3**
   1. [谷歌“世界模拟器”深夜上线！一句话生成3D世界，支持分钟级超长记忆](https://mp.weixin.qq.com/s/ulhJGiiq301f1yuPRTl36g)
      1. **Genie 3相比上一代大幅升级，支持****720P画质，每秒24帧实时导航，以及分钟级的一致性保持**。
      2. **最让谷歌引以为傲的，还要属Genie 3的****长期环境一致性**。
      3. **DeepMind十多年来一直在关注模拟环境领域的研究，从训练智能体掌握实时战略游戏， 到开发用于开放式学习和机器人技术的模拟环境。**
   2. [谷歌推出「G」字号第三代世界模型Genie 3，号称「宇宙模拟器」，视频生成更加符合物理定律。](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652617195&idx=1&sn=91f7f14b4c811e2a1cd9bb5cf5652a11&scene=21#wechat_redirect)
3. **OpenAI开源两个推理模型：gpt-oss-120b**和**gpt-oss-20b**。
   1. [刚刚，OpenAI开源2个推理模型：笔记本/手机就能跑，性能接近o4-mini](https://mp.weixin.qq.com/s/bIaUXw9XWR2Sb4dy4i37_Q)
      1. **gpt-oss，即Open Source Series，意思就是“开源系列”。**
      2. **gpt-oss-120b**：1170亿参数（MoE架构，激活参数约51亿），可在单张80GB GPU上运行，性能接近闭源的o4-mini。
      3. **gpt-oss-20b**：210亿参数（Moe架构，激活参数约36亿），可在16GB内存的消费级设备上运行，性能接近o3-mini。
      4. **整体来看，这两个模型在工具使用、少样本函数调用、链式思考推理（如Tau-Bench智能评估套件的结果所示）以及HealthBench上表现强劲，甚至超越了包括OpenAI o1和GPT‑4o在内的专有模型。**
      5. **gpt-oss-120b每个token激活5.1B个参数，而gpt-oss-20b激活3.6B个参数。这些模型分别具有117b和21b的总参数。**
      6. **技术博客地址：**[https://openai.com/index/introducing-gpt-oss/](https://openai.com/index/introducing-gpt-oss/)
      7. **HuggingFace地址：**[https://huggingface.co/openai/gpt-oss-120b](https://huggingface.co/openai/gpt-oss-120b)
      8. **GtiHub地址：**[https://github.com/openai/gpt-oss](https://github.com/openai/gpt-oss)
      9. OpenAI-OSS-120B用起来要谨慎，写代码特别不稳定。OpenAI-OSS-20B在这个参数量大小下反而挺好。
   2. [全网开测GPT-oss！技术架构也扒明白了](https://mp.weixin.qq.com/s/U2TsYntvP9Hdlg6e9oUpoQ)
      1. GPT-oss在架构设计上既保留了MoE Transformer的核心架构，又通过细节优化提升性能、降低复杂度，使其成为适合开源模型的基础架构。

         * 对每个注意力头，设置一个可以学习的标量，然后进行softmax汇聚。
         * 与GPT-3相同，交替使用滑动窗口层和全连接层。
         * 对每个输入分配4个相关专家处理，再整合结果，专家之间彼此完全独立，同时使用标准负载均衡损失，确保资源高效分配。
         * 使用了改进的swiglu激活函数，通过α=1.702让sigmoid的线性单元silu近似于高斯误差线性单元gelu。裁剪激活值防止梯度爆炸，通过调整“up+1”有助于梯度流动。
         * 采用YaRN上下文窗口扩展技术，提升长文本处理能力。
         * 移除了RMSNorm归一化过程中的可学习偏置参数，减少拟合风险。
4. **声音理解能力新SOTA**，小米全量开源了模型**MiDashengLM-7B**，基于Xiaomi Dasheng作为音频编码器和Qwen2.5-Omni-7B Thinker作为自回归解码器，通过创新的通用音频描述训练策略，实现了对语音、环境声音和音乐的统一理解。[小米模型实现声音理解新SOTA！数据吞吐效率暴增20倍，推理速度快4倍 | 全量开源](https://mp.weixin.qq.com/s/NYyRBge-3eYEbXXTkx7AvA)

## 2025-07-28


#### GLM-4.5  [智谱GLM-4.5 系列 测评](https://mp.weixin.qq.com/s/N3OHlfyczY8PB_2IbO3dAQ?scene=1&click_id=39)

[智谱终于发布GLM-4.5技术报告，从预训练到后训练，细节大公开](https://mp.weixin.qq.com/s/4EAlA5mS3CIWCjJ7uZebbw)

1. 逻辑能力
   1. 幻觉过重：基础模式的幻觉是全方面的，不但对prompt输入本身存在幻觉，其输出有时也存在“梦游”现象，输出一些自己也不知道是什么的内容。比如在输出中试图引用一张图片来解释原理，但图片Url无法访问。大概是训练材料混入的脏数据。#42报告提炼问题，基础模式放弃了计算统计数据，使用占位符，对报告中核心观点的摘要也提炼不完整。在仅有的1pass中虽然计算了统计值，但计算错误。不过好在推理模式中，幻觉控制要好的多，没有出现类似问题。相关问题表现达到推理模型平均水准。
   2. 计算误差：受幻觉影响，基础模式数学计算误差显著偏高，以#38函数求交尤为典型，在kimi-k2的误差中，往往是小数点第3位之后的精度问题，按四舍五入算大体是对的。而GLM-4.5的误差体现在计算过程中小错误不断积累，最终答案只是看起来像，实际完全不对。同样由于推理模式对幻觉的抑制有效，同样题目在推理模式下准确率极高，#38题稳定满分，#42年报报告提炼问题中数据汇总部分也基本没有问题，偶有误差。
   3. 暴力倾向：对于复杂问题，基础模式2个版本有半数几率使用暴力穷举，在中等难度的#36六阶数独问题如此，在难题#23解密，#24数字规律等问题同样如此。在没有使用穷举的轮次中，二者均能正常响应，输出虽然不满分，但在同梯队中表现尚可的答案。值得一提的是，GLM前一个版本air-0414和Z1也因为过多使用暴力穷举，导致模型输出极易陷入死循环而耗尽Token，新版则只在少数（低于2%）输出死循环，大部分穷举Badcase是真的在穷举。**推理模式**下也存在同样问题，但概率较小，仅在个别高难度问题如#43目标数，#44工具组合，中有体现。

## 2025-7-26

1. [多模态卷王阶跃星辰Step 3登场，推理效率可达DeepSeek-R1 300%](https://mp.weixin.qq.com/s/abvxxTefWkdRoddnREnAbg)

   1. 2025 WAIC大会上，阶跃星辰的新一代主力基座模型Step 3，带来了意想不到的惊喜。新一代旗舰基模Step 3的发布，标志着阶跃多模态大模型又一个新里程碑。
   2. Step 3在MMMU、MathVision、SimpleVQA、AIME 2025、LiveCodeBench（2024.08-2025.05）等榜单上直接拿下了开源多模态推理模型的SOTA成绩。
2. [九天大模型大变身：性能狂飙35%！还能一键P大象](https://mp.weixin.qq.com/s/3VkR9VBaSs6eMZEaWqfdYg)

   1. 7月26日，在2025世界人工智能大会期间，中国移动焕新发布「九天」基础大模型3.0。本次发布的「九天」基础大模型3.0，重点聚焦模型的端到端技术升级以及生成可控性能力的增强，进一步强化九天大模型「高安全、高可控、全国产、全行业」的独特优势。

## 历史

1. 2025-07-17 10:58:27 Thursday ｜  Kimi-2 已上线 LiveBench AI：超越 GPT-4.1，开源 AI 新王者诞生
2. 2025-07-03 11:20:12 Thursday ｜ https://mp.weixin.qq.com/s/__VhGST5Qm_KI8yoc_d68A

Grok 4 (grok-4-0629)，则是一个更大、更智能的Thinking模型。官方宣称，这是他们最新、最强大的旗舰模型，在自然语言、数学和推理上性能无与伦比，是用户的最佳选择。

而Grok 4 Code（grok-4-code-0629）则专为编程而打造。你可以向它询问代码问题，甚至直接把它嵌入到自己的代码编辑器中，还可以一键在Cursor上使用。

3. 2025-07-03 10:27:17 Thursday ｜ OpenRouter 上出现了一个神秘模型，该模型被命名为「Cypher Alpha」。其可以免费使用，100 万 token 上下文，还具有推理能力。 https://mp.weixin.qq.com/s/lmIQhT7uI9etjxGgIYqLoA
4. 2025-07-02 14:09:31 Wednesday ｜SuperCLUE推理榜惊现黑马：原来中兴是一家AI公司？ https://mp.weixin.qq.com/s/H2urbOlVVcFR5b-GA7Rnhw
5. 2025-07-01 11:23:45 Tuesday ｜ 百度官宣文心大模型4.5系列正式开源，还同步提供API服务 https://mp.weixin.qq.com/s/jG0R66Uq_6kFwajb7XKM3w

报告地址：https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf

6. 2025-06-28 18:48:36 Saturday ｜ 一手实测有道14B「子曰3」数学模型，击败满血版DeepSeek R1 https://mp.weixin.qq.com/s/x56TbKXzijRxaJLXKvKV_g

网易有道开源了「 **子曰3** 」 **数学模型** （Confucius3-Math），以14B参数的轻量级模型在多项数学推理任务上超越了满血参数的DeepSeek-R1。

7. 2025-06-27 14:04:27 Friday ｜AI秒懂短视频，快手大模型Keye-VL理解力爆表！技术细节全开源 https://mp.weixin.qq.com/s/hFO2TQNcn3IK3E1F1QQObw
8. 2025-06-26 12:06:05 Thursday ｜ Gemini Robotics On-Device，谷歌 DeepMind 首个可以直接部署在机器人上的视觉-语言-动作（VLA）模型https://mp.weixin.qq.com/s/mjZAAvVtPevYDD5HfexN6g
9. 2025-07-01 10:44:45 Tuesday ｜ 华为正式宣布开源盘古 70 亿参数的稠密模型「 **盘古 Embedded** 」、盘古 Pro MoE 720 亿参数的混合专家模型（参见机器之心报道：[华为盘古首次露出，昇腾原生72B MoE架构，SuperCLUE千亿内模型并列国内第一](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650971050&idx=1&sn=93a499f2a2bcb83302ad201b8d193bda&scene=142#wechat_redirect) ）和基于昇腾的模型推理技术。
   开源链接：https://gitcode.com/ascend-tribe

https://mp.weixin.qq.com/s/v1NNVaH9oDufqkrkyVLnVw

更重要的是，这些模型采用了一些领先的技术来实现高效的训练和推理，比如分组混合专家 MoGE 算法、自适应快慢思考合一以及全链路的高性能推理系统优化。

10. 2025-06-23 11:46:54 Monday｜ 在华为开发者大会 2025（HDC 2025）上，华为重磅发布了盘古大模型 5.5 https://mp.weixin.qq.com/s/Ie824EYirtd3gqpog786Nw
    1. 盘古 Ultra MoE 的技术 报告地址：https://arxiv.org/pdf/2505.04519
    2. 盘古 Pro MoE 的技术报告 项目地址：https://gitcode.com/ascend-tribe/pangu-pro-moe
    3. 小模型**盘古 Embedding **报告地址：https://arxiv.org/pdf/2505.22375
    4. 华为发布了开放域信息获取 Agent—— **盘古 DeepDiver **报告地址：https://arxiv.org/pdf/2505.24332
11. 2025-06-19 20:05:29 Thursday ｜ MiniMax刚刚发布海螺2.0版本，能处理极端物理情况，原生支持1080P。
12. 2025-06-19 19:40:54 Thursday ｜ Gemini 2.5 Pro 稳定版发布且已全面可用，其与 6 月 5 日的预览版相比无变化。
    1. 报告地址：https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf
    2. AI玩宝可梦找出30年前代码Bug！谷歌论文介绍AI通关全过程，复杂任务都能解 https://mp.weixin.qq.com/s/fOGbijWnqEloziC3TISz_w
13. 2025-06-17 11:20:40 Tuesday ｜开源代码模型 **Kimi-Dev** ，在SWE-bench Verified上以60.4%的成绩 **取得开源SOTA：** 项目主页：https://moonshotai.github.io/Kimi-Dev/ GitHub：https://github.com/MoonshotAI/Kimi-Dev HuggingFace：https://huggingface.co/moonshotai/Kimi-Dev-72B
14. 2025-06-17 11:11:46 Tuesday ｜ MiniMax开源MiniMax-M1，目前模型权重已可在HuggingFace下载，技术报告同步公开。
15. 2025-06-12 10:53:36 Thursday | 豆包大模型1.6发布
16. 2025-06-11 11:15:20 Wednesday｜o3-pro发布，严格的「4/4 可靠性」评估，即只有在四次尝试中（而不仅仅是一次）正确回答问题，模型才被视为成功
17. 20250606｜gemini-2.5-pro-0605发布
18. 20250606｜Qwen3-Embedding系列发布：Qwen3-Embedding系列支持119种语言，涵盖主流自然语言及多种编程语言。

### 多模态模型

2025-07-01 11:20:23 Tuesday ｜Black Forest Labs刚刚宣布开源旗舰图像模型 **FLUX.1 Kontext[dev]** ，专为图像编辑打造，还能直接在消费级芯片上运行。 https://mp.weixin.qq.com/s/Cu-58gySRJ0-bWCwO8ViuQ

2025-06-30 18:00:22 Monday ｜ 阿里多模态模型Qwen-VLo https://mp.weixin.qq.com/s/RiAnvEhp0lkPpC-ED24Tgw

#### VLM

2025-07-03 10:59:19 Thursday ｜ 9B“小”模型干了票“大”的：性能超8倍参数模型，拿下23项SOTA | 智谱开源 https://mp.weixin.qq.com/s/5jcSAR6I7MyHc4INo7f9BQ

**智谱发布并开源了一个仅9B大小的模型——GLM-4.1V-9B-Thinking**

引入了 **思维链** （Chain-of-Thought）推理机制，并通过 **课程采样强化学习** （RLCS，Reinforcement Learning with Curriculum Sampling）来全面提升模型能力。

团队采用“课程学习”的方式进行大规模强化训练，也就是先让模型从简单任务开始，逐步挑战更难的任务。通过这种由浅入深的训练策略，模型在实用性、准确性以及稳定性方面都有了明显的提升。

2. 2025-07-03 11:01:58 Thursday ｜ 字节最新发布多主体控制生成模型 **Xverse** ——

既可以对设定好的每个主体进行精确控制，也不会破坏图像的生成质量 https://mp.weixin.qq.com/s/JzuyHDfRGd-hFoL_VOXCAg

XVerse的核心是通过学习DiT（Diffusion Transformer，一种扩散模型和Transformer架构的生成模型）中文本流调制机制中的偏移量，**实现对多个主体身份和语义属性的****一致控制**。

#### 音频

2025-07-02 14:54:01 Wednesday ｜ 阿里通义开源首个CoT音频模型，音·画同步被狠狠拿捏了 https://mp.weixin.qq.com/s/NPb2iQvAiTJb0LZG8CSdXg

没错，这就是阿里通义语音团队最新开源的 **泛音频生成模型ThinkSound** ，主要用于视频配音，主打 **让每一帧画面都有专属匹配音效** 。

就在上个月，团队发布了语音生成大模型 **Cosyvoice 3.0** ，通过大规模数据预训练和特殊设计的强化学习后训练，它能提供多语言语音生成、零样本语音复刻等功能。

更早之前，团队还推出了基于模态对齐实现的端到端音频多模态大模型 **MinMo** 。

### 智能体模型

2025-06-28 17:18:09 Saturday ｜ AI自动修bug，解决率达44%！这是全球开源模型的最新最强水平。来自蚂蚁的开源新模型，在SWE-bench Lite上超越所有开源方案，性能媲美闭源模型。 https://mp.weixin.qq.com/s/Y-vqZG2dQMOwvXTinDbT1Q

### 端侧模型

vivo突破手机AI部署难题，绕开MoE架构限制，骁龙8 Elite流畅运行｜ICCV 2025[ https://mp.weixin.qq.com/s/ztTdARR4Q0opOGP139NQkQ](https://mp.weixin.qq.com/s/ztTdARR4Q0opOGP139NQkQ)

2025-06-28 17:02:38 Saturday ｜ 最低仅需2G显存，谷歌开源端侧模型刷新竞技场纪录，原生支持图像视频 ，今天凌晨，谷歌正式官宣了 **Gemma 3n** ，原生支持文本、图像和音视频等多种模态。 https://mp.weixin.qq.com/s/iN4Fir3tSt96vPJufn5PSQ

模型、权重：https://huggingface.co/collections/google/gemma-3n-685065323f5984ef315c93f4

文档：https://ai.google.dev/gemma/docs/gemma-3n

博客：https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/

3. 2025-06-28 17:11:15 Saturday ｜ https://mp.weixin.qq.com/s/1jIi40A9Jm9zFLuuCuE3OA

早在两个月前的阿里云AI势能大会上，阿里云百炼就透露了要做Agent Store的计划。

现在，这个**[Agent Store正式上线](https://bailian.console.aliyun.com/?spm=5176.29619931.J_AHgvE-XDhTWrtotIBlDQQ.13.74cd521cK99oYc&tab=app#/app-market/newTemplate)**了，提供了覆盖各行各业的上百个Agent模板。

 **CGM的技术论文、核心代码、模型权重与训练数据均已开源** ，感兴趣的同学可进一步了解详情。

* 技术论文：https://arxiv.org/abs/2505.16901
* 开源代码：https://github.com/codefuse-ai/CodeFuse-CGM
* 模型权重：https://huggingface.co/codefuse-ai/CodeFuse-CGM-72B
* 训练数据：https://huggingface.co/datasets/codefuse-ai/CodeGraph

😎团队此前工作：

* Code LLM综述：Awesome-Code-LLM（TMLR）https://github.com/codefuse-ai/Awesome-Code-LLM
* Graph+LLM前序研究：GALLa（ACL 2025）https://github.com/codefuse-ai/GALLa
* 高效注意力架构：Rodimus（ICLR 2025）https://arxiv.org/abs/2410.06577
* 代码多任务微调框架：MFTCoder（KDD 2024）https://arxiv.org/abs/2311.02303
