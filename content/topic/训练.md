+++
title = '训练'
date = 2025-08-07T00:00:00+08:00
draft = false
toc = true
+++

# 训练

1. 2025-06-13 18:50:11 Friday ｜

Magistral
 **标题** ： Magistral
 **链接** ：https://arxiv.org/abs/2506.10910

 **作者** ： Mistral-AI:  Abhinav Rastogi,  Albert Q. Jiang,  Andy Lo,  Gabrielle Berrada,  Guillaume Lample,  Jason Rute,  Joep Barmentlo,  Karmesh Yadav,  Kartik Khandelwal,  Khyathi Raghavi Chandu,  Léonard Blier,  Lucile Saulnier,  Matthieu Dinot,  Maxime Darrin,  Neha Gupta,  Roman Soletskyi,  Sagar Vaze,  Teven Le Scao,  Yihan Wang,  Adam Yang,  Alexander H. Liu,  Alexandre Sablayrolles,  Amélie Héliou,  Amélie Martin,  Andy Ehrenberg,  Anmol Agarwal,  Antoine Roux,  Arthur Darcet,  Arthur Mensch,  Baptiste Bout,  Baptiste Rozière,  Baudouin De Monicault,  Chris Bamford,  Christian Wallenwein,  Christophe Renaudin,  Clémence Lanfranchi,  Darius Dabert,  Devon Mizelle,  Diego de las Casas,  Elliot Chane-Sane,  Emilien Fugier,  Emma Bou Hanna,  Gauthier Delerce,  Gauthier Guinet,  Georgii Novikov,  Guillaume Martin,  et al. (53 additional authors not shown)
 **摘要** ：我们介绍了Magistral，Mistral的第一个推理模型和我们自己的可扩展强化学习（RL）管道。我们不依赖于现有的实现和从先前模型中提取的RL跟踪，而是遵循一种自上而下的方法，完全依赖于我们自己的模型和基础设施。值得注意的是，我们展示了一个堆栈，使我们能够探索LLM的纯RL训练的限制，提出了一种简单的方法来强制模型的推理语言，并表明仅对文本数据的RL保持了大部分初始检查点的功能。我们发现，RL的文本保持或提高多模态理解，指令遵循和函数调用。我们提出了Magistral Medium，在Mistral Medium 3的基础上单独使用RL进行推理训练，我们开源了Magistral Small（Apache 2.0），其中进一步包括来自Magistral Medium的冷启动数据。

## 训练范式

2025-07-03 10:51:03 Thursday ｜ 同时监督和强化的单阶段大模型微调，告别“先背书再刷题”，推理泛化双提升｜中科院&美团等 https://mp.weixin.qq.com/s/9dTE8dtVIO1TE0Xy3vUReQ

**中国科学院自动化研究所深度强化学习团队**联合 **美团** ，提出一种 **单阶段监督-强化微调方法——SRFT (Supervised Reinforcement Fine-Tuning)** 。该方法通过基于熵的动态加权机制，将两种训练范式结合。

![](https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=ZTA1MWVmMWNiYjQ2NmUyMDdjZTg4ZGM1NDllNjFmNTZfcE1vVU5rdkZtemU0Mm1xcVpXZ0pLdXBMWVc3R3NvOFVfVG9rZW46UEsxVmJrcGNQbzNIRnR4cXQ3SmNQZ0xOblNoXzE3NTQ1MzkzMjQ6MTc1NDU0MjkyNF9WNA)

图注：SRFT方法示意图，展示了对探索试错（rollout）数据和演示（demonstration）数据的协同学习，以及平衡监督和强化信号的熵感知策略更新。

SRFT的核心在于其单阶段学习机制：通过SFT实现 **粗粒度行为策略逼近** ，通过RL实现 **细粒度策略精化** ，借助于 **单阶段训练** ，将微调同时应用于演示数据和自生成的试错数据。

2. 2025-07-01 10:59:44 Tuesday ｜ 首创Mid-training范式破解RL奥秘，Llama终于追平Qwen！**https://mp.weixin.qq.com/s/25wERcyTi79GOBpytujEWA**

深入探讨了不同基础语言模型家族（如 Llama 和 Qwen）在强化学习（RL）训练中迥异表现的背后原因，并提出创新性的中期训练（mid-training）策略，成功地将 Llama 模型改造成高度适配强化学习的推理基础模型，显著缩小了其与天生擅长 RL 扩展的 Qwen 模型之间的性能差距，为下一代 reasoning 能力 AI 系统的开发提供了关键的科学基础和技术路径。

论文链接：https://arxiv.org/abs/2506.20512

代码仓库：https://github.com/GAIR-NLP/OctoThinker

开源模型 & 数据：https://huggingface.co/OctoThinker

3. 2025-06-25 10:19:06 Wednesday ｜ 生成式视角重塑监督学习！标签不只是答案，更是学习指南 | ICML 2025 https://mp.weixin.qq.com/s/ITHsYOAHXYS4G0W3FFHqDg

受生成式一致性模型的启发，来自上海交大、SII、MIT、港中文深圳等机构的研究团队在ICML 2025最新提出预测一致性学习（PCL，Predictive Consistency Learning）。PCL通过扩散模型的扩散过程消减标签的信息，将噪声标签（Noised Labels）引入模型的输入，使得模型在数据输入和噪声标签的共同参照下预测完整标签，实现标签信息的复用和价值挖掘。

2. 2025-06-25 11:04:11 Wednesday ｜

**[SRFT：一种具有监督和强化微调的单阶段推理方法](https://papers.cool/arxiv/2506.19767)** **[PDF(3)]** **[Copy]** **[Kimi(4)]** **[REL]**

 **Authors** : [Yuqian Fu](https://arxiv.org/search/?searchtype=author&query=Yuqian%20Fu), [Tinghong Chen](https://arxiv.org/search/?searchtype=author&query=Tinghong%20Chen), [Jiajun Chai](https://arxiv.org/search/?searchtype=author&query=Jiajun%20Chai), [Xihuai Wang](https://arxiv.org/search/?searchtype=author&query=Xihuai%20Wang), [Songjun Tu](https://arxiv.org/search/?searchtype=author&query=Songjun%20Tu), [Guojun Yin](https://arxiv.org/search/?searchtype=author&query=Guojun%20Yin), [Wei Lin](https://arxiv.org/search/?searchtype=author&query=Wei%20Lin), [Qichao Zhang](https://arxiv.org/search/?searchtype=author&query=Qichao%20Zhang), [Yuanheng Zhu](https://arxiv.org/search/?searchtype=author&query=Yuanheng%20Zhu), [Dongbin Zhao](https://arxiv.org/search/?searchtype=author&query=Dongbin%20Zhao)

大型语言模型 （LLM） 在推理任务方面取得了显着进步，但监督微调 （SFT） 和强化学习 （RL） 的最佳集成仍然是一个根本挑战。通过从基于熵的角度对代币分布、学习动态和集成机制进行全面分析，我们揭示了这些范式之间的主要差异：SFT 诱导 LLM 策略分布的粗粒度全局变化，而 RL 执行细粒度选择性优化，熵作为训练效果的关键指标。基于这些观察结果，我们提出了监督强化微调 （SRFT），这是一种单阶段方法，通过熵感知加权机制统一了两种微调范式。我们的方法同时应用 SFT 和 RL 来直接优化 LLM，使用演示和自我探索推出，而不是通过两阶段顺序方法。广泛的实验表明，SRFT 实现了 59.1% 的平均准确率，在五个数学推理基准上比零 RL 方法高出 9.0%，在三个分布外基准上比零 RL 方法高出 10.9%。

## 预训练

### 数据工程

2025-06-30 19:05:49 Monday ｜

**[AutoMixer：作为自动数据混合器的检查点工件](https://papers.cool/arxiv/2506.21910)** **[PDF()]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [Ernie Chang](https://arxiv.org/search/?searchtype=author&query=Ernie%20Chang), [Yang Li](https://arxiv.org/search/?searchtype=author&query=Yang%20Li), [Patrick Huber](https://arxiv.org/search/?searchtype=author&query=Patrick%20Huber), [David Kant](https://arxiv.org/search/?searchtype=author&query=David%20Kant), [Yangyang Shi](https://arxiv.org/search/?searchtype=author&query=Yangyang%20Shi), [Vikas Chandra](https://arxiv.org/search/?searchtype=author&query=Vikas%20Chandra)

在语言模型训练中，最好为模型配备来自各种任务的功能。但是，由于数据和任务之间的关系很难建模，因此尚不清楚如何直接获得这些功能的正确数据混合。在这项工作中，我们观察到检查点模型在训练轨迹的不同点表现出新兴的能力。通常，训练过程会将检查点保存为未充分利用的工件，作为训练中数据信号的来源。我们根据这些伪影模型在基准上的各自能力来识别这些伪影模型，并通过使用它们在源数据上的聚合一阶影响近似将它们用作数据混合器。我们在 8 个推理基准上证明，所提出的框架在预训练设置方面显示出显着改进，性能提升高达 1.93%。总体而言，这表明检查点模型在提高数据质量和优化数据混合方面的潜力。

2. 2025-06-27 14:18:53 Friday

**[语言模型训练的数据效能](https://papers.cool/arxiv/2506.21545)** **[PDF(9)]** **[Copy]** **[Kimi(1)]**  **[REL] ** **[#1](https://arxiv.org/abs/2506.21545)****[Data Efficacy for Language Model Training](https://papers.cool/arxiv/2506.21545)**** [PDF(10)] [Copy] [Kimi(1)] [REL]**

作者：戴亚伦、黄扬宇、张鑫、吴文山、李冲、卢文辉、曹世杰、董力、李思嘉

数据是语言模型 （LM） 训练的基础。最近的研究致力于数据效率，旨在通过选择训练数据的最小或最佳子集来最大限度地提高性能。数据过滤、采样和选择等技术在这一领域起着至关重要的作用。为了补充它，我们定义了数据效能，它侧重于通过优化训练数据的组织来最大限度地提高性能，并且仍然相对未得到充分开发。这项工作介绍了一种通用范式 DELT，用于在 LM 训练中考虑数据功效，这突出了训练数据组织的重要性。DELT 包括三个组件：数据评分、数据选择和数据排序。在这些组件中，我们设计了可学习性-质量评分 （LQS），作为数据评分的新实例，它从梯度一致性的角度考虑了每个数据样本的可学习性和质量。我们还设计了折叠排序 （FO），作为数据排序的一个新实例，它解决了模型遗忘和数据分布偏差等问题。综合实验验证了 LM 训练中的数据效能，它证明了以下内容：首先，所提出的 DELT 的各种实例在不同程度上提高了 LM 性能，而无需增加数据规模和模型大小。其次，在这些实例中，我们提出的用于数据评分的 LQS 和用于数据排序的 Folding 相结合实现了最显着的改进。最后，通过应用数据选择，可以实现数据效率和数据效率。因此，我们相信数据有效性是 LM 训练中一个有前途的基础领域。

3. 2025-06-13 18:18:45 Friday ｜ 清华刘知远团队：高质量 LLM 训练数据获取https://mp.weixin.qq.com/s/1vDxmomJvoML-RF4HEIgIw
4. 2025-06-13 18:49:44 Friday ｜Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture  without Training
   **标题** ： Domain 2Vec：对数据集进行数据集进行数据量化，无需训练即可找到最佳数据混合
   **链接** ：https://arxiv.org/abs/2506.10952
5. 2025-06-18 10:46:16 Wednesday

Assessing the Role of Data Quality in Training Bilingual Language Models
 **标题** ： 评估数据质量在训练双语语言模型中的作用
 **链接** ：https://arxiv.org/abs/2506.12966

 **作者** ： Skyler Seto,  Maartje ter Hoeve,  Maureen de Seyssel,  David Grangier
 **备注** ：26 pages, 18 figures, 25 tables
 **摘要** ：双语和多语言语言模型为跨不同语言和用户扩展NLP系统提供了一条有前途的道路。然而，它们的性能通常在语言之间变化很大，因为先前的工作表明，添加更多的语言可能会降低某些语言（如英语）的性能，同时提高其他语言（通常是更多的数据约束语言）。在这项工作中，我们调查这些不一致的原因，通过比较双语和单语语言模型。我们的分析表明，不平等的数据质量，而不仅仅是数据量，是双语环境中性能下降的主要驱动因素。我们提出了一个简单而有效的数据过滤策略，选择高质量的双语训练数据，只有高质量的英语数据。应用于法语、德语和中文，我们的方法将单语性能提高了2-4%，并将双语模型性能差距缩小至1%。这些结果突出了多语言预训练中被忽视的数据质量的重要性，并为平衡性能提供了实用的方法。

## 微调

2025-06-27 14:25:51 Friday

**[为下游任务优化语言模型：训练后视角](https://papers.cool/arxiv/2506.20917)** **[PDF(2)]** **[Copy]** **[Kimi()]** **[REL]**

作者：石正严

语言模型 （LM） 在 NLP 中表现出了卓越的功能，但要有效、稳健地适应特定任务仍然具有挑战性。随着其规模和复杂性的增长，对标记数据进行微调 LM 往往没有充分利用可用的未标记数据，导致小任务特定集的过度拟合，并带来巨大的计算成本。这些限制阻碍了它们在现实世界语言任务的开放式环境中的应用。本论文提出了一系列方法，以更好地使 LM 适应下游应用。首先，我们探索了从未标记数据中提取任务相关知识的策略，引入了一种新的持续预训练技术，该技术优于最先进的半监督方法。接下来，我们提出了一种参数高效的微调方法，该方法可显著降低内存和计算成本，同时保持有竞争力的性能。我们还引入了改进的监督微调方法，使 LM 能够更好地遵循指令，尤其是在标记数据稀缺的情况下，从而提高它们在一系列 NLP 任务（包括开放式生成）中的性能。最后，我们开发了新的评估方法和基准，例如多跳空间推理任务，以更全面地评估 LM 能力和适应能力。通过对不同 NLP 任务的广泛实证研究，我们的结果表明，这些方法大大提高了 LM 的稳健性、效率和泛化性，使其更能适应广泛的应用。这些进步标志着朝着更强大、更高效的 LM 迈出了重要一步，使我们更接近通用人工智能的目标。

2. 2025-06-27 14:25:00 Friday

[#22](https://arxiv.org/abs/2506.21119) **[Progtuning：基于 Transformer 的语言模型的渐进式微调框架](https://papers.cool/arxiv/2506.21119)** **[PDF()]** **[Copy]** **[Kimi()]** **[REL]**

作者：纪晓霜，赵振东，陈晓军，赵鑫，刘泽尧

微调是一种很有前途的技术，可用于在下游任务中利用基于 Transformer 的语言模型。随着模型大小的不断增长，更新所有模型参数的成本越来越高。参数高效的微调方法通过选择性地更新一小部分参数来有效地解决此问题。然而，微调和大多数现有的参数高效微调方法需要更新与初始大小相同数量的参数，忽略了 Transformer 块之间的不平等贡献，并导致计算资源分配效率极低。在本文中，我们提出了 Progtuning，这是一种新颖的微调框架，结合了基于 Transformer 的语言模型的渐进式学习。具体来说，Progtuning 会根据贡献逐步减少更新的 transformer 块的数量。值得注意的是，Progtuning 优化了资源分配，并将更新参数的数量减少了大约 25\%，同时仍然保持有竞争力的性能。它还通过参数高效的微调方法表现出高适应性，在各种适应场景中表现出优异的性能。

3. 2025-06-23 12:41:02 Monday ｜ NFT

监督学习也能从错误中学习反思？！清华英伟达联合提出隐式负向策略爆炸提升数学能力 https://mp.weixin.qq.com/s/E9qGWKCCg-xx0XVl5g7ubA

清华大学与英伟达、斯坦福联合提出新的监督学习方案—— **NFT（Negative-aware FineTuning）** ，在RFT（Rejection FineTuning）算法基础上通过构造一个“隐式负向模型” 来额外利用负向数据进行训练。

这并不意味着使用“差数据”进行训练，而是在已知的模型计算结果前提下，通过负向数据训练正向模型，即 **“隐式负向策略（Implicit Negative Policy）”** 。

这一策略弥合了监督学习和强化学习的差距，使得两者性能基本持平。

项目网页: https://research.nvidia.com/labs/dir/Negative-aware-Fine-Tuning/

论文链接: https://arxiv.org/pdf/2505.18116

项目代码: https://github.com/NVlabs/NFT

4. 2025-06-13 18:28:14 Friday｜

Slimming Down LLMs Without Losing Their Minds
 **标题** ： 在不失去理智的情况下减肥LLM
 **链接** ：https://arxiv.org/abs/2506.10885

 **作者** ： Qingda (Michael)Mai
 **备注** ：10 pages
 **摘要** ：本文研究并验证了微调对大型语言模型性能的影响，重点是参数有效的方法（LoRA和QLoRA）。我们在三个关键领域评估模型能力：（1）常识推理（HellaSwag），（2）数学推理（GSM 8 K）和（3）多领域知识（MMLU-CS）。   我们的研究结果表明：（1）基于LoRA的方法有效地提高了特定于任务的性能，同时保持了计算效率，（2）性能在很大程度上取决于微调数据集和基准任务之间的对齐。该研究为开发人员在有限的资源下实现高效的LLM适应提供了理论见解和实践指导。

### 图像生成

2025-07-02 14:10:32 Wednesday ｜ ICML 2025 Spotlight | 清华朱军组&NVIDIA提出DDO：扩散/自回归模型训练新范式，刷新图像生成SOTAhttps://mp.weixin.qq.com/s/tiytMxR8QJN2fFSry1mQ1w

为解决 MLE 的局限性，文章考虑使用 **GAN 式判别**的思想，在训练目标中引入**反向 KL 散度**的成分，强化模型在真实数据附近的密度，同时抑制错误区域，将模型分布由图（a）：强调密度覆盖，微调为图（b）：强调密度集中，从而提高生成保真度与有限模型容量下的生成质量。然而， **直接使用 GAN 损失会引入额外的判别器网络与工程优化上的复杂性** ，尤其对于扩散/自回归模型这类需要迭代式多步生成的模型。

### 领域微调

2025-06-16 12:02:10 Monday

LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical  Evaluation Judge with Fuzzy Logic
 **标题** ： LLM作为模糊法官：使用模糊逻辑对大型语言模型进行微调，作为临床评估法官
 **链接** ：https://arxiv.org/abs/2506.11221

 **作者** ： Weibing Zheng,  Laurah Turner,  Jess Kropczynski,  Murat Ozer,  Tri Nguyen,  Shane Halse
 **备注** ：12 pages, 1 figure, 2025 IFSA World Congress NAFIPS Annual Meeting
 **摘要** ：临床沟通技能在医学教育中至关重要，大规模地实践和评估临床沟通技能具有挑战性。虽然LLM驱动的临床情景模拟在增强医学生的临床实践方面显示出了希望，但提供遵循细微差别的医生判断的自动化和可扩展的临床评估是困难的。本文结合**模糊逻辑**和大语言模型（LLM），提出LLM作为模糊评判，以解决医学生临床技能自动评价与医生主观偏好相结合的难题。LLM作为模糊判断是一种方法，LLM经过微调，根据来自四个模糊集的人类注释来评估医学生在学生-AI患者对话脚本中的话语，包括语言学，医学相关性，道德行为和上下文干扰。本文的方法从LLM-powered医学教育系统的数据收集开始，基于多维模糊集的数据注释，然后是提示工程和使用这些人类注释的预训练LLMs的监督微调（SFT）。结果表明，LLM作为一个模糊判断达到80%以上的准确性，与主要标准项目超过90%， **有效地利用模糊逻辑和LLM作为一个解决方案，提供可解释的，人类对齐的评估** 。这项工作表明了 **利用模糊逻辑和LLM与人类偏好保持一致的可行性** ，推进了医学教育的自动化评估，并支持更强大的评估和判断实践。该工作的GitHub存储库可在https://github.com/2sigmaEdTech/LLMAsAJudge上获得

## 训练加速

2025-06-19 19:52:13 Thursday ｜ 清华SageAttention3，FP4量化5倍加速！且首次支持8比特训练 https://mp.weixin.qq.com/s/aVlYM_cMrpTKeH3ao-UJuA

论文标题：SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-bit Training

论文链接：https://arxiv.org/abs/2505.11594

开源代码：https://github.com/thu-ml/SageAttention

## 算力集群

2025-06-30 18:13:11 Monday｜ 华为CloudMatrix重磅论文披露AI数据中心新范式，推理效率超NV H100 https://mp.weixin.qq.com/s/MmpWP77k3tyurv5t-9M2xw

华为发布了一篇60页的重磅论文，提出了他们的下一代AI数据中心架构设计构想—— **Huawei CloudMatrix** ，以及该构想的第一代产品化的实现CloudMatrix384。相对于简单的“堆卡”，华为CloudMatrix给出的架构设计原则是，高带宽全对等互连和细粒度资源解耦。

华为的CloudMatrix384通过“全对等架构+软硬协同”的模式，**打破了传统上算力、延迟和成本之间的“不可能三角”。**

2025-07-03 10:45:43 Thursday ｜华为CloudMatrix384超节点很强，但它的「灵魂」在云上  https://mp.weixin.qq.com/s/OG2-0xvgynUXzJouGeIYnw
