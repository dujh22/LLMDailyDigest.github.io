+++
title = '记忆'
date = 2025-08-08T00:00:00+08:00
draft = false
toc = true
+++

# 记忆

1. 2025-07-02 17:16:24 Wednesday ｜

 **[微调方法对大型语言模型中记忆的影响](https://papers.cool/arxiv/2507.00258)** **[PDF()]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [Jie Hou](https://arxiv.org/search/?searchtype=author&query=Jie%20Hou), [Chuxiong Wu](https://arxiv.org/search/?searchtype=author&query=Chuxiong%20Wu), [Lannan Luo](https://arxiv.org/search/?searchtype=author&query=Lannan%20Luo), [Qiang Zeng](https://arxiv.org/search/?searchtype=author&query=Qiang%20Zeng)

随着预训练大型语言模型 （LLM） 的功能不断进步，“预训练和微调”范式越来越成为主流，导致了各种微调方法的发展。然而，在微调过程中记忆所带来的隐私风险受到的关注相对较少。为了解决这一差距，我们对流行的微调方法进行了分类，并通过成员推理攻击 （MIA） 的视角评估了它们对记忆的影响。我们的结果表明，与基于参数的微调相比，基于提示的微调实现了有竞争力的性能，同时表现出较低的 MIA 脆弱性。此外，无论模型规模如何，基于提示的方法都保持低记忆。这些发现表明，基于参数的微调更容易泄露私人信息，而基于提示的微调是一种更能保护隐私的选项。

 **科目** :  **[计算和语言](https://papers.cool/arxiv/cs.CL)** , [人工智能](https://papers.cool/arxiv/cs.AI)

 **发布** ： 2025-06-30 20：52：15 UTC

2. 2025-06-30 19:11:06 Monday ｜

**M****[emBench：对基于 LLM 的代理的内存进行更全面的评估](https://papers.cool/arxiv/2506.21605)** **[PDF(1)]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [Haoran Tan](https://arxiv.org/search/?searchtype=author&query=Haoran%20Tan), [Zeyu Zhang](https://arxiv.org/search/?searchtype=author&query=Zeyu%20Zhang), [Chen Ma](https://arxiv.org/search/?searchtype=author&query=Chen%20Ma), [Xu Chen](https://arxiv.org/search/?searchtype=author&query=Xu%20Chen), [Quanyu Dai](https://arxiv.org/search/?searchtype=author&query=Quanyu%20Dai), [Zhenhua Dong](https://arxiv.org/search/?searchtype=author&query=Zhenhua%20Dong)

最近的工作强调了基于 LLM 的代理中记忆机制的重要性，这使它们能够存储观察到的信息并适应动态环境。然而，评估它们的内存能力仍然具有挑战性。以前的评估通常受到内存级别和交互式场景多样性的限制。它们也缺乏全面的指标来从多个方面反映内存能力。为了解决这些问题，在本文中，我们构建了一个更全面的数据集和基准来评估基于 LLM 的代理的内存能力。我们的数据集将事实记忆和反思记忆作为不同的层次，并提出参与和观察作为各种互动场景。基于我们的数据集，我们提出了一个名为 MemBench 的基准测试，从多个方面评估基于 LLM 的代理的内存能力，包括它们的有效性、效率和容量。为了造福研究社区，我们在 https://github.com/import-myself/Membench 上发布了我们的数据集和项目。

3. 2025-06-30 19:55:59 Monday ｜

**[通过电路发现了解 LLM 中的逐字记忆](https://papers.cool/arxiv/2506.21588)** **[PDF()]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [Ilya Lasy](https://arxiv.org/search/?searchtype=author&query=Ilya%20Lasy), [Peter Knees](https://arxiv.org/search/?searchtype=author&query=Peter%20Knees), [Stefan Woltran](https://arxiv.org/search/?searchtype=author&query=Stefan%20Woltran)

LLM 中记忆的潜在机制 -- 训练数据的逐字复制 -- 仍然知之甚少。网络的确切部分决定检索我们认为作为记忆序列开始的令牌？模型在产生记忆句子和非记忆句子时的行为究竟有何不同？在这项工作中，我们利用变压器电路从机制可解释性的角度来解决这些问题——变压器电路是在模型中执行特定功能的最小计算子图。通过精心构建的对比数据集，我们确定了模型生成与记忆内容不同的点，并隔离了负责记忆的两个不同方面的特定电路。我们发现，启动记忆的电路在启动后也可以保持它，而只保持记忆的电路不能触发它的启动。有趣的是，记忆预防机制在不同的文本域之间稳健地转移，而记忆归纳似乎更依赖于上下文。

20250808｜协同检索器 - ICML 2025｜M+: Extending MemoryLLM with Scalable Long-Term Memory

* **论文链接：**[https://arxiv.org/abs/2502.00592](https://arxiv.org/abs/2502.00592)
* **代码仓库：**[GitHub - wangyu-ustc/MemoryLLM: The official implementation of the ICML 2024 paper &#34;MemoryLLM: Towar](https://github.com/wangyu-ustc/MemoryLLM)
* **开源模型：**[https://huggingface.co/YuWangX](https://huggingface.co/YuWangX)

#### [人大高瓴-华为诺亚：大语言模型智能体记忆机制的系列研究](https://mp.weixin.qq.com/s/n_oc7X1cZ1vGwPWhXpLUjA)

20250808｜Memory+Agent：人大高瓴人工智能学院与华为诺亚方舟实验室聚焦大语言模型智能体的记忆能力，在该领域形成了一套完整的包括综述论文、数据集和工具包的研究体系，致力于推动该领域的发展。

1. 论文标题： A Survey on the Memory Mechanism of Large Language Model based Agents
   1. 论文链接： [https://dl.acm.org/doi/10.1145/3748302](https://dl.acm.org/doi/10.1145/3748302)
2. 论文标题： MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants
   1. 论文链接： [https://arxiv.org/abs/2409.20163](https://arxiv.org/abs/2409.20163)
3. 论文标题： MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents
   1. 论文链接： [https://arxiv.org/abs/2506.21605](https://arxiv.org/abs/2506.21605)
4. [论文标题： MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents](https://arxiv.org/abs/2506.21605)
   1. 论文链接：[https://dl.acm.org/doi/10.1145/3701716.3715299](https://dl.acm.org/doi/10.1145/3701716.3715299)
