+++
title = '应用'
date = 2025-08-12T00:00:00+08:00
draft = false
toc = true
+++

# 应用

## 社会学研究

### 辩论

1. 2025-07-03 11:37:35 Thursday ｜

**[LLM 中理解和说服之间的细线](https://papers.cool/arxiv/2507.01936)** **[PDF()]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [Adrian de Wynter](https://arxiv.org/search/?searchtype=author&query=Adrian%20de%20Wynter), [Tangming Yuan](https://arxiv.org/search/?searchtype=author&query=Tangming%20Yuan)

大型语言模型 （LLM） 在维护高层次、令人信服的对话方面非常出色。它们正在被快速部署为敏感领域的聊天机器人和评估器，例如同行评审和心理健康应用程序。这一点，以及关于他们推理能力的不同描述，需要对 LLM 及其对对话的理解进行更仔细的检查。在这项工作中，我们首先评估了 LLM 维持辩论的能力——这是人类交流的最纯粹但最复杂的形式之一。然后我们衡量这种能力如何与他们对所谈论内容的理解相关，即他们对对话结构和语用上下文的理解。我们发现 LLM 能够保持连贯、有说服力的辩论，经常动摇参与者和听众的信念。我们还注意到，对 AI 参与的认识或怀疑会鼓励人们对所提出的论点持更多批评态度。然而，当对 LLM 进行民意调查时，他们无法证明这种理解。我们的研究结果将 LLM 作为评估者的缺点与他们理解上下文的（不）能力联系起来。更广泛地说，对于论证论领域，我们假设，如果一个代理人能够令人信服地维持对话，那么它就没有必要知道它在说什么。因此，语用背景和连贯性的建模是次于有效性的。

 **科目** :  **[计算和语言](https://papers.cool/arxiv/cs.CL)** , [计算机与社会](https://papers.cool/arxiv/cs.CY)

### 决策

3. 2025-07-03 11:38:51 Thursday ｜

 **[面向决策的文本评估](https://papers.cool/arxiv/2507.01923)** **[PDF()]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [Yu-Shiang Huang](https://arxiv.org/search/?searchtype=author&query=Yu-Shiang%20Huang), [Chuan-Ju Wang](https://arxiv.org/search/?searchtype=author&query=Chuan-Ju%20Wang), [Chung-Chi Chen](https://arxiv.org/search/?searchtype=author&query=Chung-Chi%20Chen)

自然语言生成 （NLG） 越来越多地部署在高风险领域，但常见的内在评估方法，如 n-gram 重叠或句子合理性，与实际决策效率的相关性很弱。我们提出了一个以决策为导向的框架，通过直接测量其对人类和大型语言模型 （LLM） 决策结果的影响来评估生成的文本。使用市场摘要文本（包括客观的早间总结和主观的收盘钟分析）作为测试案例，我们根据人类投资者和独立 LLM 代理人执行的交易的财务表现来评估决策质量，这些交易仅由这些文本提供信息。我们的研究结果表明，当仅依赖摘要时，人类和 LLM 代理都没有始终超过随机性能。然而，更丰富的分析评论使协作的人类 LLM 团队能够显著优于个人人类或代理基线。我们的方法强调了通过促进人类和 LLM 之间协同决策的能力来评估生成文本的重要性，突出了传统内在指标的关键局限性。

 **主题** : **[计算和语言](https://papers.cool/arxiv/cs.CL)**


## 选型

3. 2025-06-19 20:07:43 Thursday ｜ 告别玄学选LLM！弗吉尼亚理工选型框架入选ICML 2025 https://mp.weixin.qq.com/s/JTXjazJ8KRCURggbfTjNIA

来自弗吉尼亚理工大学的研究人员推出了个选型框架 **LensLLM** ——

大幅提升选型效果的同时，成本却降低近90%。

LensLLM的理论基础来自一项 **全新的PAC-Bayes泛化界限推导** ，首次从数学上揭示了LLM在不同数据规模下微调表现的 **非线性变化规律** ，

研究团队构建了一个基于 **神经切线核（NTK）增强的缩放律模型** ，能够在只微调极少量数据的前提下：

* 精确拟合整个微调曲线（如图2和表2所示）
* 预测最终测试性能
* 排出最优模型排名


## 时序

4. 2025-06-30 17:59:43 Monday ｜ 航空发动机用上大模型：解决复杂时序问题，性能超越ChatGPT-4o实现SOTA｜上交创智复旦 https://mp.weixin.qq.com/s/DzOOT8ojdd2zTeS3IpYcug
5. 2025-06-23 12:50:53 Monday ｜ 首个「万亿级时间点」预训练，清华发布生成式时序大模型日晷 | ICML Oral https://mp.weixin.qq.com/s/y3sc2e2lmW1sqfnoK-ZdDA




## 提示工程


2025-06-24 13:38:50 Tuesday｜

RiOT: Efficient Prompt Refinement with Residual Optimization Tree
**链接** ：https://arxiv.org/abs/2506.16389

 **作者** ：ou, Zhengyan Shi, Yuan Yao, Lei Liang, Huajun Chen, Qiang Zhang
 **摘要** ：大型语言模型（LLM）的最新进展突出了它们在各种任务中的潜力，但它们的性能仍然严重依赖于有效提示的设计。现有的自动提示优化方法面临两个挑战：缺乏多样性，限制了对有价值和创新方向的探索，以及语义漂移，其中对一个任务的优化可能会降低其他任务的性能。为了解决这些问题，我们提出了残差优化树（RiOT），一种新的自动提示优化框架。RiOT通过文本梯度迭代地细化提示，在每一步生成多个语义不同的候选项，并使用困惑度选择最佳提示。此外，RiOT结合了文本剩余连接，通过在优化迭代中选择性地保留有益内容来减轻语义漂移。树结构有效地管理优化过程，确保可扩展性和灵活性。在五个基准测试中进行了广泛的实验，涵盖常识，数学，逻辑，时间和语义推理，证明RiOT优于以前的提示优化方法和手动提示。

2. 2025-06-25 10:42:37 Wednesday  ｜ LLM进入「拖拽时代」！只靠Prompt，几秒定制一个大模型，效率飙升12000倍 https://mp.weixin.qq.com/s/geOn7zyJRQwfJra38EjcxQ

DnD是一种基于提示词的参数生成器，能够对LLM进行无需训练的自适应微调。

通过一个轻量级文本编码器与一个级联超卷积解码器的组合，DnD能在数秒内，仅根据无标签的任务提示词，生成针对该任务的LoRA权重矩阵。

总结来说，DnD的核心优势如下：

* **极致效率：** 其计算开销比传统的全量微调低12,000倍。
* **卓越性能：** 在零样本学习的常识推理、数学、编码及多模态基准测试中，其性能比最强大的、需要训练的LoRA模型还要高出30%。
* **强大泛化：** 仅需无标签的提示词，即可在不同领域间展现出强大的泛化能力


## RAG

6. 2025-06-27 13:34:29 Friday ｜ 全模态RAG突破文本局限，港大构建跨模态一体化系统 https://mp.weixin.qq.com/s/lFKyKvm0luZTpx8_nGyWEw

https://mp.weixin.qq.com/s/VuowC1hvE3P4RxIfYDZlLA

突破传统检索增强生成（RAG）技术的单一文本局限，实现对文档中文字、图表、表格、公式等复杂内容的统一智能理解。

香港大学黄超教授团队开源多模态智能处理系统RAG-Anything，将碎片化的信息孤岛转化为结构化的知识网络，为智能多模态文档分析开辟了全新技术路径。


## 情感&情绪

2025-06-28 17:43:13 Saturday Anthropic最新研究：Claude正悄悄进化为“情绪价值大师” https://mp.weixin.qq.com/s/mGEbAVCSWZjydrwwOouzOA

## 深度研究

2025-07-03 11:40:31 Thursday ｜

**[AI4Research：人工智能对科学研究的调查](https://papers.cool/arxiv/2507.01903)** **[PDF(3)]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [Qiguang Chen](https://arxiv.org/search/?searchtype=author&query=Qiguang%20Chen), [Mingda Yang](https://arxiv.org/search/?searchtype=author&query=Mingda%20Yang), [Libo Qin](https://arxiv.org/search/?searchtype=author&query=Libo%20Qin), [Jinhao Liu](https://arxiv.org/search/?searchtype=author&query=Jinhao%20Liu), [Zheng Yan](https://arxiv.org/search/?searchtype=author&query=Zheng%20Yan), [Jiannan Guan](https://arxiv.org/search/?searchtype=author&query=Jiannan%20Guan), [Dengyun Peng](https://arxiv.org/search/?searchtype=author&query=Dengyun%20Peng), [Yiyan Ji](https://arxiv.org/search/?searchtype=author&query=Yiyan%20Ji), [Hanjing Li](https://arxiv.org/search/?searchtype=author&query=Hanjing%20Li), [Mengkang Hu](https://arxiv.org/search/?searchtype=author&query=Mengkang%20Hu), [Yimeng Zhang](https://arxiv.org/search/?searchtype=author&query=Yimeng%20Zhang), [Yihao Liang](https://arxiv.org/search/?searchtype=author&query=Yihao%20Liang), [Yuhang Zhou](https://arxiv.org/search/?searchtype=author&query=Yuhang%20Zhou), [Jiaqi Wang](https://arxiv.org/search/?searchtype=author&query=Jiaqi%20Wang), [Zhi Chen](https://arxiv.org/search/?searchtype=author&query=Zhi%20Chen), [Wanxiang Che](https://arxiv.org/search/?searchtype=author&query=Wanxiang%20Che)

人工智能 （AI） 的最新进展，特别是在 OpenAI-o1 和 DeepSeek-R1 等大型语言模型 （LLM） 方面，在逻辑推理和实验编码等复杂领域展示了卓越的能力。在这些进步的推动下，许多研究探索了人工智能在创新过程中的应用，特别是在科学研究的背景下。这些 AI 技术的主要目的是开发能够在广泛的科学学科中自主进行研究过程的系统。尽管取得了这些重大进展，但仍然缺乏对人工智能研究 （AI4Research） 的全面调查，这阻碍了我们的理解并阻碍了该领域的进一步发展。为了解决这一差距，我们提出了一项全面的调查，并提供了关于 AI4Research 的统一观点。具体来说，我们工作的主要贡献如下：（1） 系统分类法：我们首先引入了系统分类法，对 AI4Research 中的五个主流任务进行分类。（2） 新前沿：然后，我们确定关键的研究差距并突出有希望的未来方向，重点关注自动化实验的严谨性和可扩展性，以及社会影响。（3） 丰富的应用程序和资源：最后，我们编译了丰富的资源，包括相关的多学科应用程序、数据语料库和工具。我们希望我们的工作能够为研究界提供快速访问这些资源的途径，并激发 AI4Research 的创新突破。

 **科目** :  **[计算和语言](https://papers.cool/arxiv/cs.CL)** , [人工智能](https://papers.cool/arxiv/cs.AI)

 **发布** ： 2025-07-02 17：19：20 UTC

2. 2025-06-27 13:40:46 Friday ｜ 北大发布学术搜索评测ScholarSearch：难倒一众DeepResearch的“开卷考试” https://mp.weixin.qq.com/s/avGM6aB5aQcn6w5sKnZdKA

OpenAI的Deep Research、Grok的DeepSearch、Gemini的Deep Research以及月之暗面的Kimi-Researcher等，以“深度搜索”功能为核心，为攻克高难度信息检索任务提供了新的范式。

3. 2025-06-16 12:10:08 Monday ｜

DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents
 **标题** ： 深度研究平台：深度研究代理的全面基准
 **链接** ：https://arxiv.org/abs/2506.11763

 **作者** ： Mingxuan Du,  Benfeng Xu,  Chiwei Zhu,  Xiaorui Wang,  Zhendong Mao
 **备注** ：31 pages, 5 figures
 **摘要** ：深度研究代理是基于LLM的代理的突出类别。通过自动编排多步骤的网络探索、目标检索和高阶综合，他们将大量的在线信息转化为分析师级的、引用丰富的报告--将数小时的手动桌面研究压缩为几分钟。然而，仍然没有一个全面的基准来系统地评价这些代理人的能力。为了弥合这一差距，我们提出了DeepResearch Bench，这是一个由100个博士级研究任务组成的基准，每个任务都由22个不同领域的领域专家精心制作。评估DRA本质上是复杂和劳动密集型的。因此，我们提出了两种新的方法，实现与人类判断的强烈一致。第一种是基于参考文献的方法，采用自适应标准来评估生成的研究报告的质量。另一个框架是通过评估其有效引用计数和整体引用准确性来评估图书馆的信息检索和收集能力。我们在https://github.com/Ayanami0730/deep_research_bench上拥有开源的DeepResearch Bench和这些框架的关键组件，以加速实用的基于法学硕士的代理的开发。

#### [季峰陈天桥联手AGI首秀炸场！最强开源深度研究模型，GAIA测试82.4分超OpenAI](https://mp.weixin.qq.com/s/VHR2vxmuHlTc6H4xzTxH_A)

1. MiroMind ODR（Open Deep Research），来自代季峰加盟陈天桥的技术首秀。
2. 它是真·全开源可复现，它的核心模型、数据、训练流程、AI Infra、DR Agent框架统统开源。
3. 与现有的深度研究方法相比，MiroMind ODR项目开放了深度研究的各个阶段，包括四个子项目：MiroFlow（Agent框架）、MiroThinker（模型）、MiroVerse（数据）和MiroTrain（训练基础设施）。

   1. **MiroFlow** ，支持多种主流工具调用，扩展大语言模型，支持工具辅助的深度研究推理。它的亮点在于可以稳定复现最强性能，也就是GAIA上82.4的成绩。
   2. **MiroThinker** ，原生支持工具辅助推理的大语言模型，可训练、可复现，在 GAIA 中表现最佳。
   3. **MiroVerse** ，147K开源训练数据支持深度研究训练。此外团队还会关注社区反馈，每月持续提供高质量、深入的研究数据集。
   4. **MiroTrain** ，支持深度研究模型的稳定高效训练，覆盖整个Deep Research训练流程，支持长文本训练和RL训练工具。
4. MiroMind-M1是一系列基于Qwen-2.5 完全开源推理语言模型，专注于提升数学推理能力。

   1. 该模型通过监督式微调（SFT）在 719K 个精心筛选的问题集上进行训练，并采用可验证奖励的强化学习（RLVR）在 62K 个具有挑战性的示例上进行优化，使用了基于上下文的多阶段策略优化方法（CAMPO）。
2. Blog: https://miromind.ai/blog/miromind-open-deep-research
   Demo: https://dr.miromind.ai/
   GitHub: https://github.com/MiroMindAI
   Hugging Face: https://huggingface.co/miromind-ai


## 生物


1. 2025-06-27 13:42:36 Friday ｜ Deepmind突破性生物模型**AlphaGenome  **https://mp.weixin.qq.com/s/fhsKbgoPFuJ_2IInt_Q-tQ

谷歌DeepMind重磅发布AlphaGenome——一款革命性的AI工具，以及103页的详细技术报告。

论文地址：https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/

2. 2025-07-02 15:21:56 Wednesday ｜ 诺奖得主Hassabis预言成真！AI零样本发现新抗体，轰动整个医药圈 https://mp.weixin.qq.com/s/yOd6_Qn6mlVqfRDkdS_eyw

Chai-2的重磅发布，意味着：在今年年底，AI设计药物有望进入临床试验。

#### [蛋白质基座的GPT时代来了？！](https://mp.weixin.qq.com/s/WmGTYPO9gTm2XJ-Rjqvm-Q)

1. 清华大学智能产业研究院（AIR）周浩副教授课题组联合上海人工智能实验室发布了 **AMix-1** ：首次以**Scaling Law、Emergent Ability、In-Context Learning和Test-time Scaling的系统化方法论**来构建蛋白质基座模型。
2. AMix-1是 **基于贝叶斯流网络** （Bayesian Flow Networks, BFNs）的蛋白质基座新范式，为蛋白质基座模型实现Test-time Scaling提供了一整套系统性的技术方案
3. 技术报告：https://arxiv.org/pdf/2507.08920
   项目主页：https://gensi-thuair.github.io/AMix-1/
   模型权重：https://huggingface.co/GenSI/AMix-1-1.7B
   代码仓库：https://github.com/GenSI-THUAIR/AMix-1
4. 虚拟生物实验室：https://virtualbiolab.intern-ai.org.cn/

## 医疗

1. [让OpenAI只领先5天，百川发布推理新模型，掀翻医疗垂域开源天花板](https://mp.weixin.qq.com/s/YCfbNgiGGwzmUnrWSEY8zw)

   1. 百川开源最新医疗推理大模型 **Baichuan-M2-32B** ，在OpenAI发布的Healthbench评测集上，超越其刚刚发布5天的开源模型gpt-oss-120b。
   2. HealthBench是由OpenAI今年发布的一个医疗健康领域评估测试集，数据集中包含5000条多轮对话，模拟模型与个人用户或医疗专业人士之间的真实交流。这些对话跨越多语言、多背景（如急诊、临床数据解读、全球健康等）。
      1. 每段对话配有由262名医生（来自60个国家）撰写的具体评价准则，一共涉及48562条特点明确的标题标准（rubric criteria）。评分不仅涵盖医学准确性，还包括指令遵从、沟通能力等行为维度。
   3. 创新性提出了 **患者模拟器和Verifier系统** 。核心基于一个大型的Verifier系统，能够从真实存在的医疗问题出发，进行端到端强化学习训练，能够在保持模型通用能力同时大幅提升医疗领域表现。
   4. Blog：https://www.baichuan-ai.com/blog/baichuan-M2

## 预测

10. 2025-06-30 19:59:32 Monday ｜

**[面向未来的基准：预测代理的 Pastcasting 基准](https://papers.cool/arxiv/2506.21558)** **[PDF()]** **[Copy]** **[Kimi()]** **[REL]**

 **Authors** : [FutureSearch](https://arxiv.org/search/?searchtype=author&query=FutureSearch): [Jack Wildman](https://arxiv.org/search/?searchtype=author&query=Jack%20Wildman), [Nikos I. Bosse](https://arxiv.org/search/?searchtype=author&query=Nikos%20I.%20Bosse), [Daniel Hnyk](https://arxiv.org/search/?searchtype=author&query=Daniel%20Hnyk), [Peter Mühlbacher](https://arxiv.org/search/?searchtype=author&query=Peter%20M%C3%BChlbacher), [Finn Hambly](https://arxiv.org/search/?searchtype=author&query=Finn%20Hambly), [Jon Evans](https://arxiv.org/search/?searchtype=author&query=Jon%20Evans), [Dan Schwarz](https://arxiv.org/search/?searchtype=author&query=Dan%20Schwarz), [Lawrence Phillips](https://arxiv.org/search/?searchtype=author&query=Lawrence%20Phillips)

预测是一项具有挑战性的任务，它为研究 AI 系统提供了一种明确可衡量的方法。预测需要在互联网上进行大量研究，而评估需要时间让事件发生，这使得预测基准的开发具有挑战性。迄今为止，还没有预测基准为 LLM 预测者提供真实、封闭和可重复的环境。我们介绍了 Bench To the Future （BTF），这是一个“pastcasting”基准测试，其中包含数百个高质量的问题，其解决方案已经已知。每个问题都伴随着一个包含数万个相关网页的大型离线语料库，从而能够从 LLM 中得出对过去事件的现实“预测”。结果表明，我们的过去广播环境可以产生与基于使用互联网对当时未解决的问题的预测的结果相当的结果。我们使用多个 LLM（包括最近发布的 Claude 4 模型）展示了对代理和思维链预测方法的结果，并展示了 BTF 随着时间的推移跟踪稳定预测能力进展的能力。我们打算将其作为一个活的基准，不断添加新问题，以解决不断增加的训练数据截止日期的问题。我们邀请研究人员通过 hello@futuresearch.ai 与我们联系，以利用我们的基准测试或工具进行自己的研究。

 **科目** :  **[计算和语言](https://papers.cool/arxiv/cs.CL)** , [人工智能](https://papers.cool/arxiv/cs.AI), [机器学习](https://papers.cool/arxiv/cs.LG)

 **发布** ： 2025-06-11 16：18：40 UTC
