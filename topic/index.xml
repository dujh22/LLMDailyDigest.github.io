<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Topics on LLM-DailyDigest</title>
    <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/</link>
    <description>Recent content in Topics on LLM-DailyDigest</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 07 Aug 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="https://dujh22.github.io/LLMDailyDigest.github.io/topic/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SWE 软件工程</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/</guid>
      <description>&lt;h1 id=&#34;swe-软件工程&#34;&gt;SWE 软件工程&lt;/h1&gt;&#xA;&lt;h1 id=&#34;总览&#34;&gt;总览&lt;/h1&gt;&#xA;&lt;p&gt;2025-06-23 11:46:23 Monday ｜ Amazon Q Developer &lt;a href=&#34;https://mp.weixin.qq.com/s/8JfR11MUxZneJBDnLDCX_g&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/8JfR11MUxZneJBDnLDCX_g&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;250609｜SWE-Flow：以测试驱动方式合成软件工程数据&lt;/p&gt;&#xA;&lt;p&gt;250607｜SWE-Dev：构建具备训练与推理扩展能力的软件工程智能体&lt;/p&gt;&#xA;&lt;p&gt;250516｜SWE-Dev：评估与训练自主功能驱动的软件开发&lt;/p&gt;&#xA;&lt;h1 id=&#34;概念&#34;&gt;概念&lt;/h1&gt;&#xA;&lt;h2 id=&#34;软件开发方法论&#34;&gt;软件开发方法论&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;by豆包&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;是指导软件开发过程的哲学和实践框架，它们各有侧重，适用于不同的项目需求和团队文化。&lt;/p&gt;&#xA;&lt;p&gt;以下是对主流方法论的系统整理，包括核心特点、适用场景和典型工具：&lt;/p&gt;&#xA;&lt;h3 id=&#34;一敏捷开发agile-development&#34;&gt;&lt;strong&gt;一、敏捷开发（Agile Development）&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt; ：快速迭代、客户反馈、团队协作，应对需求变化。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;典型方法&lt;/strong&gt; ：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scrum&lt;/strong&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt; ：通过短周期迭代（Sprint）、每日站会、产品待办列表（Backlog）管理项目。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;角色&lt;/strong&gt; ：产品负责人（Product Owner）、Scrum Master、开发团队。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;工具&lt;/strong&gt; ：Jira、Trello、Azure DevOps。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Kanban&lt;/strong&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt; ：可视化工作流程（看板），限制在制品（WIP），持续交付。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;适用场景&lt;/strong&gt; ：需求稳定、流程明确的项目。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;工具&lt;/strong&gt; ：Notion、Monday.com、GitHub Projects。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;极限编程（XP, Extreme Programming）&lt;/strong&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt; ：结对编程、测试驱动开发（TDD）、持续集成、现场客户。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;实践&lt;/strong&gt; ：小型发布、简单设计、重构、集体代码所有权。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;二测试驱动开发tdd-test-driven-development&#34;&gt;&lt;strong&gt;二、测试驱动开发（TDD, Test-Driven Development）&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt; ：先写测试，再实现代码，最后优化（红-绿-重构）。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;流程&lt;/strong&gt; ：&lt;/p&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;编写测试用例&lt;/strong&gt; （失败状态）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;实现功能代码&lt;/strong&gt; （使测试通过）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;重构代码&lt;/strong&gt; （优化结构，保持测试通过）。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;工具&lt;/strong&gt; ：JUnit（Java）、PyTest（Python）、Jest（JavaScript）。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt; ：对质量要求高、需要频繁重构的项目。&lt;/p&gt;&#xA;&lt;h3 id=&#34;三行为驱动开发bdd-behavior-driven-development&#34;&gt;&lt;strong&gt;三、行为驱动开发（BDD, Behavior-Driven Development）&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt; ：以用户行为为中心，通过自然语言描述需求（Gherkin 语法）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>元</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%85%83/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%85%83/</guid>
      <description>&lt;h1 id=&#34;元&#34;&gt;元&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;2025-06-12 12:05:13 Thursday｜ Large Language Models Have Intrinsic Meta-Cognition, but Need a Good  Lens&#xA;&lt;strong&gt;标题&lt;/strong&gt; ： 大型语言模型具有内在的元认知，但需要良好的镜头&#xA;&lt;strong&gt;链接&lt;/strong&gt; ：https://arxiv.org/abs/2506.08410&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;作者&lt;/strong&gt; ： Ziyang Ma,  Qingyue Yuan,  Zhenglin Wang,  Deyu Zhou&#xA;&lt;strong&gt;备注&lt;/strong&gt; ：Preprint&#xA;&lt;strong&gt;摘要&lt;/strong&gt; ：以前的研究主要集中在大型语言模型（LLM）的认知错误检测能力上，通常会促使它们分析推理链中的错误。然而，很少有研究考察LLM的&lt;strong&gt;元认知&lt;/strong&gt;能力（例如，他们的自我意识的步骤错误），这是至关重要的，他们的可靠性。尽管对LLM自我评价的研究提出了&lt;strong&gt;困惑度&lt;/strong&gt;等能够反映答案正确性的测量指标，并将其作为元认知的透镜，但缺乏对LLM自我评价的步骤分析和适应性研究。本文研究了如何用现有的评价方法来评价法学硕士元认知，以及如何改进这些评价方法。具体来说，我们提出了AutoMeco，一个 &lt;strong&gt;自动化的元认知评估框架&lt;/strong&gt; ，用于对现有的镜头进行基准测试。此外，提出了一种无需训练的马尔可夫内在奖励调整策略MIRA，以提高当前的元认知镜头。在三个数学推理数据集和三个LLM上的实验结果表明，AutoMeco验证方法与Best-of-N验证方法相比具有一定的合理性。此外，MIRA可以更好地评估LLM的元认知能力。&lt;/p&gt;&#xA;&lt;h2 id=&#34;认知能力&#34;&gt;认知能力&lt;/h2&gt;&#xA;&lt;p&gt;2025-06-30 19:58:27 Monday ｜&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://papers.cool/arxiv/2506.21571&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;了解大型推理模型的认知习惯&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;[PDF()]&lt;/strong&gt; &lt;strong&gt;[Copy]&lt;/strong&gt; &lt;strong&gt;[Kimi(2)]&lt;/strong&gt; &lt;strong&gt;[REL]&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt; : &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Jianshuo%20Dong&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Jianshuo Dong&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Yujia%20Fu&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Yujia Fu&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Chuanrui%20Hu&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Chuanrui Hu&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Chao%20Zhang&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Han%20Qiu&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Han Qiu&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>博弈 Self-Play</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%8D%9A%E5%BC%88/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%8D%9A%E5%BC%88/</guid>
      <description>&lt;h1 id=&#34;博弈-self-play&#34;&gt;博弈 Self-Play&lt;/h1&gt;&#xA;&lt;h2 id=&#34;强化学习&#34;&gt;强化学习&lt;/h2&gt;&#xA;&lt;h4 id=&#34;spiral零和游戏自对弈成为语言模型推理训练的免费午餐&#34;&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/jAaM3hD46gFEFGFJdLVVJg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;SPIRAL：零和游戏自对弈成为语言模型推理训练的「免费午餐」&lt;/a&gt;&lt;/h4&gt;&#xA;&lt;p&gt;2025-08-05&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;研究方向为可扩展的自主提升，致力于构建能在未知环境中智能决策的自主智能体&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;通过基于结果的奖励机制，强化学习使模型能够发展出可泛化的推理策略，在复杂问题上取得了监督微调难以企及的进展。&lt;/li&gt;&#xA;&lt;li&gt;本文通过让模型在零和游戏中与自己对弈，自主发现并强化可泛化的推理模式，完全摆脱了对人工监督的依赖。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;论文标题：&lt;/strong&gt; SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning&lt;/li&gt;&#xA;&lt;li&gt;论文链接：https://huggingface.co/papers/2506.24119&lt;/li&gt;&#xA;&lt;li&gt;代码链接：https://github.com/spiral-rl/spiral&lt;/li&gt;&#xA;&lt;li&gt;研究团队的核心洞察是：如果强化学习能够从预训练语言模型中选择出可泛化的思维链（Chain-of-Thought, CoT）模式，那么游戏为这一过程提供了完美的&lt;strong&gt;试炼场&lt;/strong&gt;：它们通过输赢结果提供廉价、可验证的奖励，无需人工标注。通过在这些游戏上进行自对弈，强化学习能够自动发现哪些 CoT 模式在多样化的竞争场景中获得成功，并逐步强化这些模式，创造了一个自主的推理能力提升系统。&lt;/li&gt;&#xA;&lt;li&gt;实验发现，不同游戏确实培养了专门化的认知能力：&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;井字棋专家在空间推理游戏 Snake 上达到 56% 胜率。&lt;/li&gt;&#xA;&lt;li&gt;库恩扑克大师在概率游戏 Pig Dice 上取得惊人的 91.7% 胜率。&lt;/li&gt;&#xA;&lt;li&gt;简单谈判专家在战略优化游戏上表现出色。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ol start=&#34;9&#34;&gt;&#xA;&lt;li&gt;更有趣的是，当结合多个游戏训练时，技能产生协同效应。&lt;/li&gt;&#xA;&lt;li&gt;SPIRAL 验证了一个关键假设：预训练模型中已经包含了各种推理模式，强化学习的作用是从这些模式中筛选和强化那些真正可泛化的思维链。&lt;/li&gt;&#xA;&lt;li&gt;未来的研究开辟了新方向：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;混合博弈类型：结合零和、合作和混合动机游戏，可能培养更全面的推理能力。&lt;/li&gt;&#xA;&lt;li&gt;元游戏学习：让模型不仅玩游戏，还能创造新游戏，实现真正的创造性推理。&lt;/li&gt;&#xA;&lt;li&gt;跨模态游戏：将语言游戏扩展到包含视觉、音频等多模态信息，培养更丰富的认知能力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;主动学习&#34;&gt;主动学习&lt;/h2&gt;&#xA;&lt;h4 id=&#34;atgen主动文本生成框架&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://papers.cool/arxiv/2506.23342&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;ATGen：主动文本生成框架&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt;&#xA;&lt;p&gt;2025-07-01 12:04:39 Tuesday&lt;/p&gt;&#xA;&lt;p&gt;主动学习 （AL） 在减少训练机器学习模型所需的注释工作方面表现出了巨大的潜力。然而，尽管近年来自然语言生成 （NLG） 任务的普及率飙升，但 AL 在 NLG 中的应用一直受到限制。在本文中，我们介绍了主动文本生成 （ATGen） - 一个将 AL 与文本生成任务联系起来的综合框架，能够将最先进的 AL 策略应用于 NLG。我们的框架使用人工注释器和基于大型语言模型 （LLM） 的自动注释代理简化了 NLG 任务中 AL 授权的注释。该框架支持作为服务（如 ChatGPT 和 Claude）部署的 LLM，或在本地运行的 LLM。此外，ATGen 提供了一个统一的平台，用于顺利实施和对针对 NLG 任务量身定制的新型 AL 策略进行基准测试。最后，我们介绍了跨不同设置和多个文本生成任务的最新 AL 策略的评估结果。我们表明，ATGen 减少了人工注释者的工作量和与对基于 LLM 的注释代理的 API 调用相关的成本。该框架的代码可在 GitHub 上根据 MIT 许可证获得。视频演示可在 &lt;a href=&#34;http://atgen-video.nlpresearch.group&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;http://atgen-video.nlpresearch.group&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>工具</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%B7%A5%E5%85%B7/</guid>
      <description>&lt;h1 id=&#34;工具&#34;&gt;工具&lt;/h1&gt;&#xA;&lt;h2 id=&#34;效率工具&#34;&gt;效率工具&lt;/h2&gt;&#xA;&lt;h3 id=&#34;ai校验&#34;&gt;AI校验&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. Binoculars&lt;/strong&gt;这一MGT（机器生成文本）检测器&lt;/p&gt;&#xA;&lt;h3 id=&#34;学习用资料&#34;&gt;学习用资料&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;**Lean 中文文档翻译  **&lt;strong&gt;&lt;a href=&#34;https://github.com/Lean-zh&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Lean-zh&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;2025-06-11 17:37:53 Wednesday | 提示词自动优化网站 &lt;a href=&#34;https://mp.weixin.qq.com/s/Y0X3z-ARRcPgEDCZffiNfg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/Y0X3z-ARRcPgEDCZffiNfg&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;agent工具&#34;&gt;Agent工具&lt;/h3&gt;&#xA;&lt;p&gt;2025-07-18 14:11:00 Friday ｜ 刚刚，OpenAI通用智能体ChatGPT Agent正式登场 &lt;a href=&#34;https://mp.weixin.qq.com/s/4xJGBr1dXdIPHgSrPpwW5w&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/4xJGBr1dXdIPHgSrPpwW5w&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;kimi-dev&lt;/p&gt;&#xA;&lt;p&gt;2025-06-30 16:07:47 Monday ｜ 初创公司 Cluely，推出了名为「Cluely」的 AI 工具，旨在为用户提供面试、考试、销售电话等场景的实时辅助https://mp.weixin.qq.com/s/58taCee98HkAxUHTgIWkUA&lt;/p&gt;&#xA;&lt;p&gt;2025-06-28 18:39:39 Saturday ｜ 不靠Agent，4步修复真Bug！蚂蚁CGM登顶SWE-Bench开源榜 &lt;a href=&#34;https://mp.weixin.qq.com/s/fbKB3Y1F4yZbv_mGDVep2g&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/fbKB3Y1F4yZbv_mGDVep2g&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;蚂蚁集团另辟蹊径，给出一个完全不同的新解法：**代码图模型 CGM（ Code Graph Model ） **&lt;/li&gt;&#xA;&lt;li&gt;论文：https://arxiv.org/abs/2505.16901&lt;/li&gt;&#xA;&lt;li&gt;模型：https://huggingface.co/codefuse-ai/CodeFuse-CGM-72B&lt;/li&gt;&#xA;&lt;li&gt;代码：https://github.com/codefuse-ai/CodeFuse-CGM&lt;/li&gt;&#xA;&lt;li&gt;数据：https://huggingface.co/datasets/codefuse-ai/CodeGraph&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;2025-06-28 16:54:14 Saturday ｜ 阿里发布信息检索Agent-WebDancer，可自主上网查资料，GAIA基准超越GPT-4o | 模型&amp;amp;数据开源 &lt;a href=&#34;https://mp.weixin.qq.com/s/LETDaeU96OV-beuoCuJHHQ&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/LETDaeU96OV-beuoCuJHHQ&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;2025-06-26 14:25:53 Thursday｜ Gemini CLI 开源+免费https://mp.weixin.qq.com/s/370Vt6Ly_2kLuyBUJ7vfIw&lt;/p&gt;</description>
    </item>
    <item>
      <title>强化学习</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;h1 id=&#34;强化学习&#34;&gt;强化学习&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;2025-07-18 20:24:54 Friday ｜ 真相大白！RL不是魔法，随机奖励有效只是由于数据泄露！ &lt;a href=&#34;https://mp.weixin.qq.com/s/J7dzjfHMHyvQNpKQFpoq7w&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/J7dzjfHMHyvQNpKQFpoq7w&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;🌈 2025-07-18 14:07:23 Friday｜强化学习的两个「大坑」，终于被两篇ICLR论文给解决了 &lt;a href=&#34;https://mp.weixin.qq.com/s/myqak4eAAQ7ONKJKOFxk8g&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/myqak4eAAQ7ONKJKOFxk8g&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;2025-07-17 10:59:26 Thursday ｜ 字节跳动Seed最新强化学习配方POLARIS开源 4B 模型数学推理接近 235B 表现&lt;/li&gt;&#xA;&lt;li&gt;2025-06-30 19:00:34 Monday ｜ 强化学习也能预训练？效果可提升20倍，华人新作引爆RL新范式! &lt;a href=&#34;https://mp.weixin.qq.com/s/WyJuhjkmreZ2clSw1XvHiw&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/WyJuhjkmreZ2clSw1XvHiw&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;研究人员构建的模型将「意图」编码为潜在变量，并通过「流匹配」（flow matching）来预测未来状态的访问概率。&lt;/p&gt;&#xA;&lt;p&gt;论文地址：https://arxiv.org/abs/2506.08902&lt;/p&gt;&#xA;&lt;p&gt;博客地址：https://chongyi-zheng.github.io/infom/&lt;/p&gt;&#xA;&lt;p&gt;由于普通流匹配方法无法拼接多个状态转换，研究者引入基于SARSA的时序差分流匹配损失进行改进。&lt;/p&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;2025-06-24 11:28:01 Tuesday ｜ CPGD：只训练数学，却在物理化学生物战胜o1！新强化学习算法带来显著性能提升，还缓解训练崩溃问题 &lt;a href=&#34;https://mp.weixin.qq.com/s/RDUPagBn8l00P7dNPHjBcA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/RDUPagBn8l00P7dNPHjBcA&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;相比于传统GRPO、RLOO等算法显著缓解了训练不稳定（甚至崩溃）的问题，并带来显著性能提升。&lt;/p&gt;&#xA;&lt;p&gt;基于OpenRLHF，团队构建了一个高效、可扩展的多模态强化学习框架，支持Qwen-VL、InternVL等多种模型与RL算法，包括GRPO、REINFORCE++、RLOO，以及提出的新型RL算法CPGD，并已成功训练出Qwen2.5VL-32B、InternVL2.5-38B等大型模型。&lt;/p&gt;&#xA;&lt;p&gt;该框架相较于已有方案（如R1-V），具备更强的可扩展性与稳定性，为大规模多模态强化学习提供了基础设施支撑。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;开源代码：&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://github.com/ModalMinds/MM-EUREKA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/ModalMinds/MM-EUREKA&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://github.com/ModalMinds/MM-EUREKA/tree/mm-prm&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/ModalMinds/MM-EUREKA/tree/mm-prm&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;技术报告：&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2503.07365&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://arxiv.org/abs/2503.07365&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2505.12504&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://arxiv.org/abs/2505.12504&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2505.13427&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://arxiv.org/abs/2505.13427&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>推理</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%8E%A8%E7%90%86/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%8E%A8%E7%90%86/</guid>
      <description>&lt;h1 id=&#34;推理&#34;&gt;推理&lt;/h1&gt;&#xA;&lt;h2 id=&#34;一般推理&#34;&gt;一般推理&lt;/h2&gt;&#xA;&lt;p&gt;研究发现，只有用强化学习（RL）训练的模型才能将数学推理技能广泛迁移到其他任务上。而用监督微调（SFT）训练的模型则表现出有限的迁移甚至没有迁移。&lt;a href=&#34;https://mp.weixin.qq.com/s/L1vwB7Lj_JcvSfD7cQ5eSQ&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/L1vwB7Lj_JcvSfD7cQ5eSQ&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;数学题干带猫AI就不会了！错误率翻300%，DeepSeek、o1都不能幸免&lt;a href=&#34;https://mp.weixin.qq.com/s/qesEHt47UQNdjnryMLHwGA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/qesEHt47UQNdjnryMLHwGA&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;物理学家靠生物揭开AI创造力来源：起因竟是“技术缺陷”&lt;/strong&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s/Lmh2oX-h4xOOyKPeNjxJGg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/Lmh2oX-h4xOOyKPeNjxJGg&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;2025-06-30 19:09:50 Monday ｜&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://papers.cool/arxiv/2506.21609&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;从思考到输出：推理语言模型中的思维链和文本生成特征&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;[PDF(2)]&lt;/strong&gt; &lt;strong&gt;[Copy]&lt;/strong&gt; &lt;strong&gt;[Kimi(3)]&lt;/strong&gt; &lt;strong&gt;[REL]&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt; : &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Junhao%20Liu&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Junhao Liu&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Zhenhao%20Xu&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Zhenhao Xu&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Yuxin%20Fang&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Yuxin Fang&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Yichuan%20Chen&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Yichuan Chen&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Zuobin%20Ying&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Zuobin Ying&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Wenhan%20Chang&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Wenhan Chang&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;最近，大型语言模型 （LLM） 取得了显着进展，表明它们在复杂推理方面的能力不断增强。然而，现有的研究在很大程度上忽视了 &lt;strong&gt;对这些模型的推理过程和输出的彻底和系统的比较&lt;/strong&gt; ，特别是关于它们的自我反思模式（也称为“顿悟时刻”）和不同领域的相互联系。本文提出了一种新的框架，用于使用关键词统计和 LLM 作为判断范式分析四种尖端大型推理模型（GPT-o1、DeepSeek-R1、Kimi-k1.5 和 Grok-3）的推理特征。我们的方法将他们的内部思考过程与最终产出联系起来。多样化的数据集由基于真实场景的问题组成，涵盖逻辑推论、因果推理和多步骤问题解决。此外，还提出了一组指标来评估推理的连贯性和输出的准确性。研究结果揭示了这些模型如何在推理过程中平衡探索和开发、处理问题和得出结论的各种模式。通过定量和定性比较，确定了这些模型在推理深度、对中间步骤的依赖以及它们的思维过程和输出模式与 GPT-o1 的相似程度等方面的差异。这项工作为计算效率和推理鲁棒性之间的权衡提供了有价值的见解，并为在实际应用中加强模型设计和评估提供了实用建议。我们在以下位置公开发布我们的项目： &lt;a href=&#34;https://github.com/ChangWenhan/FromThinking2Output&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/ChangWenhan/FromThinking2Output&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;20250604｜新泛化跨领域推理框架：General-Reasoner &lt;a href=&#34;https://mp.weixin.qq.com/s/GDe5Dm17ekCCbUwKO475iA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/GDe5Dm17ekCCbUwKO475iA&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;2025-06-09 10:47:26 Monday ｜Unleashing the Reasoning Potential of Pre-trained LLMs by Critique  Fine-Tuning on One Problem&#xA;&lt;strong&gt;标题&lt;/strong&gt; ： 通过对一个问题的批评微调来释放预训练LLM的推理潜力&#xA;&lt;strong&gt;链接&lt;/strong&gt; ：https://arxiv.org/abs/2506.03295&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;作者&lt;/strong&gt; ： Yubo Wang,  Ping Nie,  Kai Zou,  Lijun Wu,  Wenhu Chen&#xA;&lt;strong&gt;摘要&lt;/strong&gt; ：我们已经见证了强大的LLM，如Qwen-Math，MiMo和Phi-4拥有从预训练阶段继承的巨大推理潜力。通过强化学习（RL），这些模型可以显着改善推理任务。最近的研究表明，即使是针对单个问题的强化学习也可以释放这些模型的推理能力。然而，RL不仅昂贵而且不稳定。即使是一次性的RL也需要数百个GPU小时。这就提出了一个关键问题：是否有更有效的方法来释放这些强大的基础LLM的推理潜力？在这项工作中，我们证明， &lt;strong&gt;批判微调（CFT）只有一个问题，可以有效地释放LLM的推理潜力&lt;/strong&gt; 。我们的方法通过收集不同的模型生成的解决方案，以一个单一的问题，并使用教师LLM提供详细的批评，构建批判数据。我们微调Qwen和Llama家族模型，从1.5B到14 B参数，在CFT数据上，并观察到在不同推理任务中的显着性能增益。例如，仅用5个GPU小时的训练，Qwen-Math-7 B-CFT在六个数学基准测试中平均提高了15%， &lt;strong&gt;在三个逻辑推理基准测试中平均提高了16%&lt;/strong&gt; 。这些结果与RL的结果相当，甚至超过RL的结果，但计算量减少了20倍。消融研究揭示了单次CFT在不同提示问题中的稳健性。这些结果突出了一次性CFT作为一种简单，通用和计算效率高的方法来释放现代LLM的推理能力。&lt;/p&gt;</description>
    </item>
    <item>
      <title>数据合成</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%95%B0%E6%8D%AE%E5%90%88%E6%88%90/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%95%B0%E6%8D%AE%E5%90%88%E6%88%90/</guid>
      <description>&lt;h1 id=&#34;数据合成&#34;&gt;&lt;strong&gt;数据合成&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;结语：合成任务的新时代&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;ViGaL 的成功揭示了一个潜在的新趋势：当高质量人类数据枯竭，简单任务性能饱和的时候，精心设计的游戏，作为一种合成任务，可能为多模态推理能力的发展开辟新道路。&lt;/p&gt;&#xA;&lt;p&gt;与传统的直接训练方法相比，这种游戏化的训练范式展现出独特的优势：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;成本极低：无需人工标注，可无限扩展&lt;/li&gt;&#xA;&lt;li&gt;效果显著：零数学样本超越数学专训模型&lt;/li&gt;&#xA;&lt;li&gt;拓展性强：可以组合多个任务进一步提升性能&lt;/li&gt;&#xA;&lt;li&gt;通用性好：不会造成 &amp;ldquo;偏科&amp;rdquo; 问题，保持模型的全面能力&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;更重要的是，ViGaL 可能揭示了一个朴素但深刻的道理：在直接学习目标任务之外，培养底层的通用推理能力，也许同样有助于模型性能的提升。就像我们不只是通过死记硬背数学公式来培养数学思维，而是通过各种思维训练来发展抽象推理能力一样。&lt;/p&gt;&#xA;&lt;p&gt;在 Scaling Law 可能逐渐面临困境的今天，ViGaL 用一个简单而优雅的想法提醒我们：有时候，让 AI&amp;quot;玩游戏&amp;quot; 可能比让它 &amp;ldquo;刷题&amp;rdquo; 更有效。&lt;/p&gt;&#xA;&lt;h1 id=&#34;通用框架&#34;&gt;通用框架&lt;/h1&gt;&#xA;&lt;h4 id=&#34;----synthetic-data-rl-task-definition-is-all-you-need&#34;&gt;🌈 🌈 🌈  Synthetic Data RL: Task Definition Is All You Need&lt;/h4&gt;&#xA;&lt;p&gt;2025-06-25 10:31:10 Wednesday ｜ Synthetic Data RL: Task Definition Is All You Need （可以参考一下其中的实验部分）https://mp.weixin.qq.com/s/rjNQdHUCZ4YmvRNVveMQ8w&lt;/p&gt;&#xA;&lt;p&gt;传统上，为了让这些模型适应特定领域，最直接的方法是使用大规模的人类标注数据进行微调。然而，这一过程不仅成本高昂、耗时漫长，而且在许多实际应用场景中并不可行。&lt;/p&gt;&#xA;&lt;p&gt;为了解决上述挑战，北京大学、MIT等机构的研究人员提出了「合成数据强化学习」（Synthetic Data RL）框架。这是一个简单而通用的框架，仅从一个任务定义出发，合成大量多样的领域特定样本，然后利用强化学习（RL）对模型进行微调。&lt;/p&gt;&#xA;&lt;p&gt;论文链接：https://arxiv.org/pdf/2505.17063&lt;/p&gt;&#xA;&lt;p&gt;代码仓库：https://github.com/gydpku/Data_Synthesis_RL&lt;/p&gt;&#xA;&lt;p&gt;这种方式实现了参数化的自适应，将领域知识直接嵌入到模型的参数中，并且完全无需任何人类标注的数据。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=MmRkMGJkYmJkODkwODI2ZmZhMjRlNjMzNjJhZWIyM2NfYUlCNWxUMGRSMkFhWWQxbFp3VVVPbXRTemZNcEFaWjhfVG9rZW46QndPeWIwN21Ub3hnbUR4aThTbGMzMDlrbmtkXzE3NTQ0NjI0MzY6MTc1NDQ2NjAzNl9WNA&#34; srcset=&#34;https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=MmRkMGJkYmJkODkwODI2ZmZhMjRlNjMzNjJhZWIyM2NfYUlCNWxUMGRSMkFhWWQxbFp3VVVPbXRTemZNcEFaWjhfVG9rZW46QndPeWIwN21Ub3hnbUR4aThTbGMzMDlrbmtkXzE3NTQ0NjI0MzY6MTc1NDQ2NjAzNl9WNA&amp;amp;size=small, https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=MmRkMGJkYmJkODkwODI2ZmZhMjRlNjMzNjJhZWIyM2NfYUlCNWxUMGRSMkFhWWQxbFp3VVVPbXRTemZNcEFaWjhfVG9rZW46QndPeWIwN21Ub3hnbUR4aThTbGMzMDlrbmtkXzE3NTQ0NjI0MzY6MTc1NDQ2NjAzNl9WNA&amp;amp;size=medium 1.5x, https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=MmRkMGJkYmJkODkwODI2ZmZhMjRlNjMzNjJhZWIyM2NfYUlCNWxUMGRSMkFhWWQxbFp3VVVPbXRTemZNcEFaWjhfVG9rZW46QndPeWIwN21Ub3hnbUR4aThTbGMzMDlrbmtkXzE3NTQ0NjI0MzY6MTc1NDQ2NjAzNl9WNA&amp;amp;size=large 2x&#34; sizes=&#34;auto&#34; data-title=&#34;https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=MmRkMGJkYmJkODkwODI2ZmZhMjRlNjMzNjJhZWIyM2NfYUlCNWxUMGRSMkFhWWQxbFp3VVVPbXRTemZNcEFaWjhfVG9rZW46QndPeWIwN21Ub3hnbUR4aThTbGMzMDlrbmtkXzE3NTQ0NjI0MzY6MTc1NDQ2NjAzNl9WNA&#34; data-alt=&#34;https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=MmRkMGJkYmJkODkwODI2ZmZhMjRlNjMzNjJhZWIyM2NfYUlCNWxUMGRSMkFhWWQxbFp3VVVPbXRTemZNcEFaWjhfVG9rZW46QndPeWIwN21Ub3hnbUR4aThTbGMzMDlrbmtkXzE3NTQ0NjI0MzY6MTc1NDQ2NjAzNl9WNA&#34; class=&#34;suffix-invalid suffix-invalid__small suffix-invalid__large&#34; style=&#34;background: url(/LLMDailyDigest.github.io/svg/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;data-alt&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;data-alt&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>新模型</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%96%B0%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%96%B0%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;h1 id=&#34;新模型&#34;&gt;新模型&lt;/h1&gt;&#xA;&lt;h2 id=&#34;2025-08-07&#34;&gt;2025-08-07&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/No7YJsxrIWaVbFZXGd0pbQ&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;端侧｜Qwen紧追OpenAI开源4B端侧大模型，AIME25得分超越Claude 4 Opus&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Qwen3-4B-Instruct-2507：非推理模型，大幅提升通用能力&lt;/li&gt;&#xA;&lt;li&gt;Qwen3-4B-Thinking-2507：高级推理模型，专为专家级任务设计，逻辑、数学、科学及代码中的高级推理能力——专为专家级任务设计。&lt;/li&gt;&#xA;&lt;li&gt;更智能、更精准，并且支持256k上下文，更具上下文感知能力。&lt;/li&gt;&#xA;&lt;li&gt;抱抱脸直通车：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;[1]https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&lt;/li&gt;&#xA;&lt;li&gt;[2]https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;魔搭社区直通车：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ttps://modelscope.cn/models/Qwen/Qwen3-4B-Instruct-2507&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://modelscope.cn/models/Qwen/Qwen3-4B-Thinking-2507&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://modelscope.cn/models/Qwen/Qwen3-4B-Thinking-2507&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;智能体｜Reflection AI已经发布了他们的首款AI智能体Asimov，较Claude Code Sonnet 4等模型，得到了用户更多偏好。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Asimov是一款专为代码理解打造的，它能对代码仓库、架构文档、GitHub讨论串、对话历史等多种信息进行索引，从而形成对代码库结构、历史及团队知识的全面认知。&lt;/li&gt;&#xA;&lt;li&gt;Asimov &lt;strong&gt;并非单一智能体&lt;/strong&gt; ，而是 &lt;strong&gt;由几个小型智能体协同工作&lt;/strong&gt; 。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;2025-08-06&#34;&gt;2025-08-06&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Claude Opus 4.1&lt;/strong&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/objwQLTeGWyrYnuy93aZFw&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Claude Opus 4.1火速发布！坐稳编程之王，官方：马上还有大更新&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;编程性能&lt;/strong&gt;再次突破天花板，超越Claude Opus 4，拿下SOTA。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;在SWE-bench上，Opus 4.1超越Opus 4、Gemini 2.5 Pro、o3，将性能提升至74.5%，拿下新SOTA。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Blog：&lt;/strong&gt;&lt;a href=&#34;https://www.anthropic.com/news/claude-opus-4-1&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.anthropic.com/news/claude-opus-4-1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;System Card：&lt;/strong&gt;&lt;a href=&#34;https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;谷歌DeepMind发布了****新一代通用世界模型Genie 3&lt;/strong&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/ulhJGiiq301f1yuPRTl36g&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;谷歌“世界模拟器”深夜上线！一句话生成3D世界，支持分钟级超长记忆&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Genie 3相比上一代大幅升级，支持****720P画质，每秒24帧实时导航，以及分钟级的一致性保持&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;最让谷歌引以为傲的，还要属Genie 3的****长期环境一致性&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DeepMind十多年来一直在关注模拟环境领域的研究，从训练智能体掌握实时战略游戏， 到开发用于开放式学习和机器人技术的模拟环境。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2652617195&amp;amp;idx=1&amp;amp;sn=91f7f14b4c811e2a1cd9bb5cf5652a11&amp;amp;scene=21#wechat_redirect&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;谷歌推出「G」字号第三代世界模型Genie 3，号称「宇宙模拟器」，视频生成更加符合物理定律。&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;OpenAI开源两个推理模型：gpt-oss-120b&lt;/strong&gt;和&lt;strong&gt;gpt-oss-20b&lt;/strong&gt;。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/bIaUXw9XWR2Sb4dy4i37_Q&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;刚刚，OpenAI开源2个推理模型：笔记本/手机就能跑，性能接近o4-mini&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;gpt-oss，即Open Source Series，意思就是“开源系列”。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;gpt-oss-120b&lt;/strong&gt;：1170亿参数（MoE架构，激活参数约51亿），可在单张80GB GPU上运行，性能接近闭源的o4-mini。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;gpt-oss-20b&lt;/strong&gt;：210亿参数（Moe架构，激活参数约36亿），可在16GB内存的消费级设备上运行，性能接近o3-mini。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;整体来看，这两个模型在工具使用、少样本函数调用、链式思考推理（如Tau-Bench智能评估套件的结果所示）以及HealthBench上表现强劲，甚至超越了包括OpenAI o1和GPT‑4o在内的专有模型。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;gpt-oss-120b每个token激活5.1B个参数，而gpt-oss-20b激活3.6B个参数。这些模型分别具有117b和21b的总参数。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;技术博客地址：&lt;/strong&gt;&lt;a href=&#34;https://openai.com/index/introducing-gpt-oss/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://openai.com/index/introducing-gpt-oss/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;HuggingFace地址：&lt;/strong&gt;&lt;a href=&#34;https://huggingface.co/openai/gpt-oss-120b&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://huggingface.co/openai/gpt-oss-120b&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;GtiHub地址：&lt;/strong&gt;&lt;a href=&#34;https://github.com/openai/gpt-oss&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/openai/gpt-oss&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;OpenAI-OSS-120B用起来要谨慎，写代码特别不稳定。OpenAI-OSS-20B在这个参数量大小下反而挺好。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/U2TsYntvP9Hdlg6e9oUpoQ&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;全网开测GPT-oss！技术架构也扒明白了&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;GPT-oss在架构设计上既保留了MoE Transformer的核心架构，又通过细节优化提升性能、降低复杂度，使其成为适合开源模型的基础架构。&lt;/p&gt;</description>
    </item>
    <item>
      <title>新趋势</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%96%B0%E8%B6%8B%E5%8A%BF/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%96%B0%E8%B6%8B%E5%8A%BF/</guid>
      <description>&lt;h1 id=&#34;新趋势&#34;&gt;新趋势&lt;/h1&gt;&#xA;&lt;h2 id=&#34;通用验证器&#34;&gt;通用验证器&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;OpenAI正在通过一种名为「Universal Verifier」的技术，让GPT-5在全领域实现稳步提升。翻译过来就是：通用验证器。这项技术的核心思想是：让一个AI 模型充当「验证者」，检查另一个模型的输出质量。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;去年下半年，代号为Orion的模型本应成为GPT-5，但其性能提升远低于预期，最终只能以GPT-4.5的身份发布。原因在于三大技术瓶颈同时出现：&lt;strong&gt;高质量训练数据枯竭、强化学习过程不稳定、模型扩展时的性能退化。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;这个系统的工作原理类似于生成对抗网络（GAN）：&lt;strong&gt;一个模型负责生成答案，另一个模型负责评判质量。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;OpenAI此前的论文「&lt;strong&gt;Prover-Verifier Games Improve Legibility of LLM Outputs&lt;/strong&gt;」详细展示了这种方法的威力。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当时的超级对齐研究团队设计了一个巧妙的游戏：「&lt;strong&gt;证明者&lt;/strong&gt;」模型被赋予两种角色：「helpful」（提供正确答案）和「sneaky」（故意制造错误）。「&lt;strong&gt;验证者&lt;/strong&gt;」模型则需要学会识别哪些答案是正确的。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4 id=&#34;compassverifier-llm评估和结果奖励的统一鲁棒验证器24&#34;&gt;&lt;a href=&#34;https://huggingface.co/papers/2508.03686?utm_source=digest-papers&amp;amp;utm_medium=email&amp;amp;utm_campaign=2025-08-06&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;CompassVerifier: llm评估和结果奖励的统一鲁棒验证器（24▲） &lt;/a&gt;&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;CompassVerifier 是一个轻量级、稳健的模型，用于跨多个领域验证 LLM 输出，支持该模型的是 VerifierBench，一个全面的基准数据集。&lt;/li&gt;&#xA;&lt;li&gt;答案验证不仅对于通过将大型语言模型（LLMs）的非结构化输出与标准答案进行匹配来评估其性能至关重要，同时也作为奖励模型指导 LLM 的优化。大多数评估框架依赖正则化匹配或使用通用 LLMs 进行答案验证，这需要对正则表达式规则或评估提示进行大量且重复的定制。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;目前方法存在两个根本性限制：1）缺乏系统评估不同 LLMs 验证能力的综合基准；2）验证器开发尚处于初期阶段，现有方法既缺乏处理复杂边缘案例的鲁棒性，也缺乏跨领域的泛化能力。&lt;/li&gt;&#xA;&lt;li&gt;在本工作中，我们开发了 CompassVerifier，一种准确且鲁棒的轻量级验证模型，用于评估和结果奖励。它展现了涵盖数学、知识及多样推理任务的多领域能力，能够处理多种答案类型，包括多子问题、公式和序列答案，同时有效识别异常/无效响应。&lt;/li&gt;&#xA;&lt;li&gt;我们介绍了 VerifierBench 基准测试，该测试包含从多个数据源收集的模型输出，并通过对元错误模式的人工分析进行增强，以提升 CompassVerifier 的性能。&lt;/li&gt;&#xA;&lt;li&gt;我们期望 CompassVerifier 和 VerifierBench 能够促进答案验证、评估协议和强化学习研究。代码和数据集可在 &lt;a href=&#34;https://github.com/open-compass/CompassVerifier&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/open-compass/CompassVerifier&lt;/a&gt; 获取。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;dllm-扩散语言模型&#34;&gt;dLLM 扩散语言模型&lt;/h2&gt;&#xA;&lt;p&gt;本综述系统梳理了离散扩散方向的研究图谱，呈现了离散扩散语言模型（dLLMs）与离散扩散多模态语言模型（dMLLMs）的理论基础、代表模型、训练与推理技术，以及在推理、视觉、生物等多个领域的应用进展。&lt;a href=&#34;https://mp.weixin.qq.com/s/hcIUmS-jUIVLOIfS7-1gtQ&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/hcIUmS-jUIVLOIfS7-1gtQ&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;diffusion--文本&#34;&gt;Diffusion + 文本&lt;/h3&gt;&#xA;&lt;p&gt;2025-06-28 18:43:50 Saturday 这个扩散LLM太快了！没有「请稍后」，实测倍速于Gemini 2.5 Flash&lt;/p&gt;&#xA;&lt;p&gt;Mercury 就是为此诞生的，其是首个基于扩散模型的 LLM。与自回归（AR）模型相比，Mercury 模型在性能和效率上都达到了最先进的水平。&lt;/p&gt;&#xA;&lt;p&gt;在性能表现上，根据第三方测评机构 Artificial Anlys 的基准测试数据显示，Mercury 可媲美 GPT-4.1 Nano 和 Claude 3.5 Haiku 等速度经过优化的前沿模型，同时运行速度提升超过 7 倍。 &lt;a href=&#34;https://mp.weixin.qq.com/s/dSEkdYHOQbaiRN3O4D-hKg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/dSEkdYHOQbaiRN3O4D-hKg&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>新闻</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%96%B0%E9%97%BB/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%96%B0%E9%97%BB/</guid>
      <description>&lt;h1 id=&#34;新闻&#34;&gt;新闻&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;2025-07-02 15:30:17 Wednesday ｜ 刚刚，Claude Code推出Hooks功能，让AI 编程从「看心情」到「真工程」&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/7t1sJlLnA_ardC2cK_EEfg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/7t1sJlLnA_ardC2cK_EEfg&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;这个基于Shell的钩子系统能在关键时刻自动运行，让你能够精确地编排每次编程会话中必须发生的事情。&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;2025-07-01 11:35:41 Tuesday ｜ 2025年AI现状报告 &lt;a href=&#34;https://mp.weixin.qq.com/s/XKHqP-dDIaK0ny8iIJK9aA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/XKHqP-dDIaK0ny8iIJK9aA&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;报告链接：https://cdn.prod.website-files.com/65d0d38fc4ec8ce8a8921654/685ac42fd2ed80e09b44e889_ICONIQ%20Analytics_Insights_The_AI_Builders_Playbook_2025.pdf&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;2025-07-01 11:30:31 Tuesday ｜ 7万个模型、1600万开发者，魔搭已建成中国最大AI开源社区 &lt;a href=&#34;https://mp.weixin.qq.com/s/nAa4WcjcQz93neQHuMvo6w&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/nAa4WcjcQz93neQHuMvo6w&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;2025-07-01 11:25:06 Tuesday｜真·全民AI健康管家来了！实测蚂蚁AQ：追问识药看皮肤，还能连医院接硬件  &lt;a href=&#34;https://mp.weixin.qq.com/s/FufBkoQv5Csk9FiG3-GaTQ&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/FufBkoQv5Csk9FiG3-GaTQ&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;2025-06-26 12:07:09 Thursday ｜ 华为开发者大会 2025（HDC 2025）上发布了 CloudRobo 具身智能平台https://mp.weixin.qq.com/s/rtBnAnEvsJr0TIOQzzm30w&lt;/li&gt;&#xA;&lt;li&gt;20250605｜openai上线会议记录 + MCP连接器（Model Context Protocol，把GitHub、Google Drive、Dropbox、SharePoint……这些原本互不搭界的知识源头，全都通过MCP接入 ChatGPT）&lt;/li&gt;&#xA;&lt;li&gt;2025-06-10 10:13:38 Tuesday ｜ 苹果展示了把人工智能融入其所有产品的计划，提供从通话实时翻译到 AI 识物、智能搜索等一系列能力。https://mp.weixin.qq.com/s/E5O6BuHny7vVY2hP0y3IIg&lt;/li&gt;&#xA;&lt;li&gt;2025-06-12 10:53:21 Thursday | meta发布世界模型intphys2 &lt;a href=&#34;https://mp.weixin.qq.com/s/i2lMeFX6VWWxqL_ZKmznfw&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/i2lMeFX6VWWxqL_ZKmznfw&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;2025-06-12 10:53:25 Thursday | 欧洲人工智能公司 Mistral AI 发布了 Magistral，这是一个全新的大语言模型（LLM）系列，展现了强大的推理能力。它能够进行不断反思，并解决更复杂的任务。https://mp.weixin.qq.com/s/Go5dXv4DA3hy5lGhxxE8SA&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;观点&#34;&gt;观点&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/VeuaDE9onAlWZ430SRiybw&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Token成本下降，订阅费却飞涨，AI公司怎么了？&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;LLM 成本每年会下降 10 倍。AI 能完成的任务长度，每 6 个月翻一倍。&lt;/li&gt;&#xA;&lt;li&gt;用户只对「最强语言模型」有需求，仅此而已。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;研讨&#34;&gt;研讨&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;2025-07-01 12:14:04 Tuesday｜&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://papers.cool/arxiv/2506.22698&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;人类和人工智能的文本生成和理解：跨学科研讨会报告&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;[PDF(1)]&lt;/strong&gt; &lt;strong&gt;[Copy]&lt;/strong&gt; &lt;strong&gt;[Kimi()]&lt;/strong&gt; &lt;strong&gt;[REL]&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>智能体</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%99%BA%E8%83%BD%E4%BD%93/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E6%99%BA%E8%83%BD%E4%BD%93/</guid>
      <description>&lt;h1 id=&#34;智能体&#34;&gt;智能体&lt;/h1&gt;&#xA;&lt;h2 id=&#34;洞察&#34;&gt;洞察&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;智能体&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;自主决策、执行、洞察、反哺&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;具备任务自主化能力，能够主动拆解目标、智能调度资源，并在交互过程中持续优化策略，展现出强大的动态进化能力。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;区别推理和规划能力&lt;/li&gt;&#xA;&lt;li&gt;递归自我改进（RSI）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://deepshare.feishu.cn/wiki/Cu5Bw0k4WijJu9keRsIceDOZnpe?from=from_copylink&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;2025年agent前沿研究&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;2025-07-18 14:05:54 Friday ｜ 模仿学习新范式，Chain-of-Action：轨迹自回归实现动作推理 &lt;a href=&#34;https://mp.weixin.qq.com/s/fJXWvpC1s_2FkoUYhnmTCg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/fJXWvpC1s_2FkoUYhnmTCg&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;2025-07-17 10:59:05 Thursday ｜ 昆仑万维Skywork发布分层多智能体协作框架AgentOrchestra&lt;/p&gt;&#xA;&lt;p&gt;20250604｜开启 AI 自主进化时代，普林斯顿Alita颠覆传统通用智能体，GAIA榜单迎来终章&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/vmp8H-3S_HH6Gvb4dH5FxA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://mp.weixin.qq.com/s/vmp8H-3S_HH6Gvb4dH5FxA&lt;/a&gt;&#xA;论文标题：ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF-EVOLUTION&lt;/p&gt;&#xA;&lt;p&gt;论文链接：https://arxiv.org/abs/2505.20286&lt;/p&gt;&#xA;&lt;p&gt;Twitter：https://x.com/JiahaoQiu99/status/1927376487285432790&lt;/p&gt;&#xA;&lt;p&gt;GitHub：https://github.com/CharlesQ9/Alita&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;核心：普林斯顿大学 AI Lab 推出了 Alita——一个秉持「&lt;strong&gt;极简即是极致复杂&lt;/strong&gt;」哲学的通用智能体，通过「&lt;strong&gt;最小化预定义&lt;/strong&gt;」与「&lt;strong&gt;最大化自我进化&lt;/strong&gt;」的设计范式，让智能体可以自主思考、搜索和创造其所需要的 MCP 工具。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;现有的主流智能体系统通常依赖大量人工预定义的工具和复杂的工作流，这种方法有三个关键缺陷：覆盖范围有限、创造力受限、适配失配，这些挑战共同限制了现有通用智能体的创造力、可扩展性和泛化能力。&lt;/li&gt;&#xA;&lt;li&gt;与当前日益复杂的趋势相反，Alita 团队认为对于通用智能体而言，「simplicity is the ultimate sophistication」——简单即极致的复杂。遵循这一原则，Alita 实现了可扩展的动态能力、增强的创造力与灵活性，以及跨生态系统的兼容性。Alita 团队由此提出了两大设计范式：&lt;/li&gt;&#xA;&lt;li&gt;**最小化预定义：**仅为智能体配备最核心的基础能力，避免为特定任务或模态设计人工预定义的组件。&lt;/li&gt;&#xA;&lt;li&gt;**最大化自进化：**赋予智能体按需自主创建、优化和复用 MCP 工具的能力，实现自我进化。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;2025-06-09 10:50:14 Monday ｜TextAtari: 100K Frames Game Playing with Language Agents&#xA;&lt;strong&gt;标题&lt;/strong&gt; ： 文本Atari：使用语言代理玩10万帧游戏&#xA;&lt;strong&gt;链接&lt;/strong&gt; ：https://arxiv.org/abs/2506.04098&#xA;&lt;strong&gt;摘要&lt;/strong&gt; ：我们提出了TextAtari，这是一个 &lt;strong&gt;用于评估语言代理在长达10万步的长期决策任务上的基准&lt;/strong&gt; 。通过将经典Atari游戏的视觉状态表示转换为丰富的文本描述，TextAtari创建了一个具有挑战性的测试平台，将顺序决策与自然语言处理联系起来。该基准测试包括近100个不同的任务，具有不同的复杂性，动作空间和规划视野，所有这些任务都通过无监督表示学习框架（AtariARI）呈现为文本。我们评估了三个开源的大型语言模型（Qwen2.5- 7 B，Gemma-7 B和Llama3.1-8B）在三个代理框架（zero-shot，Few-Shot chain-of-thought和reflection reasoning），以评估不同形式的先验知识如何影响这些长期挑战的性能。四个基本的，模糊的，手动增强，并参考为基础的语义理解，指令理解和专家示范代理决策的影响。我们的研究结果揭示了语言智能体和人类玩家在广泛的规划任务中的显着性能差距，突出了顺序推理，状态跟踪和数万个步骤的战略规划方面的挑战。TextAtari提供了标准化的评估协议、基线实现和框架，用于推进语言模型和规划交叉点的研究。&lt;/p&gt;</description>
    </item>
    <item>
      <title>研究方向</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/</guid>
      <description>&lt;h1 id=&#34;研究方向&#34;&gt;研究方向&lt;/h1&gt;&#xA;&lt;h2 id=&#34;持续学习&#34;&gt;持续学习&lt;/h2&gt;&#xA;&lt;h4 id=&#34;gere面向-llm-持续学习中通过通用样本重放实现高效抗遗忘的探索&#34;&gt;&lt;a href=&#34;https://papers.cool/arxiv/2508.04676&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;GeRe：面向 LLM 持续学习中通过通用样本重放实现高效抗遗忘的探索&lt;/a&gt;&lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://papers.cool/arxiv/2508.04676&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay &lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;**大型语言模型（LLMs）的持续学习能力对于推动通用人工智能的发展至关重要。然而，在不同领域对 LLMs 进行持续微调时，常常会遭遇灾难性遗忘，表现为：1）其通用能力显著下降，2）先前学习任务的性能急剧下降。为了以简单且稳定的方式同时解决这两个问题，我们提出了通用样本重放（General Sample Replay，GeRe）框架，该框架利用常规预训练文本实现高效的抗遗忘。除了在 GeRe 框架下回顾最常见的基于重放的实践外，我们进一步利用神经状态，引入了一种基于阈值边际（TM）损失的增强激活状态约束优化方法，以在重放学习过程中保持激活状态的一致性。我们首次验证了，一小组固定的预先收集的通用重放样本足以解决这两个问题——既保留通用能力，又促进顺序任务的整体性能。事实上，前者本质上可以促进后者。 通过受控实验，我们在 GeRe 框架下系统地比较了 TM 与不同的重放策略，包括普通的标签拟合、通过 KL 散度进行的 logit 模仿以及通过 L1/L2 损失进行的特征模仿。结果表明，TM 始终提升了性能并表现出更好的鲁棒性。我们的工作为未来高效重放 LLMs 铺平了道路。我们的代码和数据可在 **&lt;a href=&#34;https://github.com/Qznan/GeRe&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Qznan/GeRe&lt;/a&gt; 获取。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Subjects&lt;/strong&gt;: &lt;a href=&#34;https://papers.cool/arxiv/cs.CL&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Computation and Language&lt;/a&gt;, &lt;a href=&#34;https://papers.cool/arxiv/cs.AI&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Artificial Intelligence&lt;/a&gt;, &lt;a href=&#34;https://papers.cool/arxiv/cs.LG&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Machine Learning&lt;/a&gt;&#xA;&lt;strong&gt;主题：计算与语言，人工智能，机器学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Publish&lt;/strong&gt;: 2025-08-06 17:42:22 UTC**&#xA;**发布：2025-08-06 17:42:22 UTC&lt;/p&gt;</description>
    </item>
    <item>
      <title>自我进化 Self-Evolve</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%87%AA%E6%88%91%E8%BF%9B%E5%8C%96/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%87%AA%E6%88%91%E8%BF%9B%E5%8C%96/</guid>
      <description>&lt;h1 id=&#34;self-evolve&#34;&gt;Self-Evolve&lt;/h1&gt;&#xA;&lt;h2 id=&#34;2025-08-07&#34;&gt;2025-08-07&lt;/h2&gt;&#xA;&lt;h4 id=&#34;seagent具备自主经验学习的自我进化计算机使用代理&#34;&gt;SEAgent：具备自主经验学习的自我进化计算机使用代理&lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2508.04700&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;#68&lt;/a&gt;&lt;a href=&#34;https://papers.cool/arxiv/2508.04700&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience&lt;/a&gt;  #68&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;将大型视觉语言模型（LVLMs）重新用作计算机使用代理（CUAs）已带来重大突破，这主要依赖于人工标注数据。然而，这些模型在处理新颖和专业的软件时常常表现不佳，尤其是在缺乏人工注释的场景中。为了解决这一挑战，我们提出了 SEAgent，一种代理自我进化框架，使 CUAs 能够通过与陌生软件的交互自主进化。具体而言，SEAgent 使计算机使用代理能够通过体验式学习自主掌握新软件环境，代理通过探索新软件、反复试错学习，并逐步完成从简单到复杂自动生成的任务。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;为实现这一目标，我们设计了一个用于逐步轨迹评估的世界状态模型，以及一个生成日益多样且具有挑战性任务的课程生成器。代理的策略通过体验式学习进行更新，包括对失败动作的对抗模仿和对成功动作的群体相对策略优化（GRPO）。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;此外，我们引入了一种专家到通才的训练策略，该策略整合了专家代理的个体经验见解，促进了更强大的通才 CUA 的开发，使其能够持续自主进化。该统一代理最终在其专门的软件上实现了超越单个专家代理集成的性能。&lt;/li&gt;&#xA;&lt;li&gt;我们在 OS-World 中的五个新颖软件环境中验证了 SEAgent 的有效性。我们的方法在成功率上相较于一个具有竞争力的开源 CUA（即 UI-TARS）实现了显著提升，成功率从 11.3%提升至 34.5%，提高了 23.2%。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;发布时间：2025-08-06 17:58:46 UTC&lt;/p&gt;&#xA;&lt;h4 id=&#34;sea带有逐步奖励的自我进化代理用于计算机使用&#34;&gt;SEA：带有逐步奖励的自我进化代理用于计算机使用&lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2508.04037&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;#24&lt;/a&gt;&lt;a href=&#34;https://papers.cool/arxiv/2508.04037&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;SEA: Self-Evolution Agent with Step-wise Reward for Computer Use&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;计算机使用代理是人工智能中的一个新兴领域，旨在操作计算机以完成用户任务，吸引了工业界和学术界的广泛关注。然而，目前的代理性能距离实际应用仍有较大差距。本文提出了用于计算机使用的自我进化代理（Self-Evolution Agent，SEA），并在数据生成、强化学习和模型增强方面提出了创新方法。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;具体来说，我们首先提出了一个自动化流程来生成可验证的训练轨迹。&lt;/li&gt;&#xA;&lt;li&gt;随后，提出了高效的逐步强化学习方法，以缓解长时间训练所需的巨大计算资源。&lt;/li&gt;&#xA;&lt;li&gt;最后，提出了一种增强方法，将基础能力和规划能力合并到一个模型中，无需额外训练。&lt;/li&gt;&#xA;&lt;li&gt;基于我们提出的数据生成、训练策略和增强创新，获得了仅有 7B 参数的自我进化代理（SEA），其性能优于同参数规模的模型，并且与更大规模模型的性能相当。 我们将在未来开源模型权重和相关代码。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;发布时间：2025-08-06 02:57:22 UTC&lt;/p&gt;</description>
    </item>
    <item>
      <title>规划</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%A7%84%E5%88%92/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%A7%84%E5%88%92/</guid>
      <description>&lt;h1 id=&#34;规划&#34;&gt;规划&lt;/h1&gt;&#xA;&lt;h2 id=&#34;训练&#34;&gt;训练&lt;/h2&gt;&#xA;&lt;h3 id=&#34;o1&#34;&gt;o1&lt;/h3&gt;&#xA;&lt;h4 id=&#34;神经-符号融合规划器&#34;&gt;&lt;strong&gt;“神经-符号”融合规划器&lt;/strong&gt;&lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/IpG_Y0Lu767pLWdzTmtLXA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;“神经-符号”融合规划器性能显著超越o1：借鉴人类运动学习机制｜中国科学院磐石研发团队&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;论文链接：https://www.sciencedirect.com/science/article/abs/pii/S095070512501086X?via%3Dihub&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;混合规划器，同时融合了神经规划系统和符号规划系统的优势。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;借鉴人类的闭环反馈机制，构建 &lt;strong&gt;双向规划机制&lt;/strong&gt; ，在表达能力、适应能力、泛化能力以及可解释性上都实现了显著提升。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;基于 &lt;strong&gt;Knowledge of Result&lt;/strong&gt;  &lt;em&gt;（KR）&lt;/em&gt; 的闭环系统是人类运动学习的关键部分，可以帮助学习者纠正错误，向着目标方向实现有效学习。&lt;/li&gt;&#xA;&lt;li&gt;在运动学习中KR是执行运动后的增强信息，表明既定目标是否成功，而闭环系统是以反馈、错误检测和错误纠正为核心的过程。规划任务中的问题、规划器和动作序列可近似对应于人类运动学习中的试验、学习者和行动序列，规划任务与运动学习有较强的相似性。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;“神经-符号”融合规划器&lt;/strong&gt;通过借鉴人类运动学习中的反馈闭环理念，构建了一种闭环反馈的双向规划机制—— &lt;strong&gt;KRCL&lt;/strong&gt;  &lt;em&gt;(Knowledge-of-Results based Closed-Loop)&lt;/em&gt; ，正向神经规划器生成问题的动作序列与反向KR反馈机制构成动态的错误检测-纠正闭环。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;还能只在正向规划器需要时，自动激活反馈接收，在规划覆盖率和规划效率上均显著优于 &lt;strong&gt;OpenAI o1&lt;/strong&gt; 。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;评测&#34;&gt;评测&lt;/h2&gt;&#xA;&lt;h4 id=&#34;planbench-用于评估大语言模型规划性能的基准数据集&#34;&gt;&lt;strong&gt;PlanBench&lt;/strong&gt; &lt;em&gt;（用于评估大语言模型规划性能的基准数据集）&lt;/em&gt;&lt;/h4&gt;&#xA;&lt;h4 id=&#34;看似简单的规划问题实际上计算复杂倒计时游戏&#34;&gt;看似简单的规划问题实际上计算复杂：倒计时游戏&lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2508.02900&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;#46&lt;/a&gt;&lt;a href=&#34;https://papers.cool/arxiv/2508.02900&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;普遍认为，当前基础模型和智能体无法制定长期计划是其主要局限之一。然而，现有的规划基准测试远远不足以真正衡量它们的规划能力。大多数现有基准测试要么侧重于像旅行规划这样定义模糊的任务，要么最终利用国际规划竞赛中的现有领域和问题。前者任务难以形式化和验证，后者则专门设计用来测试和挑战现有自动规划器的弱点。为了解决这些不足，我们提出了一种创建以名为 Countdown 的游戏为核心的规划基准测试的方法，该游戏要求玩家通过算术运算从一组输入数字中形成目标数字。我们讨论了该问题如何满足与理想规划能力评估基准相关的多项期望条件。 具体来说，该领域允许对每个问题实例进行直观的自然语言描述，计算上具有挑战性（NP 完全），且实例空间足够丰富，因此我们无需担心记忆问题。我们进行了广泛的理论分析，确立了计算复杂性结果，并展示了我们的实例生成程序相较于公共基准的优势。我们评估了多种现有的 LLM 辅助规划方法在使用我们程序生成的实例上的表现。结果表明，与 24 点游戏（Countdown 的一个特例）等其他领域不同，我们提出的动态基准对现有基于 LLM 的方法仍然极具挑战性。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;发布：2025-08-04 21:01:03 UTC&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>训练</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%AE%AD%E7%BB%83/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E8%AE%AD%E7%BB%83/</guid>
      <description>&lt;h1 id=&#34;训练&#34;&gt;训练&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;2025-06-13 18:50:11 Friday ｜&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Magistral&#xA;&lt;strong&gt;标题&lt;/strong&gt; ： Magistral&#xA;&lt;strong&gt;链接&lt;/strong&gt; ：https://arxiv.org/abs/2506.10910&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;作者&lt;/strong&gt; ： Mistral-AI:  Abhinav Rastogi,  Albert Q. Jiang,  Andy Lo,  Gabrielle Berrada,  Guillaume Lample,  Jason Rute,  Joep Barmentlo,  Karmesh Yadav,  Kartik Khandelwal,  Khyathi Raghavi Chandu,  Léonard Blier,  Lucile Saulnier,  Matthieu Dinot,  Maxime Darrin,  Neha Gupta,  Roman Soletskyi,  Sagar Vaze,  Teven Le Scao,  Yihan Wang,  Adam Yang,  Alexander H. Liu,  Alexandre Sablayrolles,  Amélie Héliou,  Amélie Martin,  Andy Ehrenberg,  Anmol Agarwal,  Antoine Roux,  Arthur Darcet,  Arthur Mensch,  Baptiste Bout,  Baptiste Rozière,  Baudouin De Monicault,  Chris Bamford,  Christian Wallenwein,  Christophe Renaudin,  Clémence Lanfranchi,  Darius Dabert,  Devon Mizelle,  Diego de las Casas,  Elliot Chane-Sane,  Emilien Fugier,  Emma Bou Hanna,  Gauthier Delerce,  Gauthier Guinet,  Georgii Novikov,  Guillaume Martin,  et al. (53 additional authors not shown)&#xA;&lt;strong&gt;摘要&lt;/strong&gt; ：我们介绍了Magistral，Mistral的第一个推理模型和我们自己的可扩展强化学习（RL）管道。我们不依赖于现有的实现和从先前模型中提取的RL跟踪，而是遵循一种自上而下的方法，完全依赖于我们自己的模型和基础设施。值得注意的是，我们展示了一个堆栈，使我们能够探索LLM的纯RL训练的限制，提出了一种简单的方法来强制模型的推理语言，并表明仅对文本数据的RL保持了大部分初始检查点的功能。我们发现，RL的文本保持或提高多模态理解，指令遵循和函数调用。我们提出了Magistral Medium，在Mistral Medium 3的基础上单独使用RL进行推理训练，我们开源了Magistral Small（Apache 2.0），其中进一步包括来自Magistral Medium的冷启动数据。&lt;/p&gt;</description>
    </item>
    <item>
      <title>逻辑推理</title>
      <link>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E9%80%BB%E8%BE%91%E6%8E%A8%E7%90%86/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://dujh22.github.io/LLMDailyDigest.github.io/topic/%E9%80%BB%E8%BE%91%E6%8E%A8%E7%90%86/</guid>
      <description>&lt;h1 id=&#34;逻辑推理&#34;&gt;逻辑推理&lt;/h1&gt;&#xA;&lt;p&gt;未来的评估体系将具有高度可扩展的发展路径。&lt;/p&gt;&#xA;&lt;p&gt;挑战：如何优化统一框架设计、提高训练效率和应对大规模数据等挑战。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;老数据也可以有新用途。&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;为此，我正在打造一个可扩展的&lt;strong&gt;通用数据引擎。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;强调自主决策&lt;/p&gt;&#xA;&lt;p&gt;关注正确率到关注效率、安全与社会价值。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;计算机科学中的逻辑：https://arxiv.org/list/cs.LO/recent&lt;/p&gt;&#xA;&lt;p&gt;计算机科学与博弈论：https://arxiv.org/list/cs.GT/recent&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;250614｜苹果《思考的错觉》再挨批，Claude与人类共著论文指出其三大关键缺陷&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;2025-06-16 12:33:50 Monday ｜更强大的语言模型会产生更多类似人类的错误&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;20250604｜Probing the Geometry of Truth: Consistency and Generalization of Truth Directions in LLMs Across Logical Transformations and Question Answering Tasks&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;标题： 探索真理的几何学：跨逻辑转换和问题解答任务的LLM中真值方向的一致性和概括性&lt;/li&gt;&#xA;&lt;li&gt;链接：&lt;a href=&#34;https://arxiv.org/abs/2506.00823&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://arxiv.org/abs/2506.00823&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;2025-06-10 10:55:11 Tuesday ｜ PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in  Puzzlehunts&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;标题&lt;/strong&gt; ： PuzzleWorld：益智游戏中多模式、开放式推理的基准&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;链接&lt;/strong&gt; ：https://arxiv.org/abs/2506.06211&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;摘要&lt;/strong&gt; ：Puzzlehunts是一种复杂的，多步骤的谜题，缺乏明确的问题定义。与由具有明确指令的任务组成的传统推理基准相比，puzzlehunts需要模型从多模态证据和迭代推理中发现潜在的问题结构，反映现实世界的领域，如科学发现，探索性数据分析或调查性问题解决。尽管基金会模型最近取得了进展，但它们在这种开放式环境中的表现在很大程度上仍未得到检验。在本文中，我们介绍了PuzzleWorld，一个大规模的基准&lt;strong&gt;667拼图狩猎式&lt;/strong&gt;的问题，旨在评估一步一步的，开放式的，创造性的多模态推理。每个谜题都标注了最终解决方案、详细的推理轨迹和认知技能标签，从而实现整体基准测试和细粒度诊断分析。大多数最先进的模型只能达到1-2%的最终答案准确率，最好的模型只能解决14%的难题，逐步准确率达到40%。为了证明我们的推理注释的价值，我们表明，对推理轨迹进行微调可以将逐步推理从4%提高到11%，而仅对最终答案进行训练则会将性能降低到接近零。我们的错误分析表明，目前的模型表现出近视推理，基于语言的推理的局限性，缺乏草图的视觉和空间推理的关键能力。我们在https://github.com/MIT-MI/PuzzleWorld上发布PuzzleWorld，以支持未来构建更通用，开放和创造性推理系统的工作。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;2025-06-11 11:19:47 Wednesday ｜Evaluating Large Language Models on the Frame and Symbol Grounding  Problems: A Zero-shot Benchmark&#xA;&lt;strong&gt;标题&lt;/strong&gt; ： 基于框架和符号基础问题的大型语言模型评估：Zero-Shot基准&#xA;&lt;strong&gt;链接&lt;/strong&gt; ：https://arxiv.org/abs/2506.07896&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
